[{"categories":["默认分类","java"],"content":"使用PDFWatermarkRemover去除PDF水印的教程 引言 在处理PDF文档的过程中，我们经常遇到需要移除水印的情况。无论是为了提升文档的可读性，还是为了满足特定的业务需求，去除水印都是一个常见的任务。然而，现有的解决方案往往存在收费昂贵或上手难度高的问题。例如，某些软件要求用户具备一定的技术背景，并且需要指定水印的操作码才能进行有效的删除15。鉴于此，我开发了一个名为PDFWatermarkRemover的Java项目，旨在提供一个免费、易于使用的工具来解决这些问题。\n项目概述 开发理由 免费与成本效益 市场上许多专业的PDF编辑软件虽然功能强大，但大多需要付费购买才能解锁全部功能，特别是对于去水印这样的高级功能。这对于个人用户或者预算有限的小型企业来说可能是一个不小的负担。相比之下，PDFWatermarkRemover完全免费，为用户提供了一个经济实惠的选择。\n简化操作流程 一些现有的工具虽然能够实现去除水印的功能，但它们通常需要用户具有较高的技术水平，比如理解并输入特定的操作码来定位和删除水印。这不仅增加了使用门槛，也使得普通用户难以快速掌握。PDFWatermarkRemover通过简化命令行接口，让用户只需输入几个简单的参数即可完成水印的去除工作，极大地降低了学习成本和技术障碍。\n基本信息 项目名称：PDFWatermarkRemover 语言：Java 功能：去除PDF文件中的水印 使用说明\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Usage: PDFWatermarkRemover [options] Options: * -f, -file-path 需要处理的pdf文件路径 help, -help, -h 查看帮助信息 -p, -key-page 关键页，通常选择pdf中包含水印的任意一页的页码，这个页码不是页面上显示逻辑页码，而是浏览器打开后顶部显示的当前页码。未指定时，使用默认值1 Default: 1 -t, -key-token 使用者在第一步操作后生成的pdf中确认水印消失的那一页的页码，这里的“页码”含义同key-page的含义一样。 version, -version, -v 显示当前版本号 Default: false 操作步骤 第一步 首先，你需要提供PDF文件的路径以及关键页（通常是PDF中包含水印的任意一页）。例如：\n1 java -jar PDFWatermarkRemover.jar -f /path/to/file.pdf -p 1 执行上述命令后，在原文件的同级目录下会生成一个新文件，如/path/to/file_output_001.pdf。此时，请检查该文件以确定水印是否已从特定页码处消失。假设你发现水印消失的页码是10。\n第二步 接下来，再次运行程序，并提供之前找到的水印消失的页码作为参数。例如：\n1 java -jar PDFWatermarkRemover.jar -f /path/to/file.pdf -p 1 -t 10 成功执行后，原文件同级目录下将生成一个新的PDF文件，如/path/to/file_new.pdf，其中的水印已经被移除。\n实现原理 该项目利用了Apache PDFBox库来解析和修改PDF文件内容。具体来说，它通过分析PDF文件结构，根据用户输入的页码，定位指定页，然后遍历所有的操作符，逐个替换操作符为空白操作符。由用户根据生成的xxx_output_001.pdf文件确定操作符的序列号，然后判断原文件每一页，只要存在与序列号所在位置的操作符一致的操作符，就替换为空白操作符，进而达到去除水印的能力。\n结语 通过PDFWatermarkRemover项目，我们可以更加便捷地处理带有水印的PDF文件。无论是出于美化文档的目的，还是为了更清晰地展示信息，这一工具都能提供有力的支持。希望这篇博客能够帮助大家更好地理解和使用该工具。\n如果您有任何疑问或者建议，请随时留言交流！\n","description":"\n","tags":["pdf","水印"],"title":"\n去除PDF水印","uri":"/posts/post-406/"},{"categories":["默认分类"],"content":"概要说明 设计一个简单的排卷系统，用于将题库中绿如的试题抽取出来，按照指定版式排布，然后到处pdf,用于打印。试卷排布后，可以保存排卷结果，方便后续复用\n","description":"\n","tags":["小学数学","排卷"],"title":"\n数学排卷","uri":"/posts/post-405/"},{"categories":["架构设计"],"content":"MDC 介绍 MDC（Mapped Diagnostic Context，映射调试上下文）是 log4j 、logback及log4j2 提供的一种方便在多线程条件下记录日志的功能。MDC 可以看成是一个与当前线程绑定的哈希表，可以往其中添加键值对。MDC 中包含的内容可以被同一线程中执行的代码所访问。当前线程的子线程会继承其父线程中的 MDC 的内容。当需要记录日志时，只需要从 MDC 中获取所需的信息即可。MDC 的内容则由程序在适当的时候保存进去。对于一个 Web 应用来说，通常是在请求被处理的最开始保存这些数据。\nAPI 说明 clear() =\u003e 移除所有 MDC get (String key) =\u003e 获取当前线程 MDC 中指定 key 的值 getContext() =\u003e 获取当前线程 MDC 的 MDC put(String key, Object o) =\u003e 往当前线程的 MDC 中存入指定的键值对 remove(String key) =\u003e 删除当前线程 MDC 中指定的键值对 MDC 使用 Constants.TRACE_ID = “traceId”\n添加拦截器 public class LogInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { //如果有上层调用就用上层的ID String traceId = request.getHeader(Constants.TRACE_ID); if (traceId == null) { traceId = TraceIdUtil.getTraceId(); } MDC.put(Constants.TRACE_ID, traceId); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception { } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception { //调用结束后删除 MDC.remove(Constants.TRACE_ID); } } 修改日志格式 \u003c!-- 日志输出格式 --\u003e \u003cproperty name=\"log.pattern\" value=\"[TraceId:%X{traceId}] %d{HH🇲🇲ss.SSS} [%thread] %-5level %logger{20} - [%method,%line] - %msg%n\"/\u003e 重点是 %X{traceId}，traceId 和 MDC 中的键名称一致。\n简单使用就这么容易，但是在有些情况下 traceId 将获取不到。\n常见问题 子线程日志打印丢失 traceId //获取traceId Map\u003cString, String\u003e mdcContextMap = MDC.getCopyOfContextMap(); return () -\u003e{ //添加到子线程中 MDC.setContextMap(mdcContextMap); System.out.println(\"你好呀！\"); } ","description":"\n","tags":[],"title":"\nSpringBoot + MDC 实现全链路调用日志跟踪","uri":"/posts/post-219/"},{"categories":["默认分类"],"content":" 实体类定义属性book_id为Long类型，但在调用 spring-data-elasticsearch:2.5.14.RELEASE中的createMapping()方法时却被转换成了keyword`类型\n查看createMapping方法，源码可以发现最终调用最下边的重载方法\nIndexOperations.createMapping(); AbstractDefaultIndexOperations.createMapping(); AbstractDefaultIndexOperations.createMapping(Class\u003c?\u003e clazz); AbstractDefaultIndexOperations.buildMapping(Class\u003c?\u003e clazz) //构建属性映射 MappingBuilder.buildPropertyMapping(Class\u003c?\u003e clazz) // 具体的properties解析，为根对象非nested对象 MappingBuilder.mapEntity(XContentBuilder builder, @Nullable ElasticsearchPersistentEntity\u003c?\u003e entity, boolean isRootObject, String nestedObjectFieldName, boolean nestedOrObjectField, FieldType fieldType, @Nullable Field parentFieldAnnotation, @Nullable DynamicMapping dynamicMapping); MappingBuilder.buildPropertyMapping(XContentBuilder builder, boolean isRootObject, ElasticsearchPersistentProperty property) //判断是否是带有@Id注解或者是字段名是否是 id或者document ，如果满足条件这是主键字段 ElasticsearchPersistentProperty.isIdProperty() //如果是主键字段则类型设置为keyword MappingBuilder.applyDefaultIdFieldMapping(XContentBuilder builder, ElasticsearchPersistentProperty property) ","description":"\n","tags":[],"title":"\n使用spring-boot-starter-data-elasticsearch 设置了long，为什么却变成了keyword类型","uri":"/posts/post-221/"},{"categories":["默认分类"],"content":"修改加密和验证方法 /** * 生成BCryptPasswordEncoder密码 * * @param password 密码 * @param salt 盐值 * @return 加密字符串 */ public static String encryptPassword(String password,String salt) { BCryptPasswordEncoder passwordEncoder = new BCryptPasswordEncoder(); return passwordEncoder.encode(password + salt); } /** * 判断密码是否相同 * * @param rawPassword 真实密码 * @param encodedPassword 加密后字符 * @param salt 盐值 * @return 结果 */ public static boolean matchesPassword(String rawPassword, String encodedPassword,String salt) { BCryptPasswordEncoder passwordEncoder = new BCryptPasswordEncoder(); return passwordEncoder.matches(rawPassword + salt, encodedPassword); } 自定义 DaoAuthenticationProvider import com.maruifu.common.core.domain.model.LoginUser; import com.maruifu.common.utils.DateUtils; import com.maruifu.common.utils.SecurityUtils; import org.springframework.security.authentication.BadCredentialsException; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.authentication.dao.DaoAuthenticationProvider; import org.springframework.security.core.AuthenticationException; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.Authentication; /** * 身份验证提供者 * @author maruifu */ public class JwtAuthenticationProvider extends DaoAuthenticationProvider { @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException { // 可以在此处覆写整个登录认证逻辑 return super.authenticate(authentication); } /** * 重写加盐后验证逻辑 * @param userDetails * @param authentication * @throws AuthenticationException */ @Override protected void additionalAuthenticationChecks(UserDetails userDetails, UsernamePasswordAuthenticationToken authentication) throws AuthenticationException { if (authentication.getCredentials() == null) { this.logger.debug(\"Failed to authenticate since no credentials provided\"); throw new BadCredentialsException(this.messages.getMessage(\"AbstractUserDetailsAuthenticationProvider.badCredentials\", \"Bad credentials\")); } else { String presentedPassword = authentication.getCredentials().toString(); LoginUser loginUser = (LoginUser)userDetails ; if (!SecurityUtils.matchesPassword(presentedPassword, userDetails.getPassword(), DateUtils.parseDateToStr(DateUtils.YYYY_MM_DD_HH_MM_SS,loginUser.getUser().getCreateTime()))) { this.logger.debug(\"Failed to authenticate since password does not match stored value\"); throw new BadCredentialsException(this.messages.getMessage(\"AbstractUserDetailsAuthenticationProvider.badCredentials\", \"Bad credentials\")); } } } } 注册到ProciderManager中 import com.maruifu.framework.security.handle.JwtAuthenticationProvider; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.authentication.ProviderManager; import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.core.userdetails.UserDetailsService; /** * spring security配置 * * @author maruifu */ @EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true) public class SecurityConfig1 extends WebSecurityConfigurerAdapter { /** * 自定义用户认证逻辑 */ @Autowired private UserDetailsService userDetailsService; /** * 解决 无法直接注入 AuthenticationManager * 重写 加盐后验证逻辑 * * @return */ @Bean @Override public AuthenticationManager authenticationManagerBean(){ JwtAuthenticationProvider provider=new JwtAuthenticationProvider(); provider.setUserDetailsService(userDetailsService); ProviderManager manager=new ProviderManager(provider); return manager; } ......省略configure方法 } ","description":"\n","tags":[],"title":"\nSpringBoot Security密码加盐","uri":"/posts/post-222/"},{"categories":["架构设计"],"content":"Spring对配置类的处理主要分为2个阶段 配置类解析阶段 会得到一批配置类的信息，和一些需要注册的bean\nbean注册阶段 将配置类解析阶段得到的配置类和需要注册的bean注册到spring容器中\n看一下什么是配置类,类中有下面任意注解之一的就属于配置类：\n类上有@Compontent注解，@Configuration注解，@CompontentScan注解，@Import注解，@ImportResource注解以及类中有@Bean标注的方法 的都是配置类\n判断一个类是不是一个配置类，是否的是下面这个方法，有兴趣的可以看一下：\norg.springframework.context.annotation.ConfigurationClassUtils#isConfigurationCandidate\nspring中处理这2个过程会循环进行，直到完成所有配置类的解析及所有bean的注册。\nSpring对配置类处理过程 源码位置 org.springframework.context.annotation.ConfigurationClassPostProcessor#processConfigBeanDefinitions\n整个过程大致的过程 通常我们会通过new AnnotationConfigApplicationContext()传入多个配置类来启动spring容器\nspring对传入的多个配置类进行解析\n配置类解析阶段：这个过程就是处理配置类上面6中注解的过程，此过程中又会发现很多新的配置类，比如@Import导入的一批新的类刚好也符合配置类，而被@CompontentScan扫描到的一些类刚好也是配置类；此时会对这些新产生的配置类进行同样的过程解析\nbean注册阶段：配置类解析后，会得到一批配置类和一批需要注册的bean，此时spring容器会将这批配置类作为bean注册到spring容器，同样也会将这批需要注册的bean注册到spring容器\n经过上面第3个阶段之后，spring容器中会注册很多新的bean，这些新的bean中可能又有很多新的配置类\nSpring从容器中将所有bean拿出来，遍历一下，会过滤得到一批未处理的新的配置类，继续交给第3步进行处理\nstep3到step6，这个过程会经历很多次，直到完成所有配置类的解析和bean的注册\n从上面过程中可以了解到：\n可以在配置类上面加上@Conditional注解，来控制是否需要解析这个配置类，配置类如果不被解析，那么这个配置上面6种注解的解析都会被跳过\n可以在被注册的bean上面加上@Conditional注解，来控制这个bean是否需要注册到spring容器中\n如果配置类不会被注册到容器，那么这个配置类解析所产生的所有新的配置类及所产生的所有新的bean都不会被注册到容器\n一个配置类被spring处理有2个阶段：配置类解析阶段、bean注册阶段（将配置类作为bean被注册到spring容器)。\n如果将Condition接口的实现类作为配置类上@Conditional中，那么这个条件会对两个阶段都有效，此时通过Condition是无法精细的控制某个阶段的，如果想控制某个阶段，比如可以让他解析，但是不能让他注册，此时就就需要用到另外一个接口了：ConfigurationCondition\nConfigurationCondition接口 相对于Condition接口多了一个getConfigurationPhase方法，用来指定条件判断的阶段，是在解析配置类的时候过滤还是在创建bean的时候过滤。\nConditional使用的3步骤 自定义一个类，实现Condition或ConfigurationCondition接口，实现matches方法\n在目标对象上使用@Conditional注解，并指定value的指为自定义的Condition类型\n启动spring容器加载资源，此时@Conditional就会起作用了\n阻止配置类的处理 在配置类上面使用@Conditional，这个注解的value指定的Condition当有一个为false的时候，spring就会跳过处理这个配置类。\n自定义一个Condition类：\nimport org.springframework.beans.factory.config.YamlPropertiesFactoryBean; import org.springframework.context.annotation.Condition; import org.springframework.context.annotation.ConditionContext; import org.springframework.context.annotation.Configuration; import org.springframework.core.io.ClassPathResource; import org.springframework.core.type.AnnotatedTypeMetadata; /** * 自定义控制器 * * @author maruifu * @date 2022-12-07 */ @Configuration public class DslLogCondition implements Condition { @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { // 读取配置文件application.yml中 spring.elasticsearch.dslLog: true 配置 YamlPropertiesFactoryBean y=new YamlPropertiesFactoryBean(); y.setResources(new ClassPathResource(\"application.yml\")); return (Boolean) y.getObject().get(\"spring.elasticsearch.dslLog\"); } } matches方法内部我们可以随意发挥，此处为了演示效果读取的配置文件。\n来个配置类，在配置类上面使用上面这个条件，此时会让配置类失效，如下：\nimport org.elasticsearch.client.RestHighLevelClient; import org.springframework.beans.factory.annotation.Value; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Conditional; import org.springframework.context.annotation.Configuration; import org.springframework.data.elasticsearch.client.ClientConfiguration; import org.springframework.data.elasticsearch.client.RestClients; /** * 用于打印dsl语句 */ @Configuration public class EsConfig { @Value(\"${spring.elasticsearch.rest.uris}\") private String elasticsearchHost; @Conditional(DslLogCondition.class) @Bean(destroyMethod = \"close\") public RestHighLevelClient restClient() { ClientConfiguration clientConfiguration = ClientConfiguration.builder().connectedTo(elasticsearchHost).build(); RestHighLevelClient client = RestClients.create(clientConfiguration).rest(); return client; } } 1：使用了自定义的条件类\n2：通过@Bean标注这restClient这个方法，如果这个配置类成功解析，会将restClient方法的返回值作为bean注册到spring容器\nbean不存在的时候才注册 IService接口有两个实现类Service1和Service1，这两个类会放在2个配置类中通过@Bean的方式来注册到容器，此时我们想加个限制，只允许有一个IService类型的bean被注册到容器。\n可以在@Bean标注的2个方法上面加上条件限制，当容器中不存在IService类型的bean时，才将这个方法定义的bean注册到容器，下面来看代码实现。\nimport org.springframework.beans.factory.config.ConfigurableListableBeanFactory; import org.springframework.context.annotation.Condition; import org.springframework.context.annotation.ConditionContext; import org.springframework.context.annotation.ConfigurationCondition; import org.springframework.core.type.AnnotatedTypeMetadata; import java.util.Map; public class OnMissingBeanCondition implements Condition { @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { //获取bean工厂 ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); //从容器中获取IService类型bean Map\u003cString, IService\u003e serviceMap = beanFactory.getBeansOfType(IService.class); //判断serviceMap是否为空 return serviceMap.isEmpty(); } 上面matches方法中会看容器中是否存在IService类型的bean，不存在的时候返回true\n来一个配置类负责注册Service1到容器\nimport org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Conditional; import org.springframework.context.annotation.Configuration; @Configuration public class BeanConfig1 { @Conditional(OnMissingBeanCondition.class) //@1 @Bean public IService service1() { return new Service1(); } } 再来一个配置类负责注册Service2到容器\nimport org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Conditional; import org.springframework.context.annotation.Configuration; @Configuration public class BeanConfig2 { @Conditional(OnMissingBeanCondition.class)//@1 @Bean public IService service2() { return new Service2(); } 来一个总的配置类，导入另外2个配置类\nimport org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.Import; @Configuration @Import({BeanConfig1.class,BeanConfig2.class}) public class MainConfig { } 根据环境选择配置类 平常我们做项目的时候，有开发环境、测试环境、线上环境，每个环境中有些信息是不一样的，比如数据库的配置信息，下面我们来模拟不同环境中使用不同的配置类来注册不同的bean\n自定义一个条件的注解\nimport org.springframework.context.annotation.Conditional; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; @Conditional(EnvCondition.class) //@1 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) public @interface EnvConditional { //环境(测试环境、开发环境、生产环境) enum Env { //@2 TEST, DEV, PROD } //环境 Env value() default Env.DEV; //@3 } @1：注意这个注解比较特别，这个注解上面使用到了@Conditional注解，这个地方使用到了一个自定义Conditione类：EnvCondition\n@2：枚举，表示环境，定义了3个环境\n@3：这个参数用指定环境\n上面这个注解一会我们会用在不同环境的配置类上面\n下面来3个配置类 让3个配置类分别在不同环境中生效，会在这些配置类上面使用上面自定义的@EnvConditional注解来做条件限定。\n每个配置类中通过@Bean来定义一个名称为name的bean，一会通过输出这个bean来判断哪个配置类生效了。\n下面来看3个配置类的代码\n测试环境配置类\npackage com.javacode2018.lesson001.demo25.test2; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration @EnvConditional(EnvConditional.Env.TEST)//@1 public class TestBeanConfig { @Bean public String name() { return \"我是测试环境!\"; } } @1指定的测试环境\n开发环境配置类\npackage com.javacode2018.lesson001.demo25.test2; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration @EnvConditional(EnvConditional.Env.DEV) //@1 public class DevBeanConfig { @Bean public String name() { return \"我是开发环境!\"; } } @1：指定的开发环境\n生产环境配置类\npackage com.javacode2018.lesson001.demo25.test2; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration @EnvConditional(EnvConditional.Env.PROD) //@1 public class ProdBeanConfig { @Bean public String name() { return \"我是生产环境!\"; } } @1：指定的生产环境\n下面来看一下条件类：EnvCondition\n条件类会解析配置类上面@EnvConditional注解，得到环境信息。\n然后和目前的环境对比，决定返回true还是false，如下：\nimport org.springframework.context.annotation.Condition; import org.springframework.context.annotation.ConditionContext; import org.springframework.core.type.AnnotatedTypeMetadata; public class EnvCondition implements Condition { @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { //当前需要使用的环境 EnvConditional.Env curEnv = EnvConditional.Env.DEV; //@1 //获取使用条件的类上的EnvCondition注解中对应的环境 EnvConditional.Env env = (EnvConditional.Env) metadata.getAllAnnotationAttributes(EnvConditional.class.getName()).get(\"value\").get(0); return env.equals(curEnv); } } @1：这个用来指定当前使用的环境，此处假定当前使用的是开发环境，这个我们以后可以任意发挥，比如将这些放到配置文件中，此处方便演示效果。\nCondition指定优先级 多个Condition按顺序执行 @Condtional中value指定多个Condtion的时候，默认情况下会按顺序执行，还是通过代码来看一下效果。\n下面代码中定义了3个Condition，每个Condition的matches方法中会输出当前类名，然后在配置类上面同时使用这3个Condition\nimport org.springframework.context.annotation.Condition; import org.springframework.context.annotation.ConditionContext; import org.springframework.context.annotation.Conditional; import org.springframework.context.annotation.Configuration; import org.springframework.core.type.AnnotatedTypeMetadata; class Condition1 implements Condition { @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { System.out.println(this.getClass().getName()); return true; } } class Condition2 implements Condition { @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { System.out.println(this.getClass().getName()); return true; } } class Condition3 implements Condition { @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { System.out.println(this.getClass().getName()); return true; } } @Configuration @Conditional({Condition1.class, Condition2.class, Condition3.class}) public class MainConfig5 { } 指定Condition的顺序 自定义的Condition可以实现PriorityOrdered接口或者继承Ordered接口，或者使用@Order注解，通过这些来指定这些Condition的优先级。\n排序规则：先按PriorityOrdered排序，然后按照order的值进行排序；也就是：PriorityOrdered asc,order值 asc\n下面这几个都可以指定order的值 接口：org.springframework.core.Ordered，有个getOrder方法用来返回int类型的值 接口：org.springframework.core.PriorityOrdered，继承了Ordered接口，所以也有getOrder方法 注解：org.springframework.core.annotation.Order，有个int类型的value参数指定Order的大小\nimport org.springframework.context.annotation.Condition; import org.springframework.context.annotation.ConditionContext; import org.springframework.context.annotation.Conditional; import org.springframework.context.annotation.Configuration; import org.springframework.core.Ordered; import org.springframework.core.PriorityOrdered; import org.springframework.core.annotation.Order; import org.springframework.core.type.AnnotatedTypeMetadata; @Order(1) //@1 class Condition1 implements Condition { @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { System.out.println(this.getClass().getName()); return true; } } class Condition2 implements Condition, Ordered { //@2 @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { System.out.println(this.getClass().getName()); return true; } @Override public int getOrder() { //@3 return 0; } } class Condition3 implements Condition, PriorityOrdered { //@4 @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { System.out.println(this.getClass().getName()); return true; } @Override public int getOrder() { return 1000; } } @Configuration @Conditional({Condition1.class, Condition2.class, Condition3.class})//@5 public class MainConfig6 { } @1：Condition1通过@Order指定顺序，值为1\n@2：Condition2通过实现了Ordered接口来指定顺序，@3：getOrder方法返回1\n@4：Condition3实现了PriorityOrdered接口，实现这个接口需要重写getOrder方法，返回1000\n@5：Condtion顺序为1、2、3\nConfigurationCondition使用 ConfigurationCondition使用的比较少，很多地方对这个基本上也不会去介绍，Condition接口基本上可以满足99%的需求了，但是springboot中却大量用到了ConfigurationCondition这个接口。\nConfigurationCondition通过解释比较难理解，来个案例感受一下：\n来一个普通的类：Service\npublic class Service { } 来一个配置类，通过配置类注册上面这个Service\n1 2 3 4 5 6 7 8 9 10 11 import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class BeanConfig1 { @Bean public Service service() { return new Service(); } } 再来一个配置类：BeanConfig2\nimport org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class BeanConfig2 { @Bean public String name() { return \"路人甲Java\"; } } 来一个总的配置类\nimport org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.Import; @Configuration @Import({BeanConfig1.class, BeanConfig2.class}) public class MainConfig7 { } 现在我们有个需求\n当容器中有Service这种类型的bean的时候，BeanConfig2才生效。\n很简单吧，加个Condition就行了，内部判断容器中是否有Service类型的bean，继续\n来个自定义的Condition\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import org.springframework.beans.factory.config.ConfigurableListableBeanFactory; import org.springframework.context.annotation.Condition; import org.springframework.context.annotation.ConditionContext; import org.springframework.core.type.AnnotatedTypeMetadata; public class MyCondition1 implements Condition { @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { //获取spring容器 ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); //判断容器中是否存在Service类型的bean boolean existsService = !beanFactory.getBeansOfType(Service.class).isEmpty(); return existsService; } } 上面代码很简单，判断容器中是否有IService类型的bean。\n@Configuration @Conditional(MyCondition1.class) public class BeanConfig2 { @Bean public String name() { return \"路人甲Java\"; } } 结果name永远注册不上\n为什么？ 在文章前面我们说过，配置类的处理会依次经过2个阶段：配置类解析阶段和bean注册阶段，Condition接口类型的条件会对这两个阶段都有效，解析阶段的时候，容器中是还没有Service这个bean的，配置类中通过@Bean注解定义的bean在bean注册阶段才会被注册到spring容器，所以BeanConfig2在解析阶段去容器中是看不到Service这个bean的，所以就被拒绝了。\n此时我们需要用到ConfigurationCondition了，让条件判断在bean注册阶段才起效。\n自定义一个ConfigurationCondition类 import org.springframework.beans.factory.config.ConfigurableListableBeanFactory; import org.springframework.context.annotation.ConditionContext; import org.springframework.context.annotation.ConfigurationCondition; import org.springframework.core.type.AnnotatedTypeMetadata; public class MyConfigurationCondition1 implements ConfigurationCondition { @Override public ConfigurationPhase getConfigurationPhase() { return ConfigurationPhase.REGISTER_BEAN; //@1 } @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) { //获取spring容器 ConfigurableListableBeanFactory beanFactory = context.getBeanFactory(); //判断容器中是否存在Service类型的bean boolean existsService = !beanFactory.getBeansOfType(Service.class).isEmpty(); return existsService; } } @1：指定条件在bean注册阶段，这个条件才有效\nmatches方法中的内容直接复制过来，判断规则不变\n修改BeanConfig2的类容\n将 @Conditional(MyCondition1.class) 替换为 @Conditional(MyConfigurationCondition1.class) 此时name这个bean被注入了。\n可以再试试将BeanConfig1中service方法上面的@Bean去掉，此时Service就不会被注册到容器\n判断bean存不存在的问题，通常会使用ConfigurationCondition这个接口，阶段为：REGISTER_BEAN，这样可以确保条件判断是在bean注册阶段执行的。\n对springboot比较熟悉的，它里面有很多@Conditionxxx这样的注解，可以去看一下这些注解，很多都实现了ConfigurationCondition接口。\nSpring中这块的源码 @Conditional注解是被下面这个类处理的\n1 org.springframework.context.annotation.ConfigurationClassPostProcessor 总结 @Conditional注解可以标注在spring需要处理的对象上（配置类、@Bean方法），相当于加了个条件判断，通过判断的结果，让spring觉得是否要继续处理被这个注解标注的对象\nspring处理配置类大致有2个过程：解析配置类、注册bean，这两个过程中都可以使用@Conditional来进行控制spring是否需要处理这个过程\nCondition默认会对2个过程都有效\nConfigurationCondition控制得更细一些，可以控制到具体那个阶段使用条件判断\n","description":"\n","tags":[],"title":"\nSpring中@Conditional通过条件来控制bean的注册","uri":"/posts/post-223/"},{"categories":["默认分类"],"content":"application.yml增加配置 # 日志配置 logging: level: #es日志 org.springframework.data.elasticsearch.client.WIRE : trace 增加配置类 package com.maruifu.business.config; import org.elasticsearch.client.RestHighLevelClient; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.elasticsearch.client.ClientConfiguration; import org.springframework.data.elasticsearch.client.RestClients; /** * 用于打印dsl语句 */ @Configuration public class EsConfig { @Bean(destroyMethod = \"close\") public RestHighLevelClient restClient() { ClientConfiguration clientConfiguration = ClientConfiguration.builder() .connectedTo(\"172.16.45.138:11700\") .build(); RestHighLevelClient client = RestClients.create(clientConfiguration).rest(); return client; } } 查看打印效果 ","description":"\n","tags":[],"title":"\nSpringDataElasticsearch控制台打印查询语句","uri":"/posts/post-224/"},{"categories":["默认分类"],"content":"免责声明 本脚本为免费使用，本脚本只供个人学习使用，使用需严格遵守开源许可协议。严禁用于商业用途，禁止进行任何盈利活动。对一切非法使用所产生的后果，概不负责！\n#!/bin/bash set -e file=$(defaults read /Applications/Navicat\\ Premium.app/Contents/Info.plist) regex=\"CFBundleShortVersionString = \"([^\\.]+)\" [[ $file =~ $regex ]] version=${BASH_REMATCH[1]} echo \"Detected Navicat Premium version $version\" case $version in \"16\") file=~/Library/Preferences/com.navicat.NavicatPremium.plist ;; \"15\") file=~/Library/Preferences/com.prect.NavicatPremium15.plist ;; *) echo \"Version '$version' not handled\" exit 1 ;; esac echo -n \"Reseting trial time...\" regex=\"([0-9A-Z]{32}) = \" [[ $(defaults read $file) =~ $regex ]] hash=${BASH_REMATCH[1]} if [ ! -z $hash ]; then defaults delete $file $hash fi regex=\"\\.([0-9A-Z]{32})\" [[ $(ls -a ~/Library/Application\\ Support/PremiumSoft\\ CyberTech/Navicat\\ CC/Navicat\\ Premium/ | grep '^\\.') =~ $regex ]] hash2=${BASH_REMATCH[1]} if [ ! -z $hash2 ]; then rm ~/Library/Application\\ Support/PremiumSoft\\ CyberTech/Navicat\\ CC/Navicat\\ Premium/.$hash2 fi echo \" Done\" ","description":"\n","tags":[],"title":"\nnavicat16 mac版无限重置试用期脚本","uri":"/posts/post-225/"},{"categories":["默认分类"],"content":"\nHashMap集合简介 HashMap基于哈希表的Map接口实现，是以key-value存储形式存在，即主要用来存放键值对。HashMap的实现不是同步的，这意味着它不是线程安全的。它的key、value都可以为null。此外，HashMap中的映射不是有序的。\nJDK1.8之前的HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了节解决哈希碰撞(两个对象调用的hashCode方法计算的哈希码值一致导致计算的数组索引值相同)而存在的（“拉链法”解决冲突）。\nJDK1.8之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（或者红黑树的边界值，默认为8）并且当前数组的长度大于64时，此时此索引位置上的所有数据改为使用红黑树存储。\n数组里面都是key-value的实例，在JDK1.8之前叫做Entry，在JDK1.8之后叫做Node。\n由于它的key、value都为null，所以在插入的时候会根据key的hash去计算一个index索引的值。计算索引的方法如下：\n/** * 根据key求index的过程 * 1,先用key求出hash值 */ static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h \u003e\u003e\u003e 16); } //2,再用公式index = (n - 1) \u0026 hash（n是数组长度） int hash=hash(key); index=(n-1)\u0026hash; 这里的Hash算法本质上就是三步：取key的hashCode值、高位运算、取模运算。\n这样的话比如说put(“A”,王炸)，插入了key为\"A\"的元素，这时候通过上述公式计算出插入的位置index，若index为3则结果如下（即hash(“A”)=3）：\n那么，HashMap中的链表又是干什么用的呢？\n大家都知道数组的长度是有限的，在有限的长度里面使用哈希函数计算index的值时，很有可能插入的k值不同，但所产生的hash是相同的（也叫做哈希碰撞），这也就是哈希函数存在一定的概率性。就像上面的K值为A的元素，如果再次插入一个K值为a的元素，很有可能所产生的index值也为3，也就是即hash(“a”)=3；那这就形成了链表，这种解决哈希碰撞的方法也叫做拉链法。\n当这个链表长度大于阈值8并且数组长度大于64则进行将链表变为红黑树。\n将链表转换成红黑树前会判断，如果阈值大于8，但是数组长度小64，此时并不会将链表变为红黑树。而是选择进行数组扩容。\n这样做的目的是因为数组比较小，尽量避开红黑树结构，这种情况下变为红黑树结构，反而会降低效率，因为红黑树需要进行左旋，右旋，变色这些操作来保持平衡。同事数组长度小于64时，搜索时间相对快一些。所以综上所述为了提高性能和减少搜索时间，底层在阈值大于8并且数组长度大于64时，链表才转换为红黑树。具体可以参考treeifyBin方法。\n当然虽然增了红黑树作为底层数据结构，结构变得复杂了，但是阈值大于8并且数组长度大于64时，链表转换为红黑树时，效率也变得更高效。\n特点 存取无序的 键和值位置都可以是null，但是键位置只能是一个null 键位置是唯一的，底层的数据结构控制键的 jdk1.8前数据结构是：链表 + 数组 jdk1.8之后是 ：链表 + 数组 + 红黑树 阈值(边界值) \u003e 8 并且数组长度大于64，才将链表转换为红黑树，变为红黑树的目的是为了高效的查询。 HsahMap底层数据结构 HashMap存储数据的过程 每一个Node结点都包含键值对的key，value还有计算出来的hash值，还保存着下一个 Node 的引用 next（如果没有下一个 Node，next = null），来看看Node的源码：\nstatic class Node\u003cK,V\u003e implements Map.Entry\u003cK,V\u003e { final int hash; final K key; V value; Node\u003cK,V\u003e next; ... } HashMap存储数据需要用到put()方法，关于这些方法的详解，我们下节再说，这里简要说一下；\npublic static void main(String[] args) { HashMap\u003cString,Integer\u003e hmap=new HashMap\u003c\u003e(); hmap.put(\"斑\",55); hmap.put(\"镜\",63); hmap.put(\"带土\",25); hmap.put(\"鼬\",9); hmap.put(\"佐助\",43); hmap.put(\"斑\",88); System.out.println(hmap); } 当创建HashMap集合对象的时候，在jdk1.8之前，构造方法中会创建很多长度是16的Entry[] table用来存储键值对数据的。在jdk1.8之后不是在HashMap的构造方法底层创建数组了，是在第一次调用put方法时创建的数组，Node[] table用来存储键值对数据的。\n比方说我们向哈希表中存储\"斑\"-55的数据，根据K值(“斑”)调用String类中重写之后的hashCode()方法计算出值（数量级很大），然后结合数组长度采用取余（(n-1)\u0026hash）操作或者其他操作方法来计算出向Node数组中存储数据的空间的索引值。如果计算出来的索引空间没有数据，则直接将\"斑\"-55数据存储到数组中。跟上面的\"A-王炸\"数据差不多。\n我们回到上方的数组图，如果此时再插入\"A-蘑菇\"元素，那么首先根据Key值(“A”)调用hashCode()方法结合数组长度计算出索引肯定也是3，此时比较后存储的\"A-蘑菇\"和已经存在的数据\"A-王炸\"的hash值是否相等，如果hash相等，此时发生hash碰撞。\n那么底层会调用\"A\"所属类String中的equals方法比较两个key内容是否相等，若相等，则后添加的数据直接覆盖已经存在的Value，也就是\"蘑菇\"直接覆盖\"王炸\"；若不相等，继续向下和其他数据的key进行比较，如果都不相等，则规划出一个节点存储数据。\n哈希碰撞相关的问题 哈希表底层采用何种算法计算hash值？还有哪些算法可以计算出hash值？\n底层是采用key的hashCode方法的值结合数组长度进行无符号右移（»\u003e）、按位异或（^）、按位与（\u0026）计算出索引的\n还可以采用：平方取中法，取余数，伪随机数法。这三种效率都比较低。而无符号右移16位异或运算效率是最高的。\n当两个对象的hashCode相等时会怎么样？\n会产生哈希碰撞，若key值内容相同则替换旧的value.否则连接到链表后面，链表长度超过阈值8就转换为红黑树存储。\n何时发生哈希碰撞和什么是哈希碰撞,如何解决哈希碰撞？\n只要两个元素的key计算的哈希值相同就会发生哈希碰撞。jdk8前使用链表解决哈希碰撞。jdk8之后使用链表+红黑树解决哈希碰撞。\n如果两个键的hashcode相同，如何存储键值对？\nhashcode相同，通过equals比较内容是否相同。相同：则新的value覆盖之前的value 不相同：则将新的键值对添加到哈希表中\n红黑树结构 当位于一个链表中的元素较多，即hash值相等但是内容不相等的元素较多时，通过key值依次查找的效率较低。而jdk1.8中，哈希表存储采用数组+链表+红黑树实现，当链表长度(阀值)超过 8 时且当前数组的长度 \u003e 64时，将链表转换为红黑树，这样大大减少了查找时间。jdk8在哈希表中引入红黑树的原因只是为了查找效率更高。\nJDK 1.8 以前 HashMap 的实现是 数组+链表，即使哈希函数取得再好，也很难达到元素百分百均匀分布。当 HashMap 中有大量的元素都存放到同一个桶中时，这个桶下有一条长长的链表，这个时候 HashMap 就相当于一个单链表，假如单链表有 n 个元素，遍历的时间复杂度就是 O(n)，完全失去了它的优势。针对这种情况，JDK 1.8 中引入了 红黑树（查找时间复杂度为 O(logn)）来优化这个问题。当链表长度很小的时候，即使遍历，速度也非常快，但是当链表长度不断变长，肯定会对查询性能有一定的影响，所以才需要转成树。\n存储流程图 HashMap存放数据是用的put方法，put 方法内部调用的是 putVal() 方法，所以对 put 方法的分析也是对 putVal 方法的分析，整个过程比较复杂，流程图如下：\n来看看put()源码：\npublic V put(K key, V value) { //对key的hashCode()做hash，调用的是putVal方法 return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node\u003cK,V\u003e[] tab; Node\u003cK,V\u003e p; int n, i; /* 1，tab为空则开始创建， 2，(tab = table) == null 表示将空的table赋值给tab,然后判断tab是否等于null，第一次肯定是null 3，(n = tab.length) == 0 表示没有为table分配内存 4，tab为空，执行代码 n = (tab = resize()).length; 进行扩容。并将初始化好的数组长度赋值给n. 5，执行完n = (tab = resize()).length，数组tab每个空间都是null */ if ((tab = table) == null || (n = tab.length) == 0) //调用resize()方法进行扩容 n = (tab = resize()).length; /* 1，i = (n - 1) \u0026 hash 表示计算数组的索引赋值给i，即确定元素存放在哪个桶中 2，p = tab[i = (n - 1) \u0026 hash]表示获取计算出的位置的数据赋值给节点p 3，(p = tab[i = (n - 1) \u0026 hash]) == null 判断节点位置是否等于null， 如果为null，则执行代码：tab[i] = newNode(hash, key, value, null);根据键值对创建新的节点放入该位置的桶中 小结：如果当前桶没有哈希碰撞冲突，则直接把键值对插入空间位置 */ if ((p = tab[i = (n - 1) \u0026 hash]) == null) //节点位置为null，则直接进行插入操作 tab[i] = newNode(hash, key, value, null); //节点位置不为null，表示这个位置已经有值了，于是需要进行比较hash值是否相等 else { Node\u003cK,V\u003e e; K k; /* 比较桶中第一个元素(数组中的结点)的hash值和key是否相等 1，p.hash == hash 中的p.hash表示原来存在数据的hash值 hash表示后添加数据的hash值 比较两个hash值是否相等 2，(k = p.key) == key ：p.key获取原来数据的key赋值给k key表示后添加数据的key 比较两个key的地址值是否相等 3，key != null \u0026\u0026 key.equals(k)：能够执行到这里说明两个key的地址值不相等，那么先判断后添加的key是否等于null，如果不等于null再调用equals方法判断两个key的内容是否相等 */ if (p.hash == hash \u0026\u0026 ((k = p.key) == key || (key != null \u0026\u0026 key.equals(k)))) /* 说明：两个元素哈希值相等（哈希碰撞），并且key的值也相等 将旧的元素整体对象赋值给e，用e来记录 */ e = p; // hash值不相等或者key不相等；判断p是否为红黑树结点 else if (p instanceof TreeNode) // 是红黑树，调用树的插入方法 e = ((TreeNode\u003cK,V\u003e)p).putTreeVal(this, tab, hash, key, value); // 说明是链表节点，这时进行插入操作 else { /* 1，如果是链表的话需要遍历到最后节点然后插入 2，采用循环遍历的方式，判断链表中是否有重复的key */ for (int binCount = 0; ; ++binCount) { /* 1)e = p.next 获取p的下一个元素赋值给e 2)(e = p.next) == null 判断p.next是否等于null，等于null，说明p没有下一个元 素，那么此时到达了链表的尾部，还没有找到重复的key,则说明HashMap没有包含该键 将该键值对插入链表中 */ if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); //插入后发现链表长度大于8，转换成红黑树结构 if (binCount \u003e= TREEIFY_THRESHOLD - 1) //转换为红黑树 treeifyBin(tab, hash); break; } //key值以及存在直接覆盖value if (e.hash == hash \u0026\u0026 ((k = e.key) == key || (key != null \u0026\u0026 key.equals(k)))) break; p = e; } } //若结点为null，则不进行插入操作 if (e != null) { V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } //修改记录次数 ++modCount; // 判断实际大小是否大于threshold阈值，如果超过则扩容 if (++size \u003e threshold) resize(); // 插入后回调 afterNodeInsertion(evict); return null; } 小结：\n根据哈希表中元素个数确定是扩容还是树形化 如果是树形化遍历桶中的元素，创建相同个数的树形节点，复制内容，建立起联系 然后让桶中的第一个元素指向新创建的树根节点，替换桶的链表内容为树形化内容 HashMap的扩容机制 我们知道，数组的容量是有限的，多次插入数据的话，到达一定数量就会进行扩容；先来看两个问题\n什么时候需要扩容？ 当HashMap中的元素个数超过数组长度loadFactor(负载因子)时，就会进行数组扩容，loadFactor的默认值是0.75,这是一个折中的取值。也就是说，默认情况下，数组大小为16，那么当HashMap中的元素个数超过16×0.75=12(这个值就是阈值)的时候，就把数组的大小扩展为2×16=32，即扩大一倍，然后重新计算每个元素在数组中的位置，而这是一个非常耗性能的操作，所以如果我们已经预知HashMap中元素的个数，那么预知元素的个数能够有效的提高HashMap的性能。\n怎么进行扩容的？ HashMap在进行扩容时使用 resize() 方法，计算 table 数组的新容量和 Node 在新数组中的新位置，将旧数组中的值复制到新数组中，从而实现自动扩容。因为每次扩容都是翻倍，与原来计算的 (n-1)\u0026hash的结果相比，只是多了一个bit位，所以节点要么就在原来的位置，要么就被分配到\"原位置+旧容量“这个位置。\n因此，我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来hash值新增的那个bit是1还是0就可以了，是0的话索引没变，是1的话索引变成“原索引+oldCap(原位置+旧容量)”。这里不再详细赘述，可以看看下图为16扩充为32的resize示意图：\nHashMap数组长度为什么是2的次幂 我们先看看它的成员变量：\n序列化版本号 private static final long serialVersionUID = 362498820763181265L; 集合的初始化容量initCapacity //默认的初始容量是16 -- 1\u003c\u003c4相当于1*2的4次方---1*16 static final int DEFAULT_INITIAL_CAPACITY = 1 \u003c\u003c 4; 初始化容量默认是16，容量过大，遍历时会减慢速度，效率低；容量过小，那么扩容的次数变多，非常耗费性能。\n负载因子 /** * The load factor used when none specified in constructor. */ static final float DEFAULT_LOAD_FACTOR = 0.75f; 初始默认值为0.75，若过大，会导致哈希冲突的可能性更大；若过小，扩容的次数也会提高。\n为什么必须是2的n次幂？ 当向HashMap中添加一个元素的时候，需要根据key的hash值，去确定其在数组中的具体位置。HashMap为了提高存取效率，要尽量较少碰撞，就是要尽量把数据分配均匀，每个链表长度大致相同，这个实现就在把数据存到哪个链表中的算法。\n这个算法实际就是取模，hash%length，计算机中直接求余效率不如位移运算。所以源码中做了优化,使用 hash\u0026(length-1)，而实际上hash%length等于hash\u0026(length-1)的前提是length是2的n次幂。\n如果输入值不是2的幂会怎么样？ 如果数组长度不是2的n次幂，计算出的索引特别容易相同，及其容易发生hash碰撞，导致其余数组空间很大程度上并没有存储数据，链表或者红黑树过长，效率降低。\n1，当根据key的hash确定其在数组的位置时，如果n为2的幂次方**，**可以保证数据的均匀插入，如果n不是2的幂次方，可能数组的一些位置永远不会插入数据，浪费数组的空间，加大hash冲突。\n2，一般可能会想通过 % 求余来确定位置，这样也可以，只不过性能不如 \u0026 运算。而且当n是2的幂次方时：hash \u0026 (length - 1) == hash % length\n3，因此，HashMap 容量为2次幂的原因，就是**为了数据的的均匀分布，减少hash冲突，**毕竟hash冲突越大，代表数组中一个链的长度越大，这样的话会降低hashmap的性能\n","description":"\n","tags":[],"title":"\nJDK1.8 HashMap数据结构","uri":"/posts/post-226/"},{"categories":["maven"],"content":"maven\nJava项目很多都会有子module，一般父项目没有逻辑代码，在父项目pom.xml中注明依赖、version和其他一些公用的东西，子module的pom继承父pom，子pom就不用写依赖的版本了，但至少也要写用到依赖的groupId、artifactId，这样默认会使用父项目依赖的版本。子pom也可以写版本，这样就不受父pom影响了，和继承类似，但还是有些区别。\n使用时需要注意，我就是忘了其中一项，没有生效：\n父pom需要添加\u003cpackaging\u003epom\u003c/packaging\u003e 父pom需要用\u003cmodules\u003e\u003cmodule\u003e子module名\u003c/module\u003e\u003c/modules\u003e注明子module有哪些 父pom声明依赖时\u003cdependencies\u003e外要嵌套\u003cdependencyManagement\u003e才能被子pom继承到，我就是忘了这点 子pom需要通过\u003cparent\u003e\u003c/parent\u003e指定父项目，声明依赖时就默认会用父pom中的版本了 dependencyManagement：像上面提到的，一般在父项目中会声明这个元素，和普通依赖用法类似，这个元素并不会真的引入依赖，只会标明依赖和版本，子项目会从父项目找\u003cdependencyManagement\u003e从而确定需要引用依赖版本，类似于模板模式。\n父pom例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u003c!-- 省略无关配置 --\u003e \u003cpackaging\u003epom\u003c/packaging\u003e \u003cmodules\u003e \u003c!-- 注明所有子module --\u003e \u003cmodule\u003emodule1\u003c/module\u003e \u003cmodule\u003emodule2\u003c/module\u003e \u003c/modules\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003c!-- 以Lombk为例 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003cversion\u003e1.18.8\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e 子pom module1例子： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u003c!-- 省略无关配置 --\u003e \u003cparent\u003e \u003cgroupId\u003e父项目group\u003c/groupId\u003e \u003cartifactId\u003e父项目artifactId\u003c/artifactId\u003e \u003cversion\u003e父项目version\u003c/version\u003e \u003crelativePath\u003e../pom.xml\u003c/relativePath\u003e \u003c/parent\u003e \u003cdependencies\u003e \u003c!--这样会使用父pom中的依赖版本1.18.8，如果这里写version就不会使用父pom里的版本了--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003cscope\u003eprovided\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e relativePath 指定查找该父项目pom.xml的(相对)路径。默认顺序：relativePath \u003e 本地仓库 \u003e 远程仓库 没有relativePath标签等同…/pom.xml, 即默认从当前pom文件的上一级目录找 表示不从relativePath找, 直接从本地仓库找,找不到再从远程仓库找 经过 maven3.6版本测试，似乎没有relativePath标签时，它没有从当前pom文件的上一级目录找，子模块继承不到父模块中dependencyManagement中包的version信息。子模块想要用父模块pom中的版本，请注意配置relativePath属性！\n","description":"\n","tags":[],"title":"\nmaven子pom没有继承到父pom依赖版本","uri":"/posts/post-227/"},{"categories":["默认分类"],"content":" Could not resolve dependencies for project com.xxx:xxx-framework🏺3.8.4: The following artifacts could not be resolved: com.sun:tools🏺1.8, com.sun:jconsole🏺1.8: Could not find artifact com.sun:tools🏺1.8 at specified path /root/.m2/repository/com/alibaba/druid/1.2.11/lib/openjdk-1.8-tools.jar 问题原因 OracleJDK面临商业闭源风险，所以用到的Jconsole和Tools引入的是OpenJDK\nopenjdk-1.8-jconsole.jar openjdk-1.8-tools.jar 解决方案 使用OpenJDK \u003cdependency\u003e \u003cgroupId\u003ecom.sun\u003c/groupId\u003e \u003cartifactId\u003etools\u003c/artifactId\u003e \u003cversion\u003e1.8\u003c/version\u003e \u003cscope\u003esystem\u003c/scope\u003e \u003csystemPath\u003e${JAVA_HOME}/lib/tools.jar\u003c/systemPath\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ejdk.tools\u003c/groupId\u003e \u003cartifactId\u003ejdk.tools\u003c/artifactId\u003e \u003cversion\u003e1.8\u003c/version\u003e \u003cscope\u003esystem\u003c/scope\u003e \u003csystemPath\u003e${JAVA_HOME}/lib/tools.jar\u003c/systemPath\u003e \u003c/dependency\u003e 排除使用 大多数未用到这个功能（未参与源码(开发），则排除即可\n\u003cexclusions\u003e \u003cexclusion\u003e \u003cgroupId\u003ecom.sun\u003c/groupId\u003e \u003cartifactId\u003ejconsole\u003c/artifactId\u003e \u003c/exclusion\u003e \u003cexclusion\u003e \u003cgroupId\u003ecom.sun\u003c/groupId\u003e \u003cartifactId\u003etools\u003c/artifactId\u003e \u003c/exclusion\u003e \u003c/exclusions\u003e ","description":"\n","tags":[],"title":"\nDruid Maven引入缺少Jconsole.jar和Tools.jar的问题原因及解决办法","uri":"/posts/post-228/"},{"categories":["默认分类"],"content":"一、安装内容 Jenkins（本文主要安装）、Maven、Git、JDK（这个三个安装过程略）\nJenkins与Github配合实现持续集成需要注意以下几点：\n①Jenkins要部署到外网，因为内网Github是无法访问到的（走过的坑！），这里我租用的是阿里云的服务器实现。\n②Jenkins所在的主机需要安装Git,通过Git程序从Github上clone代码\n③在Jenkins中需要指定Git、Maven、JDK，路子都是相同的。\n④在Github上使用每一个repository的webhook方式远程触发jenkins构建\n⑤在Jenkins内关闭“防止跨站点请求伪造”\n二、实现过程 1.不使用Jenkins： ①我们开发人员需要编写代码，提交到版本控制服务器（Svn、Git）\n②我们开发人员需要手动拉取最新代码，构建maven工程，进行打包（war或jar）\n③我们开发人员手动部署war或jar至应用服务器\n④一旦项目上线，bug修改等小改动问题都要重复以上过程\n2.使用Jenkins： ①同样，业务代码还是需要开发人员来编写并commit或push至版本控制自服务器（SVN、Git）\n②通过以上图，我们发现，Jenkins帮我们做了：拉取最新代码、打包、部署\n③我们开发人员只需专注于：业务代码的编写\n④一旦项目上线，bug修改等小改动问题，我们开发人员只需提交最新代码即可，另一边的测试或最终用户就能看到最终效果，大大减少我们开发人员的工作量\n三、Github仓库准备 鄙人写了一个小demo，用IDEA+Maven构建的SpringBoot的web项目：https://github.com/Simple-Coder/jenkins-demo\n四、Jenkins的下载安装 下载地址：https://jenkins.io/download/（下载速度极慢），这里我已经将最新版的war包上传至CSDN下载，亲测可用，下载地址如下：\nhttps://download.csdn.net/download/qq_39947137/11829473\n1.Jenkins的war包下载 由于我是Java开发人员，最喜欢一键部署了，下载Jenkins的war直接丢进tomcat的webapps目录即可完成部署。\n然后找到documentation，get started，这是学习一门新技术的一些套路了：官网—-\u003edownload—-\u003edocumentation—-\u003egetting started\n2.将war包丢进服务器的tomcat/webapps目录，浏览器访问：IP:端口/jenkins 注：第一次安装，这里坑了我好久！！！（vim /root/.jenkins/hudson.model.UpdateCenter.xml）\n打开 hudson.model.UpdateCenter.xml\n把 http://updates.jenkins-ci.org/update-center.json\n改成 :（以下其中一个）\nhttp://mirror.xmission.com/jenkins/updates/update-center.json\nhttps://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json\nhttp://mirror.esuni.jp/jenkins/updates/update-center.json\n，还是不行的话找到 updates 目录下的 default.json 把里面所有的谷歌地址改成百度的，即将 http://www.google.com/ 替换为 http://www.baidu.com/。输入密码后出现以下界面说明成功。\n配置完成出现以下界面说明url配置完成！\n3.推荐插件安装 4.创建用户 5.实例配置 6.开始使用 7.进入首页 至此、Jenkins的下载安装，完成，下面对Jenkins进行一系列的配置。\n五、Jenkins的配置 1.插件配置 ①**Maven Integration：新建job时有maven项目可以选择； ②Deploy to container：将war包部署到tomcat所在的服务器上； ③Publish Over SSH：**通过ssh推送文件，并可以执行shell命令；\n2.Maven、Git、JDK配置 点击：“系统管理”——\u003e“全局工具配置”\n六、新建Jenkins任务 1.点击“系统管理”—-\u003e“系统设置”，进行ssh配置 2.首页点击：“新建任务” 3.General配置 4.源码管理 5.构建触发器 6.Github配置WebHook,完成钩子程序的配置 7.构建环境 启动脚本restart.sh如下:\necho \"stop服务开始\" pidlist=`ps -ef|grep jenkins-demo.jar | grep -v \"grep\"|awk '{print $2}'` #ps -u $USER|grep \"Java\"|grep -v \"grep\" if [ \"$pidlist\" = \"\" ]; then echo \"no jenkins-demo pid alive\" else echo \"jenkins-demo Id list :$pidlist\" for pid in ${pidlist} { kill -9 $pid echo \"KILL $pid:\" echo \"service stop success\" } fi echo \"stop服务脚本结束\" echo \"start服务脚本开始\" JAVA_HOME=/usr/java/jdk1.8.0_181 dir=/opt/jenkins_jars cd $dir echo dir=$dir jar=$(find /lib -type f -name *.jar) classpath=$dir/*:$dir/lib/*:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar echo classpath=$classpath echo --------------------------------------------- nohup $JAVA_HOME/bin/java -classpath $classpath -XX:-UseGCOverheadLimit -Xms1024m -Xmx2048m -jar $dir/jenkins-demo.jar \u003e $dir/log/$(date +'%Y%m%d').log \u0026 echo \"start服务脚本结束\" 8.构建 至此，第一个任务的配置完毕，接下来就是测试了！\n七、测试任务 1.立即构建 2.控制台查看输出 控制台的输出如下：\n3.浏览器访问：http://47.92.236.212:8091/test 4.IDEA修改该JSP页面，并推送至git仓库 5.推送github后，触发钩子程序，jenkins自动构建任务 6.浏览器再次访问：http://47.92.236.212:8091/test 回到顶部\n八、总结 这里需要注意一下，如果只是单单部署war项目就比较简单了，配置如下：\n1.deploy to container 2.配置容器 转载于： https://www.cnblogs.com/rmxd/p/11609983.html\n","description":"\n","tags":[],"title":"\nJenkins+Maven+Github+Springboot实现可持续自动部署(非常详细)","uri":"/posts/post-229/"},{"categories":["默认分类"],"content":"下载 https://www.sonatype.com/download-oss-sonatype\n推荐使用迅雷下载，用浏览器下载可能会失败。\n安装 安装JDK 安装JDK的过程就不在这里缀述了。\n安装 Nexus # 解压下载的 Nexus Repository OSS tar -zxvf latest-unix.tar.gz # 解压会得到如下两个文件夹： nexus-3.23.0-03/ sonatype-work/ # 进入 nexus-**/bin/ # 编辑nexus.vmoptions 配置，我这里因为内存不够，我将运行内存改成了1G 启动 nexus ./nexus start 这里启动很慢，我从启动到能够访问web页面，差不多花了3~5分钟\n配置私服 添加阿里镜像到仓库组 在浏览器访问 http://{IP}:8081(启动成功才能看到如下页面）\n根据提示，登录admin （密码有提示放在**/opt/sonatype-work/nexus3/admin.password**）进入设置向导，然后修改 admin 的密码，然后根据需要完成剩余向导\n添加阿里镜像代理 将新增的maven 代理添加到 maven-public 组 配置maven setting.xml 下载私服jar包 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003csettings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\"\u003e \u003c!-- 本地仓地址 --\u003e \u003clocalRepository\u003eD:\\nexus\\repository\u003c/localRepository\u003e \u003c!-- 配置用于鉴权的账号（由下面的“id”属性引用）--\u003e \u003cservers\u003e \u003cserver\u003e \u003cid\u003enexus\u003c/id\u003e \u003cusername\u003eadmin\u003c/username\u003e \u003cpassword\u003eadmin123\u003c/password\u003e \u003c/server\u003e \u003c/servers\u003e \u003cmirrors\u003e \u003cmirror\u003e \u003c!-- mirror的id要选定一个server的id，当拉取包时，会用server的id进行鉴权 --\u003e \u003cid\u003enexus\u003c/id\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003cname\u003enexus maven\u003c/name\u003e \u003c!-- 私服地址，一般用maven-public分组仓库地址 --\u003e \u003curl\u003ehttp://192.168.10.128:8081/repository/maven-public/\u003c/url\u003e \u003c/mirror\u003e \u003c/mirrors\u003e \u003c!-- 配置 允许下载snapshot版本包（默认无法下载snapshot版本包）, 如果不配置profile无法从私服下载 SNAPSHOT 版本的包 --\u003e \u003cprofiles\u003e \u003cprofile\u003e \u003cid\u003eprofile-1\u003c/id\u003e \u003crepositories\u003e \u003crepository\u003e \u003cid\u003enexus\u003c/id\u003e \u003cname\u003elocal private nexus\u003c/name\u003e \u003c!-- 仓库的路径，我们只是使用public这个分组仓库 --\u003e \u003curl\u003ehttp://192.168.10.128:8081/repository/maven-public/\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003c/snapshots\u003e \u003c/repository\u003e \u003c/repositories\u003e \u003cpluginRepositories\u003e \u003cpluginRepository\u003e \u003cid\u003enexus\u003c/id\u003e \u003cname\u003elocal private nexus\u003c/name\u003e \u003curl\u003ehttp://192.168.10.128:8081/repository/maven-public/\u003c/url\u003e \u003creleases\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003c/releases\u003e \u003csnapshots\u003e \u003cenabled\u003etrue\u003c/enabled\u003e \u003c/snapshots\u003e \u003c/pluginRepository\u003e \u003c/pluginRepositories\u003e \u003c/profile\u003e \u003c/profiles\u003e \u003cactiveProfiles\u003e \u003c!-- 输入要激活的profile的ID --\u003e \u003cactiveProfile\u003eprofile-1\u003c/activeProfile\u003e \u003c/activeProfiles\u003e \u003c/settings\u003e 配置 pom.xml 发布包到私服 \u003cproject\u003e \u003c!-- ....省略部分内容 --\u003e \u003cdistributionManagement\u003e \u003crepository\u003e \u003c!-- 这里的id必须和 setting.xml中配置的server的id相同（用于鉴权） --\u003e \u003cid\u003enexus\u003c/id\u003e \u003cname\u003enexus-release\u003c/name\u003e \u003curl\u003ehttp://192.168.10.128:8081/repository/maven-releases/\u003c/url\u003e \u003c/repository\u003e \u003c!-- pom中版本如果以SNAPSHOT 结尾，则会被发布到 snapshot 仓库 --\u003e \u003csnapshotRepository\u003e \u003cid\u003enexus\u003c/id\u003e \u003cname\u003enexus-snapshot\u003c/name\u003e \u003curl\u003ehttp://192.168.10.128:8081/repository/maven-snapshots/\u003c/url\u003e \u003c/snapshotRepository\u003e \u003c/distributionManagement\u003e \u003c/project\u003e ","description":"\n","tags":[],"title":"\nLinux Maven私服（Nexus）搭建","uri":"/posts/post-230/"},{"categories":["默认分类"],"content":"问题现象 解决方案 方案一 1、win+R打开运行窗口\n2、输入gpedit.msc命令，点击“确定”\n3、依次展开“计算机配置”-\u003e“管理模板”-\u003e“系统”-\u003e“凭据分配”设置名称： 加密数据库修正\n4、双击“加密数据库修正”，将状态改为“启用”，保护级别改为“易受攻击”，应用—\u003e确定\n方案二 1、win+R打开运行窗口\n2、输入regedit命令，点击“确定”，打开注册表文件\n3、在注册表中进入如下路径：HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\System\\CredSSP\\Parameters\n4、右击Parameters—\u003e新建—\u003eDWORD（32）位，命名为AllowEncryptionOracle\n注意：如果此文件已存在，则不需要创建，如果不存在，则创建\n5、双击刚新建的AllowEncryptionOracle，将数值数据修改为2\n","description":"\n","tags":[],"title":"\nWindows远程桌面出现CredSSP加密数据修正问题解决方案","uri":"/posts/post-231/"},{"categories":["默认分类"],"content":"现象 一台安装有Windows 8 Enterprise x64系统的计算机，试图安装VMware Workstation 15.5时报错“Setup failed to generate the SSL keys necessary to run VMWare Server. Click Ok to cancel this installation.（大意为：安装程序无法生成VMware Server所需的SSL密钥，请单击‘确定’，终止安装程序。）”。\n可能的原因 查阅资料显示，这一问题可能与错误的系统时间、DirectX配置不正确、没有正确安装的Visual C++运行库、PATH环境变量中包含指向VMware不支持的OpenSSL程序版本的路径等问题有关。\n解决方案 经排查，VMware Workstation 15.5的安装程序会自动安装Microsoft Visual C++ 2015-2019 Redistributable，但似乎存在问题，可以先从 [控制面板] \u003e [程序和功能] 页面删除Microsoft Visual C++ 2015-2019 Redistributable (x86)和Microsoft Visual C++ 2015-2019 Redistributable (x64)，然后从 Microsoft下载中心下载Microsoft Visual C++ 2015 Redistributable Update 3 (x86)和Microsoft Visual C++ 2015 Redistributable Update 3 (x64)并安装。随后，重新执行VMware Workstation安装程序，问题解决。\n参考资料 https://kb.vmware.com/s/article/1008179\nhttp://element-ui.cn/article/show-85929.aspx\nhttps://www.cnblogs.com/d9394/p/13776623.html\nhttps://blog.csdn.net/weixin_37949588/article/details/106306033\n","description":"\n","tags":[],"title":"\nVMWare Workstation无法生成SSL密钥导致安装失败问题","uri":"/posts/post-232/"},{"categories":["默认分类"],"content":"1.首先解释一下报错原因： stanford parser和jdk版本对应关系\nJ2SE 8 = 52, J2SE 7 = 51, J2SE 6.0 = 50, J2SE 5.0 = 49, JDK 1.4 = 48, JDK 1.3 = 47, JDK 1.2 = 46, JDK 1.1 = 45 Unsupported major.minor version 52.0: 看到Unsupported你是不是会想到jdk高版本能兼容低版本，但是低版本不能兼容高版本，不错，猜对了，其实就是这个意思。这个错误意思是你项目用JDK1.8运行过，现在又在本地的eclipse等开发工具或者本地环境变量为低版本的jdk1.7或者jdk1.6下运行，eclipse会说：“抱歉，我本地jdk版本太低，不支持这个高级版本jdk1.8编译过的项目运行”。\n你看看你本地是报52还是51或者其他的错。\n2.配置jdk解决问题： 这几个地方jdk要一致：\n看看你系统的jdk环境变量配置的是jdk那个版本\nWindows—— Preferences——Java——Compiler——设为jdk1.8\n在此页面的Java——Installed JREs——设为jdk1.8\n关闭此页面，项目右键（或者core包）——Build Path（也可是Properties）——Configure Build Path——Java Build Path——Libraries下面的JRE System Library改为jdk1.8（此处设置见参考3），保证旁边的Order and Export这个jdk与之相同\n同页面的Java Compiler选项改为jdk1.8\n同页面的Project Facets——右侧的Java改为1.8（此项也可以不改）\n如果还不行看看你的Eclipse的Server里配置的tomcat和jdk版本是否不同：\nWindows——Preference——Server——Runtime Environments——点击你要用的tomcat——点击Edit ——在弹出面板的JRE中选择和你项目对应的jdk版本\n如果上述还不管用的话试试： 修改org.eclipse.wst.common.project.facet.core.xml： 打开项目所在的文件夹，打开.settings文件夹，修改里面的“org.eclipse.wst.common.project.facet.core.xml”文件\n如我的路径是：D:\\cctv5cms\\maven.1490956540309\\cms-cms\\cms-core.settings\\org.eclipse.wst.common.project.facet.core.xml\n本文链接：http://blog.csdn.net/superit401/article/details/72731381\n参考1：https://www.zifangsky.cn/600.html\n参考2：http://bbs.csdn.net/topics/391873068\n参考3：http://www.oschina.net/question/207494_84715\n","description":"\n","tags":[],"title":"\nUnsupported major.minor version 52.0解决办法","uri":"/posts/post-233/"},{"categories":["默认分类"],"content":"1. 官网下载安装包 下载地址： https://dev.mysql.com/downloads/mysql/\n通过下载页面可以选择安装包或者是压缩包。\n这里选择安装文件（Installer MSI）\n2. 点击下载的程序包安装 2.1 选择安装类型\n选择【Server only】然后【Next】\n2.2 安装前提检查\n如果电脑上之前没有安装Microsoft Visual C++环境的话， 会自动弹出MS Visual C++的安装页面，进行安装即可。\n点击【Execute】\n安装MS Visual C++:\n设置成功后，点击【关闭】：\n2.3 再次安装前提检查 MS Visual C++的安装后，再次进入安装前提检查页面，继续安装MySQL。\n点击【Next】:\n点击【Execute】:\n点击【Next】:\n2.4 High Availability选择 选择【Standalone】选项\n2.5 端口号等设置 端口号等保持默认即可,点击【Next】。\n2.6 认证方式等设置 选择推荐方式，点击【Next】。\n2.7 Root密码等设置 设置MySQL root用户的登录密码。\n这里输入密码：root\n2.8 Windowns服务注册 点击【Next】:\n2.9 安装过程等待 点击【Next】:\n2.10 安装结束 点击【Next】，结束安装。\n2.11 安装后产品配置 点击【Next】：\n2.12 保存安装日志。 点击【Copy Log to Clipboard】,保存安装日志方便安装问题的调查。\n3. 安装成功后，验证 通过开始菜单（Win键）调用MySQL命令行客户端（MySQL Command Line Client），就可以进行MySQL操作了。\n点击开始菜单（Win键），找到安装的MySQL文件夹。\n点击【MySQL 8.0 Command Line Client】,然后输入密码开始MySQL之旅。\n4. MySQL的路径设置 按照上面的方法安装MySQL后，可以通过开始菜单（Win键）调用MySQL命令行，也可以通过Windows的【命令提示符】调用MySQL监视器对MySQL进行操作。 默认安装情况下MySQL监视器是放在以下路径中：\n1 C:\\Program Files\\MySQL\\MySQL Server 8.0\\bin 所以，要想启动的话，需要先移动到这个文件夹中。\n在【系统变量】或者【用户变量】中，选择变量【Path】，点击【编辑】-\u003e【新建】，输入上面的MySQL路径“C:\\Program Files\\MySQL\\MySQL Server 8.0\\bin”。这样，以后在Windows命令行中调用MySQL命令行就不用每次都移动文件夹了。\n转载于：https://cloud.tencent.com/developer/article/1636375\n","description":"\n","tags":[],"title":"\n手把手教你在Windows 10安装MySQL 8.0（详细图文）","uri":"/posts/post-234/"},{"categories":["默认分类"],"content":" $(\"\").load()中文乱码问题\nJSP 请求页面\n$(\"#baseLineThreeCenterTab\").load(basePath+\"/pro/baseline/gotoProConfigBaseLineMain.action?parameter=\"+parameter); java后台接收的如：parameter=“中文”，则会出现乱码。\n解决方法：\nJSP页面 // encodeURI()编码\t$(\"#baseLineThreeCenterTab\").load(basePath+\"/pro/baseline/gotoProConfigBaseLineMain.action?parameter=\"+encodeURI(parameter)); JAVA: // URLDecoder.decode(parameter, \"utf-8\");解码 import java.net.URLDecoder; String parameter = URLDecoder.decode(parameter, \"utf-8\"); ","description":"\n","tags":[],"title":"\njquery中load中文乱码的解决方法","uri":"/posts/post-235/"},{"categories":["默认分类"],"content":"原因 谷歌(Google)以使用率低为由，停止了Google翻译在中国大陆的服务，Google翻译退出中国,仅存唯一功能也没了.\n现象 点击翻译无反应,依然显示英文.\n分析 我们通过抓包工具可以看见翻译的时候会访问 https://translate.googleapis.com\ntranslate.googleapis.com（Google 翻译 API）,因为停止了中国大陆的服务,不再分配中国内地的服务器地址，所以浏览器内置的 Google 翻译无法使用\n浏览器内置API不支持扩展配置的socks5代理，所以挂梯子是无效的，除非用系统代理。\n解决方法 Google 在中国开展业务的相关网站所使用的 IP 地址都是共享的，包括谷歌翻译业务在内，因此只要能找到你能正常访问的 Google 服务的相关域名，比如谷歌中国主页、能够在网页上正常加载的 Adsense 广告或 Analytics 统计所使用的 JavaScript 脚本文件网址等，就可以很轻松的获取到在你所在的网络环境中可以正常使用的 IP 地址。获取到可用 IP 地址后，将其添加到操作系统的 hosts 文件，使其映射到谷歌翻译 API 所使用的域名，Chrome 翻译功能就能正常使用了。\n下面是获取可用 IP 地址以及修改 Windows 系统和 macOS 系统 hosts 文件的具体方法。\n手动 可以编辑HOSTS文件对域名的地址解析进行修正\n由于 translate.googleapis.com 采用与 google.cn 相同的 IP地址，可以先ping一下得到对应的IP再修改HOSTS文件。\n1 2 3 4 5 6 7 8 9 10 # 打开终端或者CMD 得到IP地址 ping google.cn # windows C:\\Windows\\System32\\drivers\\etc\\hosts # Linux / MacOS /etc/hosts # 在文件中添加一行保存即可，格式示例（自己根据通过 `ping google.cn` 得到的地址修改前面的IP地址）： 114.250.65.34 translate.googleapis.com 自动 windows 为简化操作，已手动修改 hosts 文件的步骤写成了批处理脚本，只需一键即可完成所有修改步骤。\n下载批处理脚本：fix-google-translate-cn.bat 使用方法很简单，下载完成并解压缩，在批处理文件上点击右键，在弹出的菜单中点击【以管理员身份运行】即可。如果看到如下所示提示，表示规则添加成功，Chrome 翻译就恢复正常了。\nAdding the rule \"114.250.65.34 translate.googleapis.com\" Done. 请按任意键继续... 此脚本可以重复使用。添加规则后再次使用时会出现交互提示信息，输入 1 会尝试更新已添加规则的 IP 地址，如果没有变化则不做任何修改，输入 2 会删除已添加的规则。\nlinux\u0026MacOS 为简化操作，已将手动修改 hosts 文件的步骤写成了 Shell 脚本，只需一键即可完成所有修改步骤。\n打开“终端”，拷贝以下命令并将其粘贴到终端上，按回车，输入你的系统密码，再按回车。注意，输入密码时是不显示任何信息的，只要确保输入的密码是正确的就可以。\nsudo bash -c \"$(curl -skL https://nas.mrf.ink:3000/tools/shell/raw/master/browser/fix-google-translate-cn/mac\u0026linux.sh)\" 如果看到如下所示提示，表示规则添加成功，也就可以正常使用 Chrome 的谷歌翻译功能了。\nAdding the rule \"114.250.65.34 translate.googleapis.com\" Done. 结果 可以看出再次翻译显示中文了.\n","description":"\n","tags":[],"title":"\nChrome浏览器内置翻译无法使用,右键翻译无反应?（已失效）","uri":"/posts/post-236/"},{"categories":["默认分类"],"content":" mysql 批量更新如果一条条去更新效率是相当的慢, 循环一条一条的更新记录,一条记录update一次，这样性能很差，也很容易造成阻塞。mysql 批量更新共有四种办法\nreplace into 批量更新 1 replace into test_tbl (id,dr) values (1,'2'),(2,'3'),...(x,'y'); insert into …on duplicate key update批量更新 1 insert into test_tbl (id,dr) values (1,'2'),(2,'3'),...(x,'y') on duplicate key update dr=values(dr); 创建临时表，先更新临时表，然后从临时表中update 1 2 3 create temporary table tmp(id int(4) primary key,dr varchar(50)); insert into tmp values (0,'gone'), (1,'xx'),...(m,'yy'); update test_tbl, tmp set test_tbl.dr=tmp.dr where test_tbl.id=tmp.id; 注意：这种方法需要用户有temporary 表的create 权限。\n使用mysql 自带的语句构建批量更新 mysql 实现批量 可以用点小技巧来实现:\n1 2 3 4 5 6 7 UPDATE tableName SET orderId = CASE id WHEN 1 THEN 3 WHEN 2 THEN 4 WHEN 3 THEN 5 END WHERE id IN (1,2,3) 这句sql 的意思是，更新orderId 字段，如果id=1 则orderId 的值为3，如果id=2 则orderId 的值为4…… where部分不影响代码的执行，但是会提高sql执行的效率。确保sql语句仅执行需要修改的行数，这里只有3条数据进行更新，而where子句确保只有3行数据执行。\n如果更新多个值的话，只需要稍加修改：\n1 2 3 4 5 6 7 8 9 10 11 12 UPDATE categories SET orderId = CASE id WHEN 1 THEN 3 WHEN 2 THEN 4 WHEN 3 THEN 5 END, title = CASE id WHEN 1 THEN 'New Title 1' WHEN 2 THEN 'New Title 2' WHEN 3 THEN 'New Title 3' END WHERE id IN (1,2,3) 到这里，已经完成一条mysql语句更新多条记录了。\n总结 更新 100000条数据的性能就测试结果来看，测试当时使用replace into性能较好。\nreplace into 和 insert into on duplicate key update的不同在于：\nreplace into 操作本质是对重复的记录先delete 后insert，如果更新的字段不全会将缺失的字段置为缺省值，用这个要悠着点否则不小心清空大量数据可不是闹着玩的。 insert into 则是只update重复记录，不会改变其它字段。\n","description":"\n","tags":[],"title":"\n大批量更新数据mysql批量更新的四种方法","uri":"/posts/post-237/"},{"categories":["默认分类"],"content":"数据库相关信息 查看 confluence.home 配置\n1 cat /opt/atlassian/confluence/confluence/WEB-INF/classes/confluence-init.properties | grep confluence.home 在 confluence.home 下面的 confluence.cfg.xml 文件里面查看数据库信息\n1 cat /var/atlassian/application-data/confluence/confluence.cfg.xml | grep connection 修改管理员密码 登录数据库\nmysql -hlocalhost -uconfluence -p confluence 在数据库里面查看管理员用户\n1 2 3 select u.id, u.user_name, u.active from cwd_user u join cwd_membership m on u.id=m.child_user_id join cwd_group g on m.parent_id=g.id join cwd_directory d on d.id=g.directory_id where g.group_name = 'confluence-administrators' and d.directory_name='Confluence Internal Directory'; 更新管理员用户密码为 admin\n1 2 3 update cwd_user set credential = 'x61Ey612Kl2gpFL56FT9weDnpSo4AV8j8+qx2AuTHdRyY036xxzTTrw10Wq3+4qQyB+XURPWx1ONxp3Y3pB37A==' where id=xxxxxx; # 这里需要改成 393217 注意此处xxxxxx 为上一步的 id\n如果你的密码是{PKCS5S2}前缀开头的，则用下面这个sql:\n1 2 3 update cwd_user set credential = '{PKCS5S2}ltrb9LlmZ0QDCJvktxd45WgYLOgPt2XTV8X7av2p0mhPvIwofs9bHYVz2OXQ6/kF' where id=xxxxxx; 这个管理员密码为 Ab123456\n","description":"\n","tags":[],"title":"\nconfluence 忘记密码","uri":"/posts/post-238/"},{"categories":["默认分类"],"content":" 在平时我们打包会将其打成Jar，那么在其他平台运行的时候就需要安装jre来支持运行。我们用的是javapackager,javapackager是jdk1.8自带的一个打包工具，可以生成各个系统的安装包\n准备工作 innosetup-5.6.0.exe（windows下Java8支持6版本以下的，不要下载6及其6以上的版本，否则无法打包成功） wix（打包成msi必须下载，没有下载javapackager会提示缺少wix） JDK8 用法 javapackager command [options] command :应该执行的任务\n[options] :以空格分隔的命令的一个或多个选项\nCommands 您可以指定以下命令之一。在命令之后，指定它的选项。\n-createbss:将 CSS 文件转换为二进制形式。 -createjar:根据其他参数生成 JAR 存档。 -deploy:组装应用程序包以进行重新分发。默认情况下，部署任务会生成基础应用程序包，但如果需要，它也可以生成自包含的应用程序包。 -makeall:使用预定义的大多数参数，一次调用执行编译、createjar和deploy步骤，并尝试生成所有适用的自包含应用程序包。源文件必须位于名为 的文件夹src中，生成的文件（JAR、JNLP、HTML 和自包含应用程序包）位于名为 的文件夹中dist。此命令只能以最少的方式配置，并且尽可能自动化。 -signjar:使用提供的证书对 JAR 文件进行签名。 createbss 命令的选项 -outdir dir: 将接收生成的输出文件的目录的名称。\n-srcdir dir:要打包的文件的基本目录。\n-srcfiles files:-srcdir选项指定的目录中的文件列表。如果省略，将使用目录中的所有文件（在这种情况下这是一个强制参数）。列表中的文件必须用空格分隔。\ncreatejar 命令的选项 -appclass app-class:要执行的应用程序类的限定名称。\n-argument arg:要作为\u003cfx:argument\u003e元素插入到 JNLP 文件中的未命名参数。\n-classpath files:相关 JAR 文件名列表。\n-manifestAttrs manifest-attributes:其他清单属性的名称和值列表。句法：“名称 1=值 1，名称 2=值 2，名称 3=值 3”\n-nocss2bin:打包器在复制到 JAR 之前不会将 CSS 文件转换为二进制形式。\n-outdir dir:将接收生成的输出文件的目录的名称。\n-outfile filename:将生成的文件的名称（不带扩展名）。\n-paramfile file:具有默认命名应用程序参数的属性文件。\n-preloader preloader-class:要执行的 JavaFX 预加载器类的限定名称。此选项仅用于 JavaFX 应用程序。不要用于 Java 应用程序，包括无头应用程序。\n-srcdir dir:要打包的文件的基本目录。\n-srcfiles files:-srcdir选项指定的目录中的文件列表。如果省略，将使用目录中的所有文件（在这种情况下这是一个强制参数）。列表中的文件必须用空格分隔。\ndeploy命令的选项 -allpermissions:如果存在，应用程序将需要 JNLP 文件中的所有安全权限。\n-appclass app-class:要执行的应用程序类的限定名称。 就是详细包名+类名，也就是程序的入口类的全类名\n-argument arg:要插入到fx:argumentJNLP 文件中的元素中的未命名参数。\n-Bbundler-argument=value: 向用于打包自包含应用程序的捆绑程序提供信息。有关每个捆绑器的参数的信息，请参阅自包含应用程序捆绑器的参数。\n-callbacks:在生成的 HTML 中指定用户回调方法。格式如下：“名称 1：值 1，名称 2：值 2，…”\n-description description:应用程序的描述。\n-embedCertificates:如果存在，证书将嵌入 JNLP 文件中。\n-embedjnlp:如果存在，JNLP 文件将嵌入到 HTML 文档中。\n-height height:应用程序的高度。\n-htmlparamfile file:属性文件，其中包含在浏览器中运行时生成的应用程序的参数。\n-isExtension:如果存在，则将srcfiles其视为扩展。\n-name name:应用程序的名称。\n-native type:生成独立的应用程序包（如果可能）。使用该-B选项为正在使用的捆绑器提供参数。如果指定了类型，则仅创建此类型的捆绑包。如果未指定类型，all则使用。\n以下值对type有效： * `all`：为运行它的平台运行所有安装程序，并为应用程序创建磁盘映像。如果未指定类型，则使用此值。 * `installer`：运行它所在平台的所有安装程序。 * `image`：为应用程序创建磁盘映像。创建原生的镜像(打成window的exe)。 * `exe`: 生成一个 Windows`.exe`包。 * `msi`：生成一个 Windows 安装程序包。 -outdir dir:将接收生成的输出文件的目录的名称。\n-outfile filename:将生成的文件的名称（不带扩展名）。\n-paramfile file:具有默认命名应用程序参数的属性文件。\n-preloader preloader-class:要执行的 JavaFX 预加载器类的限定名称。此选项仅用于 JavaFX 应用程序。不要用于 Java 应用程序，包括无头应用程序。\n-srcdir dir:要打包的文件的基本目录。就是我们之前包含jar文件的文件夹(注意这里不是java源代码目录)\n-srcfiles files:-srcdir选项指定的目录中的文件列表。如果省略，将使用目录中的所有文件（在这种情况下这是一个强制参数）。列表中的文件必须用空格分隔。\n20 -templateId:模板处理应用的应用ID。\n21 -templateInFilename:HTML 模板文件的名称。占位符采用以下形式：#XXXX.YYYY(APPID)#\n其中 APPID 是应用程序的标识符，XXX 是以下之一： DT.SCRIPT.URLdtjava.js 在部署工具包中的位置。默认情况下，位置是http://java.com/js/dtjava.js DT.SCRIPT.CODE包含部署工具包的 dtjava.js 的脚本元素。 DT.EMBED.CODE.DYNAMIC将应用程序嵌入给定占位符的代码。预计代码将被包装在function()方法中。 DT.EMBED.CODE.ONLOAD使用钩子将应用程序嵌入网页所需的所有代码onload（包含 dtjava.js 除外）。 DT.LAUNCH.CODE启动应用程序所需的代码。预计代码将被包装在function()方法中。 22 -templateOutFilename:将从模板生成的 HTML 文件的名称。\n23 -title title:应用程序的标题。\n24 -vendor vendor:应用程序的供应商。\n25 -width width:应用程序的宽度。\n26 -updatemode update-mode:设置 JNLP 文件的更新模式。\nmakeall 命令的选项 -appclass app-class:要执行的应用程序类的限定名称。\n-classpath files:相关 JAR 文件名列表。\n-height height:应用程序的高度。\n-name name:应用程序的名称。\n-preloader preloader-class:要执行的 JavaFX 预加载器类的限定名称。此选项仅用于 JavaFX 应用程序。不要用于 Java 应用程序，包括无头应用程序。\n-width width:应用程序的宽度。\nsignjar 命令的选项 -alias:密钥的别名。 -keyPass:用于恢复密钥的密码。 -keyStore file:密钥库文件名。 -outdir dir:将接收生成的输出文件的目录的名称。 -srcdir dir:要签名的文件的基本目录。 -srcfiles files:-srcdir选项指定的目录中的文件列表。如果省略，将使用目录中的所有文件（在这种情况下这是一个强制参数）。列表中的文件必须用空格分隔。 -storePass:检查密钥库完整性或解锁密钥库的密码 -storeType:密钥库类型。默认值为“jks”。 应用程序捆绑的参数 这些自定义的bundle参数在使用的时候要注意，-B加上参数名=值 例如 icon 使用的时候就是 -Bicon=“path\n该命令的-B选项用于-deploy指定用于创建自包含应用程序的捆绑程序的参数。每种类型的捆绑器都有自己的一组参数。\nappVersion=version:应用程序包的版本。一些捆绑器会限制版本字符串的格式。\nclassPath=path :相对于组装的应用程序目录的类路径。javapackager该路径通常从 JAR 文件清单中提取，如果您使用其他命令，则不需要设置。\nicon=path:用于启动器和其他辅助的默认图标的位置。对于 Windows，格式必须为.ico.\nidentifier=value:用于其他平台特定值的默认值，例如mac.CFBundleIdentifier. 建议使用反向 DNS 顺序，例如com.example.application.my-application.\njvmOptions=option:运行应用程序时传递给 JVM 的选项。java可以使用对命令有效的任何选项。要传递多个选项，请使用该-B选项的多个实例，如下例所示：-BjvmOptions=-Xmx128m -BjvmOptions=-Xms128m`\njvmProperties=property=value:运行应用程序时要传递给 VM 的 Java 系统属性。可以使用-D对命令选项有效的任何属性。java指定属性名称和属性值。要传递多个属性，请使用该-B选项的多个实例，如下例所示：-BjvmProperties=apiUserName=示例 -BjvmProperties=apiKey=abcdef1234567890\nmainJar=filename:包含应用程序主类的 JAR 文件的名称。javapackager文件名通常从 JAR 文件清单中提取，如果您使用其他命令，则不需要设置。\npreferencesID=node:要检查的首选项节点以检查用户可以覆盖的 JVM 选项。指定的节点在运行时作为选项传递给应用程序-Dapp.preferences.id。此参数与userJVMOptions参数一起使用。\nruntime=path:运行时=路径要包含在包中的 JRE 或 JDK 的位置。提供 JDK 或 JRE 的根文件夹的文件路径。要使用系统默认的 JRE，请不要提供路径，如下例所示：-Bruntime=\nserJvmOptions=option=value:用户可以覆盖的 JVM 选项。java可以使用对命令有效的任何选项。指定选项名称和选项的值。要传递多个选项，请使用该-B选项的多个实例，如下例所示：-BuserJvmOptions=-Xmx=128m -BuserJvmOptions=-Xms=128m\nWindows EXE Bundler 参数 copyright=string:应用程序的版权字符串。字符串必须是不超过 100 个字符的单行。此参数用于各种 exe 和注册表元数据。\nlicenseFile=path:捆绑商提供或记录的最终用户许可协议 (EULA) 的位置。该路径是相对于打包的应用程序资源的，例如-BlicenseFile=COPYING.\nmenuHint=boolean:指示快捷方式是否安装在开始菜单或开始屏幕上的标志。设置为true安装快捷方式。默认值为true.\nortcutHint=boolean:指示快捷方式是否放置在桌面上的标志。设置为true向桌面添加快捷方式。默认值为false.\nsystemWide=boolean:指示应用程序是安装在 Program Files 中还是安装在用户主目录中的标准位置的标志。设置为true在 Program Files 中安装应用程序。设置为false将应用程序安装在用户的主目录中。默认值为false.\nwin.menuGroup=group:何时安装应用程序的菜单menuHint组true。menuHint当is时，该参数被忽略false。\nvendor=value:提供申请的公司、组织或个人。此参数用于各种 exe 和注册表元数据。\nWindows MSI Bundler 参数 menuHint=boolean:指示快捷方式是否安装在开始菜单或开始屏幕上的标志。设置为true安装快捷方式。默认值为true.\nshortcutHint=boolean:指示快捷方式是否放置在桌面上的标志。设置为true向桌面添加快捷方式。默认值为false.\nsystemWide=boolean:指示应用程序是安装在 Program Files 中还是安装在用户主目录中的标准位置的标志。设置为true在 Program Files 中安装应用程序。设置为false将应用程序安装在用户的主目录中。默认值为true.\nwin.menuGroup=group:何时安装应用程序的菜单menuHint组true。menuHint当is时，该参数被忽略false。\nvendor=value:提供申请的公司、组织或个人。此参数用于各种 exe 和注册表元数据。\n不推荐使用的选项 打包工具不再使用以下选项，如果存在则将其忽略。\n-runtimeversion version:所需 JavaFX 运行时的版本。已弃用。 -noembedlauncher:如果存在，打包程序不会将 JavaFX 启动器类添加到 JAR 文件中。已弃用。 -v选项可以与任何任务命令一起使用以启用详细输出。\n当-srcdir命令中允许该选项时，它可以多次使用。如果指定了该选项，则将在前面选项-srcfiles中指定的位置查找参数中命名的文件。srcdir如果没有-srcdir前面的 ，则使用执行命令-srcfiles的目录。javapackager\n例子 使用 -createjar 命令 javapackager -createjar -appclass package.ClassName -srcdir classes -outdir out -outfile outjar -v classes将目录的内容打包为outjar.jar，将应用程序类设置为package.ClassName。\n使用 -deploy 命令 javapackager -deploy -outdir outdir -outfile outfile -width 34 -height 43 -name AppName -appclass package.ClassName -v -srcdir compiled 为应用程序生成outfile.jnlp和对应的outfile.html文件，它由34 x 43 像素启动并具有尺寸。outdir``AppName``package.ClassName\n使用 -makeall 命令 javapackager -makeall -appclass brickbreaker.Main -name BrickBreaker -width 600 -height 600 是否所有打包工作，包括编译createjar、和deploy.\n使用 -signjar 命令 javapackager -signJar --outdir dist -keyStore sampleKeystore.jks -storePass **** -alias duke -keypass **** -srcdir dist 对目录中的所有 JAR 文件进行签名dist，附加具有指定别名的证书，keyStore然后storePass将签名的 JAR 文件放回dist目录中。\n将 -deploy 命令与 Bundler 参数一起使用 javapackager -deploy -native exe -BsystemWide=true -BjvmOptions=-Xmx128m -BjvmOptions=-Xms128m -outdir packages -outfile BrickBreaker -srcdir dist -srcfiles BrickBreaker.jar -appclass brickbreaker.Main -name BrickBreaker -title \"BrickBreaker demo\" 生成本机 Windows EXE 包，用于将 BrickBreaker 应用程序作为自包含应用程序运行。\njavapackager -deploy -native -outdir packages -outfile md5 -srcfiles md5.jar -appclass com.sysware.md5.MyFrame -name md5 生成本机安装包(在linux下生成deb,在windows下生成exe,在mac下生成dkg)，用于将 md5.jar 应用程序作为自包含应用程序运行。\n分析一下\njavapackager---java8自带的打包程序 -deploy---用来构建目标机器的发行版本，简单说就是打包成exe或者其他平台的包，如果不带任何参数，会生成一个基本的应用程序，不建议不带任何参数 -native image---为jar创建磁盘镜像（可以将image替换为其他的类型，例如exe，msi，deb，rpm,dmg,pkg,省略就是该系统支持的文件格式） -outdir packages---输出目录。 -outfile md5----输出文件（不要带后缀，比如md5.exe，就写md5就行了）。 -srcfiles md5.jar---要打包的jar文件。 -appclass com.sysware.md5.MyFrame---jar文件的主类的全限定名。（注意是全限定名） -name md5---启动之后的应用名称 文章翻译自:https://docs.oracle.com/javase/8/docs/technotes/tools/windows/javapackager.html\n","description":"\n","tags":[],"title":"\n使用javapackager打包各系统安装包","uri":"/posts/post-239/"},{"categories":["默认分类"],"content":" 怎么调?其实主要是看配料表,国家严格要求,按照配料东西的比例有大到小写的顺序\n普及一下 谷氨酸钠=味精\n呈味核=增味剂\n苯甲酸钠=防腐剂\n山梨酸钾=防腐剂\n氯化钠=盐\n酵母提取物=味精\n香油怎么选 工艺:水代的比压榨的好\n产地:国产的比埃塞俄比亚就好\n味精鸡精的秘密 其实都是提鲜的,其实味精是最干净的 用小麦提炼的\n鸡精中比例最大的就是味精\n酱油怎么选 生抽:增鲜提味用的\n老抽:菜上色用的\n其他功能性的:蒸鱼的,吃海鲜的,草菇,极味鲜,鲜上鲜 其实是生抽的一种,其实没必要买,里面的配料都有谷氨酸钠,呈味核,目的是发酵时间不够,添加出来的味道.买酱油肯定是吃自然发酵的,\n配料中有一个脱脂大豆,其实就是炼油厂脱完脂的大豆的豆渣,酱油厂商为了降低成本所以使用这些脱脂大豆,好的酱油都是用全脂大豆,像非转基因大豆,小麦粉酿出来的才是好酱油\n白酒怎么选 不说那些茅台,五粮液啥的太贵了,不是我们喝的,就说一下性价比最高的高粱酒\n执行标准分三类:液态法白酒,固液态法白酒和固态法白酒\n液态法白酒:其实也是蒸馏出来的,但是不是用粮食酿出来的,就是红薯类似的东西加上食用酒精和香精勾兑出来的,市面上已经比较少了\n固液态法白酒:一部分是纯粮 酿造出来的,另一部分就是用红薯干酿造出来一起兑的,市面上百分之八九十写的纯粮食酿的就是用固液态法\n固态法白酒:纯粮食做基础酿造出来的\n为什么找纯粮的酒,他醒酒快,口不干,第二天也不难受,所以我们买酒买固态法白酒,\n执行编号:G/BT20761 酱香型 G/BT10781.2 清香型 G/BT10781.1 浓香型\n白醋怎么选 不要选带冰醋精的没啥营养价值,价格便宜,酸度非常酸.也不要选苯甲酸钠的,有这个说明原材料成分很低,水的成分高\n白醋最基本的就是用大米或者糯米发酵而成的.用了酒精说明是一种速成不是自然发酵而成的,可以吃但是不是一个营养价值非常好的白醋\n白醋适合做热菜,米醋的酸度比较柔和适合做凉菜\n陈醋怎么选 三个点:酸度,执行标准号,配料\n焦糖色:专门用来调颜色的,一般是醋的发酵时间不够,加焦糖色,调一下颜色\n苯甲酸钠:防腐剂,因为酸度不够,怕坏了\n酸度在5%以上,都是固态发酵\n陈醋:gb/t 18187,只不过工艺不一样,用高粱发酵的酸度高一些,糯米的酸中有一些回甜\n山西老陈醋:执行标准必须是gb/t 19777.第二配料一定是高粱,用高粱发酵的\n镇江香醋:gb/t 18623,酸度柔和,第二配料一定是糯米,用糯米发酵的\n一般炒菜用陈醋,拌凉菜用香醋\n盐怎么选 背景:因为七八十年代大部分人缺碘,出现了大脖子病,1995年国家要求全民吃碘盐最近这几年得甲亢的或者高碘区的人,他们摄入的碘已经够了,没有卖不加碘的盐,2017年国家又放开了政策出现了海藻盐,不含碘盐,低钠盐,低钠海藻盐,还有岩盐.\n不加碘的盐:如果你经常吃海带,海藻,海鱼,海虾等海产品比较多或者你有甲亢.其实你本身 碘的补充是多了,这时候不含碘的盐才适合你吃.\n低钠盐:高血压,心脏病呀这类患者适合吃低钠盐,普通盐里面氯化钠含量很高,会促使血管膨胀,血流加快\n岩盐:比较高端的一种盐,也叫喜马拉雅盐,矿物质含量比较多,一般在高档餐厅,高档烤肉或者一些料理餐厅中,一般炒菜用不到这种,有钱人随意哈,\n耗油怎么选 谷氨酸钠(味精),呈味核(味精精) 为啥要加这些因为耗的成分少,我们是要吃用耗提炼出来的精华去做菜,让味道更鲜美,不是吃水掺了的酱油加了一些耗油的耗油汁,\n山梨酸钾,苯甲酸钠 其实就是防腐剂,因为水的比例比较多,容易坏所以加这些防腐剂\n一般配料表中第一位是耗汁的才是好耗油,没有防腐剂的当然没有味精焦糖色更好,不过市面上很少见没有添加味精的.\n食用油怎么选 低档油 调和油:看配料表 现在比较争议比较大的 转基因的好不好 这个我也不知道,但是非转基因的肯定没问题,\n调和油没有加工工艺\n中档油 食用油的三种加工工艺:浸出,热压(热榨),冷压(冷榨)\n浸出:用化学试剂去浸泡,再去压榨,再去脱酸脱臭的一些处理,里面有一些试剂的残留,不过国家允许范围内,这种不太健康,不过便宜 因为出油率高.\n热榨:温度在60以上,相对冷榨出油率高,所以性价比好一些,没必要买冷榨的除了贵 ,没太多优点,营养价值比不上高档油\n还有一个问题一级,S级,浓香,特级和油的品质一毛钱关系都没有不用关心这个\n油我们除了吃一个口味外还有一个营养价值饱和脂肪酸的含量和不饱和脂肪酸的含量\n饱和脂肪酸尽量少吃,容易三高,脂肪含量高,各方面数据高,不饱和脂肪酸高可以防止三高这些东西\n不饱和脂肪酸有单不饱和脂肪酸和多不饱和脂肪酸\n中档油中不同油脂单不饱和脂肪酸的含量从高到低\n橄榄油\u003e油茶籽油\u003e一般菜籽油\u003e低芥酸菜籽油\u003e花生油\u003e米糠油\u003e芝麻油\u003e棕榈油\u003e玉米油\u003e花椒籽油\u003e葵花籽油\u003e亚麻籽油\u003e鸡油\u003e大豆油\u003e葡萄籽油\u003e鸭油\u003e核桃油\u003e红花籽油\u003e羊油\u003e棉籽油\u003e牛油\u003e猪油\n中档油中不同油脂多不饱和脂肪酸的含量从高到低\n牛油\u003e羊油\u003e猪油\u003e鸭油\u003e鸡油\u003e棕榈油\u003e棉籽油\u003e花生油\u003e橄榄油\u003e米糠油\u003e玉米油\u003e芝麻油\u003e大豆油\u003e葡萄籽油\u003e花椒籽油\u003e葵花籽油\u003e核桃油\u003e亚麻籽油\u003e一般菜籽油\u003e红花籽油\u003e低芥酸籽油\u003e油茶籽油\n葵花籽油和菜籽油这两个混着吃,营养要均衡比如这周吃单不饱和脂肪酸含量最多的 下周吃 多不饱和脂肪酸含量最多的\n高档油 橄榄油,亚麻籽油,核桃油,山茶油都说自己是世界上最好的油\n高档油除了看配料外另外就是能量表\n橄榄油和山茶油 是单不饱和脂肪酸特别高\n亚麻籽油和核桃油,是多不饱和脂肪酸特别高\n橄榄油:看配料 精炼的(是把特级和一级混合到一起了)没有特级的好,橄榄油特点炒菜没有味 不适合中餐\n山茶油:煎炒烹炸炖都合适 ,单不饱和脂肪酸推荐这个\n亚麻籽油和核桃油:能量是一样的,推荐亚麻籽油 因为他便宜五六十一斤 ,核桃油一百五六一斤,这种两油有个问题不耐高温,炒炸不适合,适合拌凉菜啥的\n山茶油炒菜吃,亚麻籽油拌凉菜吃\n番茄沙司怎么选 食品添加剂多的不要买\n冰乙酸 瓜尔胶 柠檬酸 苯甲酸钠 黄原胶 有这写配料的 番茄纯度不高 水的比例高,需要加一些色素,胶增稠.\n番茄沙司就是调制的都是兑的,番茄酱是西红柿打成的酱\n有辣椒粉(增红) 和淀粉添加剂(增稠)的 也可以购买吧\n买就最好买那种无添加剂无淀粉辣椒粉的那种是最好的\n牛奶怎么选 大致分六类\n纯牛奶:营养成分保留最全面的,鲜牛奶高温杀菌而成,分两种巴氏奶和常温奶,巴氏奶保质期短一般最多只有21天,常温奶有6个月不过处理的更复杂,杀菌更多,当然营养成分也会流失一些,纯牛奶配料很简单就一个生牛乳,推荐和巴氏奶,营养和口感都比常温的要好\n舒化奶:也就是无乳糖牛奶,喝牛奶拉肚子,是对常规的牛奶的乳糖,消化系统不接受这种糖.喝常规奶拉肚子就需要喝这种无乳糖样的奶,里面有乳糖酶会把乳糖给水解掉.但是口感喝起来很甜, 营养成分和纯牛奶差不多,选择时候选配料比较干净的就生牛乳和乳糖酶的就行.\n高钙奶:比普通的奶百毫升中多了25毫克钙,里面添加的是碳钙和乳酸钙,这种钙很难吸收,并不比纯牛奶的营养高,平常经常吃奶制品或乳制品或豆制品,没必要买这种奶\n脱脂牛奶:常规奶都是全脂牛奶,脂肪比例在3%,脱脂牛奶通过离心技术把脂肪含量控制在0.5%,但是这种牛奶口味淡,没有那种醇香奶香的味道,和兑了水似的.脱脂过程中,其实维生素ADE也没有了,配料也是只有生牛乳,\n早餐奶:和早餐没啥关系,有大量的添加剂,只不过里面含有奶的成分,其实就是含乳饮料,不推荐这种\n含乳饮料:优酸乳一类的 不推荐\n总结 蚝油:推荐财神蚝油 和 旧庄蚝油(更好)\n酱油:丸庄 黑豆原汁酱油 不是原酿酱油,千禾 380天零添加酱油不是180天的(有脱脂大豆)\n香醋:镇江恒顺香醋\n陈醋:千禾 3年窖藏 还有山西老陈醋 国标GB/T19777不是山西陈醋\n白醋:东湖九度白醋和千禾糯米白醋 还有鲁花糯米白醋 选7度以上的 酸度才够 国标号都是GB/T18187\n料酒:欣和有机米香料酒 ,千禾零添加烹调料酒\n食用油:炒菜油推荐菜籽油和葵花籽油,高档点的推荐山茶油\n","description":"\n","tags":[],"title":"\n厨房调料怎么挑?","uri":"/posts/post-240/"},{"categories":["默认分类"],"content":"准备测试数据 CREATE TABLE `employee` ( `id` int NOT NULL AUTO_INCREMENT, `name` varchar(20) DEFAULT NULL, `dep_id` int DEFAULT NULL, `age` int DEFAULT NULL, `salary` decimal(10,2) DEFAULT NULL, `cus_id` int DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci; CREATE TABLE `customer` ( `id` int NOT NULL, `name` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci; CREATE TABLE `department` ( `id` int NOT NULL AUTO_INCREMENT, `deptName` varchar(30) DEFAULT NULL, `address` varchar(40) DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci; -- 测试数据 INSERT INTO employee VALUES ( 1, '鲁班', 1, 10, 1000.00, 1 ); INSERT INTO employee VALUES ( 2, '后裔', 1, 20, 2000.00, 1 ); INSERT INTO employee VALUES ( 3, '孙尚香', 1, 20, 2500.00, 1 ); INSERT INTO employee VALUES ( 4, '凯', 4, 20, 3000.00, 1 ); INSERT INTO employee VALUES ( 5, '典韦', 4, 40, 3500.00, 2 ); INSERT INTO employee VALUES ( 6, '貂蝉', 6, 20, 5000.00, 1 ); INSERT INTO employee VALUES ( 7, '孙膑', 6, 50, 5000.00, 1 ); INSERT INTO employee VALUES ( 8, '蔡文姬', 30, 35, 4000.00, 1 ); -- 测试数据 INSERT INTO department VALUES (1, '研发部(RD)', '2层'); INSERT INTO department VALUES (2, '人事部(HR)', '3层'); INSERT INTO department VALUES (3, '市场部(MK)', '4层'); INSERT INTO department VALUES (4, '后勤部(MIS)', '5层'); INSERT INTO department VALUES (5, '财务部(FD)', '6层'); -- 测试数据 INSERT INTO customer VALUES (1, 'zs'); INSERT INTO customer VALUES (2, 'lisi'); INSERT INTO customer VALUES (3, 'wangwu'); explain的简介 mysql中可以使用explain这个关键字来获取（查询）sql语句的查询执行计划的。使用explain关键字，可以模拟mysql优化器执行的sql语句，从而知道mysql是如何处理sql语句的。通过explain可以分析查询语句或表结构的性能瓶颈。\nexplain的作用 ①、查看表的读取顺序\n②、数据读取操作的操作类型\n③、查看哪些索引可以使用\n④、查看哪些索引被实际使用\n⑤、查看表之间的引用\n⑥、查看每张表有多少行被优化器执行\nexplain的使用方法 explain sql语句\nexplain select * from employee; explain执行计划输出中的各个列的详解 id 描述：select查询的序列号,包含一组数字，该组数字表示查询中执行select子句或操作表的顺序\nid值的三种情况如下：\nid相同 -- 分析的sql语句 explain select * from employee e,department d,customer c where e.dep_id = d.id and e.cus_id = c.id; 分析的结果截图：\n从上图中可以看到，id列的值都是1。那么该条sql语句的执行顺序是由上到下，也就是说 先查询的c表 然后查询 e表 最后查询d表。\nid不同 -- 分析的sql语句 EXPLAIN SELECT * from department WHERE id = (SELECT id from employee WHERE id= (SELECT id from customer WHERE id = 1) ) 从上图中可以看到，id列的值是1、2、3。那么该条sql语句的执行顺序是从大到小（由下到上），也就是说 id列的值是3的先执行 其次是id列的值是2 最后是id列的值是1再执行。\n这里都是子查询，如果是子查询，id的序号会递增，id值越大优先级越高，优先被执行。**\nid相同和不同 -- 分析的sql语句 EXPLAIN SELECT * FROM department d, ( SELECT * FROM employee GROUP BY dep_id ) t WHERE d.id = t.dep_id; 从上图中可以看到，id列的值是1、1、2。那么该条sql语句的执行顺序是怎样的呢？根据上面的①和②这里应该也能猜到了。该条sql语句的执行顺序是 先执行id列的值是2的，其次执行id列的值是1的（最上面那个id列的值是1的，也就是table列的值是d），最后执行中间那个id列的值是1的。\n上图中有一个select_type列，其中select_type有一列的值是derived，而derived表示 衍生出来的虚表。再次说明，id值越大，优先级越高，越先执行。\n总结 相同，顺序走（由上到下）,不同，看谁大，大的先执行。\nselect_type **描述：**查询类型，主要用于区别普通查询，联合查询，子查询等复杂查询。\nselect_type列的值主要有以下6种情况：\n①、SIMPLE：简单的select查询，查询中不包含子查询或者UNION\n②、PRIMARY：查询中若包含任何复杂的子查询，那么最外层的查询则被标记为primary\n③、SUBQUERY：在select或where中包含了子查询\n④、DERIVED：在from列表中包含的子查询被标记为derived(衍生)，把结果放在临时表当中。\n⑤、UNION：若第二个select出现在union之后，则被标记为union。若union包含在from子句的子查询中，外层select将被标记为deriver。\n⑥、UNION RESULT：从union表获取结果select。两个UNION合并的结果集在最后。\ntable **描述：**显示当前查询的数据是关于哪张表的。\npartitions 描述：如果查询是基于分区表的话，会显示查询访问的分区。\ntype（重要） 描述：\n表示访问某个表的类型。更专业一点的解释就是：type代表着mysql对某个表的执行查询时的访问方法，其中type列的值就表明了这个访问方法是个啥。通过type可以知道mysql是做了全表扫描还是范围扫描等，从而知道当前的sql语句到底要不要去优化。\ntype列的值一般最常用的有7种，按照最好到最差来排序 分别是：system\u003econst\u003eeq_ref\u003eref\u003erange\u003eindex\u003eALL。\nsystem 表中只有一条记录，并且该表使用的存储引擎的统计数据是精确的，比如MyISAM、Memory，那么该表的type列的值就是system。这是const类型的特例，平时不会出现，也不用奢求将sql优化到这种级别的。\nconst 表示通过索引（主键索引或唯一索引）一次就找到了那一条数据。这里和上面那个system的区别就是 system表里面只能有一条数据，而const表示表中可能会有多条数据，但是const能直接从多条数据中直接定位到那一条数据（通过主键索引或唯一索引）。因为只匹配一行数据，所以const速度很快。\neq_ref 唯一性索引扫描。对于每个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描。\nemployee表中有五条数据，而department表中有对应的五条数据，其中employee的id（主键索引）和department的id（主键索引）是一 一对应的，所以这里就会出现eq_ref，eq_ref也就是这个意思。\neq_ref基本上很难在单表上出现，一般都是在多表的情况下才会出现eq_ref。\nref 非唯一性索引扫描。大白话解释一下就是：出现该连接类型的条件是， 查找条件列使用了索引而且不是使用的主键索引和唯一索引（unique），使用的是普通索引。其实，意思就是虽然使用了索引，但该索引列的值并不唯一，有重复。这样即使 使用索引快速查找到了第一条数据，仍然不能停止扫描，要进行目标值附近的小范围扫描。但它的好处是它并不需要扫全表，因为索引是有序的，即便有重复值，也是在一个非常小的范围内扫描。下面为了演示这种情形，给employee表中的age列添加一个普通的索引\nALTER TABLE employee ADD INDEX idx_age(age) USING BTREE; range 指的是有范围的索引扫描，相对于index的全索引扫描，它有范围限制，因此要优于index。关于range比较容易理解，需要记住的是出现了range，则一定是基于索引的。一般就是在你的where语句中出现between，and，\u003c，\u003e，or，in等查询，那么type列的值就是range\nindex Full Index Scan。index与All区别为index类型只遍历索引树，通常比All要快，因为索引文件通常比数据文件要小。all和index都是读全表，但index是从索引中读取，all是从硬盘当中读取。\nALL 将表中的所有数据进行了扫描（全表扫描），从硬盘当中读取数据。如果出现了All 且数据量非常大，那么该条sql必须去做优化的。\n说下要求：一般来说，要保证SQL查询至少达到range级别，最好能达到ref级别。\npossible_keys **描述：**表示这张表中可能会用到的索引（一个或多个），查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询实际使用到，可能自己创建了4个索引，在实际执行sql查询的时候，根据mysql内部的自动判断，只使用了3个。\nkey（重要） **描述：**mysql在执行的时候实际使用到的索引，如果为NULL，则没有使用索引。\n其它说明：\n查询中若使用了覆盖索引，则该索引仅出现在key列表中。\n覆盖索引：查询的字段和建立的字段刚好吻合，这种我们称为覆盖索引。\npossible_keys与key关系：前者表示理论应该用到哪些索引，后者表示实际用到了哪些索引。\nkey_len **描述：**表示索引中使用的字节数，可通过该列计算查询中使用的索引长度 。下面为了演示这种情形，给employee表添加一个复合索引。\nALTER TABLE employee ADD INDEX idx_name_dep_id_age(name, dep_id, age) USING BTREE; ref 描述：\n索引是否被引入到，到底引用到了哪几个索引。\n这里就不写加索引的语句了，直接上几张截图看吧\nrows 描述：\n根据表的统计信息及索引选用情况，大致估算出找到所需的记录所需要扫描（读取）的行数。表有多少行被优化器查询过。没有建立索引和建立索引之后 rows所显示的数据肯定是不一样的。这里就不进行截图演示了。\nfiltered **描述：**满足查询的记录数量的比例，注意是百分比，不是具体记录数，值越大越好，filtered列的值依赖统计信息，并不十分准确。对于单表查询来说，这个filtered列的值没什么意义，更关注在连接查询中对应的执行计划记录的filtered列的值。关于这里的多表demo也就先不演示了。\nExtra **描述：**顾名思义，Extra列是用来说明一些额外信息的，可以通过这些额外信息来更准确的理解mysql到底将如何执行给定的查询语句。mysql提供的额外信息有好几十个，这里就不一个一个介绍了，只挑一些平时常见的或者比较重要的做下说明。\n①、Using filesort：专业术语成为“文件排序”。说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行。mysql无法利用索引完成排序操作称为\"文件排序\"，当你看到using filesort的时候，那么一定要优化该条sql语句。（得到所需结果集，需要对所有记录进行\"文件排序\" 出现这个 表示该条SQL语句性能较低，需要进行优化）\n**关于filesort的更多详解：**filesort 并不是说通过磁盘文件进行排序，而只是告诉我们进行了一个排序操作。文件排序是通过相应的排序算法，将取得的数据在内存中进行排序。mysql需要将数据在内存中进行排序，所使用的内存区域也就是我们通过 sort_buffer_size 系统变量所设置的排序区。这个排序区是每个 Thread 独享的，所以说可能在同一时刻 在mysql中可能存在多个 sort buffer 内存区域。\nfilesort分两种：\n双路排序：是首先根据相应的条件取出相应的排序字段和可以直接定位行数据的行指针信息，然后在sort buffer 中进行排序。排序后再吧查询字段依照行指针取出，共执行两次磁盘io。\n单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序。 执行一次磁盘io。\n在mysql4.1版本之前只有第一种排序算法 双路排序。第二种算法是从mysql4.1开始的改进算法，主要目的是为了减少第一次算法中需要两次访问表数据的 IO 操作，将两次变成了一次，但相应也会耗用更多的sort buffer 空间。当然，mysql4.1开始的以后所有版本同时也支持第一种算法。\n典型说明：在一个没有建立索引的列上进行了order by，就会触发filesort，常见的优化方案是，在order by的列上添加索引，避免每次查询都全量排序。\nUsing filesort示例截图：\n②、Using temporary：在许多查询的执行过程中，mysql可能会借助临时表来完成一些功能，比如去重、排序之类的，比如我们在执行许多包含DISTINCT、GROUP BY、UNION等子句的查询过程中，如果不能有效利用索引来完成查询，mysql很有可能寻求通过建立内部的临时表来执行查询。如果查询中使用到了内部的临时表，在执行计划的Extra列将会显示using temporary提示。当你看到using temporary的时候，那么一定要优化该条sql语句。（需要建立临时表(temporary table)来暂存中间结果，出现这个 表示该条SQL语句性能较低，通常情况下需要进行优化）\n③、Useing index：表示相应的select中使用了覆盖索引，避免访问了表中的数据行，效率很好。如果同时出现了Using where 表明索引被用来执行索引键值的查找。如果没有同时出现Using where 表明索引 用来读取数据而非执行查找动作。（SQL所需要返回的所有列数据均在一棵索引树上，而无需访问实际的行记录，出现这个 表示该条SQL语句性能较好）\n示例截图：\nusing index示例截图如下：\nusing where using index示例截图如下：\n④、Using where：说明使用了where过滤（SQL使用了where条件过滤数据 需要需要优化该条SQL语句 需要配合explain结果中的type（连接类型）来综合判断）\n⑤、Using join buffer(Block Nested Loop)：在连接查询执行过程中，当sql查询语句不能有效的利用索引加快访问速度，mysql选择退而求其次，一般会为其分配一块名叫join buffer的内存块来加快查询速度，也就是我们所讲的基于块的嵌套循环算法。（需要进行嵌套循环计算 出现这个 表示该条SQL语句性能较低，需要进行优化）\n打个比方：内层和外层的type均为ALL，rows均为4，需要循环进行4*4次计算。\n典型说明：两个关联表join，关联字段均未建立索引，就会出现这种情况。常见的优化方案是，在关联字段上添加索引，避免每次嵌套循环计算。\n⑥、impossible where：where子句中的值总是false 获取不到任何数据。出现这种提示通常情况下说明你的sql语句有误，请看情况选择是否进行修改相应的sql语句。\n⑦、Using index condition：确实命中了索引，但不是所有的列数据都在索引树上，还需要访问实际的行记录。（出现这个 表示 该条SQL语句性能也较高，但不如Using index）\n","description":"\n","tags":[],"title":"\nmysql中的查询计划及sql语句性能分析","uri":"/posts/post-241/"},{"categories":["数据库"],"content":" MySQL方法GROUP_CONCAT的应用，多对多联表查询，以A表为主表，通过关联表C查询出B表关联A表任意记录的多条记录的某个字段的合并值\n开发中遇到这样的一个需求：用户表为A，角色表为B，用户角色关系通过C表多对多关联，我们需要查询出每一个用户所拥有的角色，以下图的格式显示：\n用户ID 用户姓名 拥有角色 1 小明1 角色1,角色4,角色5,角色6… 2 小明2 角色1,角色4,角色5,角色6… -- 用户表 CREATE TABLE `sys_user` ( `user_id` int NOT NULL AUTO_INCREMENT COMMENT '用户ID', `user_name` varchar(50) NOT NULL COMMENT '用户姓名', `user_age` varchar(3) DEFAULT NULL COMMENT '用户年龄', `creater` varchar(255) DEFAULT NULL COMMENT '创建人', `create_time` datetime DEFAULT NULL COMMENT '创建时间', `updater` varchar(50) DEFAULT NULL COMMENT '更新人', `update_time` datetime DEFAULT NULL COMMENT '更新时间', PRIMARY KEY (`user_id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 COMMENT='用户表'; -- 角色表 CREATE TABLE `sys_role` ( `role_id` int NOT NULL AUTO_INCREMENT COMMENT '角色ID', `role_name` varchar(50) NOT NULL COMMENT '角色名称', `creater` varchar(50) NULL COMMENT '创建人', `create_time` datetime NULL COMMENT '创建时间', `updater` varchar(50) NULL COMMENT '更新人', `update_time` datetime NULL COMMENT '更新时间', PRIMARY KEY (`role_id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 COMMENT='角色表'; -- 用户角色关系表 CREATE TABLE `sys_user_role` ( `user_role_id` int NOT NULL AUTO_INCREMENT COMMENT '用户角色关系ID', `role_id` varchar(50) NOT NULL COMMENT '角色ID', `user_id` varchar(50) NOT NULL COMMENT '用户ID', PRIMARY KEY (`user_role_id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 COMMENT='用户角色关系表'; -- 插入模拟数据 start create procedure insert8() begin declare i int default 0; repeat INSERT INTO sys_role(role_name,creater,create_time,updater,update_time)select role_name, creater, create_time, updater,update_time from sys_role UNION ALL select '角色','1',NOW(),'1', NOW() from dual ; INSERT INTO sys_user(user_name,user_age,creater,create_time,updater,update_time) select user_name,user_age,creater,create_time, updater,update_time from sys_user UNION ALL select '小明','10','1',NOW(),'1',NOW() from dual ; set i=i+1; until i\u003e8 end repeat; end; call insert8; drop procedure if exists insert8; INSERT INTO sys_user_role (role_id, user_id ) select role_id, user_id from sys_role INNER JOIN sys_user ; update sys_user set user_name=REPLACE(user_name,user_name,CONCAT( user_name,user_id) ); update sys_role set role_name=REPLACE(role_name,role_name,CONCAT(role_name,role_id) ); -- 插入模拟数据 end -- 测试完毕删除数据 drop table sys_user; drop table sys_role; drop table sys_user_role; 在解决问题中发现了两种方式可实现该功能\n方式一 SELECT su.user_id AS userId,su.user_name AS userName, ( SELECT GROUP_CONCAT(sr.role_name) FROM sys_user_role sur LEFT JOIN sys_role sr ON sr.role_id = sur.role_id WHERE sur.user_id = su.user_id ) AS roleNames FROM sys_user su ORDER BY su.user_id 方式一是把查询c表作为主表，并且left join B表的一个子查询，查出每一个用户id拥有的角色名称拼接结果作为拥有角色字段值的，我们看看其查询性能\n查询时间：56.088s 共511条 可见查询22条左右数据需要4秒多，这种速度我们显然是不能接受的，而且需要以拥有小区的名称做模糊查询时候也无从下手。于是后来继续想办法优化，就找到了下面的方式二。\n方式二 SELECT su.user_id AS userId, su.user_name AS userName,temp.roleNames FROM sys_user su LEFT JOIN ( SELECT sur.user_id, GROUP_CONCAT(sur.role_id) AS roleIds, GROUP_CONCAT(sr.role_name) AS roleNames FROM sys_user_role sur LEFT JOIN sys_role sr ON sr.role_id = sur.role_id GROUP BY sur.user_id ) temp ON temp.user_id = su.user_id ORDER BY su.user_id 方式二依然有一个查询用户拥有小区名称拼接结果的子查询，只是这个子查询不是直接作为结果字段返回，而是根据用户id为group规则查询出来每一个用户的拥有小区结果字符串，然后作为A表的left join的虚拟表，下面看一下测试结果\n查询时间：0.657s 共511条 可见同样查询一万条数据一秒钟都不用，查询速度提高了至少20倍，而且因为是虚拟关联表，可以直接用 temp.roleNames like’%角色1%’ 而实现模糊查询。\n","description":"\n","tags":[],"title":"\nMySQL方法GROUP_CONCAT的应用","uri":"/posts/post-242/"},{"categories":["数据库"],"content":"创建用户 1 CREATE USER 'username'@'host' IDENTIFIED BY 'password'; username：你将创建的用户名 host：指定该用户在哪个主机上可以登陆，如果是本地用户可用localhost，如果想让该用户可以从任意远程主机登陆，可以使用通配符% password：该用户的登陆密码，密码可以为空，如果为空则该用户可以不需要密码登陆服务器 例子 1 2 3 4 5 CREATE USER 'dog'@'localhost' IDENTIFIED BY '123456'; CREATE USER 'pig'@'192.168.1.101_' IDENDIFIED BY '123456'; CREATE USER 'pig'@'%' IDENTIFIED BY '123456'; CREATE USER 'pig'@'%' IDENTIFIED BY ''; CREATE USER 'pig'@'%'; 授权 1 GRANT privileges ON databasename.tablename TO 'username'@'host' privileges：用户的操作权限，如SELECT，INSERT，UPDATE等，如果要授予所的权限则使用ALL databasename：数据库名 tablename：表名，如果要授予该用户对所有数据库和表的相应操作权限则可用*表示，如*.* 例子 1 2 GRANT SELECT, INSERT ON test.user TO 'pig'@'%'; GRANT ALL ON *.* TO 'pig'@'%'; 注意\n用以上命令授权的用户不能给其它用户授权，如果想让该用户可以授权，用以下命令:\nGRANT privileges ON databasename.tablename TO 'username'@'host' WITH GRANT OPTION; 设置与更改用户密码 1 SET PASSWORD FOR 'username'@'host' = PASSWORD('newpassword'); 如果是当前登陆用户用:\n1 SET PASSWORD = PASSWORD(\"newpassword\"); 例子 1 SET PASSWORD FOR 'pig'@'%' = PASSWORD(\"123456\"); 撤销用户权限 1 REVOKE privilege ON databasename.tablename FROM 'username'@'host'; privilege, databasename, tablename：同授权部分\n例子 1 REVOKE SELECT ON *.* FROM 'pig'@'%'; 假如你在给用户'pig'@'%'授权的时候是这样的（或类似的）：GRANT SELECT ON test.user TO 'pig'@'%'，则在使用REVOKE SELECT ON *.* FROM 'pig'@'%';命令并不能撤销该用户对test数据库中user表的SELECT 操作。\n相反，如果授权使用的是GRANT SELECT ON *.* TO 'pig'@'%';则REVOKE SELECT ON test.user FROM 'pig'@'%';命令也不能撤销该用户对test数据库中user表的Select权限。\n具体信息可以用命令SHOW GRANTS FOR 'pig'@'%'; 查看。\n删除用户 1 DROP USER 'username'@'host'; ","description":"\n","tags":[],"title":"\nMySQL创建用户与授权","uri":"/posts/post-243/"},{"categories":["默认分类"],"content":"前言 最近在做提供虚拟机的工作时发现，vcenter的模板虽然可以快速创建出和模板一模一样的虚拟机，但是由于对硬盘的配置每个人的要求不同，vmware只支持扩大硬盘配置。\n故在做模板时，硬盘设计的小些，然后根据每个人不同的需求再做磁盘的扩容就好了。\n场景 虚拟机初始硬盘：16G\n虚拟机扩容后硬盘：50G\n需求：将扩容的34G空间增加到文件系统/dev/mapper/centos-root中\n扩容文件系统 确认硬盘空间 列出块设备信息 lsblk\n查看文件系统的硬盘使用 df -h 查看硬盘数量和分区情况 fdisk -l 对未分配的空间进行分区 创建新分区 fdisk /dev/sda 新建分区 输入“n”，回车；（n：新建分区）\n主分区 不用输入，回车；（p：主分区）\n设置扇区 下面几个选项不用输入，回车；\n设置分区号 输入“t”，回车；接着不用输入，回车；（t：设置分区号）\n设置分区格式 输入“L”，回车；接着输入“8e”，回车；（8e：指定分区格式为Linux LVM）\n保存修改 输入“w”，回车；（w：保存修改）\n重启虚拟机 reboot 查看新的分区情况（新的分区/dev/sda3）\nfdisk -l 对目标分区扩容 创建物理卷 pvcreate /dev/sda3 添加物理卷 添加物理卷（/dev/sda3）到卷组（centos）\nvgextend centos /dev/sda3 卷组属性 查看centos卷组的属性\nvgdisplay 可以看到有不到34G的空闲空间可以扩展。\n分配空间 将空闲的空间都分配给root文件系统\nlvextend -l +100%FREE /dev/mapper/centos-root 扩容 对root文件系统执行扩容\nxfs_growfs /dev/mapper/centos-root 查看扩容结果 df -h ","description":"\n","tags":[],"title":"\ncentos7 挂载未分配的硬盘空间","uri":"/posts/post-244/"},{"categories":["默认分类"],"content":" IDEA 远程调试，像运行本地代码一样调试远程主机上的程序，以排查远程程序的BUG或代码执行流程。\n概述 原理：本机和远程主机的两个 VM 之间使用 Debug 协议通过 Socket 通信，传递调试指令和调试信息。 被调试程序的远程虚拟机：作为 Debug 服务端，监听 Debug 调试指令。jdwp是Java Debug Wire Protocol的缩写。 调试程序的本地虚拟机：IDEA 中配置的 Remote Server，指定 Debug 服务器的Host:Port，以供 Debug 客户端程序连接。\n设置 打开防火墙 #查看想开的端口是否已开： firewall-cmd --query-port=20400/tcp #添加指定需要开放的端口： firewall-cmd --add-port=20400/tcp --permanent #重载入添加的端口： firewall-cmd --reload #移除指定端口： firewall-cmd --permanent --remove-port=20400/tcp 远程服务中开启 Debug 服务 对于 SpringBoot命令行添加选项，并重启\njava -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=20400 -jar xxx.jar 对于 Tomcat 启动脚本中添加选项，并重启：\nJAVA_OPTS=\"$JAVA_OPTS -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=20400\" IDEA 中指定 Debug 服务器 点击主窗口菜单 Run / Edit Configurations，打开“Run/Debug Configurations”窗口；\n点击工具栏上的“+”按钮，下拉菜单中选择“Remote”或者“Remote JVM Debug”；\n设置 Host 为远程服务器的域名或IP，设置端口 Port=20400；\n复制命令行参数，形如 -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=20400 这个参数就是启动服务器项目时加的参数\n","description":"\n","tags":[],"title":"\nIDEA 远程调试","uri":"/posts/post-245/"},{"categories":["maven"],"content":"简介 官方文档 https://www.mojohaus.org/build-helper-[maven](https://so.csdn.net/so/search?q=maven\u0026spm=1001.2101.3001.7020)-plugin/index.html\n常用的Goals 名称 说明 build-helper:add-source 添加一个或者多个目录到POM. build-helper:add-test-source 添加测试目录到 POM. build-helper:add-resource 添加资源目录到POM. build-helper:add-test-resource 添加测试资源目录到POM. build-helper:attach-artifact 附加要安装和部署的其他部件。 build-helper:maven-version 设置一个包含当前版本的 maven 的属性。 build-helper:regex-property 通过将正则表达式替换规则应用于提供的值来设置属性。 build-helper:regex-properties 通过将正则表达式替换规则应用于提供的值来设置属性. build-helper:released-version 解决本项目最新发布的版本. build-helper:parse-version 将版本解析为不同的属性. build-helper:remove-project-artifact 从本地存储库中删除项目的工件. build-helper:reserve-network-port 保留随机和未使用的网络端口列表. build-helper:local-ip 检索当前主机 IP 地址. build-helper:hostname 检索当前主机名. build-helper:cpu-count 检索可用 CPU 的数量. build-helper:timestamp-property 根据当前日期和时间设置属性. build-helper:uptodate-property 根据文件集的输出相对于其输入是否是最新的来设置属性. build-helper:uptodate-properties 根据多个文件集的输出相对于它们的输入是否是最新的来设置多个属性. build-helper:rootlocation 设置定义多模块构建的根文件夹的属性. 简单用法 \u003cproject\u003e \u003cbuild\u003e \u003cplugins\u003e \u003c!--独立打包--\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-maven-plugin\u003c/artifactId\u003e \u003cversion\u003e2.1.1.RELEASE\u003c/version\u003e \u003cconfiguration\u003e \u003cfork\u003etrue\u003c/fork\u003e \u003c!-- 如果没有该配置，devtools不会生效 --\u003e \u003c/configuration\u003e \u003cexecutions\u003e \u003cexecution\u003e \u003cgoals\u003e \u003cgoal\u003erepackage\u003c/goal\u003e \u003c/goals\u003e \u003c/execution\u003e \u003c/executions\u003e \u003c/plugin\u003e \u003c!-- domain 打包进去--\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.codehaus.mojo\u003c/groupId\u003e \u003cartifactId\u003ebuild-helper-maven-plugin\u003c/artifactId\u003e \u003cversion\u003e3.3.0\u003c/version\u003e \u003cexecutions\u003e \u003cexecution\u003e \u003c!--id是必须的，常常和goals是一样的--\u003e \u003cid\u003eadd-source\u003c/id\u003e \u003cphase\u003egenerate-sources\u003c/phase\u003e \u003cgoals\u003e \u003cgoal\u003eadd-source\u003c/goal\u003e \u003c/goals\u003e \u003c!--在configuration中设置goals的具体属性--\u003e \u003cconfiguration\u003e \u003c!--这些熟悉可以通过文档获得--\u003e \u003csources\u003e \u003csource\u003e${basedir}/src/main/java\u003c/source\u003e \u003csource\u003e${basedir}/src/main/domain\u003c/source\u003e ... \u003c/sources\u003e \u003c/configuration\u003e \u003c/execution\u003e \u003c!--在比如下面的，可以获得当前时间--\u003e \u003cexecution\u003e \u003cid\u003etimestamp-property\u003c/id\u003e \u003cgoals\u003e \u003cgoal\u003etimestamp-property\u003c/goal\u003e \u003c/goals\u003e \u003cconfiguration\u003e \u003cname\u003ecurrent.time\u003c/name\u003e \u003cpattern\u003eyyyyMMddHHmmss\u003c/pattern\u003e \u003ctimeZone\u003eGMT+8\u003c/timeZone\u003e \u003c/configuration\u003e \u003c/execution\u003e \u003c/executions\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e \u003c/project\u003e 获得当前时间的那个，可以通过configuration的name在pom的其他地方通过${current.time}来引用当前时间\n","description":"\n","tags":[],"title":"\nbuild-helper-maven-plugin 简单讲解","uri":"/posts/post-246/"},{"categories":["默认分类"],"content":" 首先说明一下自己电脑的情况，，在thinkpad官网下载安装好声卡驱动后还是没有声音 ，检测的时候也会根据声音大小跳动，我测试蓝牙耳机连接后声音没问题， 一度让我怀疑我的笔记本扬声器坏了 ，\n最近疫情严重了大家都居家隔离都在家办公，经常有开会分享屏幕，手机接听就太小屏幕看不见，电脑接听没有声音，让我企业微信分享屏幕，个人微信 开启语音聊天。。。。。。,后来发现笔记本电脑上f1键亮着 上面有个小喇叭，想关也关不掉 了不废话了看怎么解决的。\n下载驱动 去联想官网下载对应电脑型号的声卡驱动，官网地址：驱动下载_ThinkPad服务网站-联想服务，进入联想thinkpad官网后找到服务里面的驱动下载选项，然后点击进去，如下图:、\n然后会进入到下个界面，如下图：\n在这个界面，要下搜索框里输入自己的电脑主机编号，电脑主机编号一般都在电脑的背面有显示，或者在页面下方选择自己的电脑型号进去相应的驱动页面进行下载，要不然下载个联想驱动管理也可以查看自己的电脑型号，然后才能进入到自己电脑型号所对应的所有驱动的下载的地方，一般来说都是最新版的驱动，如下图：\n在这个界面就可以下载需要的驱动了，就是这个版本的声卡驱动，下载下来，直接运行安装就OK了，安装完驱动后，重启电脑才有效果。后来经过我的实践证明，只安装这个版本的声卡驱动是没有效果的，还是没有声音，必须要安装上图里的热键驱动才可以。\n就这样，去联想官网下载对应版本的声卡驱动，还有热键驱动，安装后重启电脑，就有声音了。\n其他问题可以参照 修复 Windows 10 中的声音问题\n","description":"\n","tags":[],"title":"\nThinkPad系列 win10系统没有声音问题完美解决","uri":"/posts/post-247/"},{"categories":["默认分类"],"content":"教育部关于做好2022年普通高校招生工作的通知 2022年01月29日 来源：教育部 教学〔2022〕1号 各省、自治区、直辖市高等学校招生委员会、教育厅（教委）、招生考试机构，新疆生产建设兵团教育局，有关部门（单位）教育司（局），部属各高等学校、部省合建各高等学校： 2022年普通高校招生工作要以习近平新时代中国特色社会主义思想为指导，贯彻落实党的十九大和十九届历次全会精神，学习贯彻习近平总书记关于教育的重要论述和中央人才工作会议、中央经济工作会议等精神，全面贯彻党的教育方针，弘扬伟大建党精神，坚持稳中求进的工作总基调，积极稳妥推进考试招生制度改革，统筹做好考试招生和新冠肺炎疫情常态化防控等工作，推进高校考试招生治理能力和水平现代化，确保考试招生工作安全、有序实施。现就有关工作通知如下。 一、进一步提升常态化疫情防控下考试招生管理水平 1.切实加强组织领导。省级高校招生委员会是本行政区域内组织高考、治理考试环境、维护考试招生安全稳定、做好考试疫情防控、整肃考风考纪的责任主体，主要负责同志是第一责任人，省级教育行政部门主要负责同志、分管负责同志和省级招生考试机构主要负责同志是直接责任人。高校是本校考试招生（含特殊类型招生）工作的责任主体，主要负责同志是第一责任人，分管负责同志是直接责任人。各地各校要在当地党委和政府的领导下，强化组织领导，层层压实责任，从严从实做好考试组织管理工作。各地要建立各环节风险梳理和排查机制，完善防范各类涉考突发事件的应急处置工作预案，确保出现突发情况后的快速反应和应急措施到位。重大事件处置决策要向当地省（区、市）党委政府请示汇报，并及时报教育部。 2.完善防疫工作方案。各地各校要认真总结近年高考组考防疫工作经验，认真落实国家教育考试组考防疫要求，将高考组考防疫列入当地应对新冠肺炎疫情联防联控机制（领导小组、指挥部）工作重点，结合本地实际，进一步细化完善防疫工作方案。合理安排有关特殊类型招生考试时间，积极采取线上等非现场方式，减少人员聚集和流动。强化命题制卷、考点考场、评卷等场所防疫举措，深入细致做好考生和工作人员健康监测、考试招生场所消毒、防疫物资与场地配备等各环节工作，原则上安排接种过疫苗的人员担任考务工作。按要求为每个考点配备防疫副主考，设置必要的隔离考场、隔离设施。加强考生与考务工作人员防疫知识和操作培训，确保各项措施落实到位，坚决守住不因组织考试引发疫情传播的底线。考前发生疫情的地区，要加强疫情形势的分析研判，根据疫情发展情况，及时调整相关组考防疫措施，稳妥做好考试组织工作。 3.强化安全保密管理。各地各校要把安全保密工作摆在突出重要位置，细化命题、制卷、运送、保管、分发、施考、评卷等关键环节、关键人员的管理，确保试题试卷绝对安全。强化部门协作机制，集中开展净化涉考网络环境、打击销售作弊器材、净化考点周边环境、打击替考作弊等专项行动，综合治理考试环境。加强标准化考点管理，做好设备维护和升级，有效屏蔽无线电作弊信号。加强考点考场管理，加大人员入场检测力度，严格执行考生进入考点（考场）安全检查工作规范，强化考点手机存放管理，严防考生携带手机、高科技作弊器材等入场。严肃考风考纪，严格执行考场监考、考点巡考和考场视频回放制度，严查违规违纪行为。 二、进一步促进高等教育入学机会公平 4.继续加大对中西部和农村地区倾斜力度。综合考虑生源数量、入学机会及学校办学条件等因素，合理安排国家支援中西部地区招生协作计划，向中西部地区和考生大省倾斜。中央部门所属高校要严格控制属地招生计划比例，合理确定分省招生名额。继续实施重点高校面向农村和脱贫地区专项计划，严格报考条件，加强资格审核，优化招录程序，推动专项计划优惠政策落实到位。从2023年招生起，往年被专项计划录取后放弃入学资格或退学的考生，不再具有专项计划报考资格。有关高校要及时将往年放弃入学的相关考生信息反馈生源省份。 5.做好随迁子女在流入地参加高考工作。各地要加强中高考报名政策统筹衔接，会同有关部门提前做好摸底核查，针对不同情况，加强分类引导，确保符合条件的进城务工人员及其他非户籍就业人员随迁子女能在当地参加高考。对于因特殊原因不符合流入地报考条件的考生，流入地省级高校招生委员会要主动协调流出地予以稳妥处理，原则上回流出地参加高考。要会同有关部门严格审核考生的户籍、学籍和实际就读情况，严厉打击“高考移民”。对于通过非正常户籍学籍迁移、户籍学籍造假、出具虚假证明材料等手段获取高考资格的，要依法依规进行严肃处理。要加强政策宣传，组织中学在新生入学等关键节点，让学生和家长熟知高考报名政策。 三、进一步深化高校考试招生改革 6.深化高考综合改革。高考综合改革省份要加强改革协同，推动教学、评价、考试、招生各环节有机衔接。要加强学生生涯规划教育和选科指导，从有利于学生未来成长发展的角度，进一步引导学生科学合理确定选考科目。要严格落实普通高中课程方案，开齐国家规定课程开足课时，不得组织学生提前选科。尚未启动改革的省份要认真借鉴改革省份经验，抓紧完善基础条件，研究谋划本地改革实施方案，积极做好启动改革准备工作。各高校要加强与中学人才培养衔接，进一步优化选考科目要求，完善综合素质评价使用办法并向社会公布，逐步转变简单以考试成绩为唯一标准的招生模式。 7.深化考试内容改革。2022年高考命题坚持以习近平新时代中国特色社会主义思想为指导，贯彻党的教育方针，落实立德树人根本任务，充分发挥高考命题的育人功能和积极导向作用，构建引导学生德智体美劳全面发展的考试内容体系。依据高校人才选拔要求和国家课程标准，优化试题呈现方式，加强对关键能力和学科素养的考查，引导减少死记硬背和“机械刷题”现象。各地要加强国家教育考试工作队伍建设，完善工作激励保障机制，提升国家教育考试队伍能力和水平。 8.深入实施强基计划。各试点高校要深入总结近年强基计划实施情况，坚持试点定位，着力选拔真正对基础研究感兴趣、有培养潜质的学生。要进一步完善招生办法，优化工作程序，合理安排高校考核的时间，完善考核内容和形式，着重考查学生发现问题和解决问题能力、归纳演绎等思辨能力以及对科学探究的浓厚兴趣等。要加强学生入校后的培养和管理工作，优化人才培养模式，畅通本硕博衔接培养通道，提高人才培养质量。 9.完善高职院校分类考试。各地要坚持职业教育类型定位，加强省级统筹，立足当地经济社会发展，合理安排高职院校分类考试招生规模，保持分类考试主渠道。要优化招生院校专业结构，重点向区域经济建设急需、社会民生领域紧缺、技术技能培养要求高和就业质量高的专业倾斜。要遵循职业教育人才培养规律，进一步完善“文化素质+职业技能”的职教高考制度，服务现代职业教育高质量发展需要。要坚持立德树人、德技并修、面向实践、强化能力，完善分类考试内容、形式和招生录取机制，着力选拔培养高素质技术技能人才。原则上高职院校分类考试安排在春季举行。各省级教育行政部门要加强分类考试规范管理，加大对高职院校组织考试的监督力度，确保公平公正。 四、进一步加强招生录取规范管理 10.完善招生信息公开。各地各校要结合实际，进一步完善信息公开的范围、内容、方式和时间，自觉接受纪检监察部门及利益相关者的监督。要畅通社会监督举报渠道，完善考生申诉和学校仲裁机制，及时回应处理各种问题。要加强信息安全防护工作，落实国家信息系统安全等级保护相关要求，加强对高校招生信息化服务平台的监测和运行维护，及时消除安全隐患，确保招考信息安全。 11.严格招生录取管理。各地各校要严格执行国家招生计划和招生政策规定，严肃招生工作纪律，认真遵守高校招生“30个不得”“八项基本要求”等纪律要求。各地要加强高校招生录取批次管理，不得随意将普通批次招生专业安排至本科提前批次招生。严格规范大类招生行为，对于培养方案不合理、不到位或招生和培养方案不一致的，不得开展大类招生。高校要规范招生宣传管理，招生广告或者宣传的表述应当严谨、规范，不得采取贬损、夸张、低俗以及其他不适当的语言或者方式开展招生宣传，不得以新生高额奖学金、违规承诺录取等方式争抢生源。要认真落实录取通知书寄递工作要求，确保录取通知书寄递安全、及时、准确。要严格组织新生入学资格复查，确保招生录取公平公正。 12.强化监督管理责任。各省级高校招生委员会、教育行政部门要按照“学校负责、招办监督”的原则，认真落实考试招生工作的监管责任，会同教育纪检部门加强对报名、考试、录取全过程监督。要认真审核省属高校招生章程及属地高校的有关特殊类型招生办法，对相关高校招生政策及计划执行情况开展督促检查。要加大违规查处力度，对于因疏于管理，造成考场秩序混乱、作弊情况严重、招生违规严重的，要依法依规对相关责任人严肃处理并追责问责。 五、进一步优化考试招生宣传服务 13.优化考生咨询服务。各地要深入实施“高考护航行动”，为考生提供更多更优质的考试招生全流程服务。考试期间，要强化对治安、交通、卫生防疫等方面的综合保障，为残疾人平等参加高考提供合理便利，营造温馨的考试招生环境。志愿填报期间，要充分发挥基层教育部门和中学的主渠道作用，为考生提供形式多样的志愿填报指导服务。要积极采取研发志愿填报辅助系统等信息化手段，为考生提供个性化的信息服务。要加强考生志愿填报各环节管理，指导考生妥善保管个人信息，严防志愿被篡改。严禁学校和教师与校外培训等社会机构合作，通过为考生提供志愿填报咨询服务收取费用、谋取利益。要联合网信、公安、市场监管等部门，加强对社会培训机构或个人开展志愿填报咨询活动的监管，加大治理收费不规范、价格欺诈及虚假宣传等问题力度，提醒考生谨防“高价志愿填报指导”诈骗陷阱。录取期间，要公开违规举报电话和咨询电话，及时妥善处置信访问题，切实维护考生合法权益。 14.严格规范招生宣传。各地各高校要坚持正确育人导向，及时、主动、准确、全面做好政策解读、信息查询和温馨提示等服务工作。要进一步完善和规范高考成绩、高校录取分数线等发布工作，坚决扭转简单以高考成绩评价学生、以录取分数线评价高校的做法。要加强对中学、教师等相关主体的管理，严禁以各种方式公布宣传炒作“高考状元”“高考喜报”“高考升学率”“高分考生”等。要加大统筹协调，严禁各地政府、学校、培训机构以高考成绩为标准奖励教师和学生。各地教育部门和中学不得给年级、班级、教师下达升学指标，不得将升学率与教师评优评先及职称晋升挂钩。高校制作录取通知书应坚持简约、节约的原则，避免铺张浪费。 请各省级高校招生委员会办公室将本通知转发至本行政区域内所有普通高校。 附件：2022年普通高等学校招生工作规定 教育部 2022年1月27日 —- 点击下载:2022年普通高等学校招生工作规定.docx\n","description":"\n","tags":["小说"],"title":"\nJava 正则提取小说章节名","uri":"/posts/post-29/"},{"categories":["默认分类"],"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!-- 日志级别从低到高分为TRACE \u003c DEBUG \u003c INFO \u003c WARN \u003c ERROR \u003c FATAL，如果设置为WARN，则低于WARN的信息都不会输出 --\u003e \u003c!-- scan:当此属性设置为true时，配置文档如果发生改变，将会被重新加载，默认值为true --\u003e \u003c!-- scanPeriod:设置监测配置文档是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。 当scan为true时，此属性生效。默认的时间间隔为1分钟。 --\u003e \u003c!-- debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 --\u003e \u003cconfiguration scan=\"true\" scanPeriod=\"60 seconds\" debug=\"false\"\u003e \u003c!-- contextName:用来设置上下文名称，每个logger都关联到logger上下文，默认上下文名称为default。但可以使用\u003ccontextName\u003e设置成其他名字，用于区分不同应用程序的记录。一旦设置，不能修改。--\u003e \u003ccontextName\u003emyApp\u003c/contextName\u003e \u003c!-- \u003cspringProperty scope=\"context\" name=\"logPath\" source=\"logging.path\" defaultValue=\"logs\"/\u003e --\u003e \u003c!-- name的值是变量的名称，value的值时变量定义的值。通过定义的值会被插入到logger上下文中。定义后，可以使“${}”来使用变量。 --\u003e \u003cproperty name=\"log.path\" value=\"logs/\" /\u003e \u003c!--0. 日志格式和颜色渲染 --\u003e \u003c!-- 彩色日志依赖的渲染类 --\u003e \u003cconversionRule conversionWord=\"clr\" converterClass=\"org.springframework.boot.logging.logback.ColorConverter\" /\u003e \u003cconversionRule conversionWord=\"wex\" converterClass=\"org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter\" /\u003e \u003cconversionRule conversionWord=\"wEx\" converterClass=\"org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter\" /\u003e \u003c!-- 彩色日志格式 --\u003e \u003cproperty name=\"CONSOLE_LOG_PATTERN\" value=\"${CONSOLE_LOG_PATTERN:-%clr(%d{yyyy-MM-dd HH🇲🇲ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}\" /\u003e \u003c!--1. 输出到控制台 --\u003e \u003cappender name=\"CONSOLE\" class=\"ch.qos.logback.core.ConsoleAppender\"\u003e \u003c!-- 此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息 --\u003e \u003cfilter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"\u003e \u003clevel\u003edebug\u003c/level\u003e \u003c/filter\u003e \u003cencoder\u003e \u003cPattern\u003e${CONSOLE_LOG_PATTERN}\u003c/Pattern\u003e \u003c!-- 设置字符集 --\u003e \u003ccharset\u003eUTF-8\u003c/charset\u003e \u003c/encoder\u003e \u003c/appender\u003e \u003c!--2. 输出到文档 --\u003e \u003c!-- 2.1 level为 DEBUG 日志，时间滚动输出 --\u003e \u003cappender name=\"DEBUG_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"\u003e \u003c!-- 正在记录的日志文档的路径及文档名 --\u003e \u003cfile\u003e${log.path}/web_debug.log\u003c/file\u003e \u003c!--日志文档输出格式 --\u003e \u003cencoder\u003e \u003cpattern\u003e%d{yyyy-MM-dd HH🇲🇲ss.SSS} [%thread] %-5level %logger{50} - %msg%n\u003c/pattern\u003e \u003ccharset\u003eUTF-8\u003c/charset\u003e \u003c!-- 设置字符集 --\u003e \u003c/encoder\u003e \u003c!-- 日志记录器的滚动策略，按日期，按大小记录 --\u003e \u003crollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"\u003e \u003c!-- 日志归档 --\u003e \u003cfileNamePattern\u003e${log.path}/web-debug-%d{yyyy-MM-dd}.%i.log \u003c/fileNamePattern\u003e \u003ctimeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"\u003e \u003cmaxFileSize\u003e100MB\u003c/maxFileSize\u003e \u003c/timeBasedFileNamingAndTriggeringPolicy\u003e \u003c!--日志文档保留天数 --\u003e \u003cmaxHistory\u003e15\u003c/maxHistory\u003e \u003c/rollingPolicy\u003e \u003c!-- 此日志文档只记录debug级别的 --\u003e \u003cfilter class=\"ch.qos.logback.classic.filter.LevelFilter\"\u003e \u003clevel\u003edebug\u003c/level\u003e \u003conMatch\u003eACCEPT\u003c/onMatch\u003e \u003conMismatch\u003eDENY\u003c/onMismatch\u003e \u003c/filter\u003e \u003c/appender\u003e \u003c!-- 2.2 level为 INFO 日志，时间滚动输出 --\u003e \u003cappender name=\"INFO_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"\u003e \u003c!-- 正在记录的日志文档的路径及文档名 --\u003e \u003cfile\u003e${log.path}/web_info.log\u003c/file\u003e \u003c!--日志文档输出格式 --\u003e \u003cencoder\u003e \u003cpattern\u003e%d{yyyy-MM-dd HH🇲🇲ss.SSS} [%thread] %-5level %logger{50} - %msg%n\u003c/pattern\u003e \u003ccharset\u003eUTF-8\u003c/charset\u003e \u003c/encoder\u003e \u003c!-- 日志记录器的滚动策略，按日期，按大小记录 --\u003e \u003crollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"\u003e \u003c!-- 每天日志归档路径以及格式 --\u003e \u003cfileNamePattern\u003e${log.path}/web-info-%d{yyyy-MM-dd}.%i.log \u003c/fileNamePattern\u003e \u003ctimeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"\u003e \u003cmaxFileSize\u003e100MB\u003c/maxFileSize\u003e \u003c/timeBasedFileNamingAndTriggeringPolicy\u003e \u003c!--日志文档保留天数 --\u003e \u003cmaxHistory\u003e15\u003c/maxHistory\u003e \u003c/rollingPolicy\u003e \u003c!-- 此日志文档只记录info级别的 --\u003e \u003cfilter class=\"ch.qos.logback.classic.filter.LevelFilter\"\u003e \u003clevel\u003einfo\u003c/level\u003e \u003conMatch\u003eACCEPT\u003c/onMatch\u003e \u003conMismatch\u003eDENY\u003c/onMismatch\u003e \u003c/filter\u003e \u003c/appender\u003e \u003c!-- 2.3 level为 WARN 日志，时间滚动输出 --\u003e \u003cappender name=\"WARN_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"\u003e \u003c!-- 正在记录的日志文档的路径及文档名 --\u003e \u003cfile\u003e${log.path}/web_warn.log\u003c/file\u003e \u003c!--日志文档输出格式 --\u003e \u003cencoder\u003e \u003cpattern\u003e%d{yyyy-MM-dd HH🇲🇲ss.SSS} [%thread] %-5level %logger{50} - %msg%n\u003c/pattern\u003e \u003ccharset\u003eUTF-8\u003c/charset\u003e \u003c!-- 此处设置字符集 --\u003e \u003c/encoder\u003e \u003c!-- 日志记录器的滚动策略，按日期，按大小记录 --\u003e \u003crollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"\u003e \u003cfileNamePattern\u003e${log.path}/web-warn-%d{yyyy-MM-dd}.%i.log \u003c/fileNamePattern\u003e \u003ctimeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"\u003e \u003cmaxFileSize\u003e100MB\u003c/maxFileSize\u003e \u003c/timeBasedFileNamingAndTriggeringPolicy\u003e \u003c!--日志文档保留天数 --\u003e \u003cmaxHistory\u003e15\u003c/maxHistory\u003e \u003c/rollingPolicy\u003e \u003c!-- 此日志文档只记录warn级别的 --\u003e \u003cfilter class=\"ch.qos.logback.classic.filter.LevelFilter\"\u003e \u003clevel\u003ewarn\u003c/level\u003e \u003conMatch\u003eACCEPT\u003c/onMatch\u003e \u003conMismatch\u003eDENY\u003c/onMismatch\u003e \u003c/filter\u003e \u003c/appender\u003e \u003c!-- 2.4 level为 ERROR 日志，时间滚动输出 --\u003e \u003cappender name=\"ERROR_FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"\u003e \u003c!-- 正在记录的日志文档的路径及文档名 --\u003e \u003cfile\u003e${log.path}/web_error.log\u003c/file\u003e \u003c!--日志文档输出格式 --\u003e \u003cencoder\u003e \u003cpattern\u003e%d{yyyy-MM-dd HH🇲🇲ss.SSS} [%thread] %-5level %logger{50} - %msg%n\u003c/pattern\u003e \u003ccharset\u003eUTF-8\u003c/charset\u003e \u003c!-- 此处设置字符集 --\u003e \u003c/encoder\u003e \u003c!-- 日志记录器的滚动策略，按日期，按大小记录 --\u003e \u003crollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"\u003e \u003cfileNamePattern\u003e${log.path}/web-error-%d{yyyy-MM-dd}.%i.log \u003c/fileNamePattern\u003e \u003ctimeBasedFileNamingAndTriggeringPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP\"\u003e \u003cmaxFileSize\u003e100MB\u003c/maxFileSize\u003e \u003c/timeBasedFileNamingAndTriggeringPolicy\u003e \u003c!--日志文档保留天数 --\u003e \u003cmaxHistory\u003e15\u003c/maxHistory\u003e \u003c/rollingPolicy\u003e \u003c!-- 此日志文档只记录ERROR级别的 --\u003e \u003cfilter class=\"ch.qos.logback.classic.filter.LevelFilter\"\u003e \u003clevel\u003eERROR\u003c/level\u003e \u003conMatch\u003eACCEPT\u003c/onMatch\u003e \u003conMismatch\u003eDENY\u003c/onMismatch\u003e \u003c/filter\u003e \u003c/appender\u003e \u003c!-- \u003clogger\u003e用来设置某一个包或者具体的某一个类的日志打印级别、 以及指定\u003cappender\u003e。\u003clogger\u003e仅有一个name属性， 一个可选的level和一个可选的addtivity属性。 name:用来指定受此logger约束的某一个包或者具体的某一个类。 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF， 还有一个特俗值INHERITED或者同义词NULL，代表强制执行上级的级别。 如果未设置此属性，那么当前logger将会继承上级的级别。 addtivity:是否向上级logger传递打印信息。默认是true。 \u003clogger name=\"org.springframework.web\" level=\"info\"/\u003e \u003clogger name=\"org.springframework.scheduling.annotation.ScheduledAnnotationBeanPostProcessor\" level=\"INFO\"/\u003e --\u003e \u003c!-- 使用mybatis的时候，sql语句是debug下才会打印，而这里我们只配置了info，所以想要查看sql语句的话，有以下两种操作： 第一种把\u003croot level=\"info\"\u003e改成\u003croot level=\"DEBUG\"\u003e这样就会打印sql，不过这样日志那边会出现很多其他消息 第二种就是单独给dao下目录配置debug模式，代码如下，这样配置sql语句会打印，其他还是正常info级别： 【logging.level.org.mybatis=debug logging.level.dao=debug】 --\u003e \u003c!-- root节点是必选节点，用来指定最基础的日志输出级别，只有一个level属性 level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR, ALL 和 OFF， 不能设置为INHERITED或者同义词NULL。默认是DEBUG 可以包含零个或多个元素，标识这个appender将会添加到这个logger。 --\u003e \u003c!-- 常用logger配置 --\u003e \u003c!-- show parameters for hibernate sql 专为 Hibernate 定制 --\u003e \u003clogger name=\"org.hibernate.type.descriptor.sql.BasicBinder\" level=\"TRACE\" /\u003e \u003clogger name=\"org.hibernate.type.descriptor.sql.BasicExtractor\" level=\"DEBUG\" /\u003e \u003clogger name=\"org.hibernate.SQL\" level=\"DEBUG\" /\u003e \u003clogger name=\"org.hibernate.engine.QueryParameters\" level=\"DEBUG\" /\u003e \u003clogger name=\"org.hibernate.engine.query.HQLQueryPlan\" level=\"DEBUG\" /\u003e \u003c!--myibatis log configure--\u003e \u003clogger name=\"com.apache.ibatis\" level=\"TRACE\"/\u003e \u003clogger name=\"java.sql.Connection\" level=\"DEBUG\"/\u003e \u003clogger name=\"java.sql.Statement\" level=\"DEBUG\"/\u003e \u003clogger name=\"java.sql.PreparedStatement\" level=\"DEBUG\"/\u003e \u003c!--打印sql配置--\u003e \u003clogger name=\"cn.maruifu.myAppName.module.dao\" level=\"DEBUG\"/\u003e \u003c!-- 4. 最终的策略 --\u003e \u003c!-- 4.1 开发环境:打印控制台 --\u003e \u003cspringProfile name=\"dev\"\u003e \u003croot level=\"info\"\u003e \u003cappender-ref ref=\"CONSOLE\" /\u003e \u003c/root\u003e \u003c/springProfile\u003e \u003c!-- 4.2 生产环境:输出到文档 --\u003e \u003cspringProfile name=\"prod\"\u003e \u003croot level=\"info\"\u003e \u003cappender-ref ref=\"CONSOLE\" /\u003e \u003cappender-ref ref=\"DEBUG_FILE\" /\u003e \u003cappender-ref ref=\"INFO_FILE\" /\u003e \u003cappender-ref ref=\"WARN_FILE\" /\u003e \u003cappender-ref ref=\"ERROR_FILE\" /\u003e \u003c/root\u003e \u003c/springProfile\u003e \u003c/configuration\u003e ","description":"\n","tags":[],"title":"\nlogback 配置文件","uri":"/posts/post-248/"},{"categories":["架构设计"],"content":"我们聊了性能优化的六大原则。原则有了，但是在针对实际的性能问题的时候，用什么样的解决方案才可以提升性能呢？这就需要你了解具体的优化策略了。\n现实中的性能问题和具体领域千差万别，我也不可能面面俱到。但是为了帮助你理解，我总结了十大常用的优化策略。\n我将这十大策略分成五个类别，每个类别对应两个相关策略，帮助你掌握。这五个类别是：时空相互转换、并行 / 异步操作、预先 / 延后处理、缓存 / 批量合并、算法设计和数据结构。我们现在一个个来讲。\n一、时空转换 第一个策略类别是“时空转换”。我们看科幻电影和小说的时候，经常会看到时空转换这个题材。性能优化里面有两个策略恰好组成了这个类别，包括“用时间换空间”和“用空间换 时间”这两个看似互相对立的策略。\n1. 用时间换空间\n用时间换空间的策略，出发点是内存和存储这样的“空间”资源，有时会成为最稀缺的资源，所以需要尽量减少占用的空间。比如，一个系统的最大性能瓶颈如果是内存使用量，那么减少内存的使用就是最重要的性能优化。\n这个策略具体的操作方法有几种：\n改变应用程序本身的数据结构或者数据格式，减少需要存储的数据的大小； 想方设法压缩存在内存中的数据，比如采用某种压缩算法，真正使用时再解压缩； 把一些内存数据，存放到外部的、更加便宜的存储系统里面，到需要时再取回来。 这些节省内存空间的方法，一般都需要付出时间的代价。\n除了内存，还有一种常见的场景是，降低数据的大小来方便网络传输和外部存储。压缩的方法和算法有很多种， 比如现在比较流行的 ZStandard（ZSTD）和 LZ4。这些算法之间有空间和时间的取舍。\n衡量任何压缩算法，基本上看三个指标：压缩比例、压缩速度以及使用内存。\n如果系统的瓶颈在网络传输速度或者存储空间大小上，那就尽量采取高压缩比的算法，这样用时间来换空间，就能够节省时间或者其他方面的成本。\n2. 用空间换时间\n“用空间换时间”就是对“用时间换空间”策略反其道而行之。有些场景下，时间和速度更加重要，但是空间尚有富余，这时我们就可以考虑用空间来换时间。\n这里要注意的一点是，我们后面还会讲一条关于使用缓存的策略。虽然缓存的策略理论上也是一种“空间换时间”的方式，但我们在这里把它分开来讲，这是因为缓存策略的“空间”定义与一般的“空间换时间”不同。一般来讲，“缓存”使用的空间，和原来的空间不在同一个层次上，添加的缓存往往比原来的空间高出一个档次。而我们这里“空间换时间”的策略，里面的“空间”是和原来的空间相似的空间。\n互联网的服务往往规模很大，比如全国的服务甚至是全球的服务。用户分布在各地，它们对访问时间的要求很高，这就要求被访问的数据和服务，要尽量放在离他们很近的地方。“空间换时间”就是对数据和服务进行多份拷贝，尽可能地完美覆盖大多数的用户。我们前面讲过的 CDN 内容分发网络技术就可以归类于此。\n其实我们部署的任何大规模系统，都或多或少地采用了用空间换时间的策略，比如在集群和服务器间进行负载均衡，就是同时用很多个服务器（空间）来换取延迟的减少（时间）。\n二、预先和延后处理 优化策略的第二大类是“预先和延后处理”，这一类别也有两个互相对立的策略。一个是预先或者提前处理，另外一个是延后或者惰性处理。\n3. 预先 / 提前处理\n预先 / 提前处理策略同样也表现在很多领域，比如网站页面资源的提前加载。Web 标准规定了至少两种提前加载的方式：preload 和 prefetch，分别用不同的优先级来加载资源，可以显著地提升页面下载性能。\n很多文件系统有预读的功能，就是提前从磁盘读取额外的数据，为下次上层应用程序读数据做准备。这个功能对顺序读取非常有效，可以明显地减少磁盘请求的数量，从而提升读数据的性能。\nCPU 和内存也有相应的预取操作，就是将内存中的指令和数据，提前存放到缓存中，从而加快处理器执行速度。缓存预取可以通过硬件或者软件实现，也就是分为硬件预取和软件预取两类。\n硬件预取是通过处理器中的硬件来实现的。该硬件会一直监控正在执行程序中请求的指令或数据，并且根据既定规则，识别下一个程序需要的数据或指令并预取。\n软件预取是在程序编译的过程中，主动插入预取指令（prefetech），这个预取指令可以是编译器自己加的，也可以是我们加的代码。这样在执行过程中，在指定位置就会进行预取的操作。\n4. 延后 / 惰性处理\n延后 / 惰性处理策略和前面说的预先 / 提前处理正好相反。就是尽量将操作（比如计算），推迟到必需执行的时刻，这样很可能避免多余的操作，甚至根本不用操作。\n运用这一策略最有名的例子，就是 COW（Copy On Write，写时复制）。假设多个线程都想操作一份数据，一般情况下，每个线程可以自己拷贝一份，放到自己的空间里面。但是拷贝的操作很费时间。系统如果采用惰性处理，就会将拷贝的操作推迟。如果多个线程对这份数据只有读的请求，那么同一个数据资源是可以共享的，因为“读”的操作不会改变这份数据。当某个线程需要修改这一数据时（写操作），系统就将资源拷贝一份给该线程使用，允许改写，这样就不会影响别的线程。\nCOW 最广为人知的应用场景有两个。一个是 Unix 系统 fork 调用产生的子进程共享父进程的地址空间，只有到某个子进程需要进行写操作才会拷贝一份。另一个是高级语言的类和\n容器，比如 Java 中的 CopyOnWrite 容器，用于多线程并发情况下的高效访问。C++ 里面经常使用的 STL 标准模板库中的很多类，比如 string 类，也是具有写时才拷贝技术的类。\n三、并行 / 异步操作 优化策略的第三大类是“并行 / 异步操作”。并行和异步两种操作虽然看起来很不一样，其实有异曲同工之妙，就是都把一条流水线和处理过程分成了几条，不管是物理上分还是逻辑上分。\n5. 并行操作\n并行操作是一种物理上把一条流水线分成好几条的策略。直观上说，一个人干不完的活，那就多找几个人来干。并行操作既增加了系统的吞吐量，又减少了用户的平均等待时间。比如现代的 CPU 都有很多核，每个核上都可以独立地运行线程，这就是并行操作。\n并行操作需要我们的程序有扩展性，不能扩展的程序，就无法进行并行处理。这里的并行概念有不同的粒度，比如是在服务器的粒度（所谓的横向扩展），还是在多线程的粒度，甚至是在指令级别的粒度。\n绝大多数互联网服务器，要么使用多进程，要么使用多线程来处理用户的请求，以充分利用多核 CPU。另外一种情况就是在有 IO 阻塞的地方，也是非常适合使用多线程并行操作的，因为这种情况 CPU 基本上是空闲状态，多线程可以让 CPU 多干点活。\n6. 异步操作\n异步操作这一策略和并行操作不同，这是一种逻辑上把一条流水线分成几条的策略。\n我们首先在编程的领域澄清一下概念：同步和异步。同步和异步的区别在于一个函数调用之后，是否直接返回结果。如果函数挂起，直到获得结果才返回，这是同步；如果函数马上返回，等数据到达再通知函数，那么这就是异步。\n我们知道 Unix 下的文件操作，是有 block 和 non-block 的方式的，有些系统调用也是block 式的，如：Socket 下的 select 等。如果我们的程序一直是同步操作，那么就会非常影响性能。采用异步操作的话，虽然稍微增加一点程序的复杂度，但会让性能的吞吐率有很大提升。\n现代的语言往往对异步操作有比较好的支持，使得异步编程变得更加简单，可读性也更好。\n四、缓存 / 批量合并 “缓存 / 批量合并”是优化策略中的第四大类。缓存和批量合并这两个策略，有些场景下会同时起作用，所以我把它们放在一起。\n7. 缓存数据\n缓存的本质是加速访问。这是一个用得非常普遍的策略，几乎体现在计算机系统里面每一个模块和领域，CPU、内存、文件系统、存储系统、内容分布、数据库等等，都会遵循这样的策略。\n我们最熟悉的应该就是 CPU 的各级缓存了。在文件系统、存储系统和数据库系统里面，也有快速缓存来存储经常访问的数据，目的是尽量提高缓存命中率，从而避免访问比较慢的存储介质。\n对于一个基于 Web 的应用服务，前端会有浏览器缓存，有 CDN 存放在边缘服务器上，有反向代理提供的静态内容缓存；后端则还会有服务器本地缓存。\n程序设计中，对于可能重复创建和销毁，且创建销毁代价很大的对象（比如套接字和线程），也可以缓存，对应的缓存形式，就是连接池和线程池等。\n对于消耗较大的计算，也可以将计算结果缓存起来，下次可以直接读取结果。比如对递归代码的一个有效优化手段，就是缓存中间结果。\n8. 批量合并处理\n在有 IO（比如网络 IO 和磁盘 IO）的时候，合并操作和批量操作往往能提升吞吐量，提高性能。\n我们最常见的是批量 IO 读写。就是在有多次 IO 的时候，可以把它们合并成一次读写数据。这样可以减少读写时间和协议负担。比如，GFS 写文件的时候，尽量批量写，以减少IO 开销。\n对数据库的读写操作，也可以尽量合并。比如，对键值数据库的查询，最好一次查询多个键，而不要分成多次。\n涉及到网络请求的时候，网络传输的时间可能远大于请求的处理时间，因此合并网络请求也很有必要。上层协议呢，端到端对话次数尽量不要太频繁（Chatty），否则的话，总的应用层吞吐量不会很高。\n五、更先进算法和数据结构 优化策略中的最后一个大类就是“更先进算法和数据结构”。这两个策略是紧密配合的，比如先进的算法有时候会需要先进的数据结构；而且它们往往和程序的设计代码直接相关，所以放在一起。\n9. 先进的算法\n同一个问题，肯定会有不同的算法实现，进而就会有不同的性能。比如各种排序算法，就是各有千秋。有的实现可能是时间换空间，有的实现可能是空间换时间，那么就需要根据你自己的实际情况做权衡。\n对每一种具体的场景（包括输入集合大小、时间空间的要求、数据的大小分布等），总会有一种算法是最适合的。我们需要考虑实际情况，来选择这一最优的算法。\n10. 高效的数据结构\n和算法的情况类似，不同的数据结构的特性，也是千差万别。\n没有一个数据结构是在所有情况下都是最好的，比如你可能经常用到的 Java 里面列表的各种实现，包括各种口味的 List、Vector、LinkedList，它们孰优孰劣，取决于很多个指标：添加元素、删除元素、查询元素、遍历耗时等等。我们同样要权衡取舍，找出实际场合下最适合的高效的数据结构。\n六、总结 各种性能问题的解决，需要采用一些策略；而且不同的人和不同的场景中，会采用有时相同有时迥异的策略，恰如韩愈所说的“草树知春不久归，百般红紫斗芳菲”。但花草树木争奇斗艳，说到底是因为“知春不久归”。\n同样的道理，这些性能优化策略，有时候很容易想到，有时候并不是那么直观。所以，我们需要系统地有层次地思考，而这一讲就是帮助你建立这样的思路。\n通过总结十大策略，希望你可以多从不同角度，思考同一个问题；有时候一个问题看似无解，但多方位思考，可能会突然发现非常好的解决方案。\n","description":"\n","tags":[],"title":"\n十年老架构师总结：性能优化其实不难，记住这十条策略就够了","uri":"/posts/post-249/"},{"categories":["默认分类"],"content":"情况描述 虚拟机中的系统为CentOS，充当服务器，但是开启Tomcat后，在宿主机Mac中无法访问，显示请求被拒接，如下：\n除此之外，但是可以使用ssh，也可以ping通。\n分析 初步认为就是防火墙的问题，但是参考iptables的一些停用方法，直接显示没有iptables这个服务；后面想验证到底是宿主机还是虚拟机的问题，在5000端口，跑了一个简单的Flask服务器（在虚拟机中可通过本机ip地址+端口号进行访问），在宿主机中仍然无法访问，同时也通过其他的一些设备来访问相应的服务器，都无法访问，从这里看来，问题还是出在了虚拟机中；后面又在宿主机mac中开启了一个服务器，在虚拟机和其它局域网设备中都可以访问，因此断定还是虚拟机的问题。那么，没有安装iptables的CentOS，究竟是出了什么问题呢？\n解决办法 因为我使用的是CentOS 7，使用iptables的版本是7以前的，CentOS 7使用firewall作为防火墙。\n查看已经开放的端口：firewall-cmd --list-ports 开启端口：firewall-cmd --zone=public --add-port=80/tcp --permanent\n命令含义：\n–zone #作用域 –add-port=80/tcp #添加端口，格式为：端口/通讯协议 –permanent #永久生效，没有此参数重启后失效123 重启、停止、禁用、查看防火墙\n1 2 3 4 firewall-cmd --reload #重启firewall systemctl stop firewalld.service #停止firewall systemctl disable firewalld.service #禁止firewall开机启动 firewall-cmd --state #查看默认防火墙状态（关闭后显示notrunning，开启后显示running）1234 因此结合上述命令来看，需要将8080端口添加到防火墙的开放端口中，然后重新载入防火墙的配置即可。如下：\n1 2 3 sudo firewall-cmd --zone=public --add-port=8080/tcp --permanent sudo firewall-cmd --reload sudo firewall-cmd --list-ports123 最后面来一张成功访问的截图：\n","description":"\n","tags":[],"title":"\n解决宿主机MAC不能访问虚拟机中CENTOS的TOMCAT服务器","uri":"/posts/post-250/"},{"categories":["运维"],"content":"1. 安装的需求背景 我们知道ifconfig 命令可以用于查看、配置、启用或禁用指定网络接口，如配置网卡的IP地址、掩码、广播地址、网关等，功能不可谓不丰富。\n此命令的功能和Wndows系统的ipconfig非常类似。\n但是，Centos7 默认已不再安装此命令，其中很多功能用 ip addr 指令 替代了。\n考虑到 既有的很多管理工具或脚本都调用了此功能命令（ifconfig），如果将这些工具直接迁移过来会报错，如果对这个指令用其它指令进行替换，及对这些工具升级，则增加了工作量，还增加了出错的风险。\n所以，在CentOS 7 系统中 安装 ifconfig 命令很有必要。\n2. 测试安装的具体步骤 CentOS 7 系统默认 没有安装 ifconfig 命令。\n如果直接运行 ifconfig 命令，则提示错误 ：-bash: ifconfig: command not found\n此时，查看 /sbin 目录下，其实是没有 ifconfig 文件的。\n那么 如何安装ifconfig 呢？我们首先想到的是 运行 yum install ifconfig 。执行效果如何呢？\n结果是：\nNo package ifconfig available. Error: Nothing to do\n啊？！ 没有 ifconfig 安装包，是不是 我们就要放弃了呢？\n其实，我们 还可以通过yum 命令的search选项 来对 包 （package）进行再次搜索。\nsearch：可以搜寻某个软件名称或者是描述（description）的重要关键字。此指令可以查找显示出相关的软件有哪些。\n所以，在放弃前，我们运行以下命令：\nyum search ifconfig\n以上运行结果，我们只要分析最好一行就可以。Matched: ifconfig 这个 分割行 是用来显示 匹配结果的。\n最后一行 中 冒号（：）前面的数据， （net-tools.x86_64 ） 是匹配的软件包；冒号（：）后面的数据，（Basic networking tools ） 是对前面包的描述。\n结合上面的信息，即 通过运行 yum search ifconfig 提示我们： 安装ifconfig 包 只需要安装 net-tools.x86_64 即可。\n所以，我们执行 yum install net-tools.x86_64\n安装后，ifconfig 命令可以正常执行。因含有ip敏感信息，截图省略。\n并且，查看/sbin 目录，此时 ifconfig 文件也出现了。\n3. 总结\nCentOS 7 安装 ifconfig 管理命令，通过yum 安装，运行 yum install net-tools.x86_64 即可安装。\n","description":"\n","tags":[],"title":"\nCentOS 7安装 ifconfig 管理命令","uri":"/posts/post-251/"},{"categories":["默认分类"],"content":"在安装配置 SSL 证书时，可以使用一种能使数据传输更加安全的Web安全协议，即在服务器端上开启HSTS (HTTP Strict Transport Security)。它告诉浏览器只能通过HTTPS访问，而绝对禁止HTTP方式。\nHTTP Strict Transport Security (HSTS) is an opt-in security enhancement that is specified by a web application through the use of a special response header. Once a supported browser receives this header that browser will prevent any communications from being sent over HTTP to the specified domain and will instead send all communications over HTTPS. It also prevents HTTPS click through prompts on browsers.\n但是，在日常开发的过程中，有时我们会想测试页面在 HTTP 连接中的表现情况，这时 HSTS 的存在会让调试不能方便的进行下去。而且由于 HSTS 并不是像 cookie 一样存放在浏览器缓存里，简单的清空浏览器缓存操作并没有什么效果，页面依然通过 HTTPS 的方式传输。 那么怎样才能关闭浏览器的 HSTS 呢，各种谷歌度娘之后，在这里汇总一下几大常见浏览器 HSTS 的关闭方法。\nSafari 浏览器 完全关闭 Safari 删除 ~/Library/Cookies/HSTS.plist 这个文件 重新打开 Safari 即可 极少数情况下，需要重启系统 Chrome 浏览器 地址栏中输入 chrome://net-internals/#hsts 在 Delete domain 中输入项目的域名，并Delete 删除 可以在 Query domain 测试是否删除成功 Opera 浏览器 和 Chrome 方法一样\nFirefox 浏览器 关闭所有已打开的页面 清空历史记录和缓存 地址栏输入about:permissions 搜索项目域名，并点击 Forget About This Site ","description":"\n","tags":[],"title":"\n如何关闭常见浏览器的 HSTS 功能","uri":"/posts/post-252/"},{"categories":["默认分类"],"content":"下载与安装 首先从 Redis 官网下载 Redis 源代码并解压，这里使用的是 redis-6.0.8.tar.gz 版本\n# 创建目录 mkdir /usr/local/redis/redis-cluster # 进入目录 cd /usr/local/redis/redis-cluster # 下载安装包 wget http://download.redis.io/releases/redis-6.0.8.tar.gz # 解压 tar -zxzf redis-6.0.8.tar.gz #进入目录 cd redis-6.0.8 # 编译用 如果不安装会编译报错 yum -y install gcc-c++ #加 MALLOC=libc 为了防止编译出错，具体百度 make MALLOC=libc make MALLOC=libc make install PREFIX=/apprun/redis # 目标安装路径 创建数据 #创建目录 cd /usr/local/redis/redis-cluster mkdir logs conf data pid #创建数据目录 cd data mkdir data1111 data2222 data3333 data4444 data5555 data6666 修改配置文件 cd /usr/local/redis/redis-cluster/conf cp /usr/local/redis/redis-cluster/redis/redis.conf . mv redis.conf redis1111.conf vim redis1111.conf # 修改绑定地址 bind 192.168.5.199 protected-mode yes # 修改端口号,但集群状态下需要注意,集群使用端口会在此端口上增加10000,所以redis自身端口+10000不能超过65535 port 1111 tcp-backlog 511 timeout 0 tcp-keepalive 300 # Redis是否后台运行 daemonize yes supervised no # 进程文件存储地址 pidfile /usr/local/redis/redis-cluster/pid/redis1111.pid loglevel notice # 日志文件存储地址 logfile \"/usr/local/redis/redis-cluster/logs/redis1111.log\" databases 16 always-show-logo yes save 900 1 save 300 10 save 60 10000 stop-writes-on-bgsave-error yes # 持久化错误之后，停止写入Redis rdbcompression yes # 快照是否压缩存储（压缩消耗CPU、占用空间小） rdbchecksum yes # 存储的快照进行数据校验（增加约10%的性能消耗） dbfilename dump.rdb rdb-del-sync-files no # 数据存放目录 dir /usr/local/redis/redis-cluster/data/data1111 # 主要是针对master对应的slave节点设置的，在slave节点数据同步的时候用到 masterauth redis123 replica-serve-stale-data yes replica-read-only yes repl-diskless-sync no repl-diskless-sync-delay 5 repl-diskless-load disabled repl-disable-tcp-nodelay no replica-priority 100 acllog-max-len 128 # 对登录权限做限制，redis每个节点的requirepass可以是独立、不同的 requirepass redis123 lazyfree-lazy-eviction no lazyfree-lazy-expire no lazyfree-lazy-server-del no replica-lazy-flush no lazyfree-lazy-user-del no oom-score-adj no oom-score-adj-values 0 200 800 # aof日志开启，有需要就开启 appendonly yes appendfilename \"appendonly.aof\" appendfsync everysec # 每秒同步一次（always 每次修改同步一次） no-appendfsync-on-rewrite no auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb aof-load-truncated yes aof-use-rdb-preamble yes lua-time-limit 5000 # 开启集群模式 cluster-enabled yes # 集群的配置文件，首次启动自动生成 cluster-config-file /usr/local/redis/redis-cluster/conf/nodes1111.conf # 请求超时时间，默认15s cluster-node-timeout 10000 slowlog-log-slower-than 10000 slowlog-max-len 128 latency-monitor-threshold 0 notify-keyspace-events \"\" hash-max-ziplist-entries 512 hash-max-ziplist-value 64 list-max-ziplist-size -2 list-compress-depth 0 set-max-intset-entries 512 zset-max-ziplist-entries 128 zset-max-ziplist-value 64 hll-sparse-max-bytes 3000 stream-node-max-bytes 4096 stream-node-max-entries 100 activerehashing yes client-output-buffer-limit normal 0 0 0 client-output-buffer-limit replica 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 hz 10 dynamic-hz yes aof-rewrite-incremental-fsync yes rdb-save-incremental-fsync yes 复制配置 Redis 集群一般由多个节点组成，节点数量至少为 6 个，才能保证组成完整高可用的集群，所以再复制 5 份配置文件\ncp redis1111.conf redis2222.conf cp redis1111.conf redis3333.conf cp redis1111.conf redis4444.conf cp redis1111.conf redis5555.conf cp redis1111.conf redis6666.conf # vim 进去里边修改：比如：% s/1111/2222/ 配置启动命令及启动集群 cd /usr/local/redis/redis-cluster/redis/src # 这样可以直接使用该命令，不需要再进入该命令目录 cp redis-cli redis-server /usr/bin/ #编写统一启动脚本、启动 cd /usr/local/redis/redis-cluster vi redis-start.sh #!/bin/bash redis-server /usr/local/redis/redis-cluster/conf/redis1111.conf redis-server /usr/local/redis/redis-cluster/conf/redis2222.conf redis-server /usr/local/redis/redis-cluster/conf/redis3333.conf redis-server /usr/local/redis/redis-cluster/conf/redis4444.conf redis-server /usr/local/redis/redis-cluster/conf/redis5555.conf redis-server /usr/local/redis/redis-cluster/conf/redis6666.conf # 赋予权限 chmod 755 redis-start.sh ./redis-start.sh #启动集群 执行命令：redis-cli --cluster create 192.168.5.199:1111 192.168.5.199:2222 192.168.5.199:3333 192.168.5.199:4444 192.168.5.199:5555 192.168.5.199:6666 --cluster-replicas 1 -a redis123 参数说明：注意 redis-5.0.0 版本开始才支持 “ –cluster ”\ncreate 表示创建一个redis集群。\n--cluster-replicas 1 表示为集群中的每一个主节点指定一个从节点，即一比一的复制。\nWarning: Using a password with '-a' or '-u' option on the command line interface may not be safe. \u003e\u003e\u003e Performing hash slots allocation on 6 nodes... Master[0] -\u003e Slots 0 - 5460 Master[1] -\u003e Slots 5461 - 10922 Master[2] -\u003e Slots 10923 - 16383 Adding replica 192.168.5.199:5555 to 192.168.5.199:1111 Adding replica 192.168.5.199:6666 to 192.168.5.199:2222 Adding replica 192.168.5.199:4444 to 192.168.5.199:3333 \u003e\u003e\u003e Trying to optimize slaves allocation for anti-affinity [WARNING] Some slaves are in the same host as their master M: 3c09b846d56efc9c3d3367b7db74317ff0c54980 192.168.5.199:1111 slots:[0-5460] (5461 slots) master M: f35e954bd158848b5dc09358752daf7db35c7d7e 192.168.5.199:2222 slots:[5461-10922] (5462 slots) master M: 2e54db41b7916b64d7689b22a0f456dd099086fc 192.168.5.199:3333 slots:[10923-16383] (5461 slots) master S: edf74be3f4784f0d560505ad0ca10bcd76d57d42 192.168.5.199:4444 replicates 3c09b846d56efc9c3d3367b7db74317ff0c54980 S: 609822d35d216b3bea5a308f25fa537055d85089 192.168.5.199:5555 replicates f35e954bd158848b5dc09358752daf7db35c7d7e S: ee9838644056c360a88399b3acb5f905e17eebc5 192.168.5.199:6666 replicates 2e54db41b7916b64d7689b22a0f456dd099086fc Can I set the above configuration? (type 'yes' to accept): yes \u003e\u003e\u003e Nodes configuration updated \u003e\u003e\u003e Assign a different config epoch to each node \u003e\u003e\u003e Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join . \u003e\u003e\u003e Performing Cluster Check (using node 192.168.5.199:1111) M: 3c09b846d56efc9c3d3367b7db74317ff0c54980 192.168.5.199:1111 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: edf74be3f4784f0d560505ad0ca10bcd76d57d42 192.168.5.199:4444 slots: (0 slots) slave replicates 3c09b846d56efc9c3d3367b7db74317ff0c54980 S: ee9838644056c360a88399b3acb5f905e17eebc5 192.168.5.199:6666 slots: (0 slots) slave replicates 2e54db41b7916b64d7689b22a0f456dd099086fc M: 2e54db41b7916b64d7689b22a0f456dd099086fc 192.168.5.199:3333 slots:[10923-16383] (5461 slots) master 1 additional replica(s) S: 609822d35d216b3bea5a308f25fa537055d85089 192.168.5.199:5555 slots: (0 slots) slave replicates f35e954bd158848b5dc09358752daf7db35c7d7e M: f35e954bd158848b5dc09358752daf7db35c7d7e 192.168.5.199:2222 slots:[5461-10922] (5462 slots) master 1 additional replica(s) [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. 检测集群完整性 #执行命令 redis-cli --cluster check 192.168.121.128:1111 -a redis123 [root@localhost ~]# redis-cli --cluster check 192.168.5.199:1111 -a \"redis123\" Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. 192.168.5.199:1111 (3c09b846...) -\u003e 0 keys | 5461 slots | 1 slaves. 192.168.5.199:3333 (2e54db41...) -\u003e 1 keys | 5461 slots | 1 slaves. 192.168.5.199:2222 (f35e954b...) -\u003e 1 keys | 5462 slots | 1 slaves. [OK] 2 keys in 3 masters. 0.00 keys per slot on average. \u003e\u003e\u003e Performing Cluster Check (using node 192.168.5.199:1111) M: 3c09b846d56efc9c3d3367b7db74317ff0c54980 192.168.5.199:1111 slots:[0-5460] (5461 slots) master 1 additional replica(s) S: edf74be3f4784f0d560505ad0ca10bcd76d57d42 192.168.5.199:4444 slots: (0 slots) slave replicates 3c09b846d56efc9c3d3367b7db74317ff0c54980 S: ee9838644056c360a88399b3acb5f905e17eebc5 192.168.5.199:6666 slots: (0 slots) slave replicates 2e54db41b7916b64d7689b22a0f456dd099086fc M: 2e54db41b7916b64d7689b22a0f456dd099086fc 192.168.5.199:3333 slots:[10923-16383] (5461 slots) master 1 additional replica(s) S: 609822d35d216b3bea5a308f25fa537055d85089 192.168.5.199:5555 slots: (0 slots) slave replicates f35e954bd158848b5dc09358752daf7db35c7d7e M: f35e954bd158848b5dc09358752daf7db35c7d7e 192.168.5.199:2222 slots:[5461-10922] (5462 slots) master 1 additional replica(s) [OK] All nodes agree about slots configuration. \u003e\u003e\u003e Check for open slots... \u003e\u003e\u003e Check slots coverage... [OK] All 16384 slots covered. 登录验证 #执行命令 redis-cli -h 192.168.5.199 -p 1111 -a \"redis123\" Warning: Using a password with '-a' or '-u' option on the command line interface may not be safe. 192.168.5.199:1111\u003e info cluster # Cluster cluster_enabled:1 192.168.5.199:1111\u003e cluster info cluster_state:ok cluster_slots_assigned:16384 cluster_slots_ok:16384 cluster_slots_pfail:0 cluster_slots_fail:0 cluster_known_nodes:6 cluster_size:3 cluster_current_epoch:6 cluster_my_epoch:1 cluster_stats_messages_ping_sent:67776 cluster_stats_messages_pong_sent:71182 cluster_stats_messages_sent:138958 cluster_stats_messages_ping_received:71177 cluster_stats_messages_pong_received:67776 cluster_stats_messages_meet_received:5 cluster_stats_messages_received:138958 192.168.5.199:1111\u003e ","description":"\n","tags":[],"title":"\nRedis 6.0.8 集群搭建(三主三从)","uri":"/posts/post-253/"},{"categories":["默认分类"],"content":"#!/bin/bash # # This script gets the beautiful wallpapers from http://wallhaven.cc # This script is brought to you by MacEarl and is based on the # script for wallbase.cc (https://github.com/sevensins/Wallbase-Downloader) # # This Script is written for GNU Linux, it should work under Mac OS REVISION=0.2.6 ##################################### ### Needed for NSFW/Favorites ### ##################################### # Enter your API key # you can get it here: https://wallhaven.cc/settings/account APIKEY=\"beYBHQ89MncZeTt96JXRyrqmwBFifWUr\" ##################################### ### End needed for NSFW/Favorites ### ##################################### ##################################### ### Configuration Options ### ##################################### # Where should the Wallpapers be stored? LOCATION=/Volumes/photo # How many Wallpapers should be downloaded, should be multiples of the # value in the THUMBS Variable WPNUMBER=48 # What page to start downloading at, default and minimum of 1. STARTPAGE=1 # Type standard (newest, oldest, random, hits, mostfav), search, collections # (for now only the default collection), useruploads (if selected, only # FILTER variable will change the outcome) TYPE=standard # From which Categories should Wallpapers be downloaded, first number is # for General, second for Anime, third for People, 1 to enable category, # 0 to disable it CATEGORIES=110 # filter wallpapers before downloading, first number is for sfw content, # second for sketchy content, third for nsfw content, 1 to enable, # 0 to disable FILTER=111 # Which Resolutions should be downloaded, leave empty for all (most common # resolutions possible, for details see wallhaven site), separate multiple # resolutions with , eg. 1920x1080,1920x1200 RESOLUTION= # alternatively specify a minimum resolution, please note that specifying # both resolutions and a minimum resolution will result in the desired # resolutions being ignored, to avoid unwanted behavior only set one of the # two options and leave the other blank ATLEAST= # Which aspectratios should be downloaded, leave empty for all (possible # values: 4x3, 5x4, 16x9, 16x10, 21x9, 32x9, 48x9, 9x16, 10x16), separate mutliple ratios # with , eg. 4x3,16x9 ASPECTRATIO= # Which Type should be displayed (relevance, random, date_added, views, # favorites, toplist, toplist-beta) MODE=date_added # if MODE is set to toplist show the toplist for the given timeframe # possible values: 1d (last day), 3d (last 3 days), 1w (last week), # 1M (last month), 3M (last 3 months), 6M (last 6 months), 1y (last year) TOPRANGE= # How should the wallpapers be ordered (desc, asc) ORDER=desc # Collections, only used if TYPE = collections # specify the name of the collection you want to download # Default is the default collection name on wallhaven # If you want to download your own Collections make sure USR is set to your username # If you want to download someone elses public collection enter the name here # and the username under USR # Please note that the only filter option applied to Collections is the Number # of Wallpapers to download, there is no filter for resolution, purity, ... COLLECTION=\"Default\" # Searchterm, only used if TYPE = search # you can also search by tags, use id:TAGID # to get the tag id take a look at: https://wallhaven.cc/tags/ # for example: to search for nature related wallpapers via the nature tag # instead of the keyword use QUERY=\"id:37\" QUERY=\"nature\" # Search images containing color # values are RGB (000000 = black, ffffff = white, ff0000 = red, ...) COLOR=\"\" # Should the search results be saved to a separate subfolder? # 0 for no separate folder, 1 for separate subfolder SUBFOLDER=0 # User from which wallpapers should be downloaded # used for TYPE=useruploads and TYPE=collections # If you want to download your own Collection this has to be set to your username USR=\"AksumkA\" # use gnu parallel to speed up the download (0, 1), if set to 1 make sure # you have gnuparallel installed, see normal.vs.parallel.txt for # speed improvements # using this option can lead to cloudflare blocking some of the downloads PARALLEL=0 # custom thumbnails per page # changeable here: https://wallhaven.cc/settings/browsing # valid values: 24, 32, 64 # if set to 32 or 64 you need to provide an api key THUMBS=24 ##################################### ### End Configuration Options ### ##################################### function checkDependencies { printf \"Checking dependencies...\" dependencies=(wget jq sed) [[ $PARALLEL == 1 ]] \u0026\u0026 dependencies+=(parallel) for name in \"${dependencies[@]}\" do [[ $(command -v \"$name\" 2\u003e/dev/null) ]] || { printf \"\\n%s needs to be installed. Use your package manager to do so, e.g. 'sudo apt install %s'\" \"$name\" \"$name\";deps=1; } done if [[ $deps -ne 1 ]] then printf \"OK\\n\" else printf \"\\nInstall the above and rerun this script\\n\" exit 1 fi } # /checkDependencies # # sets the authentication header/API key to give the user more functionality # requires 1 arguments: # arg1: API key # function setAPIkeyHeader { # checking parameters -\u003e if not ok print error and exit script if [ $# -lt 1 ] || [ \"$1\" == '' ] then printf \"Please make sure to enter a valid API key,\\n\" printf \"it is needed for NSFW Content and downloading \\n\" printf \"your Collections also make sure your Thumbnails per\\n\" printf \"Page Setting matches the THUMBS Variable\\n\\n\" printf \"Press any key to exit\\n\" read -r exit fi # everythings ok --\u003e set api key header httpHeader=\"X-API-Key: $APIKEY\" } # /setAPIkeyHeader # # downloads Page with Thumbnails # function getPage { # checking parameters -\u003e if not ok print error and exit script if [ $# -lt 1 ] then printf \"getPage expects at least 1 argument\\\\n\" printf \"arg1:\\\\tparameters for the wget -q command\\\\n\\\\n\" printf \"press any key to exit\\\\n\" read -r exit fi # parameters ok --\u003e get page WGET -O tmp \"https://wallhaven.cc/api/v1/$1\" } # /getPage # # downloads all the wallpaper from a wallpaperfile # arg1: the file containing the wallpapers # function downloadWallpapers { if (( \"$page\" \u003e= \"$(jq -r \".meta.last_page\" tmp)\" )) then downloadEndReached=true fi for ((i=0; i\u003cTHUMBS; i++)) do imgURL=$(jq -r \".data[$i].path\" tmp) filename=$(echo \"$imgURL\"| sed \"s/.*\\///\" ) if grep -w \"$filename\" downloaded.txt \u003e/dev/null then printf \"\\\\tWallpaper %s already downloaded!\\\\n\" \"$imgURL\" elif [ $PARALLEL == 1 ] then echo \"$imgURL\" \u003e\u003e download.txt else # check if downloadWallpaper was successful if downloadWallpaper \"$imgURL\" then echo \"$filename\" \u003e\u003e downloaded.txt fi fi done if [ $PARALLEL == 1 ] \u0026\u0026 [ -f ./download.txt ] then # export wget wrapper and download function to make it # available for parallel export -f WGET coolDown downloadWallpaper # shellcheck disable=SC2016 SHELL=$(type -p bash) parallel --gnu --no-notice \\ 'imgURL={} \u0026\u0026 downloadWallpaper $imgURL \u0026\u0026 echo \"$imgURL\"| sed \"s/.*\\///\" \u003e\u003e downloaded.txt' \u003c download.txt rm tmp download.txt else rm tmp fi } # /downloadWallpapers # # downloads a single Wallpaper by guessing its extension, this eliminates # the need to download each wallpaper page, now only the thumbnail page # needs to be downloaded # function downloadWallpaper { if [[ \"$1\" != null ]] then WGET \"$1\" else return 1 fi } # /downloadWallpaper # # Waits for 30 seconds if rate limiting is detected # function coolDown { printf \"\\\\t -Rate Limiting detected, sleeping for 30 seconds\\\\n\" sleep 30 WGET \"$@\" } # /coolDown # # wrapper for wget with some default arguments # arg0: additional arguments for wget (optional) # arg1: file to download # function WGET { # checking parameters -\u003e if not ok print error and exit script if [ $# -lt 1 ] then printf \"WGET expects at least 1 argument\\\\n\" printf \"arg0:\\\\tadditional arguments for wget (optional)\\\\n\" printf \"arg1:\\\\tfile to download\\\\n\\\\n\" printf \"press any key to exit\\\\n\" read -r exit fi # default wget command wget --server-response -q --header=\"$httpHeader\" --keep-session-cookies \\ --save-cookies cookies.txt --load-cookies cookies.txt \"$@\" 2\u003e\u00261 | \\ grep \"429 Too Many Requests\" \u003e/dev/null \u0026\u0026 coolDown \"$@\" return \"${PIPESTATUS[0]}\" } # /WGET # # displays help text (valid command line arguments) # function helpText { printf \"Usage: ./wallhaven.sh [OPTIONS]\\\\n\" printf \"Download wallpapers from wallhaven.cc\\\\n\\\\n\" printf \"If no options are specified, default values from within the \" printf \"script will be used\\\\n\\\\n\" printf \" -l, --location\\\\t\\\\tlocation where the wallpapers will be \" printf \"stored\\\\n\" printf \" -n, --number\\\\t\\\\tNumber of Wallpapers to download\\\\n\" printf \" -s, --startpage\\\\tpage to start downloading from\\\\n\" printf \" -t, --type\\\\t\\\\tType of download Operation: standard, search, \" printf \"\\\\n\\\\t\\\\t\\\\tcollections, useruploads\\\\n\" printf \" -c, --categories\\\\tcategories to download from, eg. 111 for \" printf \"General,\\\\n\\\\t\\\\t\\\\tAnime and People, 1 to include, 0 to exclude\\\\n\" printf \" -f, --filter\\\\t\\\\tfilter out content based on purity rating, \" printf \"eg. 111 \\\\n\\\\t\\\\t\\\\tfor SFW, sketchy and NSFW content, 1 to \" printf \"include, \\\\n\\\\t\\\\t\\\\t0 to exclude\\\\n\" printf \" -r, --resolution\\\\tresolutions to download, separate mutliple\" printf \" \\\\n\\\\t\\\\t\\\\tresolutions by ,\\\\n\" printf \" -g, --atleast\\\\t\\\\tminimum resolution, show all images with a\" printf \"\\\\n\\\\t\\\\t\\\\tresolution greater than the specified value\" printf \"\\\\n\\\\t\\\\t\\\\tdo not use in combination with -r (--resolution)\\\\n\" printf \" -a, --aspectratio\\\\tonly download wallpaper with given \" printf \"aspectratios, \\\\n\\\\t\\\\t\\\\tseparate multiple aspectratios by ,\\\\n\" printf \" -m, --mode\\\\t\\\\tsorting mode for wallpapers: relevance, random\" printf \",\\\\n\\\\t\\\\t\\\\tdate_added, views, favorites \\\\n\" printf \" -o, --order\\\\t\\\\torder ascending (asc) or descending \" printf \"(desc)\\\\n\" printf \" -b, --collection\\\\tname of the collections to download\\\\n\" printf \" -q, --query\\\\t\\\\tsearch query, eg. 'mario', single \" printf \"quotes needed,\\\\n\\\\t\\\\t\\\\tfor searching exact phrases use double \" printf \"quotes \\\\n\\\\t\\\\t\\\\tinside single quotes, eg. '\"super mario\"'\" printf \"\\\\n\" printf \" -d, --dye, --color\\\\tsearch for wallpapers containing the \" printf \"given color,\\\\n\" printf \"\\\\t\\\\t\\\\tcolor values are RGB without a leading #\\\\n\" printf \" -u, --user\\\\t\\\\tdownload wallpapers from given user\\\\n\" printf \" -p, --parallel\\\\t\\\\tmake use of gnu parallel (1 to enable, 0 \" printf \"to disable)\\\\n\" printf \" -v, --version\\\\t\\\\tshow current version\\\\n\" printf \" -h, --help\\\\t\\\\tshow this help text and exit\\\\n\\\\n\" printf \"Examples:\\\\n\" printf \"./wallhaven.sh\\\\t-l ~/wp/ -n 48 -s 1 -t standard -c 101 -f 111\" printf \" -r 1920x1080 \\\\n\\\\t\\\\t-a 16x9 -m random -o desc -p 1\\\\n\\\\n\" printf \"Download 48 random wallpapers with a resolution of 1920x1080 \" printf \"and \\\\nan aspectratio of 16x9 to ~/wp/ starting with page 1 \" printf \"from the \\\\ncategories general and people including SFW, sketchy\" printf \" and NSWF Content\\\\nwhile utilizing gnu parallel\\\\n\\\\n\" printf \"./wallhaven.sh\\\\t-l ~/wp/ -n 48 -s 1 -t search -c 111 -f 100 -r \" printf \"1920x1080 -a 16x9\\\\n\\\\t\\\\t-m relevance -o desc -q \" printf \"'\"super mario\"' -d cc0000 -p 1\\\\n\\\\n\" printf \"Download 48 wallpapers related to the search query \" printf \"\"super mario\" containing \\\\nthe color #cc0000 with a resolution\" printf \" of 1920x1080 and an aspectratio of 16x9\\\\nto ~/wp/ starting \" printf \"with page 1 from the categories general, anime and people,\\\\n\" printf \"including SFW Content and excluding sketchy and NSWF Content \" printf \"while utilizing\\\\ngnu parallel\\\\n\\\\n\\\\n\" printf \"latest version available at: \" printf \"\u003chttps://github.com/macearl/Wallhaven-Downloader\u003e\\\\n\" } # /helptext # Command line Arguments while [[ $# -ge 1 ]] do key=\"$1\" case $key in -l|--location) LOCATION=\"$2\" shift;; -n|--number) WPNUMBER=\"$2\" shift;; -s|--startpage) STARTPAGE=\"$2\" shift;; -t|--type) TYPE=\"$2\" shift;; -c|--categories) CATEGORIES=\"$2\" shift;; -f|--filter) FILTER=\"$2\" shift;; -r|--resolution) RESOLUTION=\"$2\" shift;; -g|--atleast) ATLEAST=\"$2\" shift;; -a|--aspectratio) ASPECTRATIO=\"$2\" shift;; -m|--mode) MODE=\"$2\" shift;; -o|--order) ORDER=\"$2\" shift;; -b|--collection) COLLECTION=\"$2\" shift;; -q|--query) QUERY=${2//\\'/} shift;; -d|--dye|--color) COLOR=\"$2\" shift;; -u|--user) USR=\"$2\" shift;; -p|--parallel) PARALLEL=\"$2\" shift;; -h|--help) helpText exit ;; -v|--version) printf \"Wallhaven Downloader %s\\\\n\" \"$REVISION\" exit ;; *) printf \"unknown option: %s\\\\n\" \"$1\" helpText exit ;; esac shift # past argument or value done checkDependencies # optionally create a separate subfolder for each search query # might download duplicates as each search query has its own list of # downloaded wallpapers if [ \"$TYPE\" == search ] \u0026\u0026 [ \"$SUBFOLDER\" == 1 ] then LOCATION+=/$(echo \"$QUERY\" | sed -e \"s/ /_/g\" -e \"s/+/_/g\" -e \"s/\\\\//_/g\") fi # creates Location folder if it does not exist if [ ! -d \"$LOCATION\" ] then mkdir -p \"$LOCATION\" fi cd \"$LOCATION\" || exit # creates downloaded.txt if it does not exist if [ ! -f ./downloaded.txt ] then touch downloaded.txt fi # set auth header only when it is required ( for example to download your # own collections or nsfw content... ) if [ \"$FILTER\" == 001 ] || [ \"$FILTER\" == 011 ] || [ \"$FILTER\" == 111 ] \\ || [ \"$TYPE\" == collections ] || [ \"$THUMBS\" != 24 ] then setAPIkeyHeader \"$APIKEY\" fi if [ \"$TYPE\" == standard ] then for (( count=0, page=\"$STARTPAGE\"; count\u003c \"$WPNUMBER\"; count=count+\"$THUMBS\", page=page+1 )); do printf \"Download Page %s\\\\n\" \"$page\" s1=\"search?page=$page\u0026categories=$CATEGORIES\u0026purity=$FILTER\u0026\" s1+=\"atleast=$ATLEAST\u0026resolutions=$RESOLUTION\u0026ratios=$ASPECTRATIO\" s1+=\"\u0026sorting=$MODE\u0026order=$ORDER\u0026topRange=$TOPRANGE\u0026colors=$COLOR\" getPage \"$s1\" printf \"\\\\t- done!\\\\n\" printf \"Download Wallpapers from Page %s\\\\n\" \"$page\" downloadWallpapers printf \"\\\\t- done!\\\\n\" if [ \"$downloadEndReached\" = true ] then break fi done elif [ \"$TYPE\" == search ] || [ \"$TYPE\" == useruploads ] then for (( count=0, page=\"$STARTPAGE\"; count\u003c \"$WPNUMBER\"; count=count+\"$THUMBS\", page=page+1 )); do printf \"Download Page %s\\\\n\" \"$page\" s1=\"search?page=$page\u0026categories=$CATEGORIES\u0026purity=$FILTER\u0026\" s1+=\"atleast=$ATLEAST\u0026resolutions=$RESOLUTION\u0026ratios=$ASPECTRATIO\" s1+=\"\u0026sorting=$MODE\u0026order=desc\u0026topRange=$TOPRANGE\u0026colors=$COLOR\" if [ \"$TYPE\" == search ] then s1+=\"\u0026q=$QUERY\" elif [ \"$TYPE\" == useruploads ] then s1+=\"\u0026q=@$USR\" fi getPage \"$s1\" printf \"\\\\t- done!\\\\n\" printf \"Download Wallpapers from Page %s\\\\n\" \"$page\" downloadWallpapers printf \"\\\\t- done!\\\\n\" if [ \"$downloadEndReached\" = true ] then break fi done elif [ \"$TYPE\" == collections ] then if [ \"$USR\" == \"\" ] then printf \"Please check the value specified for USR\\\\n\" printf \"to download a Collection it is necessary to specify a User\\\\n\\\\n\" printf \"Press any key to exit\\\\n\" read -r exit fi getPage \"collections/$USR\" i=0 while label=$(jq -e -r \".data[$i].label\" tmp) id=$(jq -e -r \".data[$i].id\" tmp) collectionsize=$(jq -e -r \".data[$i].count\" tmp) [[ $label != \"$COLLECTION\" \u0026\u0026 $label != null ]] do (( i++ )) done if [ -z \"$id\" ] then printf \"Please check the value specified for COLLECTION\\\\n\" printf \"it seems that a collection with the name \"%s\" does not exist\\\\n\\\\n\" \\ \"$COLLECTION\" printf \"Press any key to exit\\\\n\" read -r exit fi for (( count=0, page=\"$STARTPAGE\"; count\u003c \"$WPNUMBER\" \u0026\u0026 count\u003c \"$collectionsize\"; count=count+\"$THUMBS\", page=page+1 )); do printf \"Download Page %s\\\\n\" \"$page\" getPage \"collections/$USR/$id?page=$page\" printf \"\\\\t- done!\\\\n\" printf \"Download Wallpapers from Page %s\\\\n\" \"$page\" downloadWallpapers printf \"\\\\t- done!\\\\n\" done else printf \"error in TYPE please check Variable\\\\n\" fi rm -f cookies.txt ","description":"\n","tags":[],"title":"\n批量下载wallhaven壁纸","uri":"/posts/post-254/"},{"categories":["虚拟机"],"content":"前言\n大家都知道，jvm在启动的时候，会执行默认的一些参数。一般情况下，这些设置的默认参数应对一些平常的项目也够用了。但是如果项目特别大了，需要增加一下堆内存的大小、或者是系统老是莫明的挂掉，想查看下gc日志来排查一下错误的原因，都需要咱们手动设置这些参数。\n1.verbose:gc 表示，启动jvm的时候，输出jvm里面的gc信息。格式如下：\n[Full GC 178K-\u003e99K(1984K)， 0.0253877 secs] 解读 ：Full GC 就表示执行了一次Full GC的操作，178K 和99K 就表示执行GC前内存容量和执行GC后的内存容量。1984K就表示内存总容量。后面那个是执行本次GC所消耗的时间，单位是秒。\n2.-XX:+printGC 这个打印的GC信息跟上个一样，就不做介绍了。\n3.-XX:+PrintGCDetails 打印GC的详细信息。格式如下：\n–Heap – def new generation total 13824K, used 11223K [0x27e80000, 0x28d80000, 0x28d80000) – eden space 12288K, 91% used [0x27e80000, 0x28975f20, 0x28a80000) – from space 1536K, 0% used [0x28a80000, 0x28a80000, 0x28c00000) – to space 1536K, 0% used [0x28c00000, 0x28c00000, 0x28d80000) – tenured generation total 5120K, used 0K [0x28d80000, 0x29280000, 0x34680000) – the space 5120K, 0% used [0x28d80000, 0x28d80000, 0x28d80200, 0x29280000) – compacting perm gen total 12288K, used 142K [0x34680000, 0x35280000, 0x38680000) – the space 12288K, 1% used [0x34680000, 0x346a3a90, 0x346a3c00, 0x35280000) – ro space 10240K, 44% used [0x38680000, 0x38af73f0, 0x38af7400, 0x39080000) – rw space 12288K, 52% used [0x39080000, 0x396cdd28, 0x396cde00, 0x39c80000) 解读：new generation 就是堆内存里面的新生代。total的意思就是一共的，所以后面跟的就是新生代一共的内存大小。used也就是使用了多少内存大小。0x开头的那三个分别代表的是 底边界，当前边界，高边界。也就是新生代这片内存的起始点，当前使用到的地方和最大的内存地点。\neden space 这个通常被翻译成伊甸园区，是在新生代里面的，一些创建的对象都会先被放进这里。后面那个12288K就表示伊甸园区一共的内存大小，91% used，很明显，表示已经使用了百分之多少。后面的那个0x跟上一行的解释一样。\nfrom space 和to space 是幸存者的两个区。也是属于新生代的。他两个区的大小必须是一样的。因为新生代的GC采用的是复制算法，每次只会用到一个幸存区，当一个幸存区满了的时候，把还是活的对象复制到另个幸存区，上个直接清空。这样做就不会产生内存碎片了。\ntenured generation 就表示老年代。\ncompacting perm 表示永久代。由于这两个的格式跟前面我介绍的那个几乎一样，我就不必介绍了。\n4.-XX:+PrintGCTimeStamps 打印GC发生的时间戳。格式如下：\n289.556: [GC [PSYoungGen: 314113K-\u003e15937K(300928K)] 405513K-\u003e107901K(407680K), 0.0178568 secs] [Times: user=0.06 sys=0.00, real=0.01 secs] 293.271: [GC [PSYoungGen: 300865K-\u003e6577K(310720K)] 392829K-\u003e108873K(417472K), 0.0176464 secs] [Times: user=0.06 sys=0.00, real=0.01 secs] 解读：289.556表示从jvm启动到发生垃圾回收所经历的的时间。GC表示这是新生代GC（Minor GC）。PSYoungGen表示新生代使用的是多线程垃圾回收器Parallel Scavenge。314113K-\u003e15937K(300928K)]这个跟上面那个GC格式一样，只不过，这个是表示的是新生代，幸存者区。后面那个是整个堆的大小，GC前和GC后的情况。Times这个显而易见，代表GC的所消耗的时间，用户垃圾回收的时间和系统消耗的时间和最终真实的消耗时间。\n5.-X:loggc:log/gc.log 这个就表示，指定输出gc.log的文件位置。（我这里写的log/gc.log就表示在当前log的目录里，把GC日志写到叫gc.log的文件里。）\n6.-XX:+PrintHeapAtGC 表示每次GC后，都打印堆的信息。（这个打印的基本格式跟上面第二条的基本类似，我也就不比多说了。）\n7.-XX:+TraceClassLoading 监控类的加载。格式如下：\n•[Loaded java.lang.Object from shared objects file] •[Loaded java.io.Serializable from shared objects file] •[Loaded java.lang.Comparable from shared objects file] •[Loaded java.lang.CharSequence from shared objects file] •[Loaded java.lang.String from shared objects file] •[Loaded java.lang.reflect.GenericDeclaration from shared objects file] •[Loaded java.lang.reflect.Type from shared objects file] 使用这个参数就能很清楚的看到那些类被加载的情况了。\n8.-XX:+PrintClassHistogram 跟踪参数。这个按下Ctrl+Break后，就会打印一下信息：\nnum #instances #bytes class name ---------------------------------------------- 1: 890617 470266000 [B 2: 890643 21375432 java.util.HashMap$Node 3: 890608 14249728 java.lang.Long 4: 13 8389712 [Ljava.util.HashMap$Node; 5: 2062371680 [C 6: 46341904 java.lang.Class –分别显示：序号、实例数量、总大小、类型。\n这里面那个类型，B和C的其实就是byte和char类型。\n9.-Xmx -Xms 这个就表示设置堆内存的最大值和最小值。这个设置了最大值和最小值后，jvm启动后，并不会直接让堆内存就扩大到指定的最大数值。而是会先开辟指定的最小堆内存，如果经过数次GC后，还不能，满足程序的运行，才会逐渐的扩容堆的大小，但也不是直接扩大到最大内存。\n10.-Xmn 设置新生代的内存大小。\n11.-XX:NewRatio 新生代和老年代的比例。比如：1：4，就是新生代占五分之一。\n12.-XX:SurvivorRatio 设置两个Survivor区和eden区的比例。比如：2：8 ，就是一个Survivor区占十分之一。\n13.-XX:+HeapDumpOnOutMemoryError 发生OOM时，导出堆的信息到文件。\n14.-XX:+HeapDumpPath 表示，导出堆信息的文件路径。\n15.-XX:OnOutOfMemoryError 当系统产生OOM时，执行一个指定的脚本，这个脚本可以是任意功能的。比如生成当前线程的dump文件，或者是发送邮件和重启系统。\n16.-XX:PermSize -XX:MaxPermSize 设置永久区的内存大小和最大值。永久区内存用光也会导致OOM的发生。\n17.-Xss 设置栈的大小。栈都是每个线程独有一个，所有一般都是几百k的大小。\n","description":"\n","tags":[],"title":"\n常用的JVM参数，你现在就记好！","uri":"/posts/post-255/"},{"categories":["数据库"],"content":"数据库对象命名规范 数据库对象 数据库对象是数据库的组成部分，常见的有以下几种：表（Table ）、索引（Index）、视图（View）、图表（Diagram）、缺省值（Default）、规则（Rule）、触发器（Trigger）、存储过程（Stored Procedure）、 用户（User）等。命名规范是指数据库对象如数据库（SCHEMA）、表（TABLE）、索引（INDEX）、约束（CONSTRAINTS）等的命名约定。\n数据库对象全局命名规范 1、命名使用具有意义的英文词汇，词汇中间以下划线分隔\n2、命名只能使用英文字母、数字、下划线，以英文字母开头\n3、避免用MySQL的保留字如：backup、call、group等\n4、所有数据库对象使用小写字母，实际上MySQL中是可以设置大小写是否敏感的，为了保证统一性，我们这边规范全部小写表示。\n数据库命名规范 1、数据库命名尽量不超过30个字符。\n2、数据库命名一般为项目名称+代表库含义的简写，比如IM项目的工作流数据库，可以是 im_flow。\n3、数据库创建时必须添加默认字符集和校对规则子句。默认字符集为UTF8（已迁移dumbo的使用utf8mb4）\n4、命名应使用小写。\n表命名规范 1、常规表表名以t_开头，t代表table的意思，命名规则即 t + 模块（包含模块含义的简写）+ 表（包含表含义的简写），比如用户模块的教育信息表：t_user_eduinfo。\n2、临时表（RD、QA或DBA同学用于数据临时处理的表），命名规则：temp前缀+模块+表+日期后缀：temp_user_eduinfo_20210719\n3、备份表（用于保存和归档历史数据或者作为灾备恢复的数据）命名规则，bak前缀+模块+表+日期后缀：bak_user_eduinfo_20210719\n4、同一个模块的表尽可能使用相同的前缀，表名称尽可能表达含义\n5、多个单词以下划线 _ 分隔\n6、常规表表名尽量不超过30个字符，temp表和bak表视情况而定，也尽量简短为宜，命名应使用小写\n字段命名规范 1、字段命名需要表示其实际含义的英文单词或简写，单词之间用下划线 _ 进行连接，如 service_ip、service_port。\n2、各表之间相同意义的字段必须同名，比如a表和b表都有创建时间，应该统一为create_time，不一致会很混乱。\n3、多个单词以下划线 _ 分隔\n4、字段名尽量不超过30个字符，命名应该使用小写\n索引命名规范 1、唯一索引使用uni + 字段名 来命名：create unique index uni_uid on t_user_basic(uid) 。\n2、非唯一索引使用idx + 字段名 来命名：create index idx_uname_mobile on t_user_basic(uname,mobile) 。\n3、多个单词以下划线 _ 分隔。\n4、索引名尽量不超过50个字符，命名应该使用小写，组合索引的字段不宜太多，不然也不利于查询效率的提升。\n5、多单词组成的列名，取尽可能代表意义的缩写，如 test_contact表member_id和friend_id上的组合索引：idx_mid_fid。\n6、理解组合索引最左前缀原则，避免重复建设索引，如果建立了(a,b,c)，相当于建立了(a), (a,b), (a,b,c)。\n视图命名规范 1、视图名以v开头，表示view，完整结构是v+视图内容含义缩写。\n2、如果视图只来源单个表，则为v+表名。如果视图由几个表关联产生就用v+下划线（_）连接几个表名，视图名尽量不超过30个字符。如超过30个字符则取简写。\n3、如无特殊需要，严禁开发人员创建视图。\n4、命名应使用小写。\n存储过程命名规范 1、存储过程名以sp开头，表示存储过程（storage procedure）。之后多个单词以下划线（_）进行连接。存储过程命名中应体现其功能。存储过程名尽量不能超过30个字符。\n2、存储过程中的输入参数以i_开头，输出参数以o_开头。\n3、命名应使用小写。\ncreate procedure sp_multi_param(in i_id bigint,in i_name varchar(32),out o_memo varchar(100)) 函数命名规范 1、函数名以func开始，表示function。之后多个单词以下划线（_）进行连接，函数命名中应体现其功能。函数名尽量不超过30个字符。\n2、命名应使用小写。\ncreate function func_format_date(ctime datetime) 触发器命名规范 1、触发器以trig开头，表示trigger 触发器。\n2、基本部分，描述触发器所加的表，触发器名尽量不超过30个字符。\n3、后缀（_i,_u,_d）,表示触发条件的触发方式（insert,update或delete）。\n4、命名应使用小写。\nDROP TRIGGER IF EXISTS trig_attach_log_d; CREATE TRIGGER trig_attach_log_d AFTER DELETE ON t_dept FOR EACH ROW; 约束命名规范 1、唯一约束：uk_表名称_字段名。uk是UNIQUE KEY的缩写。比如给一个部门的部门名称加上唯一约束，来保证不重名，如下：ALTER TABLE t_dept ADD CONSTRAINT un_name UNIQUE(name);\n2、外键约束：fk_表名，后面紧跟该外键所在的表名和对应的主表名（不含t_）。子表名和父表名用下划线(_)分隔。如下：ALTER TABLE t_user ADD CONSTRAINT fk_user_dept FOREIGN KEY(depno) REFERENCES t_dept (id);\n3、非空约束：如无特殊需要，建议所有字段默认非空(not null)，不同数据类型必须给出默认值(default)。\n`id` int(11) NOT NULL, `name` varchar(30) DEFAULT '', `deptId` int(11) DEFAULT 0, `salary` float DEFAULT NULL, 4、出于性能考虑，如无特殊需要，建议不使用外键。参照完整性由代码控制。这个也是我们普遍的做法，从程序角度进行完整性控制，但是如果不注意，也会产生脏数据。\n5、命名应使用小写。\n用户命名规范 1、 生产使用的用户命名格式为 code_应用\n2、 只读用户命名规则为 read_应用\n[数据库对象设计规范 存储引擎的选择 1、如无特殊需求，必须使用innodb存储引擎。\n可以通过 show variables like ‘default_storage_engine’ 来查看当前默认引擎。主要有MyISAM 和 InnoDB，从5.5版本开始默认使用 InnoDB 引擎。\n基本的差别为：MyISAM类型不支持事务处理等高级处理，而InnoDB类型支持。MyISAM类型的表强调的是性能，其执行速度比InnoDB类型更快，但是不提供事务支持，而InnoDB提供事务支持以及外部键等高级数据库功能。\n字符集的选择 1、如无特殊要求，必须使用utf8或utf8mb4。\n在国内，选择对中文和各语言支持都非常完善的utf8格式是最好的方式，MySQL在5.5之后增加utf8mb4编码，mb4就是most bytes 4的意思，专门用来兼容四字节的unicode。\n所以utf8mb4是utf8的超集，除了将编码改为utf8mb4外不需要做其他转换。当然，为了节省空间，一般情况下使用utf8也就够了。\n可以使用如下脚本来查看数据库的编码格式\n1 SHOW VARIABLES WHERE Variable_name LIKE 'character_set_%' OR Variable_name LIKE 'collation%'; 2 -- 或 3 SHOW VARIABLES Like '%char%'; 表设计规范 1、不同应用间所对应的数据库表之间的关联应尽可能减少，不允许使用外键对表之间进行关联，确保组件对应的表之间的独立性，为系统或表结构的重构提供可能性。目前业内的做法一般 由程序控制参照完整性。\n2、表设计的角度不应该针对整个系统进行数据库设计，而应该根据系统架构中组件划分，针对每个组件所处理的业务进行数据库设计。\n3、表必须要有PK，主键的优势是唯一标识、有效引用、高效检索，所以一般情况下尽量有主键字段。\n4、一个字段只表示一个含义。\n5、表不应该有重复列。\n6、禁止使用复杂数据类型(数组,自定义等)，Json类型的使用视情况而定。\n7、需要join的字段(连接键)，数据类型必须保持绝对一致，避免隐式转换。比如关联的字段都是int类型。\n8、设计应至少满足第三范式,尽量减少数据冗余。一些特殊场景允许反范式化设计，但在项目评审时需要对冗余字段的设计给出解释。\n9、TEXT字段作为大体量文本存储，必须放在独立的表中 , 用PK与主表关联。如无特殊需要，禁止使用TEXT、BLOB字段。\n10、需要定期删除(或者转移)过期数据的表，通过分表解决，我们的做法是按照2/8法则将操作频率较低的历史数据迁移到历史表中，按照时间或者则曾Id做切割点。\n11、单表字段数不要太多，建议最多不要大于50个。过度的宽表对性能也是很大的影响。\n12、MySQL在处理大表时，性能就开始明显降低，所以建议单表物理大小限制在16GB，表中数据行数控制在2000W内。\n业内的规则是超过2000W性能开始明显降低。但是这个值是灵活的，你可以根据实际情况进行测试来判断，比如阿里的标准就是500W，百度的确是2000W。实际上是否宽表，单行数据所占用的空间都有起到作用的。\n13、如果数据量或数据增长在前期规划时就较大，那么在设计评审时就应加入分表策略，后续会有专门的文章来分析数据拆分的做法：垂直拆分（垂直分库和垂直分表）、水平拆分（分库分表和库内分表）；\n14、无特殊需求，严禁使用分区表\n字段设计规范 1、INT：如无特殊需要，存放整型数字使用UNSIGNED INT型，整型字段后的数字代表显示长度。比如 id int(11) NOT NULL\n2、DATETIME：所有需要精确到时间(时分秒)的字段均使用DATETIME,不要使用TIMESTAMP类型。\n对于TIMESTAMP，它把写入的时间从当前时区转化为UTC（世界标准时间）进行存储。查询时，将其又转化为客户端当前时区进行返回。而对于DATETIME，不做任何改变，基本上是原样输入和输出。\n另外DATETIME存储的范围也比较大：\ntimestamp所能存储的时间范围为：‘1970-01-01 00:00:01.000000’ 到 ‘2038-01-19 03:14:07.999999’。\ndatetime所能存储的时间范围为：‘1000-01-01 00:00:00.000000’ 到 ‘9999-12-31 23:59:59.999999’。\n但是特殊情况，对于跨时区的业务，TIMESTAMP更为合适。\n3、VARCHAR：所有动态长度字符串 全部使用VARCHAR类型,类似于状态等有限类别的字段,也使用可以比较明显表示出实际意义的字符串,而不应该使用INT之类的数字来代替；VARCHAR(N)，\nN表示的是字符数而不是字节数。比如VARCHAR(255)，可以最大可存储255个字符（字符包括英文字母，汉字，特殊字符等）。但N应尽可能小，因为MySQL一个表中所有的VARCHAR字段最大长度是65535个字节，且存储字符个数由所选字符集决定。\n如UTF8存储一个字符最大要3个字节，那么varchar在存放占用3个字节长度的字符时不应超过21845个字符。同时，在进行排序和创建临时表一类的内存操作时，会使用N的长度申请内存。(如无特殊需要，原则上单个varchar型字段不允许超过255个字符)\n4、TEXT：仅仅当字符数量可能超过20000个的时候,才可以使用TEXT类型来存放字符类数据,因为所有MySQL数据库都会使用UTF8字符集。\n所有使用TEXT类型的字段必须和原表进行分拆，与原表主键单独组成另外一个表进行存放，与大文本字段的隔离，目的是。如无特殊需要，不使用MEDIUMTEXT、TEXT、LONGTEXT类型\n5、对于精确浮点型数据存储，需要使用DECIMAL，严禁使用FLOAT和DOUBLE。\n6、如无特殊需要，尽量不使用BLOB类型\n7、如无特殊需要，字段建议使用NOT NULL属性，可用默认值代替NULL\n8、自增字段类型必须是整型且必须为UNSIGNED，推荐类型为INT或BIGINT，并且自增字段必须是主键或者主键的一部分。\n索引设计规范 1、索引区分度\n索引必须创建在索引选择性（区分度）较高的列上，选择性的计算方式为: selecttivity = count(distinct c_name)/count(*) ; 如果区分度结果小于0.2，则不建议在此列上创建索引，否则大概率会拖慢SQL执行\n2、遵循最左前缀\n对于确定需要组成组合索引的多个字段，设计时建议将选择性高的字段靠前放。使用时，组合索引的首字段，必须在where条件中，且需要按照最左前缀规则去匹配。\n3、禁止使用外键，可以在程序级别来约束完整性\n4、Text类型字段如果需要创建索引，必须使用前缀索引\n5、单张表的索引数量理论上应控制在5个以内。经常有大批量插入、更新操作表，应尽量少建索引，索引建立的原则理论上是多读少写的场景。\n6、ORDER BY，GROUP BY，DISTINCT的字段需要添加在索引的后面，形成覆盖索引\n7、正确理解和计算索引字段的区分度，文中有计算规则，区分度高的索引，可以快速得定位数据，区分度太低，无法有效的利用索引，可能需要扫描大量数据页，和不使用索引没什么差别。\n8、正确理解和计算前缀索引的字段长度，文中有判断规则，合适的长度要保证高的区分度和最恰当的索引存储容量，只有达到最佳状态，才是保证高效率的索引。\n9、联合索引注意最左匹配原则：必须按照从左到右的顺序匹配，MySQL会一直向右匹配索引直到遇到范围查询(\u003e、\u003c、between、like)然后停止匹配。\n如：depno=1 and empname\u003e’’ and job=1 如果建立(depno,empname,job)顺序的索引，job是用不到索引的。\n10、应需而取策略，查询记录的时候，不要一上来就使用*，只取需要的数据，可能的话尽量只利用索引覆盖，可以减少回表操作，提升效率。\n11、正确判断是否使用联合索引（上面联合索引的使用那一小节有说明判断规则），也可以进一步分析到索引下推（IPC），减少回表操作，提升效率。\n12、避免索引失效的原则：禁止对索引字段使用函数、运算符操作，会使索引失效。这是实际上就是需要保证索引所对应字段的”干净度“。\n13、避免非必要的类型转换，字符串字段使用数值进行比较的时候会导致索引无效。\n14、模糊查询’%value%‘会使索引无效，变为全表扫描，因为无法判断扫描的区间，但是’value%‘是可以有效利用索引。\n15、索引覆盖排序字段，这样可以减少排序步骤，提升查询效率\n16、尽量的扩展索引，非必要不新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。\n举例子：比如一个品牌表，建立的的索引如下，一个主键索引，一个唯一索引\nPRIMARY KEY (`id`), UNIQUE KEY `uni_brand_define` (`app_id`,`define_id`) 当你同事业务代码中的检索语句如下的时候，应该立即警告了，即没有覆盖索引，也没按照最左前缀原则：\nselect brand_id,brand_name from ds_brand_system where status=? and define_id=? and app_id=? 建议改成如下：\nselect brand_id,brand_name from ds_brand_system where app_id=? and define_id=? and status=? 约束设计规范 1、PK应该是有序并且无意义的，由开发人员自定义，尽可能简短，并且是自增序列。\n2、表中除PK以外,还存在唯一性约束的,可以在数据库中创建以“uk_”作为前缀的唯一约束索引。\n3、PK字段不允许更新。\n4、禁止创建外键约束，外键约束由程序控制。\n5、如无特殊需要，所有字段必须添加非空约束，即not null。\n6、如无特殊需要，所有字段必须有默认值。\nSQL使用规范 select 检索的规范性 1、尽量避免使用select *，join语句使用select *可能导致只需要访问索引即可完成的查询需要回表取数。\n一种是可能取出很多不需要的数据，对于宽表来说，这是灾难；一种是尽可能避免回表，因为取一些根本不需要的数据而回表导致性能低下，是很不合算。\n2、严禁使用 select * from t_name ，而不加任何where条件，道理一样，这样会变成全表全字段扫描。\n3、MySQL中的text类型字段存储：\n3.1、不与其他普通字段存放在一起,因为读取效率低，也会影响其他轻量字段存取效率。\n3.2、如果不需要text类型字段，又使用了select *，会让该执行消耗大量io，效率也很低下\n4、在取出字段上可以使用相关函数，但应尽可能避免出现 now() , rand() , sysdate() 等不确定结果的函数，在Where条件中的过滤条件字段上严禁使用任何函数，包括数据类型转换函数。大量的计算和转换会造成效率低下，这个在索引那边也描述过了。\n5、分页查询语句全部都需要带有排序条件 , 否则很容易引起乱序\n6、用in()/union替换or，效率会好一些，并注意in的个数小于300\n7、严禁使用%前缀进行模糊前缀查询:如：select a,b,c from t_name where a like ‘%name’; 可以使用%模糊后缀查询如：select a,b from t_name where a like ‘name%’;\n8、避免使用子查询，可以把子查询优化为join操作\n通常子查询在in子句中，且子查询中为简单SQL(不包含union、group by、order by、limit从句)时，才可以把子查询转化为关联查询进行优化。\n子查询性能差的原因：\n· 子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能 会受到一定的影响；\n· 特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大；\n· 由于子查询会产生大量的临时表也没有索引，所以会消耗过多的CPU和IO资源，产生大量的慢查询。\n操作的规范性 1、禁止使用不含字段列表的INSERT语句\n如：insert into values (‘a’,‘b’,‘c’); 应使用 insert into t_name(c1,c2,c3) values (‘a’,‘b’,‘c’); 。\n2、大批量写操作（UPDATE、DELETE、INSERT），需要分批多次进行操作\n· 大批量操作可能会造成严重的主从延迟，特别是主从模式下，大批量操作可能会造成严重的主从延迟，因为需要slave从master的binlog中读取日志来进行数据同步。\n· binlog日志为row格式时会产生大量的日志\n程序上的约束 后续我们团队的目标是研发评审工具对开发同学提交的建库、建表、刷数据、查询的语句进行分析，看看是否符合应有的规范。如果不符合，驳回修改。\n","description":"\n","tags":[],"title":"\n公司用的 MySQL 团队开发规范，太详细了，建议收藏！","uri":"/posts/post-256/"},{"categories":["默认分类"],"content":"由于Java字节码的抽象级别较高，因此它们较容易被反编译。本节介绍了几种常用的方法，用于保护Java字节码不被反编译。通常，这些方法不能够绝对防止程序被反编译，而是加大反编译的难度而已，因为这些方法都有自己的使用环境和弱点。\n隔离Java程序 最简单的方法就是让用户不能够访问到Java Class程序，这种方法是最根本的方法，具体实现有多种方式。例如，开发人员可以将关键的Java Class放在服务器端，客户端通过访问服务器的相关接口来获得服务，而不是直接访问Class文件。\n这样黑客就没有办法[反编译Class文件。目前，通过接口提供服务的标准和协议也越来越多，例如 HTTP、Web Service、RPC等。但是有很多应用都不适合这种保护方式，例如对于单机运行的程序就无法隔离Java程序。这种保护方式见图1所示。\n对Class文件进行加密 为了防止Class文件被直接反编译，许多开发人员将一些关键的Class文件进行加密，例如对注册码、序列号管理相关的类等。在使用这些被加密的类之前，程序首先需要对这些类进行解密，而后再将这些类装载到JVM当中。这些类的解密可以由硬件完成，也可以使用软件完成。\n在实现时，开发人员往往通过自定义ClassLoader类来完成加密类的装载(注意由于安全性的原因，Applet不能够支持自定义的 ClassLoader)。自定义的ClassLoader首先找到加密的类，而后进行解密，最后将解密后的类装载到JVM当中。\n在这种保护方式中，自定义的ClassLoader是非常关键的类。由于它本身不是被加密的，因此它可能成为黑客最先攻击的目标。如果相关的解密密钥和算法被攻克，那么被加密的类也很容易被解密。这种保护方式示意图见图2。\n转换成本地代码 将程序转换成本地代码也是一种防止反编译的有效方法。因为本地代码往往难以被反编译。开发人员可以选择将整个应用程序转换成本地代码，也可以选择关键模块转换。如果仅仅转换关键部分模块，Java程序在使用这些模块时，需要使用JNI技术进行调用。\n当然，在使用这种技术保护Java程序的同时，也牺牲了Java的跨平台特性。对于不同的平台，我们需要维护不同版本的本地代码，这将加重软件支持和维护的工作。不过对于一些关键的模块，有时这种方案往往是必要的。\n为了保证这些本地代码不被修改和替代，通常需要对这些代码进行数字签名。在使用这些本地代码之前，往往需要对这些本地代码进行认证，确保这些代码没有被黑客更改。如果签名检查通过，则调用相关JNI方法。这种保护方式示意图见图3。\n代码混淆 代码混淆是对Class文件进行重新组织和处理，使得处理后的代码与处理前代码完成相同的功能(语义)。但是混淆后的代码很难被[反编译，即[反编译后得出的代码是非常难懂、晦涩的，因此[反编译人员很难得出程序的真正语义。\n从理论上来说，黑客如果有足够的时间，被混淆的代码仍然可能被破解，甚至目前有些人正在研制反混淆的工具。但是从实际情况来看，由于混淆技术的多元化发展，混淆理论的成熟，经过混淆的Java代码还是能够很好地防止[反编译。下面我们会详细介绍混淆技术，因为混淆是一种保护Java程序的重要技术。图4是代码混淆的示图。\n图4 代码混淆示意图\n几种技术的总结 以上几种技术都有不同的应用环境，各自都有自己的弱点，表1是相关特点的比较。\n混淆技术介绍\n表1 不同保护技术比较表\n到目前为止，对于Java程序的保护，混淆技术还是最基本的保护方法。Java混淆工具也非常多，包括商业的、免费的、开放源代码的。Sun公司也提供了自己的混淆工具。它们大多都是对Class文件进行混淆处理，也有少量工具首先对源代码进行处理，然后再对Class进行处理，这样加大了混淆处理的力度。\n目前，商业上比较成功的混淆工具包括JProof公司的1stBarrier系列、Eastridge公司的JShrink和 4thpass.com的SourceGuard等。主要的混淆技术按照混淆目标可以进行如下分类，它们分别为符号混淆(Lexical Obfuscation)、数据混淆(Data Obfuscation)、控制混淆(Control Obfuscation)、预防性混淆(Prevent Transformation)。\n符号混淆 在Class中存在许多与程序执行本身无关的信息，例如方法名称、变量名称，这些符号的名称往往带有一定的含义。例如某个方法名为 getKeyLength()，那么这个方法很可能就是用来返回Key的长度。\n符号混淆就是将这些信息打乱，把这些信息变成无任何意义的表示，例如将所有的变量从vairant_001开始编号；对于所有的方法从method_001开始编号。\n这将对反编译带来一定的困难。对于私有函数、局部变量，通常可以改变它们的符号，而不影响程序的运行。但是对于一些接口名称、公有函数、成员变量，如果有其它外部模块需要引用这些符号，我们往往需要保留这些名称，否则外部模块找不到这些名称的方法和变量。因此，多数的混淆工具对于符号混淆，都提供了丰富的选项，让用户选择是否、如何进行符号混淆。\n数据混淆 数据混淆是对程序使用的数据进行混淆。混淆的方法也有多种，主要可以分为改变数据存储及编码(Store and Encode Transform)、改变数据访问(Access Transform)。\n改变数据存储和编码可以打乱程序使用的数据存储方式。例如将一个有10个成员的数组，拆开为10个变量，并且打乱这些变量的名字；将一个两维数组转化为一个一维数组等。对于一些复杂的数据结构，我们将打乱它的数据结构，例如用多个类代替一个复杂的类等。\n另外一种方式是改变数据访问。例如访问数组的下标时，我们可以进行一定的计算，图5就是一个例子。\n在实践混淆处理中，这两种方法通常是综合使用的，在打乱数据存储的同时，也打乱数据访问的方式。经过对数据混淆，程序的语义变得复杂了，这样增大了反编译的难度。\n控制混淆 控制混淆就是对程序的控制流进行混淆，使得程序的控制流更加难以[反编译，通常控制流的改变需要增加一些额外的计算和控制流，因此在性能上会给程序带来一定的负面影响。有时，需要在程序的性能和混淆程度之间进行权衡。控制混淆的技术最为复杂，技巧也最多。这些技术可以分为如下几类：\n增加混淆控制通过增加额外的、复杂的控制流，可以将程序原来的语义隐藏起来。例如，对于按次序执行的两个语句A、B，我们可以增加一个控制条件，以决定B的执行。通过这种方式加大反汇编的难度。但是所有的干扰控制都不应该影响B的执行。图6就给出三种方式，为这个例子增加混淆控制。\n图6 增加混淆控制的三种方式\n控制流重组重组控制流也是重要的混淆方法。例如，程序调用一个方法，在混淆后，可以将该方法代码嵌入到调用程序当中。反过来，程序中的一段代码也可以转变为一个函数调用。另外，对于一个循环的控制流，为可以拆分多个循环的控制流，或者将循环转化成一个递归过程。这种方法最为复杂，研究的人员也非常多。\n预防性混淆 这种混淆通常是针对一些专用的反编译器而设计的，一般来说，这些技术利用反编译器的弱点或者Bug来设计混淆方案。例如，有些反编译器对于 Return后面的指令不进行反编译，而有些混淆方案恰恰将代码放在Return语句后面。这种混淆的有效性对于不同反编译器的作用也不太相同的。一个好的混淆工具，通常会综合使用这些混淆技术。\n案例分析 在实践当中，保护一个大型Java程序经常需要综合使用这些方法，而不是单一使用某一种方法。这是因为每种方法都有其弱点和应用环境。综合使用这些方法使得Java程序的保护更加有效。另外，我们经常还需要使用其它的相关安全技术，例如安全认证、数字签名、PKI等。\n本文给出的例子是一个Java应用程序，它是一个SCJP(Sun Certificate Java Programmer)的模拟考试软件。该应用程序带有大量的模拟题目，所有的题目都被加密后存储在文件中。由于它所带的题库是该软件的核心部分，所以关于题库的存取和访问就成为非常核心的类。一旦这些相关的类被反编译，则所有的题库将被破解。现在，我们来考虑如何保护这些题库及相关的类。\n在这个例子中，我们考虑使用综合保护技术，其中包括本地代码和混淆技术。因为该软件主要发布在Windows上，因此转换成本地代码后，仅仅需要维护一个版本的本地代码。另外，混淆对Java程序也是非常有效的，适用于这种独立发布的应用系统。\n在具体的方案中，我们将程序分为两个部分，一个是由本地代码编写的题库访问的模块，另外一个是由Java开发的其它模块。这样可以更高程度地保护题目管理模块不被[反编译。对于Java开发的模块，我们仍然要使用混淆技术。该方案的示意图参见图7。\n图7 SCJP保护技术方案图\n对于题目管理模块，由于程序主要在Windows下使用，所以使用C++开发题库访问模块，并且提供了一定的访问接口。为了保护题库访问的接口，我们还增加了一个初始化接口，用于每次使用题库访问接口之前的初始化工作。它的接口主要分为两类：\n初始化接口 在使用题库模块之前，我们必须先调用初始化接口。在调用该接口时，客户端需要提供一个随机数作为参数。题库管理模块和客户端通过这个随机数，按一定的算法同时生成相同的SessionKey，用于加密以后输入和输出的所有数据。通过这种方式，只有授权(有效)的客户端才能够连接正确的连接，生成正确的 SessionKey，用于访问题库信息。非法的客户很难生成正确的SessionKey，因此无法获得题库的信息。如果需要建立更高的保密级别，也可以采用双向认证技术。\n数据访问接口 认证完成之后，客户端就可以正常的访问题库数据。但是，输入和输出的数据都是由SessionKey所加密的数据。因此，只有正确的题库管理模块才能够使用题库管理模块。图8时序图表示了题库管理模块和其它部分的交互过程。\n","description":"\n","tags":[],"title":"\n如何防止 Java 代码被反编译","uri":"/posts/post-257/"},{"categories":["默认分类"],"content":"\n","description":"\n","tags":[],"title":"\n虚拟机挂了怎么办？一张图给你解决了！","uri":"/posts/post-258/"},{"categories":["默认分类"],"content":"SpringBoot 已经成为 Java 届的 No.1 框架，每天都在蹂躏着数百万的程序员们。当服务的压力上升，对 SpringBoot 服务的优化就会被提上议程。\n本文将详细讲解 SpringBoot 服务优化的一般思路，适合收藏之。\n有监控才有方向 在开始对 SpringBoot 服务进行性能优化之前，我们需要做一些准备，把 SpringBoot 服务的一些数据暴露出来。\n比如，你的服务用到了缓存，就需要把缓存命中率这些数据进行收集；用到了数据库连接池，就需要把连接池的参数给暴露出来。\n我们这里采用的监控工具是 Prometheus，它是一个是时序数据库，能够存储我们的指标。SpringBoot 可以非常方便的接入到 Prometheus 中。\n创建一个 SpringBoot 项目后，首先，加入 maven 依赖。\n\u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-actuator\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eio.micrometer\u003c/groupId\u003e \u003cartifactId\u003emicrometer-registry-prometheus\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eio.micrometer\u003c/groupId\u003e \u003cartifactId\u003emicrometer-core\u003c/artifactId\u003e \u003c/dependency\u003e 然后，我们需要在 application.properties 配置文件中，开放相关的监控接口。\nmanagement.endpoint.metrics.enabled=true management.endpoints.web.exposure.include=* management.endpoint.prometheus.enabled=true management.metrics.export.prometheus.enabled=true 启动之后，我们就可以通过访问 http://localhost:8080/actuator/prometheus 来获取监控数据。\n想要监控业务数据也是比较简单的。你只需要注入一个MeterRegistry实例即可。\n下面是一段示例代码：\n@Autowired MeterRegistry registry; @GetMapping(\"/test\") @ResponseBody public String test() { registry.counter(\"test\", \"from\", \"127.0.0.1\", \"method\", \"test\" ).increment(); return \"ok\"; } 从监控连接中，我们可以找到刚刚添加的监控信息。\ntest_total{from=\"127.0.0.1\",method=\"test\",} 5.0 这里简单介绍一下流行的 Prometheus 监控体系，Prometheus 使用拉的方式获取监控数据，这个暴露数据的过程可以交给功能更加齐全的 telegraf 组件。\n如图，我们通常使用 Grafana 进行监控数据的展示，使用 AlertManager 组件进行提前预警。这一部分的搭建工作不是我们的重点，感兴趣的同学可自行研究。\n下图便是一张典型的监控图，可以看到 Redis 的缓存命中率等情况。\nJava生成火焰图 火焰图是用来分析程序运行瓶颈的工具。在纵向，表示的是调用栈的深度；横向表明的是消耗的时间。所以格子的宽度越大，越说明它可能是一个瓶颈。\n火焰图也可以用来分析 Java 应用。可以从 github 上下载 async-profiler 的压缩包进行相关操作。\n比如，我们把它解压到 /root/ 目录。然后以 javaagent 的方式来启动 Java 应用。\n命令行如下：\njava -agentpath:/root/build/libasyncProfiler.so=start,svg,file=profile.svg -jar spring-petclinic-2.3.1.BUILD-SNAPSHOT.jar 运行一段时间后，停止进程，可以看到在当前目录下，生成了 profile.svg 文件，这个文件是可以用浏览器打开的，一层层向下浏览，即可找到需要优化的目标。\nSkywalking 对于一个 web 服务来说，最缓慢的地方就在于数据库操作。所以，使用本地缓存和分布式缓存优化，能够获得最大的性能提升。\n对于如何定位到复杂分布式环境中的问题，我这里想要分享另外一个工具：Skywalking。\nSkywalking 是使用探针技术（JavaAgent）来实现的。通过在 Java 的启动参数中，加入 javaagent 的 Jar 包，即可将性能数据和调用链数据封装、发送到 Skywalking 的服务器。\n下载相应的安装包（如果使用 ES 存储，需要下载专用的安装包），配置好存储之后，即可一键启动。\n将 agent 的压缩包，解压到相应的目录。\ntar xvf skywalking-agent.tar.gz -C /opt/ 在业务启动参数中加入 agent 的包。比如，原来的启动命令是：\njava -jar /opt/test-service/spring-boot-demo.jar --spring.profiles.active=dev 改造后的启动命令是：\njava -javaagent:/opt/skywalking-agent/skywalking-agent.jar -Dskywalking.agent.service_name=the-demo-name -jar /opt/test-service/spring-boot-demo.ja --spring.profiles.active=dev 访问一些服务的链接，打开 Skywalking 的 UI，即可看到下图的界面。我们可以从图中找到响应比较慢 QPS 又比较高的的接口，进行专项优化。\n优化思路 对一个普通的 Web 服务来说，我们来看一下，要访问到具体的数据，都要经历哪些主要的环节。\n如下图，在浏览器中输入相应的域名，需要通过 DNS 解析到具体的 IP 地址上。为了保证高可用，我们的服务一般都会部署多份，然后使用 Nginx 做反向代理和负载均衡。\nNginx 根据资源的特性，会承担一部分动静分离的功能。其中，动态功能部分，会进入我们的 SpringBoot 服务\nSpringBoot 默认使用内嵌的 tomcat 作为 Web 容器，使用典型的 MVC 模式，最终访问到我们的数据。\nHTTP优化 下面我们举例来看一下，哪些动作能够加快网页的获取。为了描述方便，我们仅讨论 HTTP1.1 协议的。\n使用 CDN 加速文件获取 比较大的文件，尽量使用 CDN（Content Delivery Network）分发。甚至是一些常用的前端脚本、样式、图片等，都可以放到 CDN 上。CDN 通常能够加快这些文件的获取，网页加载也更加迅速。\n合理设置 Cache-Control 值 浏览器会判断 HTTP 头 Cache-Control 的内容，用来决定是否使用浏览器缓存，这在管理一些静态文件的时候，非常有用。\n相同作用的头信息还有 Expires。Cache-Control 表示多久之后过期，Expires 则表示什么时候过期。\n这个参数可以在 Nginx 的配置文件中进行设置：\nlocation ~* ^.+\\.(ico|gif|jpg|jpeg|png)$ { # 缓存1年 add_header Cache-Control: no-cache, max-age=31536000; } 减少单页面请求域名的数量 减少每个页面请求的域名数量，尽量保证在 4 个之内。这是因为，浏览器每次访问后端的资源，都需要先查询一次 DNS，然后找到 DNS 对应的 IP 地址，再进行真正的调用。\nDNS 有多层缓存，比如浏览器会缓存一份、本地主机会缓存、ISP 服务商缓存等。从 DNS 到 IP 地址的转变，通常会花费 20-120ms 的时间。减少域名的数量，可加快资源的获取。\n开启 gzip 开启 gzip，可以先把内容压缩后，浏览器再进行解压。由于减少了传输的大小，会减少带宽的使用，提高传输效率。\n在 Nginx 中可以很容易的开启。配置如下：\ngzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_comp_level 6; gzip_http_version 1.1; gzip_types text/plain application/javascript text/css; 对资源进行压缩 对 JavaScript 和 CSS，甚至是 HTML 进行压缩。道理类似，现在流行的前后端分离模式，一般都是对这些资源进行压缩的。\n使用 keepalive 由于连接的创建和关闭，都需要耗费资源。用户访问我们的服务后，后续也会有更多的互动，所以保持长连接可以显著减少网络交互，提高性能。\nnginx 默认开启了对客户端的 keep avlide 支持。你可以通过下面两个参数来调整它的行为。\nhttp { keepalive_timeout 120s 120s; keepalive_requests 10000; } nginx 与后端 upstream 的长连接，需要手工开启，参考配置如下：\nlocation ~ /{ proxy_pass http://backend; proxy_http_version 1.1; proxy_set_header Connection \"\"; } Tomcat优化 Tomcat 本身的优化，也是非常重要的一环。可以直接参考：《搞定tomcat重要参数调优！》\n自定义Web容器 如果你的项目并发量比较高，想要修改最大线程数、最大连接数等配置信息，可以通过自定义 Web 容器的方式，代码如下所示：\n@SpringBootApplication(proxyBeanMethods = false) public class App implements WebServerFactoryCustomizer\u003cConfigurableServletWebServerFactory\u003e { public static void main(String[] args) { SpringApplication.run(PetClinicApplication.class, args); } @Override public void customize(ConfigurableServletWebServerFactory factory) { TomcatServletWebServerFactory f = (TomcatServletWebServerFactory) factory; f.setProtocol(\"org.apache.coyote.http11.Http11Nio2Protocol\"); f.addConnectorCustomizers(c -\u003e { Http11NioProtocol protocol = (Http11NioProtocol) c.getProtocolHandler(); protocol.setMaxConnections(200); protocol.setMaxThreads(200); protocol.setSelectorTimeout(3000); protocol.setSessionTimeout(3000); protocol.setConnectionTimeout(3000); }); } } 注意上面的代码，我们设置了它的协议为 org.apache.coyote.http11.Http11Nio2Protocol，意思就是开启了 Nio2。\n这个参数在 Tomcat8.0 之后才有，开启之后会增加一部分性能。对比如下：\n默认：\n[root@localhost wrk2-master]# ./wrk -t2 -c100 -d30s -R2000 http://172.16.1.57:8080/owners?lastName= Running 30s test @ http://172.16.1.57:8080/owners?lastName= 2 threads and 100 connections Thread calibration: mean lat.: 4588.131ms, rate sampling interval: 16277ms Thread calibration: mean lat.: 4647.927ms, rate sampling interval: 16285ms Thread Stats Avg Stdev Max +/- Stdev Latency 16.49s 4.98s 27.34s 63.90% Req/Sec 106.50 1.50 108.00 100.00% 6471 requests in 30.03s, 39.31MB read Socket errors: connect 0, read 0, write 0, timeout 60 Requests/sec: 215.51 Transfer/sec: 1.31MB Nio2：\n[root@localhost wrk2-master]# ./wrk -t2 -c100 -d30s -R2000 http://172.16.1.57:8080/owners?lastName= Running 30s test @ http://172.16.1.57:8080/owners?lastName= 2 threads and 100 connections Thread calibration: mean lat.: 4358.805ms, rate sampling interval: 15835ms Thread calibration: mean lat.: 4622.087ms, rate sampling interval: 16293ms Thread Stats Avg Stdev Max +/- Stdev Latency 17.47s 4.98s 26.90s 57.69% Req/Sec 125.50 2.50 128.00 100.00% 7469 requests in 30.04s, 45.38MB read Socket errors: connect 0, read 0, write 0, timeout 4 Requests/sec: 248.64 Transfer/sec: 1.51MB 你甚至可以将 tomcat 替换成 undertow。undertow 也是一个 Web 容器，更加轻量级一些，占用的内容更少，启动的守护进程也更少，更改方式如下：\n\u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003cexclusions\u003e \u003cexclusion\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-tomcat\u003c/artifactId\u003e \u003c/exclusion\u003e \u003c/exclusions\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-undertow\u003c/artifactId\u003e \u003c/dependency\u003e 各个层次的优化方向 Controller 层 controller 层用于接收前端的查询参数，然后构造查询结果。现在很多项目都采用前后端分离的架构，所以 controller 层的方法，一般会使用 @ResponseBody 注解，把查询的结果，解析成 JSON 数据返回（兼顾效率和可读性）。\n由于 controller 只是充当了一个类似功能组合和路由的角色，所以这部分对性能的影响就主要体现在数据集的大小上。如果结果集合非常大，JSON 解析组件就要花费较多的时间进行解析。\n大结果集不仅会影响解析时间，还会造成内存浪费。假如结果集在解析成 JSON 之前，占用的内存是 10MB，那么在解析过程中，有可能会使用 20M 或者更多的内存去做这个工作。\n我见过很多案例，由于返回对象的嵌套层次太深、引用了不该引用的对象（比如非常大的 byte[] 对象），造成了内存使用的飙升。\n所以，对于一般的服务，保持结果集的精简，是非常有必要的，这也是 DTO（data transfer object）存在的必要。\n如果你的项目，返回的结果结构比较复杂，对结果集进行一次转换是非常有必要的。\n另外，可以使用异步 Servlet 对 Controller 层进行优化。它的原理如下：Servlet 接收到请求之后，将请求转交给一个异步线程来执行业务处理，线程本身返回至容器，异步线程处理完业务以后，可以直接生成响应数据，或者将请求继续转发给其它 Servlet。\nService 层 service 层用于处理具体的业务，大部分功能需求都是在这里完成的。service 层一般是使用单例模式（prototype），很少会保存状态，而且可以被 controller 复用。\nservice 层的代码组织，对代码的可读性、性能影响都比较大。我们常说的设计模式，大多数都是针对于 service 层来说的。\n这里要着重提到的一点，就是分布式事务。\n如上图，四个操作分散在三个不同的资源中。要想达到一致性，需要三个不同的资源进行统一协调。\n它们底层的协议，以及实现方式，都是不一样的。那就无法通过 Spring 提供的 Transaction 注解来解决，需要借助外部的组件来完成。\n很多人都体验过，加入了一些保证一致性的代码，一压测，性能掉的惊掉下巴。分布式事务是性能杀手，因为它要使用额外的步骤去保证一致性，常用的方法有：两阶段提交方案、TCC、本地消息表、MQ 事务消息、分布式事务中间件等。\n如上图，分布式事务要在改造成本、性能、实效等方面进行综合考虑。有一个介于分布式事务和非事务之间的名词，叫做柔性事务。柔性事务的理念是将业务逻辑和互斥操作，从资源层上移至业务层面。\n关于传统事务和柔性事务，我们来简单比较一下。\n***ACID：***关系数据库, 最大的特点就是事务处理，即满足 ACID。\n原子性（Atomicity）：事务中的操作要么都做，要么都不做。 一致性（Consistency）：系统必须始终处在强一致状态下。 隔离性（Isolation）：一个事务的执行不能被其他事务所干扰。 持续性（Durability）：一个已提交的事务对数据库中数据的改变是永久性的。 ***BASE：***BASE 方法通过牺牲一致性和孤立性来提高可用性和系统性能。\nBASE 为 Basically Available，Soft-state，Eventually consistent 三者的缩写，其中 BASE 分别代表：\n基本可用（Basically Available）：系统能够基本运行、一直提供服务。 软状态（Soft-state）：系统不要求一直保持强一致状态。 最终一致性（Eventual consistency）：系统需要在某一时刻后达到一致性要求。 互联网业务，推荐使用补偿事务，完成最终一致性。比如，通过一系列的定时任务，完成对数据的修复。\nDao 层 经过合理的数据缓存，我们都会尽量避免请求穿透到 Dao 层。除非你对 ORM 本身提供的缓存特性特别的熟悉，否则，都推荐你使用更加通用的方式去缓存数据。\nDao 层，主要在于对 ORM 框架的使用上。比如，在 JPA 中，如果加了一对多或者多对多的映射关系，而又没有开启懒加载，级联查询的时候就容易造成深层次的检索，造成了内存开销大、执行缓慢的后果。\n在一些数据量比较大的业务中，多采用分库分表的方式。在这些分库分表组件中，很多简单的查询语句，都会被重新解析后分散到各个节点进行运算，最后进行结果合并。\n举个例子，select count(*) from a 这句简单的 count 语句，就可能将请求路由到十几张表中去运算，最后在协调节点进行统计，执行效率是可想而知的。\n目前，分库分表中间件，比较有代表性的是驱动层的 ShardingJdbc 和代理层的 MyCat，它们都有这样的问题。\n这些组件提供给使用者的视图是一致的，但我们在编码的时候，一定要注意这些区别。\n总 结 下面我们来总结一下。我们简单看了一下 SpringBoot 常见的优化思路，介绍了三个新的性能分析工具。\n一个是监控系统 Prometheus，可以看到一些具体的指标大小；一个是火焰图，可以看到具体的代码热点；一个是 Skywalking，可以分析分布式环境中的调用链。\n在对性能有疑惑的时候，我们都会采用类似于神农氏尝百草的方式，综合各种测评工具的结果进行分析。\nSpringBoot 自身的 Web 容器是 Tomcat，那我们就可以通过对 Tomcat 的调优来获取性能提升。当然，对于服务上层的负载均衡 Nginx，我们也提供了一系列的优化思路。\n最后，我们看了在经典的 MVC 架构下，Controller、Service、Dao 的一些优化方向，并着重看了 Service 层的分布式事务问题。\nSpringBoot 作为一个广泛应用的服务框架，在性能优化方面已经做了很多工作，选用了很多高速组件。\n比如，数据库连接池默认使用 hikaricp，Redis 缓存框架默认使用 lettuce，本地缓存提供 caffeine 等。\n对于一个普通的于数据库交互的 Web 服务来说，缓存是最主要的优化手，但细节决定成败。\n","description":"\n","tags":[],"title":"\nSpringBoot性能优化大全，贼好使！","uri":"/posts/post-259/"},{"categories":["默认分类"],"content":"一、SpringBoot Dedevtools 他是一个让SpringBoot支持热部署的工具，下面是引用的方法\n要么在创建项目的时候直接勾选下面的配置：\n要么给springBoot项目添加下面的依赖：\n\u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-devtools\u003c/artifactId\u003e \u003coptional\u003etrue\u003c/optional\u003e \u003c/dependency\u003e idea修改完代码后再按下 ctrl + f9 使其重新编译一下，即完成了热部署功能 eclipse是按ctrl + s保存 即可自动编译 如果你想一修改代码就自动重新编译，无需按ctrl+f9。只需要下面的操作：\n1.在idea的setting中把下面的勾都打上 2.进入pom.xml,在build的反标签后给个光标，然后按Alt+Shift+ctrl+/ 3.然后勾选下面的东西，接着重启idea即可 二、Lombok Lombok是简化JavaBean开发的工具，让开发者省去构造器，getter,setter的书写。另外，搜索公众号互联网架构师后台回复“面试”，获取一份惊喜礼包。\n在项目初始化时勾选下面的配置，即可使用Lombok\n或者在项目中导入下面的依赖：\n\u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003coptional\u003etrue\u003c/optional\u003e \u003c/dependency\u003e 使用时，idea还需要下载下面的插件：\n下面的使用的例子\nimport com.baomidou.mybatisplus.annotation.TableField; import com.baomidou.mybatisplus.annotation.TableName; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @AllArgsConstructor//全参构造器 @NoArgsConstructor//无参构造器 @Data//getter + setter public class User { private Long id; private String name; private Integer age; private String email; } 三、Spring Configuration Processor 该工具是给实体类的属性注入开启提示，自我感觉该工具意义不是特别大！\n因为SpringBoot存在属性注入，比如下面的实体类：\npackage org.lzl.HelloWorld.entity; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.stereotype.Component; /** * @author Lenovo * */ @Component @ConfigurationProperties(prefix = \"mypet\") public class Pet { private String nickName; private String strain; public String getNickName() { return nickName; } public void setNickName(String nickName) { this.nickName = nickName; } public String getStrain() { return strain; } public void setStrain(String strain) { this.strain = strain; } @Override public String toString() { return \"Pet [nickName=\" + nickName + \", strain=\" + strain + \"]\"; } } 想要在application.properties和application.yml中给mypet注入属性，却没有任何的提示，为了解决这一问题，我们在创建SpringBoot的时候勾选下面的场景：\n或者直接在项目中添加下面的依赖:\n\u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-configuration-processor\u003c/artifactId\u003e \u003coptional\u003etrue\u003c/optional\u003e \u003c/dependency\u003e 并在build的标签中排除对该工具的打包：（减少打成jar包的大小）\n\u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-maven-plugin\u003c/artifactId\u003e \u003cconfiguration\u003e \u003cexcludes\u003e \u003cexclude\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-configuration-processor\u003c/artifactId\u003e \u003c/exclude\u003e \u003c/excludes\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e ","description":"\n","tags":[],"title":"\nSpringBoot 三大开发工具，你都用过么？","uri":"/posts/post-260/"},{"categories":["默认分类"],"content":"电子邮件是因特网上使用得非常多的一种应用，它可以非常方便的使相隔很远的人进行通信，它主要的特点就是操作简单，快捷。现在的电子邮件系统以是存储与转发的模型为基础。邮件服务器接受、转发、提交及存储邮件。寄信人、收信人及他们的计算机都不用同时在线。寄信人和收信人只需在寄信或收信时简短的连线到邮件服务器即可。\n互联网发展到现在，邮件服务已经成为互联网企业中必备功能之一，应用场景非常广泛，比较常见的有：用户注册、忘记密码、监控提醒、企业营销等。大多数互联网企业都会将邮件发送抽取为一个独立的微服务，对外提供接口来支持各种类型的邮件发送。\n本篇内容会从以下几部分来给大家介绍如何开发一个邮件系统：\n电子邮件的历史 发送邮件涉及到哪些协议 介绍一个完整的邮件发送流程 快速体验邮件发送流程 介绍如何开发文本、HTML、附件、图片的邮件 做一个邮件系统需要考虑的因素 邮件历史 我们先来回顾一下整个邮件的发展历史。\n电子邮件的发展 电子邮件发明在 70 年代，却在 80 年才开始有人使用。70 年代的沉寂主要是由于当时使用 Arpanet 网络的人太少，网络的速度也仅为目前 56Kbps 标准速度的二十分之一，受网络速度的限制，那时的用户只能发送些简短的信息，根本别想象现在那样发送大量照片。\n到 80 年代中期，个人电脑兴起，电子邮件开始在电脑迷以及大学生中广泛传播开来；到 90 年代中期，互联网浏览器诞生，全球网民人数激增，电子邮件被广为使用。2000 零几年的时候，那时候没有网盘，上大学的时候常常使用邮箱存储东西，那时候的邮箱也主要以网易为主；到了现在，几乎每个人都有好几个邮箱，QQ 邮箱、126 邮箱、公司邮箱等等，电子邮件已经成为人们生活和工作不可或缺的一部分。\n电子邮件发展历程：\n1974 年，因为 ARPANET 的推广，电子邮件的用户已经达到了数百人，不过他们大都是军方用户。自那之后，电子邮件开始了飞速的发展。Lawrence Roberts，这位当时为 ARPANET 服务的科学家为他的上司发明了邮件中的文件夹，以便其能够更好地梳理自己的邮件。 1975 年，南加州大学的 John Vittal 第一次发明了邮件相关的服务软件。 1977 年，现代的电子邮件系统开始出现。使用同一款软件并且联网了的计算机都可以使用 Tomlinson 的方法去发邮件。 1982 年，有关电子邮件第一个重要的标准出台了，这就是 SMTP（简单邮件传输协议 Simple Mail Transfer Protocol），它是第一个基于互联网基础传输电子邮件的标准。时至今日它还在被人使用。而也是在这一年，「email」这个词第一次出现了。 1983 年 1 月 1 日，ARPANET 正式使用 TCP/IP 取代旧的网络控制协议（NCP，Network Control Protocol），从而成为今天的互联网的基石。 从 80 年代中期开始，电子邮件被广泛使用。我国发出的第一封电子邮件就在 1987 年，是由北京计算机应用技术研究所发送到德国的。 1988 年，世界上第一个商用邮件系统 Eudora 出现，发明者是美国软件工程师 Steve Dorner。 1990 年，HTML 格式的邮件出现，除了文字之外，我们也能在邮件中看到图片了。 1992 年，MIME 协议（多用途互联网邮件扩展，Multipurpose Internet Mail Extensions）诞生，它扩展了电子邮件标准，使其能够支援更多种形式的内容。也是在这一年，微软在 MS-DOS 系统上，推出了 Outlook 邮件应用。 1996 年，世界上第一个以网页为基础的邮件应用 Hotmail 诞生，然后微软在下一年花了 4 亿美元买下了它。 …… 世界的第一封电子邮件 1969 年 10 月世界上的第一封电子邮件是由计算机科学家 Leonard K. 教授发给他的同事的一条简短消息。\n据《互联网周刊》报道世界上的第一封电子邮件是由计算机科学家Leonard K.教授发给他的同事的一条简短消息(时间应该是1969年10月)，这条消息只有两个字母：“LO”。Leonard K. 教授因此被称为电子邮件之父。所以第一条网上信息就是‘LO’，意思是‘你好！’”\n当然这个说法也有一点争议，另外一种说法是麻省理工学院博士 Ray Tomlinson 发送的第一封邮件，这里不再展开讨论。\n中国的第一封电子邮件 1987 年 9 月 14 日中国第一封电子邮件是由“德国互联网之父”维纳·措恩与王运丰在当时的兵器工业部下属单位—计算机应用技术研究所（简称 ICA）发往德国卡尔斯鲁厄大学的，其内容为德文和英文双语，第一段大意如下：\n原文：“ Across the Great Wall we can reach every corner in the world. ”\n中文大意：“ 越过长城，我们可以到达世界的每一个角落。 ”\n这是中国通过北京与德国卡尔斯鲁厄大学之间的网络连接，发出的第一封电子邮件。现在看这封邮件内容，颇具深意！\n邮件协议 发送邮件的本质是将一个人的信息传输给另外一个人，那么如何传输就需要商量好标准，这些标准就是协议。最初只有两个协议：\nSMTP 协议 SMTP 的全称是 “Simple Mail Transfer Protocol”，即简单邮件传输协议。它是一组用于从源地址到目的地址传输邮件的规范，通过它来控制邮件的中转方式。它的一个重要特点是它能够在传送中接力传送邮件，即邮件可以通过不同网络上的主机接力式传送。\nSMTP 认证，简单地说就是要求必须在提供了账户名和密码之后才可以登录 SMTP 服务器，这就使得那些垃圾邮件的散播者无可乘之机。增加 SMTP 认证的目的是为了使用户避免受到垃圾邮件的侵扰。SMTP主要负责底层的邮件系统如何将邮件从一台机器传至另外一台机器。\nPOP3 协议 POP3 是 Post Office Protocol 3 的简称，即邮局协议的第3个版本，它规定怎样将个人计算机连接到 Internet 的邮件服务器和下载电子邮件的电子协议。它是因特网电子邮件的第一个离线协议标准，POP3 允许用户从服务器上把邮件存储到本地主机（即自己的计算机）上，同时删除保存在邮件服务器上的邮件。\nPOP 协议支持“离线”邮件处理。其具体过程是：邮件发送到服务器上，电子邮件客户端调用邮件客户机程序以连接服务器，并下载所有未阅读的电子邮件。这种离线访问模式是一种存储转发服务，将邮件从邮件服务器端送到个人终端机器上，一般是 PC机或 MAC。一旦邮件发送到 PC 机或 MAC上，邮件服务器上的邮件将会被删除。但目前的POP3邮件服务器大都可以“只下载邮件，服务器端并不删除”，也就是改进的POP3协议。\n** SMTP 和 POP3 是最初的俩个协议，随着邮件的不断发展后来又增加了两个协议：**\nIMAP 协议 全称 Internet Mail Access Protocol（交互式邮件存取协议），IMAP 是斯坦福大学在1986年开发的研发的一种邮件获取协议，即交互式邮件存取协议，它是跟 POP3 类似邮件访问标准协议之一。不同的是，开启了 IMAP 后，在电子邮件客户端收取的邮件仍然保留在服务器上，同时在客户端上的操作都会反馈到服务器上，如：删除邮件，标记已读等，服务器上的邮件也会做相应的动作。所以无论从浏览器登录邮箱或者客户端软件登录邮箱，看到的邮件以及状态都是一致的。\nIMAP 的一个与 POP3 的区别是：IMAP 它只下载邮件的主题，并不是把所有的邮件内容都下载下来，而是你邮箱当中还保留着邮件的副本，没有把你原邮箱中的邮件删除，你用邮件客户软件阅读邮件时才下载邮件的内容。较好支持这两种协议的邮件客户端有：Foxmail、Outlook 等。\nMime 协议 由于 SMTP 这个协议开始是基于纯 ASCⅡ文本的，在二进制文件上处理得并不好。后来开发了用来编码二进制文件的标准，如 MIME，以使其通过 SMTP 来传输。今天，大多数 SMTP 服务器都支持 8 位 MIME 扩展，它使二进制文件的传输变得几乎和纯文本一样简单。\n用一张图来看发送邮件过程中的协议使用：\n实线代表 neo@126.com 发送邮件给 itclub@aa.com；虚线代表 itclub@aa.com 发送邮件给 neo@126.com\n邮件发送流程 发信人在用户代理上编辑邮件，并写清楚收件人的邮箱地址； 用户代理根据发信人编辑的信息，生成一封符合邮件格式的邮件； 用户代理把邮件发送到发信人的的邮件服务器上，邮件服务器上面有一个缓冲队列，发送到邮件服务器上面的邮件都会加入到缓冲队列中，等待邮件服务器上的 SMTP 客户端进行发送； 发信人的邮件服务器使用 SMTP 协议把这封邮件发送到收件人的邮件服务器上 收件人的邮件服务器收到邮件后，把这封邮件放到收件人在这个服务器上的信箱中； 收件人使用用户代理来收取邮件。首先用户代理使用 POP3 协议来连接收件人所在的邮件服务器，身份验证成功后，用户代理就可以把邮件服务器上面的收件人邮箱里面的邮件读取出来，并展示给收件人。 这就是邮件发送的一个完整流程。\n简单使用 最早期的时候使用 JavaMail 相关 API 来开发，需要自己去封装消息体，代码量比较庞大；后来 Spring 推出了 JavaMailSender 简化了邮件发送过程，JavaMailSender 提供了强大的邮件发送功能，可支持各种类型的邮件发送。\n现在 Spring Boot 在 JavaMailSender 的基础上又进行了封装，就有了现在的 spring-boot-starter-mail，让邮件发送流程更加简洁和完善。下面给大家介绍如何使用 Spring Boot 发送邮件。\n1、pom 包配置 引入加 spring-boot-starter-mail 依赖包：\n\u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-mail\u003c/artifactId\u003e \u003c/dependency\u003e \u003c/dependencies\u003e 2、配置文件 在 application.properties 中添加邮箱配置，不同的邮箱参数稍有不同，下面列举几个常用邮箱配置：\n163邮箱配置：\nspring.mail.host=smtp.163.com //邮箱服务器地址 spring.mail.username=xxx@oo.com //用户名 spring.mail.password=xxyyooo //密码 spring.mail.default-encoding=UTF-8 //超时时间，可选 spring.mail.properties.mail.smtp.connectiontimeout=5000 spring.mail.properties.mail.smtp.timeout=3000 spring.mail.properties.mail.smtp.writetimeout=5000 126 邮箱配置\nspring.mail.host=smtp.126.com spring.mail.username=yourEmail@126.com spring.mail.password=yourPassword spring.mail.default-encoding=UTF-8 qq 邮箱配置如下：\nspring.mail.host=smtp.qq.com spring.mail.username=ityouknow@qq.com spring.mail.password=yourPassword spring.mail.default-encoding=UTF-8 注意：测试时需要将 spring.mail.username 和 spring.mail.password 改成自己邮箱对应的登录名和密码，这里的密码不是邮箱的登录密码，是开启 POP3 之后设置的客户端授权密码。\n这里以 126 为邮件举例，有两个地方需要邮箱中设置：\n开启 POP3/SMTP 服务、IMAP/SMTP 服务\n图片下方会有 smtp 等相关信息的配置提示。\n开通设置客户端授权密码\n设置客户端授权密码一般需求手机验证码验证。\n3、文本邮件发送 Spring 已经帮我们内置了 JavaMailSender，直接在项目中引用即可。我们封装一个 MailService 类来实现普通的邮件发送方法。\n@Component public class MailServiceImpl implements MailService{ private final Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private JavaMailSender mailSender; @Value(\"${spring.mail.username}\") private String from; @Override public void sendSimpleMail(String to, String subject, String content) { SimpleMailMessage message = new SimpleMailMessage(); message.setFrom(from); message.setTo(to); message.setSubject(subject); message.setText(content); try { mailSender.send(message); logger.info(\"简单邮件已经发送。\"); } catch (Exception e) { logger.error(\"发送简单邮件时发生异常！\", e); } } } 文本邮件抄送使用：message.copyTo(copyTo) 来实现。\nfrom，即为邮件发送者，一般设置在配置文件中 to，邮件接收者，此参数可以为数组，同时发送多人 subject，邮件主题 content，邮件的主体 邮件发送者 from 一般采用固定的形式写到配置文件中。\n4、编写 test 类进行测试 @RunWith(SpringRunner.class) @Spring BootTest public class MailServiceTest { @Autowired private MailService MailService; @Test public void testSimpleMail() throws Exception { mailService.sendSimpleMail(\"ityouknow@126.com\",\"这是一封简单邮件\",\"大家好，这是我的第一封邮件！\"); } } 稍微等待几秒，就可以在邮箱中找到此邮件内容了。至此一个简单的文本邮件发送就完成了。\n富文本邮件 在日常使用的过程中，我们通常在邮件中加入图片或者附件来丰富邮件的内容，下面讲介绍如何使用 Spring Boot 来发送富文本邮件。\n发送 HTML 格式邮件 邮件发送支持以 HTML 语法去构建自定义的邮件格式，Spring Boot 支持使用 HTML 发送邮件。\n我们在 MailService 中添加支持 HTML 邮件发送的方法.\npublic void sendHtmlMail(String to, String subject, String content) { MimeMessage message = mailSender.createMimeMessage(); try { //true 表示需要创建一个 multipart message MimeMessageHelper helper = new MimeMessageHelper(message, true); helper.setFrom(from); helper.setTo(to); helper.setSubject(subject); helper.setText(content, true); mailSender.send(message); logger.info(\"html邮件发送成功\"); } catch (MessagingException e) { logger.error(\"发送html邮件时发生异常！\", e); } } 富文本邮件抄送使用：helper.addCc(cc) 来实现。\n和文本邮件发送代码对比，富文本邮件发送使用 MimeMessageHelper 类。MimeMessageHelper 支持发送复杂邮件模板，支持文本、附件、HTML、图片等，接下来会一一使用到。\n在测试类中构建 HTML 内容，测试发送\n@Test public void testHtmlMail() throws Exception { String content=\"\u003chtml\u003e\\n\" + \"\u003cbody\u003e\\n\" + \" \u003ch3\u003ehello world ! 这是一封html邮件!\u003c/h3\u003e\\n\" + \"\u003c/body\u003e\\n\" + \"\u003c/html\u003e\"; mailService.sendHtmlMail(\"ityouknow@126.com\",\"这是一封HTML邮件\",content); } 邮件内容大写了一段话，下面为接收到的效果：\n由此我们发现发送 HTML 邮件，就是需要拼接一段 HTML 的 String 字符串交给 MimeMessageHelper 来处理，最后由邮件客户端负责渲染显示内容。\n发送带附件的邮件 在 MailService 添加 sendAttachmentsMail 方法，发送带附件的邮件主要是使用 FileSystemResource 对文件进行封装，在添加到 MimeMessageHelper 中。\npublic void sendAttachmentsMail(String to, String subject, String content, String filePath){ MimeMessage message = mailSender.createMimeMessage(); try { MimeMessageHelper helper = new MimeMessageHelper(message, true); helper.setFrom(from); helper.setTo(to); helper.setSubject(subject); helper.setText(content, true); FileSystemResource file = new FileSystemResource(new File(filePath)); String fileName = file.getFilename(); helper.addAttachment(fileName, file); //helper.addAttachment(\"test\"+fileName, file); mailSender.send(message); logger.info(\"带附件的邮件已经发送。\"); } catch (MessagingException e) { logger.error(\"发送带附件的邮件时发生异常！\", e); } } 添加多个附件可以使用多条 helper.addAttachment(fileName, file)\n在测试类中添加测试方法\n@Test public void sendAttachmentsMail() { String filePath=\"e:\\\\temp\\\\fastdfs-client-java-5.0.0.jar\"; mailService.sendAttachmentsMail(\"ityouknow@126.com\", \"主题：带附件的邮件\", \"有附件，请查收！\", filePath); } 附件可以是图片、压缩包、Word 等任何文件，但是邮件厂商一般都会对附件大小有限制，太大的附件建议使用网盘上传后，在邮件中给出链接。\n效果图如下：\n发送带静态资源的邮件 邮件中的静态资源一般指图片，在 MailService 添加 sendInlineResourceMail 方法。\npublic void sendInlineResourceMail(String to, String subject, String content, String rscPath, String rscId){ MimeMessage message = mailSender.createMimeMessage(); try { MimeMessageHelper helper = new MimeMessageHelper(message, true); helper.setFrom(from); helper.setTo(to); helper.setSubject(subject); helper.setText(content, true); FileSystemResource res = new FileSystemResource(new File(rscPath)); helper.addInline(rscId, res); mailSender.send(message); logger.info(\"嵌入静态资源的邮件已经发送。\"); } catch (MessagingException e) { logger.error(\"发送嵌入静态资源的邮件时发生异常！\", e); } } 在测试类中添加测试方法\n@Test public void sendInlineResourceMail() { String rscId = \"neo006\"; String content=\"\u003chtml\u003e\u003cbody\u003e这是有图片的邮件：\u003cimg src=\\'cid:\" + rscId + \"\\' \u003e\u003c/body\u003e\u003c/html\u003e\"; String imgPath = \"e:\\\\temp\\\\weixin.jpg\"; mailService.sendInlineResourceMail(\"ityouknow@126.com\", \"主题：这是有图片的邮件\", content, imgPath, rscId); } 添加多个图片可以使用多条 \u003cimg src='cid:\" + rscId + \"' \u003e 和 helper.addInline(rscId, res) 来实现\n效果图如下：\n以上是邮件发送的基础服务，已演示支持各种类型邮件。\n邮件系统 如果只是想在系统中做一个邮件工具类的话，以上的内容基本就可以满足要求了。要做成一个邮件系统的话还需要考虑以下几方面：\n对外提供发送邮件的服务接口 固定格式邮件是否考虑使用模板 发送邮件时出现网络错误，是否考虑适当的重试机制 邮件系统是否考虑异步化，提升服务响应时间 是否开发邮件后台管理系统，开发出对应的管理软件，通过页面发送邮件，统计发送邮件成功率等数据。 常见异常处理措施 对外提供接口 作为一个独立的邮件系统，需要对外提供接口调用，我们以简单文本邮件为例做个演示：\n首先需要定义个实例返回对象：\npublic class MailResult { private String rspCode; private String rspMsg; public MailResult() { this.rspCode = \"00\"; this.rspMsg = \"发送成功\"; } //省略 setter/getter } 默认成功的返回码为：00，返回消息为：发送成功。\n创建一个 MailController 类对外提供 HTTP 请求接口。\n@RestController public class MailController { private final Logger logger = LoggerFactory.getLogger(this.getClass()); @Resource private MailService mailService; @RequestMapping(\"/sendSimpleMail\") public MailResult sendSimpleMail(String to, String subject, String content) { MailResult result=new MailResult(); if(StringUtils.isEmpty(to) || !to.contains(\"@\")){ result.setRspCode(\"01\"); result.setRspCode(\"手机人邮件格式不正确\"); } if(StringUtils.isEmpty(content) ){ result.setRspCode(\"03\"); result.setRspCode(\"邮件正文不能为空\"); } try { mailService.sendSimpleMail(to,subject,content); logger.info(\"简单邮件已经发送。\"); } catch (Exception e) { result.setRspCode(\"04\"); result.setRspCode(\"邮件发送出现异常\"); logger.error(\"sendSimpleMail Exception \", e); } return result; } } 外部请求过来时首先进行参数校验，如果参数有误返回请求；发送邮件出现异常时返回错误，正常情况下返回 00；注意在 Service 层如果对异常信息进行了捕获的话，需要将异常信息抛到上层。\ntry { mailSender.send(message); logger.info(\"简单邮件已经发送。\"); } catch (Exception e) { logger.error(\"发送简单邮件时发生异常！\", e); throw e; } 类似上述代码。\n按照这个思路也可以提供发送带图片、带附件的邮件，同时也可以封装发送多人邮件，群发邮件等复杂情况。\n邮件模板 通常我们使用邮件发送服务的时候，都会有一些固定的场景，比如重置密码、注册确认等，给每个用户发送的内容可能只有小部分是变化的。所以，很多时候我们会使用模板引擎来为各类邮件设置成模板，这样我们只需要在发送时去替换变化部分的参数即可。\n我们会经常收到这样的邮件：\n尊敬的 neo 用户： 恭喜您注册成为xxx网的用户,同时感谢您对xxx的关注与支持并欢迎您使用xx的产品与服务。 ... 邮件正文只有 neo 这个用户名在变化，邮件其它内容均不变，如果每次发送邮件都需拼接 HTML 代码，程序不够优雅，并且每次邮件正文有变化都需修改代码非常不方便。因此对于这类邮件，都建议做成邮件模板来处理，模板的本质很简单，就是在模板中替换变化的参数，转换为 HTML 字符串即可，这里以 Thymeleaf 为例来演示。\nThymeleaf 是 Spring 官方推荐的前端模板引擎，类似 Velocity、FreeMarker 等模板引擎，相较与其他的模板引擎，Thymeleaf 开箱即用的特性。它提供标准和 Spring 标准两种方言，可以直接套用模板实现 JSTL、 OGNL 表达式效果，避免每天套模板、该 Jstl、改标签的困扰。Thymeleaf 在有网络和无网络的环境下皆可运行，即它可以让美工在浏览器查看页面的静态效果，也可以让程序员在服务器查看带数据的动态页面效果。\n下面我们来演示使用 Thymeleaf 制作邮件模板。\n1、添加依赖包\n\u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-thymeleaf\u003c/artifactId\u003e \u003c/dependency\u003e 2、在 resorces/templates 下创建 emailTemplate.html\nemailTemplate.html 文件内容即为邮件的正文内容模板。\n\u003c!DOCTYPE html\u003e \u003chtml lang=\"zh\" xmlns:th=\"http://www.thymeleaf.org\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"/\u003e \u003ctitle\u003e邮件模板\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e 您好,感谢您的注册，这是一封验证邮件，请点击下面的链接完成注册，感谢您的支持\u003cbr/\u003e \u003ca href=\"#\" th:href=\"@{http://www.ityouknow.com/register/{id}(id=${id}) }\"\u003e激活账号\u003c/a\u003e \u003c/body\u003e \u003c/html\u003e 我们发现上述的模板中只有 id 是一个动态的值，发送过程中会根据传入的 id 值来替换链接中的 {id}。\n3、解析模板并发送\n@Test public void sendTemplateMail() { //创建邮件正文 Context context = new Context(); //设置模板需要替换的参数 context.setVariable(\"id\", \"006\"); //使用 templateEngine 替换掉动态参数生产出最后的 HTML 内容。 String emailContent = templateEngine.process(\"emailTemplate\", context); //最后调用 sendHtmlMail 发送邮件 mailService.sendHtmlMail(\"ityouknow@126.com\",\"主题：这是模板邮件\",emailContent); } 我们发现最后调用的还是 sendHtmlMail 的方法，邮件模板的作用只是处理 HTML 生成部分，通过 Thymeleaf 模板引擎解析固定的模板，再更具参数来动态替换其中的变量，最后通过前面的 HTML 发送的方法发送邮件。\n效果图如下：\n点击“激活账号”跳转的链接为：http://www.ityouknow.com/register/006\n发送失败 因为各种原因，总会有邮件发送失败的情况，比如：邮件发送过于频繁、网络异常等。在出现这种情况的时候，我们一般会考虑重新重试发送邮件，会分为以下几个步骤来实现：\n接收到发送邮件请求，首先记录请求并且入库。 调用邮件发送接口发送邮件，并且将发送结果记录入库。 启动定时系统扫描时间段内，未发送成功并且重试次数小于3次的邮件，进行再次发送. 重新发送邮件的时间，建议以 2 的次方间隔时间，比如：2、4、8、16 … 常见的错误返回码：\n421 HL:ICC 该IP同时并发连接数过大，超过了网易的限制，被临时禁止连接。 451 Requested mail action not taken: too much fail authentication 登录失败次数过多，被临时禁止登录。请检查密码与帐号验证设置 553 authentication is required，密码配置不正确 554 DT:SPM 发送的邮件内容包含了未被许可的信息，或被系统识别为垃圾邮件。请检查是否有用户发送病毒或者垃圾邮件； 550 Invalid User 请求的用户不存在 554 MI:STC 发件人当天内累计邮件数量超过限制，当天不再接受该发件人的投信。 如果使用一个邮箱频繁发送相同内容邮件，也会被认定为垃圾邮件，报 554 DT:SPM 错误\n如果使用网易邮箱可以查看这里的提示：企业退信的常见问题？\n其它 异步发送\n很多时候邮件发送并不是主业务必须关注的结果，比如通知类、提醒类的业务可以允许延时或者失败。这个时候可以采用异步的方式来发送邮件，加快主交易执行速度。在实际项目中可以采用消息中间件 MQ 发送邮件，具体做法是创建一个邮件发送的消息队列，在业务中有需要用到邮件发送功能时，给对应消息队列按照规定参数发送一条消息，邮件系统监听此队列，当有消息过来时，处理邮件发送的逻辑。\n管理后台\n考虑做一个完善的邮件系统，可以设计一个独立的邮件管理后台，不但可以让系统之间调用时使用，也可以提供图形化界面让公司的运营、市场部的同事来发送邮件，查询邮件的发送进度，统计邮件发送成功率。也可以设置一些代码钩子，统计用户点击固定链接次数，方便公司营销人员监控邮件营销转化率。\n一个非常完善的邮件系统需要考虑的因素非常多，比如是否设置白名单、黑名单来做邮件接收人的过滤机制，是否给用户提供邮件退订的接口等。因此在初期邮件发送的基本功能完成之后，再结合公司业务，快速迭代的逐步完善邮件系统，是一个推荐的做法。\n总结 使用 Spring Boot 集成发送邮件的功能非常简单，只需要简单编码就可以实现发送普通文本邮件、带附件邮件、HTML 格式邮件、带图片邮件等。如果需要做成一个邮件系统还需要考虑很多因素，比如：邮箱发送失败重试机制、防止邮件被识别为垃圾邮件，固定时间内发送邮件的限制等。在微服务架构中，常常将一些基础功能下沉下来，作为独立的服务来使用，邮件系统作为平台的基础功能，特别适合做为独立的微服务来支持整个系统。\n点击这里下载源码\n参考：\nhttps://www.geekpark.net/news/214789 ","description":"\n","tags":[],"title":"\n使用 Spring Boot 开发邮件系统","uri":"/posts/post-261/"},{"categories":["默认分类"],"content":"自动化测试\n一、接口定义 软件不同部分之间的交互接口。通常就是所谓的 API――应用程序编程接口，其表现的形式是源代码。 —— [ 百度百科 ]\n我们常说的接口一般指两种：\nAPI：应用程序编程接口。程序间的接口 GUI：图形用户界面。人与程序的接口 这里我们所说的接口特指 API 接口。API 接口定义：对协议进行定义的引用类型。\n好多公司开发人员分前后端，他们之间如何配合工作的，就是其中一方定义接口，另一方来调用接口，以实现预期功能。\n二、接口的分类 1. 接口分类 HTTP 接口 Webservice 接口 RESTful 接口 WebService 接口是走 soap 协议，请求报文和返回报文都是 xml 格式，通过 SoapUI 工具进行测试；\nHTTP API 接口走 HTTP 协议，通过路径来区分调用的方法，请求报文入参有多种形式，返回报文一般为 json 串，最常见的是 get 和 post 方法。\n三、为何要进行接口测试 1. 接口测试必要性 当今的系统复杂度不断上升，传统的测试方法成本急剧增加且测试效率大幅下降，所以就要做接口测试。\n同时，接口测试相对容易实现自动化持续集成，且相对 UI 自动化也比较稳定，可以减少人工回归测试人力成本与时间，缩短测试周期，支持后端快速发版需求。\n接口持续集成是为什么能低成本高收益的根源。现在很多系统前后端架构是分离的，从安全层面来说，只依赖前端进行限制已经完全不能满足系统的安全要求（绕过前面实在太容易）， 需要后端同样进行控制，在这种情况下就需要从接口层面进行验证。\n前后端传输、日志打印等信息是否加密传输也是需要验证的，特别是涉及到用户的隐私信息，如身份证，银行卡等。\n2. 接口测试原理 模拟客户端向服务器发送请求报文，服务器接收请求报文后对相应的报文做处理并向客户端返回应答，客户端再接收应答的一个过程。\n3. 接口测试范围 接口的功能、性能、安全性。重点关注数据的交换，传递和控制管理过程，还包括处理的次数。\n接口测试对象是接口，但随着系统复杂度越来越高，接口越来越多，完全覆盖是一件很困难的事情。\n通常情况下主要测试最外层的两类接口：数据进入系统的接口（调用外部系统的参数为本系统使用）、数据流出系统接口（验证系统处理后的数据是否正常）\n四、接口文档示例 1. 接口文档应该包括哪几部分？ 接口说明 调用的 url 请求方法（get、post） 请求参数，参数类型、请求参数说明 返回参数说明 返回示例 2. 示例 注：上图接口文档工具为 ShowDoc\n五、Postman 工具简介 1. Sidebar 侧边栏 Postman 侧边栏允许你查找、管理请求和集合。侧边栏分为两个主要的选项卡，包括历史和集合选项卡。可以拖动右边的边来调整侧边栏的宽度。侧边栏也可以隐藏到小屏幕（标题栏 view—\u003etoggle side bar）。\n（1）历史选项卡\n通过 Postman 应用程序发送的每个请求都保存在侧边栏的 History 选项卡中。\n（2）集合选项卡\n在侧栏中创建和管理集合选项卡的集合。\n2. Header toolbar Postman 的顶部工具栏包含以下选项：\n新建按钮——可以新建请求，集合，环境等 运行按钮-打开集合运行页面 导入按钮——导入 Postman 文件、文件夹、form link 等 新窗口图标-打开一个新的 tab 页、新的窗口、新的 runner 等 构建器和团队库选项卡——在请求生成器和 Team Library 视图之间切换 抓取 API 请求图标——使用 postman 抓取 API 请求 同步状态图标——同步 API 请求图标 用户下拉——管理集合链接和你的个人资料或登录 / 登出，你的 Postman 帐户 开放 API 集合（点击打开一个网址） 通知图标-接收通知或广播 设置图标——管理 Postman 应用程序设置，并找到其他支持资源 ❤——分享按钮 3. Builder Postman 通过选项卡布局，用于在构建器中发送和管理 API 请求。上半部分是请求构建器，下半部分是响应查看器。\nCookies——管理 cookie 模式是通过点击 cookie 链接访问的。该特性允许你管理与请求相关的 cookie。 Code——生成的代码片段模式通过保存按钮下面的最右边的 Code 链接。该特性允许你生成与请求相关的代码片段，该请求支持 20 多种语言（http、java、go 等语言） 4. Console Postman 有两个控制台，可以帮助我们了解系统后台到底发生了什么。\nPostman Console——包含 HTTP 请求和响应的运行日志。来自脚本的日志消息 (如在 console. Log 中)。这个功能只能在 Postman 的本地应用中使用。 DevTools Console——可以在开发期间记录诊断信息。 六、借助 Postman 完成 HTTP 请求接口测试 1. 借助 Postman Echo 演示下各种请求的构建方法 （1）Get 请求\nhttps://postman-echo.com/get?foo1=bar1\u0026foo2=bar2\nHTTP GET 请求方法是从服务器检索数据。数据由惟一 URI(统一资源标识符) 标识。GET 请求可以使用 “查询字符串参数” 将参数传递给服务器。例如，在下列请求中，http://example.com/hi/there?hand=wave，参数 “hand” 的值等于 “wave”。\n（2）POST：URI 传参\n（3）POST：Form-data 传参\n（4）POST：x-www-form-urlencoded 传参\n（5）POST：raw 传参\n（6）POST：binary 传参\n（7）Authentication Method——权限认证方法\nGET Basic Auth\n增加 auth 信息：\nDigestAuth\nHawk Auth\nOAuth1.0(verify signature)\n（8）Headers——添加 header\n2. 接下来，我们拿个开放 API 来演示下单一接口测试流程 示例 API：https://developers.douban.com/wiki/?title=book_v2#get_book\n步骤一：使用 Postman 工具发送该 Get 请求，如下图。\n步骤二：添加测试。\n上图针对该 API 添加了 3 个测试：\n要求响应时间小于 200ms\n要求 status code 等于 200\n要求 Response body 中包含字符串 “金庸”\n注：当然你还可以增加更多的测试点。\n七、Postman + Newman + Jenkins 实现接口自动化测试 1. 准备工作（具体步骤参考附件文档-作者提供） （1）安装 Newman 工具\n安装 Node.js 安装 Newman 查看 Newman 命令 （2）部署 Jenkins\n2. 将接口保存到集合 点击 Save 按钮，将接口保存到一个集合（可以保存到一个现有集合中或者新建一个集合），如下图：\n3. 将集合保存到本地 将集合保存到本地，文件为 .json 格式，如下图：\n4. 命令行通过 Newman 运行集合 （1）打开命令行窗口，运行如下命令：\nD:\\git-local\u003enewman run MyCollection1.postman_collection.json -g globals.postman_globals1.json\n（2）执行结果如下：\n可以看到，其中两条断言 passed，一条断言 failed，失败的原因是，我们期望接口响应时间小于 200 ms，但是本次接口请求响应时间是 270 ms。\n5. 通过 Jenkins 调用 Newman，执行接口测试 执行一次构建，构建失败（上面的断言失败，我们并未修复），查看构建失败原因。\n6. 假设开发修复了接口 bug 接口响应时间减少了，我们需要回归测试。（我们将断言响应小于 200 ms，修改成 1000 ms，让断言 passed）\n7. 演示一个如何调用 data file 参数化用例 我这里有一个集合，3 个接口，第一个接口为登录接口，第二个接口为获取登录用户信息接口，第三个接口为修改密码接口。登录接口如下：\n测试脚本如下：\n参数化 json 文件内容如下：\n[{ \"loginName\": \"duzl\", \"password\": \"admin123\", \"verifyCode\": \"adf\", \"value\": \"/index\" }, { \"loginName\": \"duzl\", \"password\": \"admin\", \"verifyCode\": \"adf\", \"value\": \" 账号或密码错误 \" }, { \"loginName\": \"duzl\", \"password\": \"\", \"verifyCode\": \"adf\", \"value\": \" 参数 password 不能为空 \" }] （1）好我们调用 json 文件，执行下集合，结果如下：\n结果还不错，执行了 3 次，参数都是取自用例文件（json 文件），断言也取自用例文件。\n美中不足的是，第二个和第三个接口也跟着迭代了 3 次（这并不是我们期望的结果），这是因为集合运行器中的迭代次数是针对所有接口的设置。\n（2）那如果，我们想第一个接口运行 3 遍，第二、三个接口只运行一遍，该如何做呢？Postman 给我们提供了一个内置方法，设置接口运行顺序postman.setNextRequest('');。\n注意：迭代次数从 0 开始。\n当迭代次数 !==0 时，就停止本次迭代（意思就是，第一次迭代全运行，第二次迭代开始就不执行第二、三个接口了），好，再次运行集合，看看结果：\n很好，第一次迭代，执行了 3 个接口；第二、三次迭代只执行了第一个接口。\n","description":"\n","tags":[],"title":"\n接口测试工具 Postman 使用实践","uri":"/posts/post-262/"},{"categories":["默认分类"],"content":"写在前面 上一篇文章生育假政策-成都介绍了成都的生育假问题，我们说到了女性在成都的生育假期是98+60=158天。其中60天是四川省在国家政策基础上补充的福利，从2016年的时候开始实施的。由于这60天不是国家层面的法律法规的，所以在报销生育津贴的时候会有一些疑问，这篇文章主要解释生育津贴问题以及一些和生育津贴相关问题。\n生育保险 这里指的生育保险是指生育医疗保险，津贴部分说明在文章下一部分。\n先写结论 报销的对象 基本医疗保险参保人员。\n企业在社保局给员工购买社保时，必须五险一起购买，五险分别是：养老、医疗、失业、工伤、生育。\n国家规定企业是必须要给职工购买五险的。如果企业不购买，则构成违法。\n医疗待遇补助金额 成都生育医疗待遇都是定额的，其中顺产2700，剖腹产3700。\n生育保险是什么 参见中国政府网的便民问答文章–什么是生育保险？\n生育保险是通过国家立法规定，在劳动者因生育子女而导致劳动力暂时中断时，由国家和社会及时给予物质帮助的一项社会保险制度。\n我国生育保险待遇主要包括两项。一是生育津贴，用于保障女职工产假期间的基本生活需要；二是生育医疗待遇，用于保障女职工怀孕、分娩期间以及职工实施节育手术时的基本医疗保健需要。\n生育保险的法律依据是：1994年7月5日颁布的《中华人民共和国劳动法》；原劳动部于1994年12月14日发布的《企业职工生育保险试行办法》（劳部发〔1994〕504号）。相关规定有：1988年7月21日颁布的《女职工劳动保护规定》（国务院令第9号）；原劳动部于1988年9月4日发布的《关于女职工生育待遇若干问题的通知》（劳险字〔1988〕2号）。\n生育保险报销流程 一般在医院办理出院时刷社保卡自动报销。\n生育保险报销材料 准生证、女方医保卡、夫妻双方身份证、出生证明的原件以及一份复印件，其中除准生证和医保卡，都是出院前先在医院办理，不需要医院社区来回跑。\n以双流妇幼保健院为例，需要的的准备资料如下：\n生育津贴 提前说明 成都企业女性职工领取生育津贴是需要社保满一年；如果是男方购买社保，女方没有购买社保，则无法领取生育津贴。\n而且生育津贴的领取是根据公司给员工购买社保的基数进行计算的。社保基数越高，津贴越高。\n另外，津贴只有国家规定的98天，剩余60天（两个月），需要公司以员工实际月工资进行发放。\n成都2022年社保的基数限制 没错，你没看错，购买社保时的社保基数，是有限制的，是在一个范围内的。\n为什么网上有的说工资和津贴选高的领取？ 需要明确一个问题，如果公司购买的五险一直是最低基数，而你的工资高于最低缴费基数（即是工资\u003e基数），这就是不合法的，虽然现在依旧有很多公司在这样做。\n但是上述情况客观存在，而大多数人因为一些情况，没有向劳动局投诉/举报公司，所以我们需要讨论在这种情况下如何选择工资和津贴进行领取。\n首先我们需要知道，实际每月基数问题：一般来说，新员工按照入职当月的工资总额作为社保基数，从入职第二年起，按照上一年应发工资的月平均工资作为社保基数。\n然后，有的公司工资是低于社保最低缴费基数的，这种情况下，需要以社保局要求的最低购买基数进行购买；同理，工资高于最高缴费基数的，按照最高缴费基数进行缴纳。\n例如：张三上一年月平均工资为2万元，本年缴费应基数为18630元，生育津贴按照18630元/月计算，98天应领取18630÷30×98=60858元；但是，张三选择领工资是20000÷30×98≈65333.33元。（当然，这里是税前工资，需要缴纳五险一金以及个税的）\n所以，网上关于“工资和津贴选高的领取”的问题，只针对，工资低于最低缴费基数或高于最高缴费基数的情况。\n60天的工资问题 我们知道，这60天，是四川省在法律、法规规定外新延长出来的，但是生育津贴只有98天的，那么，剩下这60天就没有钱吗？答案是：不是！！！\n根据《四川省人口与计划生育条例（2021年修正）》 第二十四条规定：\n符合本条例规定生育子女的夫妻，除法律、法规规定外，延长女方生育假60天，给予男方护理假 20天。生育假、护理假视为出勤，工资福利待遇不变。\n我们知道，这60天是生育假，而生育假，视为出勤，工资福利待遇不限。因此，这60天需要由公司发放工资，公司不能因为员工在家就不能进行工资发放！\n","description":"\n","tags":["生育假","生育津贴","生育保险","社保"],"title":"\n生育保险以及生育津贴相关-成都","uri":"/posts/post-28/"},{"categories":["默认分类"],"content":"今天跑代码时用到了Powershell，有一个环境变量死活都找不到，无奈只好重新回到cmd命令行测试，结果立马就跑通了。 由于现在Win10默认右键只有Powershell，所以为了以后方便使用就把右键添加“在此处打开命令窗口”的代码分享出来。\n效果显示“在此处打开命令窗口”选项，如图：\n具体步骤 第一步：新建一个txt文件，命名为OpenCmdHere.txt，注意设置编码格式为ANSI 第二步：在文件中输入如下代码，并保存\nWindows Registry Editor Version 5.00 [HKEY_CLASSES_ROOT\\Directory\\shell\\OpenCmdHere] @=\"在此处打开命令窗口\" \"Icon\"=\"cmd.exe\" [HKEY_CLASSES_ROOT\\Directory\\shell\\OpenCmdHere\\command] @=\"cmd.exe /s /k pushd \"%V\"\" [HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\OpenCmdHere] @=\"在此处打开命令窗口\" \"Icon\"=\"cmd.exe\" [HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\OpenCmdHere\\command] @=\"cmd.exe /s /k pushd \"%V\"\" [HKEY_CLASSES_ROOT\\Drive\\shell\\OpenCmdHere] @=\"在此处打开命令窗口\" \"Icon\"=\"cmd.exe\" [HKEY_CLASSES_ROOT\\Drive\\shell\\OpenCmdHere\\command] @=\"cmd.exe /s /k pushd \"%V\"\" [HKEY_CLASSES_ROOT\\LibraryFolder\\background\\shell\\OpenCmdHere] @=\"在此处打开命令窗口\" \"Icon\"=\"cmd.exe\" [HKEY_CLASSES_ROOT\\LibraryFolder\\background\\shell\\OpenCmdHere\\command] @=\"cmd.exe /s /k pushd \"%V\"\" 第三步：更改文件后缀名为reg，弹出的提示点确认。 第四步：双击OpenCmdHere.reg文件运行，弹出的提示点确认，修改注册表就大功告成了！\n","description":"\n","tags":[],"title":"\nWindows10右键添加\"在此处打开命令窗口\"","uri":"/posts/post-263/"},{"categories":["默认分类"],"content":"写在前面 因为老婆要生育了，在和公司沟通中发现一些理解偏差问题，在网上搜到的假期的结果也是千奇百怪，所以这里专门整理一下成都的生育政策，主要是生育假相关政策。\n需要提前说明的是，实际享受的生育假只可能是大于等于国家规定的假期的。因为一般生育假都是国家层面+当地政策共同实现的\n各方政策 首先，是国家层面的，国家法定产假是98天。\n支撑条例或规定：《女职工劳动保护特别规定》第七条规定:\n女职工生育享受98天产假，其中产前可以休假15天；难产的，增加产假15天；生育多胞胎的，每多生育1个婴儿，增加产假15天。 女职工怀孕未满4个月流产的，享受15天产假；怀孕满4个月流产的，享受42天产假。\n《女职工劳动保护特别规定》已经2012年4月18日国务院第200次常务会议通过,并在2012年05月07日 16时08分公布，自公布日开始执行。\n其次，是当地政策，这里就是指四川成都了，四川延长女方生育假60天，注意是延长，不是修改！\n《四川省人口与计划生育条例（2021年修正）》 第二十四条规定:\n符合本条例规定生育子女的夫妻，除法律、法规规定外，延长女方生育假六十天，给予男方护理假二十天。生育假、护理假视为出勤，工资福利待遇不变。县级以上地方人民政府及用人单位应当保障生育假、护理假待遇落实。\n子女三周岁以下的夫妻，每年分别享受累计十天的育儿假，育儿假视为出勤。\n关于符合本条例规定生育子女的夫妻这一主体，在《四川省人口与计划生育条例（2021年修正）》 的第一章 第二条做出了说明：\n本条例适用于本省行政区域内的国家机关、社会团体、企业事业单位、群众性自治组织和公民以及户籍在本省而离开本省行政区域的公民。\n这里很明确的指出了，符合本条例规定生育子女的夫妻这一主体是指的：\n在四川的国家机关的夫妻 在四川的社会团体的夫妻 在四川的企业单位的夫妻 在四川的事业单位的夫妻 在四川的群众性自治组织的夫妻 在四川的公民 户籍在四川的但人不在四川的公民 上述涵盖面非常广了，所以，一般来说，只要你在四川上班或者户籍在四川，都是适用这个规定的。\n后话 可以明显看见《四川省人口与计划生育条例（2021年修正）》 这一规定是2021修正版的，那么，四川是在哪一年增加的女方60天产假的呢？答案是2016年。\n四川省第十二届人民代表大会常务委员会公告第61号文件，四川省人口与计划生育条例（2016年）的第五章 奖励与社会保障 第二十六条首次正式添加了这一规定。\n符合本条例规定生育子女的夫妻，除法律、法规规定外，延长女方生育假60天，给予男方护理假 20天。生育假、护理假视为出勤，工资福利待遇不变。\n细心的人肯定注意到了，2021年的修正，除了把这一条从第二十六条改在为第二十四条外，还添加了育儿假的福利细则。关于育儿假详细说明的，我会在后面一篇文章说明。\n总结 所以在四川，女方的生育假，也就是产假，实际天数为：98+60=158天 男方的护理假，也就是陪产假，为20天。\n","description":"\n","tags":["生孩子","假期","生育假"],"title":"\n生育假政策-成都","uri":"/posts/post-25/"},{"categories":["默认分类"],"content":"工作 20 多年了，这 20 来年看到了很多公司系统架构，也看到了很多问题，在跟这些公司进行交流和讨论的时候，包括进行实施和方案比较的时候，都有很多各种方案的比较和妥协，因为相关的经历越来越多，所以，逐渐形成了自己的逻辑和方法论。今天，想写下这篇文章，把我的这些个人的经验和想法总结下来，希望能够让更多的人可以参考和借鉴，并能够做出更好的架构来。另外，我的这些思维方式和原则都针对于现有市面上众多不合理的架构和方案，所以，也算是一种“纠正”……（注意，这篇文章所说的这些架构上的原则，一般适用于相对比较复杂的业务，如果只是一些简单和访问量不大的应用，那么你可能会得出相反的结论）\n原则一：关注于真正的收益而不是技术本身 对于软件架构来说，我觉得第一重要的是架构的收益，如果不说收\b益，只是为了技术而技术，而没有任何意义。对于技术收益来说，我觉得下面这几个收益是非常重要的：\n是否可以降低技术门槛加快整个团队的开发流程。能够加快整个团队的工程流程，快速发布，是软件工程一直在解决的问题，所以，系统架构需要能够进行并行开发，并行上线和并行运维，而不会让某个团队成为瓶颈点。（注：就算拖累团队的原因是组织构架，也不妨碍我们做出并行的系统架构设计） 是否可以让整个系统可以运行的更稳定。要让整个系统可以运行的更为的稳定，提升整个系统的 SLA，就需要对有计划和无计划的停机做相应的解决方案（参看《关于高可用的架构》） 是否可以通过简化和自动化降低成本。最高优化的成本是人力成本，人的成本除了慢和贵，还有经常不断的 human error。如果不能降低人力成本，反而需要更多的人，那么这个架构设计一定是失败的。除此之外，是时间成本，资金成本。 如果一个系统架构不能在上面三个事上起到作用，那就没有意义了。\n原则二：以应用服务和 API 为视角，而不是以资源和技术为视角 国内很多公司都会有很多分工，基本上都会分成运维和开发，运维又会分成基础运维和应用运维，开发则会分成基础核心开发和业务开发。不同的分工会导致完全不同的视角和出发点。比如，基础运维和开发的同学更多的只是关注资源的利用率和性能，而应用运维和业务开发则更多关注的是应用和服务上的东西。这两者本来相关无事，但是因为分布式架构的演进，导致有一些系统已经说不清楚是基础层的还是应用层的了，比如像服务治理上的东西，里面即有底层基础技术，也需要业务的同学来配合，包括 k8s 也样，里面即有底层的如网络这样的技术，也有需要业务配合的 readniess和 liveness 这样的健康检查，以及业务应用需要 configMap 等等 ……\n这些东西都让我感觉到所谓 DevOps，其实就是因为很多技术和组件已经分不清是 Dev 还是 Ops 的了，所以，需要合并 Dev和 Ops。而且，整个组织和架构的优化，已经不能通过调优单一分工或是单一组件能够有很大提升的了。其需要有一种自顶向下的，整体规划，统一设计的方式，才能做到整体的提升（可以试想一下城市交通的优化，当城市规模到一定程度的时候，整体的性能你是无法通过优化几条路或是几条街区来完成的，你需要对整个城市做整体的功能体的规划才可能达到整体效率的提升）。而为了做到整体的提升，需要所有的人都要有一个统一的视角和目标，这几年来，我觉得这个目标就是——要站在服务和 对外API的视角来看问题，而不是技术和底层的角度。\n原则三：选择最主流和成熟的技术 技术选型是一件很重要的事，技术一旦选错，那会导致整个架构需要做调整，而对架构的调整重来都不是一件简单的事，我在过去几年内，当系统越来越复杂的时候，用户把他们的 PHP，Python, .NET，或 Node.js 的架构完全都迁移到 Java + Go 的架构上来的案例不断的发生。这个过程还是非常痛苦的，但是你没有办法，当你的系统越来越复杂，越来越大时，你就再也不能在一些玩具技术上玩了，你需要的更为工业化的技术。\n尽可能的使用更为成熟更为工业化的技术栈，而不是自己熟悉的技术栈。所谓工业化的技术栈，你可以看看大多数公司使用的技术栈，比如：互联网，金融，电信……等等 ，大公司会有更多的技术投入，也需要更大规模的生产，所以，他们使用的技术通常来说都是比较工业化的。在技术选型上，千万不要被——“你看某个公司也在用这个技术”，或是一些在论\b坛上看到的一些程序员吐槽技术的观点（没有任何的数据，只有自己的喜好）来决定自己的技术，还是看看主流大多数公司实际在用的技术栈，会更靠谱一些。 选择全球流行的技术，而不是中国流行的技术。技术这个东西一定是一个全球化的东西，不是一个局域化的事。所以，一定要选国际化的会更好。另外，千万不要被某些公司的“特别案例”骗过去了，那怕这个案例很性感，关键还是要看解决问题的思路和采用的技术是否具有普世性。只有普世性的技术有更强的生命力。 尽可能的使用红利大的主流技术，而不要自己发明轮子，更不要魔改。我见过好些个公司魔改开源软件，比如有个公司同魔改mesos，最后改着改着发现自己发明另一个 kubernetes。我还见过很多公司或技术团队喜欢自己发明自己的专用轮子，最后都会被主流开源软件所取代。完全没有必要。不重新发明轮子，不魔改，不是因为自己技术不能，而是因为，这个世界早已不是自己干所有事的年代了，这个时代是要想尽方法跟整个产业，整个技术社区融合和合作，这样才会有最大的收益。那些试图因为某个特例需要自成一套的玩法，短期没问题，但长期来说，我都不看好。 绝大多数情况下，如无非常特殊要求，选 Java基本是不会错的。一方面，这是因为 Java 的业务开发的生产力是非常好的，而且有 Spring 框架保障，代码很难写烂，另外，Java 的社区太成熟了，你需要的各种架构和技术都可以很容易获得，技术红利实在是太大。这种运行在JVM上的语言有太多太多的好处了。在 Java 的技术栈上，你的架构风险和架构的成本（无论是人力成本，时间成本和资金成本）从长期来说都是最优的 在我见过的公司中，好些公司的架构都被技术负责人个人的喜好、擅长和个人经验给绑架了，完全不是从一个客观的角度来进行技术选型。其实，从 0 到 1 的阶段，你用什么样的技术都行，如果你做一个简单的应用，没有事务处理没有复杂的交易流程，比如一些论坛、社交之类的应用，你用任何语言都行。但是如果有一天你的系统变复杂了，需要处理交易了，量也上来了，从 1 到 10，甚至从 10 到 100，你的开发团队也变大了，需要构建的系统越来越大，你可能会发现你只有一个选择，就是 Java。想想京东从.NET 到 Java，淘宝从 PHP 到 Java……\n注，一些有主观喜好的人一定会对我上述对 Java 的描述感到不适，我还用一些证据说明一下——全中国所有的电商平台，几百家银行，三大电信运营商，所有的保险公司，劵商的系统，医院里的系统，电子政府系统，等等，基本都是用 Java 开发的，包括 AWS 的主流语言也是 Java，阿里云一开始用 C++/Python 写控制系统，后面也开始用 Java ……你可能会说 B站是用 go语言，但是你可能不知道 B 站的电商和大数据是用 Java……懂着数据分析的同学，建议上各大招聘网站上搜一下 Java 的职位数量，你就知道某个技术是否主流和热门……\n原则四：完备性会比性能更重要 我发现好些公司的架构师做架构的时候，首要考虑的是架构的性能是否能够撑得住多大多大的流量，而不是考虑系统的完备性和扩展性。所以，我已经多次见过这样的案例了，一开始直接使用 MongoDB 这样的非关系型数据库，或是把数据直接放在 Redis 里，而直接放弃关系型数据库的数据完备性的模型，而在后来需要在数据上进行关系查询的时候，发现 NoSQL 的数据库在 Join 上都表现的太差，然后就开始各种飞线，为了不做 Join 就开始冗余数据，然而自己又维护不好冗余数据后带来的数据一致性的问题，导致数据上的各种错乱丢失。\n所以，我给如下的一些如下的架构原则：\n使用最科学严谨的技术模型为主，并以不严谨的模型作为补充。对于上面那个案例来说，就是——永远使用完备支持 ACID 的关系型数据库，然后用 NoSQL 作补充，而不是完全放弃关系型数据库。这里的原则就是所谓的“先紧后松”，一开始紧了，你可以慢慢松，但是开始松了，以后你想紧再也紧不过来了。 性能上的东西，总是有很多解的。我这么多年的经历告诉我，性能上的事，总是有解的，手段也是最多的，这个比起架构的完备性和扩展性来说真的不必太过担心。 为了追求所谓的性能，把整个系统的完备性丢失掉，相当地得不偿失。\n原则五：制定并遵循服从标准、规范和最佳实践 这个原则是非常重要的，因为只有服从了标准，你的架构才能够有更好的扩展性。比如：我经常性的见到很多公司的系统既没有服从业界标准，也没有形成自己公司的标准，感觉就像一群乌合之众一样。最典型的例子就是 HTTP 调用的状态返回码。业内给你的标准是 200表示成功，3xx 跳转，4xx 表示调用端出错，5xx 表示服务端出错，我实在是不明白为什么无论成功和失败大家都喜欢返回 200，然后在 body 里指出是否error（前两年我在微信公众号里看到一个有一定名气的互联网老兵推荐使用无论正确还是出错都返回 200 的做法，我在后台再三确认后，我发现这样的架构师真是害人不浅）。这样做最大的问题是——监控系统将在一种低效的状态下工作。监控系统需要把所有的网络请求包打开后才知道是否是错误，而且完全不知道是调用端出错还是服务端出错，于是一些像重试或熔断这样的控制系统完全不知道怎么搞（如果是 4xx错，那么重试或熔断是没有意义的，只有 5xx 才有意义）。有时候，我会有种越活越退步的感觉，错误码设计这种最基本最基础的东西为什么会没有？并且一个公司会任由着大家乱来？这些基础技能怎么就这样丢掉了？\n还有，我还见过一些公司，他们整个组织没有一个统一的用户 ID 的设计，各个系统之间同步用户的数据是通过用户的身份证 ID，是的，就是现实世界的身份证 ID，包括在网关上设置的用户白名单居然也是用身份证 ID。我对这个公司的内的用户隐私管理有很大的担忧。一个企业，一个组织，如果没有标准和规范，也就会有抽象，这一定是要出各种乱子的。\n下面，我罗列一些你需要注意的标准和规范（包括但不限于）：\n服务\b间调用的协议标准和规范。这其中包括 Restful API路径, HTTP 方法、状态码、标准头、自定义头等，返回数据 JSon Scheme……等。 一些命名的标准和规范。这其中包括如：用户 ID，服务名、标签名、状态名、错误码、消息、数据库……等等 日志和监控的规范。这其中包括：日志格式，监控数据，采样要求，报警……等等 配置上的规范。这其中包括：操作系统配置、中间件配置，软件包……等等 中间件使用的规范。数据库，缓存、消息队列……等等 软件和开发库版本统一。整个组织架构内，软件或开发库的版本最好每年都升一次级，然后在各团队内统一。 这里重要说一下两个事：\nRestful API 的规范。我觉得是非常重要的，这里给两个我觉得写得最好的参考：Paypal 和 Microsoft 。Restful API 有一个标准和规范最大的好处就是监视可以很容易地做各种统计分析，控制系统可以很容易的做流量编排和调度。 另一个是服务调用链追踪。对于服务调用链追踪来说，基本上都是参考于 Google Dapper 这篇论文，目前有很多的实现，最严格的实现是 Zipkin，这也是 Spring Cloud Sleuth 的底层实现。Zipkin 贴近 Google Dapper 论文的好处在于——无状态，快速地把 Span 发出来，不消耗服务应用侧的内存和 CPU。这意味着，监控系统宁可自己死了也不能干扰实际应用。 软件升级。我发现很多公司包括 BAT，他们完全没有软件升级的活动，全靠开发人员自发。然而，这种成体系的活动，是永远不可能靠大众的自发形成的。一个公司至少一年要有一次软件版本升级的review，然后形成软件版本的统一和一致，这样会极太简化系统架构的复杂度。 原则六：重视架构扩展性和可运维性 在我见过很多架构里，技术人员只考虑当下，但从来不考虑系统的未来扩展性和可运维性。所谓的管生不管养。如果你生下来的孩子胳膊少腿，严重畸形，那么未来是很难玩的。因为架构和软件不是写好就完的，是需要不断修改不断维护的，80%的软件成本都是在维护上。所以，如何让你的架构有更好的扩展性，可以更容易地运维，这个是比较重要的。所谓的扩展性，意味着，我可以很容易地加更多的功能，或是加入更多的系统，而所谓可运维，就是说我可以对线上的系统做任意的变更。扩展性要求的是有标准规范且不耦合的业务架构，可运维性要求的则是可控的能力，也就是一组各式各样的控制系统。\n通过服务编排架构来降低服务间的耦合。比如：通过一个业务流程的专用服务，或是像 Workflow，Event Driven Architecture ， Broker，Gateway，Service Discovery 等这类的的中间件来降低服务间的依赖关系。 通过服务发现或服务网关来降低服务依赖所带来的运维复杂度。服务发现可以很好的降低相关依赖服务的运维复杂度，让你可以很轻松的上线或下线服务，或是进行服务伸缩。 一定要使用各种软件设计的原则。比如：像SOLID这样的原则（参看《一些软件设计的原则》），IoC/DIP，SOA 或 Spring Cloud 等 架构的最佳实践（参看《SteveY对Amazon和Google平台的吐槽》中的 Service Interface 的那几条军规），分布式系统架构的相关\b实践（参看：《分布式系统的事务处理》，或微软件的 《Cloud Design Patterns》）……等等 原则七：对控制逻辑进行全面收口 所有的程序都会有两种逻辑，一种是业务逻辑，一种是控制逻辑，业务逻辑就是完成业务的逻辑，控制逻辑是辅助，比如你用多线程，还是用分布式，是用数据库还是用文件，如何配置、部署，运维、监控，事务控制，服务发现，弹性伸缩，灰度发布，高并发，等等，等等 ……这些都是控制逻辑，跟业务逻辑没有一毛钱关系。控制逻辑的技术深度会通常会比业务逻辑要深一些，门槛也会要高一些，所以，最好要专业的程序员来负责控制逻辑的开发，统一规划统一管理，进行收口。这其中包括：\n流量收口。包括南北向和东西向的流量的调度，主要通过流量网关，开发框架 SDK或 Service Mesh 这样的技术。 服务治理收口。包括：服务发现、健康检查，配置管理、事务、事件、重试、熔断、限流……主要通过开发框架 SDK – 如：Spring Cloud，或服务网格Service Mesh等技术。 监控数据收口。包括：日志、指标、调用链……主要通过一些标准主流的探针，再加上后台的数据清洗和数据存储来完成，最好是使用无侵入式的技术。监控的数据必须统一在一个地方进行关联，这样才会产生信息。 资源调度有应用部署的收口。包括：计算、网络和存储的收口，主要是通过容器化的方案，如k8s来完成。 中间件的收口。包括：数据库，消息，缓存，服务发现，网关……等等。这类的收口方式一般要在企业内部统一建立一个共享的云化的中间件资源池。 对此，这里的原则是：\n你要选择容易进行业务逻辑和控制逻辑分离的技术。这里，Java 的 JVM+字节码注入+AOP 式的Spring 开发框架，会带给你太多的优势。 你要选择可以享受“前人种树，后人乘凉”的有技术红利的技术。如：有庞大社区而且相互兼容的技术，如：Java, Docker, Ansible，HTTP，Telegraf/Collectd…… 中间件你要使用可以 支持HA集群和多租户的技术。这里基本上所有的主流中间件都会支持 HA 集群方式的。 原则八：不要迁就老旧系统的技术债务 我发现很多公司都很非常大的技术债务，这些债务具体表现如下：\n使用老旧的技术。比如，使用HTTP1.0， Java 1.6，Websphere，ESB，基于 socket的通讯协议，过时的模型……等等 不合理的设计。比如，在 gateway 中写大量的业务逻辑，单体架构，数据和业务逻辑深度耦合，错误的系统架构（把缓存当数据库，用消息队列同步数据）……等等 缺少配套设施。比如，没有自动化测试，没有好的软件文档，没有质量好的代码，没有标准和规范……等等 来找我寻求技术帮助的人都有各种各样的问题。我都会对他们苦口婆心地说同样的一句话——“如果你是来找我 case-by-case 解决问题，我兴趣不大，因为，你们千万不要寄希望能够很简单的把一辆夏利车改成一辆法拉利跑车，或是把一栋地基没打好的歪楼搞正。以前欠下的技术债，都得要还，没打好的地基要重新打，没建配套设施都要建。这些基础设施如果不按照正确科学的方式建立的话，你是不可能有一个好的的系统，我也没办法帮你 case-by-case 的解决问题……”，一开始，他们都会对我说，没问题，我们就是要还债，但是，最后发现要还的债真多，有点承受不了，就开始现原形了。\n他们开始为自己的“欠的技术债”找各种合理化的理由——给你解释各种各样的历史原因和不得以而为之的理由。谈着谈着，让我有一种感觉——他们希望得到一种什么都不改什么都不付出的方式就可以进步的心态，他们宁可让新的技术 low 下来迁就于这些技术债，把新的技术滥用地乱七八糟的。有一个公司，他们的系统架构和技术选型基本都搞错了，使用错误的模型构建系统，导致整个系统的性能非常之差，也才几千万条数据，但他们想的不是还债，不是把地基和配套设施建好，而且要把楼修的更高，上更多的系统——他们觉得现有的系统挺好，性能问题的原因是他们没一个大数据平台，所以要建大数据平台……\n我见过很多很多公司，包括大如 BAT 这样的公司，都会在原来的技术债上进行更多的建设，然后，技术债越来越大，利息越来越大，最终成为一个高利贷，再也还不了（我在《开发团队的效率》一文中讲过一个 WatchDog 的架构模式，一个系统烂了，不是去改这个系统，而是在旁边建一个系统来看着它，我很难理解为什么会有这样的逻辑，也许是为了要解决更多的就业……）\n这里有几个原则和方法我是非常坚持的，分享给大家：\n与其花大力气迁就技术债务，不如直接还技术债。是所谓的长痛不如短痛。 建设没有技术债的“新城区”，并通过“防腐层 ”的架构模型，不要让技术债侵入“新城区”。 原则九：不要依赖自己的经验，要依赖于数据和学习 有好些人来找我跟我说他们的技术问题，然后希望我能够给他们一个答案。我说，我需要了解一下你现有系统的情况，也就是需要先做个诊断，我只有得到这些数据后，我才可能明白真正的原因是什么 ，我才可能给你做出一个比较好的技术方案。我个人觉得这是一种对对方负责的方法，因为技术手段太多了，所有的技术手段都有适应的场景，并且有各种 trade-off，所以，只有调研完后才能做出决定。这跟医生看病是一样的，确诊病因不能靠经验，还是要靠诊断数据。在科学面前，所有的经验都是靠不住的……\n另外，如果有一天你在做技术决定的时候，开始\b凭自己以往的经验，那么你就已经不可能再成长了。人都是不可能通过不断重复过去而进步的，人的进步从来都是通过学习自己不知道的东西。所以，千万不要依赖于自己的经验做决定。做任何决定之前，最好花上一点时间，上网查一下相关的资料，技术博客，文章，论文等 ，同时，也看看各个公司，或是各个开源软件他们是怎么做的？然后，比较多种方案的 Pros/Cons，最终形成自己的决定，这样，才可能做出一个更好的决定。\n原则十：千万要小心 X – Y 问题，要追问原始需求 对于 X-Y 问题，也就是说，用户为了解决 X问题，他觉得用 Y 可以解，于是问我 Y 怎么搞，结果搞到最后，发现原来要解决的 X 问题，这个时候最好的解决方案不是 Y，而是 Z。 这种 X-Y 问题真是相当之多，见的太多太多了。所以，每次用户来找我的时候，我都要不断地追问什么是 X 问题。\n比如，好些用户都会来问我他们要一个大数据流式处理，结果追问具体要解决什么样的问题时，才发现他们的问题是因为服务中有大量的状态，需要把相同用户的数据请求放在同一个服务上处理，而且设计上导致一个慢函数拖慢整个应用服务。最终就是做一下性能调优就好了，根本没有必要上什么大数据的流式处理。\n我很喜欢追问为什么 ，这种追问，会让客户也跟着来一起重新思考。比如，有个客户来找我评估的一个技术架构的决定，从理论上来说，好像这个架构在用户的这个场景下非常不错。但是，这个场景和这个架构是我职业生涯从来没有见过的。于是，我开始追问这个为什么会是这么一个场景？当我追问的时候，我发现用户都感到这个场景的各种不合理。最后引起了大家非常深刻的研讨，最终用户把那个场景修正后，而架构就突然就变成了一个常见且成熟的的模型……\n原则十一：激进胜于保守，创新与实用并不冲突 我对技术的态度是比较激进的，但是，所谓的激进并不是瞎搞，也不是见新技术就上，而是积极拥抱会改变未来的新技术，如：Docker/Go，我就非常快地跟进，但是像区块链或是 Rust 这样的，我就不是很积极。因为，其并没有命中我认为的技术趋势的几个特征（参看《Go,Docker 和新技术 》）。当然，我也不是不喜欢的就不学了，我对区块链和 Rust 我一样学习，我也知道这些技术的优势，但我不会大规模使用它们。另外，我也尊重保守的决定，这里面没有对和错。但是，我个人觉得对技术激进的态度比起保守来说有太多的好处了。一方面来说，对于用户来说，很大程度上来说，新技术通常都表面有很好的竞争力，而且我见太多这样成功的公司都在积极拥抱新的技术的，而保守的通常来说都越来越不好。\n有一些人会跟我说，我们是实用主义，我们不需要创新，能解决当下的问题就好，所以，我们不需要新技术，现有的技术用好就行了。这类的公司，他们的技术设计第一天就在负债，虽然可以解决当下问题，但是马上就会出现新的问题，然后他们会疲于解决各种问题。最后呢，最后还是会走到新的技术上。\n这里的逻辑很简单 —— 进步永远来自于探索，探索是要付出代价的，但是收益更大。对我而言，不敢冒险才是最大的冒险，不敢犯错才是最大的错误，害怕失去会让你失去的更多……\n（全文完）\n文章转载于 酷 壳 – CoolShell\n","description":"\n","tags":[],"title":"\n我做系统架构的一些原则（转载）","uri":"/posts/post-265/"},{"categories":["默认分类"],"content":" 今天有个朋友给我说让我把网站弄一下，别让国内的人访问，主要是为了保证营销的数据准确性和防止同行抄袭。当然是没办法彻底屏蔽的，防小人不防君子吧。我用的是Nginx，\n首先我们要去弄到国内的IP地址段，访问网站 http://www.ip2location.com/free/visitor-blocker ，点击左侧的“Firewall List by Country”选项卡。点击下载ip文件\n顺便要把你现在的IP最好不要加进去，否则你自己会访问不了。\n下载不了的可以指定 使用\n国内IP地址列表\n方法一 复制整段代码到你的Nginx配置文件里面即可。\n方法二 把文件去掉第一行的“location / {”和最后一行的“}”，重命名为blockip.conf\n在nginx配置的http块下面加上include blockip.conf;\n可以加载个自定义页面\n在/www/wwwroot/watch目录下新建一个 403.html文件\nerror_page 403 /403.html; location = /403.html{ root /www/wwwroot/watch; allow all; } ","description":"\n","tags":[],"title":"\n屏蔽国内IP访问网站","uri":"/posts/post-266/"},{"categories":["默认分类"],"content":"获取登录二维码 1 2 3 4 5 curl --request GET \\ --url 'https://mp.weixin.qq.com/cgi-bin/scanloginqrcode?action=getqrcode\u0026random=1640370340' \\ --header 'Cache-Control: no-cache' \\ --header 'cookie: pgv_pvid=9632095410; ua_id=GsK0Fg1c1cbWnuJ5AAAAAAx-o-uFsXSgSZ3ywvjEups=; mm_lang=zh_CN; wxuin=14857539381975; ticket_uin=EXPIRED; ticket_certificate=EXPIRED; login_certificate=EXPIRED; fake_id=EXPIRED; login_sid_ticket=EXPIRED; master_sid=EXPIRED; master_user=EXPIRED; master_ticket=EXPIRED; sp_user=EXPIRED; sp_sid=EXPIRED; sp_slave_user=EXPIRED; safecode=EXPIRED; ticket=EXPIRED; ticket_id=EXPIRED; openid2ticket_o40kr6FMP04YPyEfeMrDSyUxY9tI=EXPIRED; infringementlogin_ticket=EXPIRED; infringementlogin_ticket_id=EXPIRED; qruin=EXPIRED; qrlogin_data_ticket=EXPIRED; xid=f004e79875fc4d0d9ff4ee20d8ac132b; slave_sid=EXPIRED; slave_user=EXPIRED; bizuin=EXPIRED; data_bizuin=EXPIRED; data_ticket=EXPIRED; rand_info=EXPIRED; slave_bizuin=EXPIRED; uuid=b5af9dd9aa01b80bf56c38341620515b' \\ --cookie 'pgv_pvid=9632095410; ua_id=GsK0Fg1c1cbWnuJ5AAAAAAx-o-uFsXSgSZ3ywvjEups=; mm_lang=zh_CN; wxuin=14857539381975; ticket_uin=EXPIRED; ticket_certificate=EXPIRED; login_certificate=EXPIRED; fake_id=EXPIRED; login_sid_ticket=EXPIRED; master_sid=EXPIRED; master_user=EXPIRED; master_ticket=EXPIRED; sp_user=EXPIRED; sp_sid=EXPIRED; sp_slave_user=EXPIRED; safecode=EXPIRED; ticket=EXPIRED; ticket_id=EXPIRED; openid2ticket_o40kr6FMP04YPyEfeMrDSyUxY9tI=EXPIRED; infringementlogin_ticket=EXPIRED; infringementlogin_ticket_id=EXPIRED; qruin=EXPIRED; qrlogin_data_ticket=EXPIRED; xid=f004e79875fc4d0d9ff4ee20d8ac132b; slave_sid=EXPIRED; slave_user=EXPIRED; bizuin=EXPIRED; data_bizuin=EXPIRED; data_ticket=EXPIRED; rand_info=EXPIRED; slave_bizuin=EXPIRED; uuid=b5af9dd9aa01b80bf56c38341620515b' 二维码扫描结果检查 1 2 3 4 5 curl --request GET \\ --url 'https://mp.weixin.qq.com/cgi-bin/scanloginqrcode?action=ask\u0026token=\u0026lang=zh_CN\u0026f=json\u0026ajax=1' \\ --header 'Cache-Control: no-cache' \\ --header 'cookie: pgv_pvid=9632095410; ua_id=GsK0Fg1c1cbWnuJ5AAAAAAx-o-uFsXSgSZ3ywvjEups=; mm_lang=zh_CN; wxuin=14857539381975; ticket_uin=EXPIRED; ticket_certificate=EXPIRED; login_certificate=EXPIRED; fake_id=EXPIRED; login_sid_ticket=EXPIRED; master_sid=EXPIRED; master_user=EXPIRED; master_ticket=EXPIRED; sp_user=EXPIRED; sp_sid=EXPIRED; sp_slave_user=EXPIRED; safecode=EXPIRED; ticket=EXPIRED; ticket_id=EXPIRED; openid2ticket_o40kr6FMP04YPyEfeMrDSyUxY9tI=EXPIRED; infringementlogin_ticket=EXPIRED; infringementlogin_ticket_id=EXPIRED; qruin=EXPIRED; qrlogin_data_ticket=EXPIRED; xid=f004e79875fc4d0d9ff4ee20d8ac132b; slave_sid=EXPIRED; slave_user=EXPIRED; bizuin=EXPIRED; data_bizuin=EXPIRED; data_ticket=EXPIRED; rand_info=EXPIRED; slave_bizuin=EXPIRED; uuid=b5af9dd9aa01b80bf56c38341620515b' \\ --cookie 'pgv_pvid=9632095410; ua_id=GsK0Fg1c1cbWnuJ5AAAAAAx-o-uFsXSgSZ3ywvjEups=; mm_lang=zh_CN; wxuin=14857539381975; ticket_uin=EXPIRED; ticket_certificate=EXPIRED; login_certificate=EXPIRED; fake_id=EXPIRED; login_sid_ticket=EXPIRED; master_sid=EXPIRED; master_user=EXPIRED; master_ticket=EXPIRED; sp_user=EXPIRED; sp_sid=EXPIRED; sp_slave_user=EXPIRED; safecode=EXPIRED; ticket=EXPIRED; ticket_id=EXPIRED; openid2ticket_o40kr6FMP04YPyEfeMrDSyUxY9tI=EXPIRED; infringementlogin_ticket=EXPIRED; infringementlogin_ticket_id=EXPIRED; qruin=EXPIRED; qrlogin_data_ticket=EXPIRED; xid=f004e79875fc4d0d9ff4ee20d8ac132b; slave_sid=EXPIRED; slave_user=EXPIRED; bizuin=EXPIRED; data_bizuin=EXPIRED; data_ticket=EXPIRED; rand_info=EXPIRED; slave_bizuin=EXPIRED; uuid=b5af9dd9aa01b80bf56c38341620515b' 真正获取登录的token 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 curl --request POST \\ --url 'https://mp.weixin.qq.com/cgi-bin/bizlogin?action=login' \\ --header ': authority: mp.weixin.qq.com' \\ --header 'Cache-Control: no-cache' \\ --header 'Content-Type: application/x-www-form-urlencoded' \\ --header 'accept: */*' \\ --header 'accept-encoding: gzip, deflate, br' \\ --header 'accept-language: zh-CN,zh;q=0.9' \\ --header 'content-length: 123' \\ --header 'cookie: pgv_pvid=9632095410; ua_id=GsK0Fg1c1cbWnuJ5AAAAAAx-o-uFsXSgSZ3ywvjEups=; mm_lang=zh_CN; wxuin=14857539381975; ticket_uin=EXPIRED; ticket_certificate=EXPIRED; login_certificate=EXPIRED; fake_id=EXPIRED; login_sid_ticket=EXPIRED; master_sid=EXPIRED; master_user=EXPIRED; master_ticket=EXPIRED; sp_user=EXPIRED; sp_sid=EXPIRED; sp_slave_user=EXPIRED; safecode=EXPIRED; ticket=EXPIRED; ticket_id=EXPIRED; openid2ticket_o40kr6FMP04YPyEfeMrDSyUxY9tI=EXPIRED; infringementlogin_ticket=EXPIRED; infringementlogin_ticket_id=EXPIRED; qruin=EXPIRED; qrlogin_data_ticket=EXPIRED; xid=f004e79875fc4d0d9ff4ee20d8ac132b; slave_sid=EXPIRED; slave_user=EXPIRED; bizuin=EXPIRED; data_bizuin=EXPIRED; data_ticket=EXPIRED; rand_info=EXPIRED; slave_bizuin=EXPIRED; uuid=b5af9dd9aa01b80bf56c38341620515b' \\ --header 'origin: https://mp.weixin.qq.com' \\ --header 'referer: https://mp.weixin.qq.com/' \\ --header 'sec-fetch-mode: cors' \\ --header 'sec-fetch-site: same-origin' \\ --header 'user-agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36' \\ --header 'x-requested-with: XMLHttpRequest' \\ --cookie 'pgv_pvid=9632095410; ua_id=GsK0Fg1c1cbWnuJ5AAAAAAx-o-uFsXSgSZ3ywvjEups=; mm_lang=zh_CN; wxuin=14857539381975; ticket_uin=EXPIRED; ticket_certificate=EXPIRED; login_certificate=EXPIRED; fake_id=EXPIRED; login_sid_ticket=EXPIRED; master_sid=EXPIRED; master_user=EXPIRED; master_ticket=EXPIRED; sp_user=EXPIRED; sp_sid=EXPIRED; sp_slave_user=EXPIRED; safecode=EXPIRED; ticket=EXPIRED; ticket_id=EXPIRED; openid2ticket_o40kr6FMP04YPyEfeMrDSyUxY9tI=EXPIRED; infringementlogin_ticket=EXPIRED; infringementlogin_ticket_id=EXPIRED; qruin=EXPIRED; qrlogin_data_ticket=EXPIRED; xid=f004e79875fc4d0d9ff4ee20d8ac132b; slave_sid=EXPIRED; slave_user=EXPIRED; bizuin=EXPIRED; data_bizuin=EXPIRED; data_ticket=EXPIRED; rand_info=EXPIRED; slave_bizuin=EXPIRED; uuid=b5af9dd9aa01b80bf56c38341620515b' \\ --data 'userlang=zh_CN\u0026redirect_url=\u0026cookie_forbidden=0\u0026cookie_cleaned=0\u0026plugin_used=0\u0026login_type=3\u0026token=\u0026lang=zh_CN\u0026f=json\u0026ajax=1' ","description":"\n","tags":["公众号","模拟登录"],"title":"\n微信公众平台模拟登录","uri":"/posts/post-23/"},{"categories":["默认分类"],"content":"成都各区的边界 直接获得所有数据\n成都二手房价格 分页查询，修改curPage\n成都新房价格 直接获得所有数据\n","description":"\n","tags":[],"title":"\n成都房价 - 参考链家","uri":"/posts/post-22/"},{"categories":["默认分类"],"content":"data: { imgApi: n, countyCodeArr: [], countyIndex: 0, streetIndex: 0, streetArray: [\"男性22/女性20—30周岁\", \"31—40周岁\", \"41—50周岁\", \"51—60周岁\"], ec: { lazyLoad: !0 }, countyName: \"区（市）县\", isLoaded: !1, isDisposed: !1, showData: !1, optionData: {}, addressArr: [], sexArr: [\"a\", \"b\", \"c\", \"d\"] //依次对应\"21—30周岁\", \"31—40周岁\", \"41—50周岁\", \"51—60周岁\" } getBirthInfo 女性生育 https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getBirthInfo.json?type=a\ntype： [\"a\", \"b\", \"c\", \"d\"] //依次对应\"21—30周岁\", \"31—40周岁\", \"41—50周岁\", \"51—60周岁\" [{ filedName: \"UNBIRTH\", name: \"未生育\" }, { filedName: \"ONECHILD\", name: \"一孩\" }, { filedName: \"TWOCHILD\", name: \"两孩\" }, { filedName: \"THREECHILD\", name: \"三孩及以上\" }] getAddr 获取全市区域代码 https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getDatacode.json?type=1\ngetStreet 获取某区街道代码 https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getDatacode.json?type=2\u0026datacode=510171\ngetDegreeInfo 获取某区人口学历情况 https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getDegreeInfo.json?datacode=510171\n#getFamilySituationInfo 获取家庭户情\nhttps://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getFamilySituationInfo.json?datacode=510171\n[{ filedName: \"familyregistration\", name: \"户数\" }, { filedName: \"familyuser\", name: \"户均人口\" }] getFirstnameInfo 获取姓氏来源信息 https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getFirstnameInfo.json?name=王\ngetgetRentalRate 获取全市租房情况 https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getgetRentalRate.json\ngetHealthInfo 老年人健康状况 https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getHealthInfo.json?datacode=510171\n[{ filedName: \"HEALTH\", name: \"健康\" }, { filedName: \"UNHEALTH\", name: \"基本健康\" }, { filedName: \"UNHEALTHSELF\", name: \"生活能自理\" }, { filedName: \"UNHEALTHUNSELF\", name: \"生活不能自理\" }] getDataCounty https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getPopulationInfo.json?quxian=510171\ngetDataStreet https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getPopulationInfo.json?street=510171\ngetRelocationValue 外地来蓉人口 https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getRelocationValue.json?areaflag=true https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getRelocationValue.json?areaflag=false\ngetRepeatnameInfo 重名人数 https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getRepeatnameInfo.json?name=潘飞\ngetRpLabour https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getRpLabour.json?type=a\n[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"] 依次对应如下： [\"16-20周岁\", \"21-30周岁\", \"31-40周岁\", \"41-50周岁\", \"51-55周岁\", \"56-60周岁\"] getUmmarriedInfo 未婚人口 https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getUmmarriedInfo.json?datacode=510171\n[{ filedName: \"man\", name: \"男性\" }, { filedName: \"wowen\", name: \"女性\" }] getWorkProperty 工作属性 https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getWorkProperty.json?datacode=510171\n[{ filedName: \"person\", name: \"个体经营户\" }, { filedName: \"freelance\", name: \"自由职业/灵活就业\" }, { filedName: \"company\", name: \"企业、事业、机关或社会团体等法人单位\" }, { filedName: \"country\", name: \"经营农村家庭承包地（包括开垦的土地）\" }] getYearInfo 出生年份 https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getYearInfo.json?datacode=510171\u0026type=a https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/getYearInfo.json?datacode=510171\u0026type=d\u0026year=1995\ntype： [\"b\", \"c\", \"d\"] 依次对应如下： [\"1930年及之前出生\", \"1931-1940年出生\", \"1941年及之后出生\"] 如果type=d, 那么, 可以使用year进行具体年龄查询 saveSatisfiedSitutation 提交满意情况（联系我们） https://cdrpcx.cdpczx.cn:6733/rp/rpdatacodeConcroller/saveSatisfiedSitutation.json?type=a\u0026memo=\ntype: [\"a\", \"b\", \"c\"] 依次对应 [\"满意\", \"一般\", \"不满意\"] memo: 意见内容 ","description":"\n","tags":["人口","人口普查"],"title":"\n成都市人口统计接口梳理情况","uri":"/posts/post-21/"},{"categories":["默认分类"],"content":"MySQL 对于很多 Linux 从业者而言，是一个非常棘手的问题，多数情况都是因为对数据库出现问题的情况和处理思路不清晰。\n在进行 MySQL 的优化之前必须要了解的就是 MySQL 的查询过程，很多的查询优化工作实际上就是遵循一些原则让 MySQL 的优化器能够按照预想的合理方式运行而已。\n优化的哲学 注：优化有风险，修改需谨慎。\n优化可能带来的问题： 优化不总是对一个单纯的环境进行，还很可能是一个复杂的已投产的系统。 优化手段本来就有很大的风险，只不过你没能力意识到和预见到。 任何的技术可以解决一个问题，但必然存在带来一个问题的风险。 对于优化来说解决问题而带来的问题，控制在可接受的范围内才是有成果。 保持现状或出现更差的情况都是失败。 优化的需求 稳定性和业务可持续性，通常比性能更重要。 优化不可避免涉及到变更，变更就有风险。 优化使性能变好，维持和变差是等概率事件。 切记优化，应该是各部门协同，共同参与的工作，任何单一部门都不能对数据库进行优化。 所以优化工作，是由业务需求驱使的!\n优化由谁参与?在进行数据库优化时，应由数据库管理员、业务部门代表、应用程序架构师、应用程序设计人员、应用程序开发人员、硬件及系统管理员、存储管理员等，业务相关人员共同参与。\n优化思路 优化什么 在数据库优化上有两个主要方面：\n安全：数据可持续性。 性能：数据的高性能访问。 优化范围 存储、主机和操作系统方面：\n主机架构稳定性 I/O 规划及配置 Swap 交换分区 OS 内核参数和网络问题 应用程序方面：\n应用程序稳定性 SQL 语句性能 串行访问资源 性能欠佳会话管理 这个应用适不适合用 MySQL 数据库优化方面：\n内存 数据库结构(物理\u0026逻辑) 实例配置 说明：不管是设计系统、定位问题还是优化，都可以按照这个顺序执行。\n优化维度 数据库优化维度有如下四个：\n硬件 系统配置 数据库表结构 SQL 及索引 优化选择 优化成本：硬件\u003e系统配置\u003e数据库表结构\u003eSQL 及索引。 优化效果：硬件\u003c系统配置\u003c数据库表结构 优化工具 检查问题常用的 12 个工具：\nMySQL mysqladmin：MySQL 客户端，可进行管理操作 mysqlshow：功能强大的查看 shell 命令 SHOW [SESSION | GLOBAL] variables：查看数据库参数信息 SHOW [SESSION | GLOBAL] STATUS：查看数据库的状态信息 information_schema：获取元数据的方法 SHOW ENGINE INNODB STATUS：Innodb 引擎的所有状态 SHOW PROCESSLIST：查看当前所有连接的 session 状态 explain：获取查询语句的执行计划 show index：查看表的索引信息 slow-log：记录慢查询语句 mysqldumpslow：分析 slowlog 文件的工具 不常用但好用的 7 个工具：\nZabbix：监控主机、系统、数据库(部署 Zabbix 监控平台) pt-query-digest：分析慢日志 MySQL slap：分析慢日志 sysbench：压力测试工具 MySQL profiling：统计数据库整体状态工具 Performance Schema：MySQL 性能状态统计的数据 workbench：管理、备份、监控、分析、优化工具(比较费资源) 数据库层面问题 解决思路 一般应急调优的思路：针对突然的业务办理卡顿，无法进行正常的业务处理，需要马上解决的场景。\n#查看正在执行的sql语句和进程 show processlist #通过执行计划判断，索引问题（有没有、合不合理）或者语句本身问题 explain select id ,name from stu where name='clsn'; # ALL id name age sex select id,name from stu where id=2-1 函数 结果集\u003e30; show index from table; # 查询锁状态 show status like '%lock%'; # 查询哪些表锁了 show OPEN TABLES where In_use \u003e 0; # 查看造成死锁的sql语句 innodb引擎的运行时信息 show engine innodb status; # 杀掉有问题的session kill SESSION_ID; # 查看正在执行的事务 select * from information_schema.INNODB_TRX; # 查看正在锁的事物 SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS # 查看等待锁的事务 SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; MySQL锁定状态查看命令 Status 含义 Checking table 正在检查数据表（这是自动的）。 Closing tables 正在将表中修改的数据刷新到磁盘中，同时正在关闭已经用完的表。这是一个很快的操作，如果不是这样的话，就应该确认磁盘空间是否已经满了或者磁盘是否正处于重负中。 Connect Out 复制从服务器正在连接主服务器。 Copying to tmp table on disk 由于临时结果集大于tmp_table_size，正在将临时表从内存存储转为磁盘存储以此节省内存。 Creating tmp table 正在创建临时表以存放部分查询结果。 deleting from main table 服务器正在执行多表删除中的第一部分，刚删除第一个表。 deleting from reference tables 服务器正在执行多表删除中的第二部分，正在删除其他表的记录。 Flushing tables 正在执行FLUSH TABLES，等待其他线程关闭数据表。 Killed 发送了一个kill请求给某线程，那么这个线程将会检查kill标志位，同时会放弃下一个kill请求。MySQL会在每次的主循环中检查kill标志位，不过有些情况下该线程可能会过一小段才能死掉。如果该线程程被其他线程锁住了，那么kill请求会在锁释放时马上生效。 Locked 被其他查询锁住了。 Sending data 正在处理SELECT查询的记录，同时正在把结果发送给客户端。 Sorting for group 正在为GROUP BY做排序。 Sorting for order 正在为ORDER BY做排序。 Opening tables 这个过程应该会很快，除非受到其他因素的干扰。例如，在执ALTER TABLE或LOCK TABLE语句行完以前，数据表无法被其他线程打开。正尝试打开一个表。 Removing duplicates 正在执行一个SELECT DISTINCT方式的查询，但是MySQL无法在前一个阶段优化掉那些重复的记录。因此，MySQL需要再次去掉重复的记录，然后再把结果发送给客户端。 Reopen table 获得了对一个表的锁，但是必须在表结构修改之后才能获得这个锁。已经释放锁，关闭数据表，正尝试重新打开数据表。 Repair by sorting 修复指令正在排序以创建索引。 Repair with keycache 修复指令正在利用索引缓存一个一个地创建新索引。它会比Repair by sorting慢些。 Searching rows for update 正在讲符合条件的记录找出来以备更新。它必须在UPDATE要修改相关的记录之前就完成了。 Sleeping 正在等待客户端发送新请求。 System lock 正在等待取得一个外部的系统锁。如果当前没有运行多个mysqld服务器同时请求同一个表，那么可以通过增加–skip-external-locking参数来禁止外部系统锁。 Upgrading lock INSERT DELAYED正在尝试取得一个锁表以插入新记录。 Updating 正在搜索匹配的记录，并且修改它们。 User Lock 正在等待GET_LOCK()。 Waiting for tables 该线程得到通知，数据表结构已经被修改了，需要重新打开数据表以取得新的结构。然后，为了能的重新打开数据表，必须等到所有其他线程关闭这个表。以下几种情况下会产生这个通知：FLUSH TABLES tbl_name, ALTER TABLE, RENAME TABLE, REPAIR TABLE, ANALYZE TABLE,或OPTIMIZE TABLE。 waiting for handler insert INSERT DELAYED已经处理完了所有待处理的插入操作，正在等待新的请求。 常规调优思路 针对业务周期性的卡顿，例如在每天 10-11 点业务特别慢，但是还能够使用，过了这段时间就好了。\n查看slowlog，分析slowlog，分析出查询慢的语句； 按照一定优先级，一个一个排查所有慢语句； 分析top SQL，进行explain调试，查看语句执行时间； 调整索引或语句本身。 系统层面问题 解决思路 CPU方面：vmstat、sar top、htop、nmon、mpstat。\n内存：free、ps-aux。\nIO 设备(磁盘、网络)：iostat、ss、netstat、iptraf、iftop、lsof。\nvmstat 命令说明：\nProcs：r 显示有多少进程正在等待 CPU 时间。b 显示处于不可中断的休眠的进程数量。在等待 I/O。 Memory：swpd 显示被交换到磁盘的数据块的数量。未被使用的数据块，用户缓冲数据块，用于操作系统的数据块的数量。 Swap：操作系统每秒从磁盘上交换到内存和从内存交换到磁盘的数据块的数量。s1 和 s0 最好是 0。 IO：每秒从设备中读入 b1 的写入到设备 b0 的数据块的数量。反映了磁盘 I/O。 System：显示了每秒发生中断的数量(in)和上下文交换(cs)的数量。 CPU：显示用于运行用户代码，系统代码，空闲，等待 I/O 的 CPU 时间。 iostat 命令说明：\n实例命令：iostat -dk 1 5;iostat -d -k -x 5 (查看设备使用率(%util)和响应时间(await))。 TPS：该设备每秒的传输次数。“一次传输”意思是“一次 I/O 请求”。多个逻辑请求可能会被合并为“一次 I/O 请求”。 iops ：硬件出厂的时候，厂家定义的一个每秒最大的 IO 次数。 “一次传输\"请求的大小是未知的。 KB_read/s：每秒从设备(drive expressed)读取的数据量。 KB_wrtn/s：每秒向设备(drive expressed)写入的数据量。 KB_read：读取的总数据量。 KB_wrtn：写入的总数量数据量;这些单位都为 Kilobytes。 解决办法 你认为到底负载高好，还是低好呢?在实际的生产中，一般认为 CPU 只要不超过 90% 都没什么问题。当然不排除下面这些特殊情况。\nCPU 负载高，IO 负载低：\n内存不够 磁盘性能差 SQL 问题：去数据库层，进一步排查 SQL 问题 IO 出问题了(磁盘到临界了、raid 设计不好、raid 降级、锁、在单位时间内 TPS 过高) TPS 过高：大量的小数据 IO、大量的全表扫描 IO 负载高，CPU 负载低：\n大量小的 IO 写操作 autocommit，产生大量小 IO;IO/PS，磁盘的一个定值，硬件出厂的时候，厂家定义的一个每秒最大的 IO 次数。 大量大的 IO 写操作：SQL 问题的几率比较大 IO和 CPU 负载都很高：\n硬件不够了或 SQL 存在问题 基础优化 优化思路:\n定位问题点吮吸：硬件\u003e系统\u003e应用\u003e数据库\u003e架构(高可用、读写分离、分库分表)。\n处理方向：明确优化目标、性能和安全的折中、防患未然。\n硬件优化 ①主机方面\n根据数据库类型，主机 CPU 选择、内存容量选择、磁盘选择：\n平衡内存和磁盘资源 随机的 I/O 和顺序的 I/O 主机 RAID 卡的 BBU(Battery Backup Unit)关闭 ②CPU 的选择\nCPU 的两个关键因素：核数、主频。根据不同的业务类型进行选择：\nCPU 密集型：计算比较多，OLTP 主频很高的 CPU、核数还要多。 IO 密集型：查询比较，OLAP 核数要多，主频不一定高的。 ③内存的选择\nOLAP 类型数据库，需要更多内存，和数据获取量级有关。OLTP 类型数据一般内存是 CPU 核心数量的 2 倍到 4 倍，没有最佳实践。\n④存储方面\n根据存储数据种类的不同，选择不同的存储设备，配置合理的 RAID 级别(raid5、raid10、热备盘)。\n对于操作系统来讲，不需要太特殊的选择，最好做好冗余(raid1)(ssd、sas、sata)。\n主机 raid 卡选择：\n实现操作系统磁盘的冗余(raid1) 平衡内存和磁盘资源 随机的 I/O 和顺序的 I/O 主机 raid 卡的 BBU(Battery Backup Unit)要关闭 ⑤网络设备方面\n使用流量支持更高的网络设备(交换机、路由器、网线、网卡、HBA 卡)。注意：以上这些规划应该在初始设计系统时就应该考虑好。\n服务器硬件优化关键点：\n物理状态灯 自带管理设备：远程控制卡(FENCE设备：ipmi ilo idarc)、开关机、硬件监控。 第三方的监控软件、设备(snmp、agent)对物理设施进行监控。 存储设备：自带的监控平台。EMC2(HP 收购了)、 日立(HDS)、IBM 低端 OEM HDS、高端存储是自己技术，华为存储。 系统优化 CPU：基本不需要调整，在硬件选择方面下功夫即可。\n内存：基本不需要调整，在硬件选择方面下功夫即可。\nSWAP：MySQL 尽量避免使用 Swap。阿里云的服务器中默认 swap 为 0。\nIO ：raid、no lvm、ext4 或 xfs、ssd、IO 调度策略。\nSwap 调整(不使用 swap 分区)：\n/proc/sys/vm/swappiness的内容改成0(临时)，/etc/sysctl. conf上添加vm.swappiness=0(永久) 这个参数决定了 Linux 是倾向于使用 Swap，还是倾向于释放文件系统 Cache。在内存紧张的情况下，数值越低越倾向于释放文件系统 Cache。\n当然，这个参数只能减少使用 Swap 的概率，并不能避免 Linux 使用 Swap。\n修改 MySQL 的配置参数 innodb_flush_ method，开启 O_DIRECT 模式。\n这种情况下，InnoDB 的 buffer pool 会直接绕过文件系统 Cache 来访问磁盘，但是 redo log 依旧会使用文件系统 Cache。\n值得注意的是，Redo log 是覆写模式的，即使使用了文件系统的 Cache，也不会占用太多。\nIO 调度策略：\n#echo deadline\u003e/sys/block/sda/queue/scheduler 临时修改为deadline 永久修改：\nvi /boot/grub/grub.conf 更改到如下内容: kernel /boot/vmlinuz-2.6.18-8.el5 ro root=LABEL=/ elevator=deadline rhgb quiet 系统参数调整 Linux 系统内核参数优化：\nvim/etc/sysctl.conf net.ipv4.ip_local_port_range = 1024 65535：# 用户端口范围 net.ipv4.tcp_max_syn_backlog = 4096 net.ipv4.tcp_fin_timeout = 30 fs.file-max=65535：# 系统最大文件句柄，控制的是能打开文件最大数量 用户限制参数(MySQL 可以不设置以下配置)：\nvim/etc/security/limits.conf * soft nproc 65535 * hard nproc 65535 * soft nofile 65535 * hard nofile 65535 应用优化 业务应用和数据库应用独立。\n防火墙：iptables、selinux 等其他无用服务(关闭)：\nchkconfig --level 23456 acpid off chkconfig --level 23456 anacron off chkconfig --level 23456 autofs off chkconfig --level 23456 avahi-daemon off chkconfig --level 23456 bluetooth off chkconfig --level 23456 cups off chkconfig --level 23456 firstboot off chkconfig --level 23456 haldaemon off chkconfig --level 23456 hplip off chkconfig --level 23456 ip6tables off chkconfig --level 23456 iptables off chkconfig --level 23456 isdn off chkconfig --level 23456 pcscd off chkconfig --level 23456 sendmail off chkconfig --level 23456 yum-updatesd off 安装图形界面的服务器不要启动图形界面 runlevel 3。\n另外，思考将来我们的业务是否真的需要 MySQL，还是使用其他种类的数据库。用数据库的最高境界就是不用数据库。\n数据库优化 SQL 优化方向：执行计划，索引，SQL 改写\n架构优化方向：高可用架构，高性能架构，分库分表\n数据库参数优化 ①调整实例整体(高级优化，扩展)：\nthread_concurrency：# 并发线程数量个数 sort_buffer_size：# 排序缓存 read_buffer_size：# 顺序读取缓存 read_rnd_buffer_size：# 随机读取缓存 key_buffer_size：# 索引缓存 thread_cache_size：# (1G—\u003e8, 2G—\u003e16, 3G—\u003e32, \u003e3G—\u003e64) **②连接层(基础优化)**设置合理的连接客户和连接方式：\nmax_connections # 最大连接数，看交易笔数设置 max_connect_errors # 最大错误连接数，能大则大 connect_timeout # 连接超时 max_user_connections # 最大用户连接数 skip-name-resolve # 跳过域名解析 wait_timeout # 等待超时 back_log # 可以在堆栈中的连接数量 ③SQL 层(基础优化)\nquery_cache_size： 查询缓存 »\u003e OLAP 类型数据库，需要重点加大此内存缓存，但是一般不会超过 GB。\n对于经常被修改的数据，缓存会马上失效。我们可以使用内存数据库(redis、memecache)，替代它的功能。\n存储引擎层优化 innodb 基础优化参数：\ndefault-storage-engine innodb_buffer_pool_size # 没有固定大小，50%测试值，看看情况再微调。但是尽量设置不要超过物理内存70% innodb_file_per_table=(1,0) innodb_flush_log_at_trx_commit=(0,1,2) # 1是最安全的，0是性能最高，2折中 binlog_sync Innodb_flush_method=(O_DIRECT, fdatasync) innodb_log_buffer_size # 100M以下 innodb_log_file_size # 100M 以下 innodb_log_files_in_group # 5个成员以下,一般2-3个够用（iblogfile0-N） innodb_max_dirty_pages_pct # 达到百分之75的时候刷写 内存脏页到磁盘。 log_bin max_binlog_cache_size # 可以不设置 max_binlog_size # 可以不设置 innodb_additional_mem_pool_size #小于2G内存的机器，推荐值是20M。32G内存以上100M ","description":"\n","tags":[],"title":"\n一份超详细的MySQL高性能优化实战总结！","uri":"/posts/post-267/"},{"categories":["默认分类"],"content":"代码 public class Main { public static void main(String[] args) { byte[] array1 = new byte[4 * 1024 * 1024]; array1 = null; byte[] array2 = new byte[2 * 1024 * 1024]; byte[] array3 = new byte[2 * 1024 * 1024]; byte[] array4 = new byte[2 * 1024 * 1024]; byte[] array5 = new byte[128 * 1024]; byte[] array6 = new byte[2 * 1024 * 1024]; } } 参数 参数设置运行 -XX:NewSize=10M -XX:MaxNewSize=10M -XX:InitialHeapSize=20M -XX:MaxHeapSize=20M -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15 -XX:PretenureSizeThreshold=3M -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:gc.log 参数介绍 -XX:NewSize:初始年轻代大小 -XX:MaxNewSize:最大年轻代大小 -XX:InitialHeapSize:定义堆的初始化大小，默认值是物理内存的1/64，其实就是:-Xms -XX:MaxHeapSize:定义最大堆的大小，默认为物理内存的1/4，其实就是:-Xmx -XX:SurvivorRatio:Eden区与Survivor区的大小比值 -XX:MaxTenuringThreshold:年轻代对象转换为老年代对象最大年龄值 -XX:PretenureSizeThreshold=3M:对象大小超过3M时直接在老年代分配内存 -XX:+UseParNewGC:使用ParNew收集器 -XX:+UseConcMarkSweepGC:使用CMS收集器 -XX:+PrintGCDetails:GC时打印详细信息 -Xloggc:输出GC日志信息到文件中 日志 日志情况 0.095: [GC (Allocation Failure) 0.095: [ParNew (promotion failed): 7838K-\u003e8391K(9216K), 0.0029438 secs]0.098: [CMS: 8194K-\u003e6659K(10240K), 0.0024311 secs] 11934K-\u003e6659K(19456K), [Metaspace: 3121K-\u003e3121K(1056768K)], 0.0055393 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] Heap par new generation total 9216K, used 2214K [0x00000007bec00000, 0x00000007bf600000, 0x00000007bf600000) eden space 8192K, 27% used [0x00000007bec00000, 0x00000007bee29820, 0x00000007bf400000) from space 1024K, 0% used [0x00000007bf500000, 0x00000007bf500000, 0x00000007bf600000) to space 1024K, 0% used [0x00000007bf400000, 0x00000007bf400000, 0x00000007bf500000) concurrent mark-sweep generation total 10240K, used 6659K [0x00000007bf600000, 0x00000007c0000000, 0x00000007c0000000) Metaspace used 3142K, capacity 4496K, committed 4864K, reserved 1056768K class space used 347K, capacity 388K, committed 512K, reserved 1048576K 日志详解 GC：表明进行了一次垃圾回收，前面没有Full修饰，表明这是一次Young GC Allocation Failure：表明本次引起GC的原因是因为在年轻代中没有足够的空间能够存储新的数据了 ParNew：表明本次GC发生在年轻代并且使用的是ParNew垃圾收集器。ParNew是一个Serial收集器的多线程版本，会使用多个CPU和线程完成垃圾收集工作（默认使用的线程数和CPU数相同，可以使用-XX：ParallelGCThreads参数限制） ParNew (promotion failed): 7838K-\u003e8391K(9216K) 7838K-\u003e8391K(9216K)：单位是KB，三个参数分别为：GC前该内存区域(这里是年轻代)使用容量，GC后该内存区域使用容量，该内存区域总容量。 0.0029438 secs：该内存区域GC耗时，单位是秒 CMS: 8194K-\u003e6659K(10240K), 0.0024311 secs] 11934K-\u003e6659K(19456K) 8194K-\u003e6659K(10240K)：GC前该内存区域(这里是老年代)使用容量变化，10240K表示该内存区域总容量， 11934K-\u003e6659K(19456K)：三个参数分别为：堆区垃圾回收前的大小，堆区垃圾回收后的大小，堆区总大小 Times: user=0.02 sys=0.00, real=0.00 secs：分别表示用户态耗时，内核态耗时和总耗时 详细介绍 可以看到出现了promotion failed，那什么情况下会出现promotion failed？\n在进行Young GC时，Survivor Space放不下，对象只能放入老年代，而此时老年代也放不下时会出现\n1.看代码\nbyte[] array1 = new byte[4 * 1024 * 1024]; array1 = null; 这行代码直接分配了一个4MB的大对象，此时这个对象会直接进入老年代，接着array1不再引用这个对象\n2.接着看下面的代码\nbyte[] array2 = new byte[2 * 1024 * 1024]; byte[] array3 = new byte[2 * 1024 * 1024]; byte[] array4 = new byte[2 * 1024 * 1024]; byte[] array5 = new byte[128 * 1024]; 连续分配了4个数组，其中3个是2MB的数组，1个是128KB的数组，如下图所示，全部会进入Eden区域中\n3.接着会执行如下代码：\nbyte[] array6 = new byte[2 * 1024 * 1024]; 此时还能放得下2MB的对象吗？不可能了，因为Eden区已经放不下了。因此此时会直接触发一次Young GC。\n4.我们看下面的GC日志：\nParNew (promotion failed): 7838K-\u003e8391K(9216K), 0.0029438 secs 这行日志显示了，Eden区原来是有 近8000KB的对象，但是回收之后发现一个都回收不掉，因为上述几个数组都被变量引用了一，所以一定会直接把这些存活的对象放入到老年代里去，但是此时老年代里已经有一个4MB的数组了，还能放的下3个2MB的数组和1个128KB的数组吗？\n明显是不行的，此时一定会超过老年代的10MB大小。\n5.所以此时我们看cms的gc日志：\nCMS: 8194K-\u003e6659K(10240K), 0.0024311 secs] 11934K-\u003e6659K(19456K), [Metaspace: 3121K-\u003e3121K(1056768K)], 0.0055393 secs 大家可以清晰看到，此时执行了CMS垃圾回收器的Full GC，我们知道Full GC其实就是会对老年代进行Old GC， 同时一般会跟一次Young GC关联，还会触发一次元数据区（永久代）的GC。\n在CMS Full GC之前，就已经触发过Young GC了，此时大家可以看到此时Young GC就已经有了，接着就是执行针对 老年代的Old GC，也就是如下日志：\nCMS: 8194K-\u003e6659K(10240K), 0.0024311 secs 6.这里看到老年代从8MB左右的对象占用，变成了6MB左右的对象占用，这是怎么个过程呢？\n很简单，一定是在Young GC之后，先把2个2MB的数组放入了老年代，此时要继续放1个2MB的数组和1个128KB的数组到老年代，一定会放不下，所以此时就会触发CMS的Full GC\n然后此时就会回收掉其中的一个4MB的数组，因为他已经没人引用了\n接着放入进去1个2MB的数组和1个128KB的数组\n所以大家再看CMS的垃圾回收日志：CMS: 8194K-\u003e6659K(10240K), 0.0024311 secs，他是从回收前的8MB变成了 6MB\n最后在CMS Full GC执行完毕之后，其实年轻代的对象都进入了老年代，此时最后一行代码要在年轻代分配2MB的数组就可以成功了\n补充知识 Young GC触发条件 当年轻代Eden区域满的时候会触发一次Young GC\nFull GC触发条件 Full GC用于清理整个堆空间。它的触发条件主要有以下几种：\n1.显式调用System.gc方法(建议JVM触发)。\n2.元空间不足\n3.年代空间不足，引起Full GC。这种情况比较复杂，有以下几种：\n大对象直接进入老年代引起，由-XX:PretenureSizeThreshold参数定义 Young GC时，经历过多次Young GC仍存在的对象进入老年代。 Young GC时，动态对象年龄判定机制会将对象提前转移老年代。年龄从小到大进行累加，当加入某个年龄段后，累加和超过survivor区域-XX:TargetSurvivorRatio的时候，从这个年龄段往上的年龄的对象进入老年代 Young GC时，Eden和From Space区向To Space区复制时，大于To Space区可用内存，会直接把对象转移到老年代 4.JVM的空间分配担保机制可能会触发Full GC：\n空间担保分配是指在发生Young GC之前，虚拟机会检查老年代最大可用的连续空间是否大于新生代所有对象的总空间。\n如果大于，则此次Young GC是安全的。\n如果小于，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。\n如果HandlePromotionFailure=true，那么会继续检查老年代最大可用连续空间是否大于历次晋升到老年代的对象的平均大小，如果大于，则尝试进行一次Young GC，但这次Young GC依然是有风险的，失败后会重新发起一次Full gc；如果小于或者HandlePromotionFailure=false，则改为直接进行一次Full GC。\nGC Easy工具 这里推荐一个gceasy(https://gceasy.io)工具，可以上传gc文件，然后他会利用可视化的界面来展现GC情况\n参考 https://www.oracle.com/java/technologies/javase/vmoptions-jsp.html\nhttps://book.douban.com/subject/34907497/\n","description":"\n","tags":[],"title":"\n一个简单案例，带你看懂GC日志！","uri":"/posts/post-268/"},{"categories":["默认分类"],"content":"下载SVN //安装brew 已经安装可以忽略 /bin/zsh -c \"$(curl -fsSL https://gitee.com/cunkai/HomebrewCN/raw/master/Homebrew.sh)\" // 安装svn brew install svn 如果出现一下错误 ：\nsvn: E170013: Commit failed (details follow): svn: E170013: Unable to connect to a repository at URL '' svn: E230001: Server SSL certificate verification failed: certificate issued for a different hostname 解决办法：\nConfigure-\u003ePreferences-\u003eVersion Control-\u003eSubversion-\u003eEnable interactive mode 勾选上 配置JDK File-\u003eProject Structure-\u003eProject-\u003eProject SDK-\u003eNew-\u003eJDK 选择自己的JDK版本 File-\u003eProject Structure-\u003eProject-\u003eProject language level-\u003eJDK 选择自己的JDK版本 File-\u003eProject Structure-\u003eModule SDK-\u003e选择自己的JDK版本 配置Tomcat // 进入Tomcat 配置 Add Configuration -\u003e Add New Configuration-\u003eTomcat Server-\u003eLocal //选择Tomcat Server-\u003eApplication server-\u003e 选择自己的Tomcat //选择JDK Server-\u003eJRE-\u003e 选择自己的JDK版本 //添加编译目录 Deployment-\u003eExternal Source-\u003e选择项目的WebRoot目录 //其他问题 检查 文件对应属性是否正确 项目右键-\u003eMark Directory As ","description":"\n","tags":[],"title":"\nMAC 下 IDEA 启动SVN Eclipse项目","uri":"/posts/post-269/"},{"categories":["默认分类"],"content":"现象 项目启动运行时发现报以下错误\n严重: Parse error in application web.xml file at jndi:/localhost/WEB-INF/web.xml java.io.FileNotFoundException: Could not resolve XML resource [null] with public ID [null], system ID [webxml/web_dataclient.xml] and base URI [jndi:/localhost/WEB-INF/web.xml] to a known, local entity. at org.apache.tomcat.util.descriptor.LocalResolver.resolveEntity(LocalResolver.java:154) at com.sun.org.apache.xerces.internal.util.EntityResolver2Wrapper.resolveEntity(EntityResolver2Wrapper.java:176) at com.sun.org.apache.xerces.internal.impl.XMLEntityManager.resolveEntityAsPerStax(XMLEntityManager.java:991) at com.sun.org.apache.xerces.internal.impl.XMLEntityManager.startEntity(XMLEntityManager.java:1206) at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanEntityReference(XMLDocumentFragmentScannerImpl.java:1908) at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:3067) at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606) at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510) at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848) at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777) 原因 servlet很多，方便管理希望能拆分文件 在web.xml文件里webapp标签上方加上\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!DOCTYPE web-app [\u003c!ENTITY dataclient SYSTEM \"webxml/web_dataclient.xml\"\u003e \u003c!ENTITY document SYSTEM \"webxml/web_document.xml\"\u003e \u003c!ENTITY project SYSTEM \"webxml/web_project.xml\"\u003e ]\u003e 我测试了一下在tomcat 6下面这个方式确实是可以的，但是在tomcat7下面就报错了。\njava.io.FileNotFoundException: Could not resolve XML resource [null] with public ID [null], system ID [webxml/web_dataclient.xml] and base URI [jndi:/localhost/WEB-INF/web.xml] to a known, local entity. 然后我又网上搜了一下，得知tomcat 7.0.52开始的版本才会出这个问题，是因为安全的考虑tomcat 7.0.52开始的版本把xmlBlockExterna属性默认为true，要解决这个问题把xmlBlockExterna设成false。\n设置前\n\u003cContext\u003e \u003c!-- Default set of monitored resources --\u003e \u003cWatchedResource\u003eWEB-INF/web.xml\u003c/WatchedResource\u003e 设置后\n\u003cContext xmlBlockExternal=\"false\"\u003e \u003c!-- Default set of monitored resources --\u003e \u003cWatchedResource\u003eWEB-INF/web.xml\u003c/WatchedResource\u003e ","description":"\n","tags":[],"title":"\nCould not resolve XML resource [null] with public ID [null]","uri":"/posts/post-270/"},{"categories":["默认分类"],"content":"潘阿林 潘阿龙 潘阿平 潘阿四 潘爱 潘爱斌 潘爱兵 潘爱春 潘爱娣 潘爱东 潘爱芳 潘爱飞 潘爱凤 潘爱国 潘爱红 潘爱花 潘爱华 潘爱辉 潘爱菊 潘爱娟 潘爱军 潘爱君 潘爱兰 潘爱丽 潘爱莲 潘爱林 潘爱玲 潘爱梅 潘爱妹 潘爱民 潘爱明 潘爱平 潘爱萍 潘爱琴 潘爱勤 潘爱青 潘爱清 潘爱琼 潘爱群 潘爱荣 潘爱蓉 潘爱武 潘爱霞 潘爱香 潘爱祥 潘爱娅 潘爱英 潘爱玉 潘爱珍 潘爱芝 潘爱忠 潘爱珠 潘安 潘安安 潘安邦 潘安东 潘安国 潘安华 潘安健 潘安君 潘安康 潘安娜 潘安宁 潘安琪 潘安仁 潘安荣 潘安生 潘安伟 潘安武 潘安正 潘安子 潘岸 潘昂 潘昂霄 潘岙 潘傲 潘奥 潘坝 潘白君 潘百明 潘柏 潘柏君 潘柏林 潘柏年 潘柏茵 潘班 潘邦杰 潘邦平 潘宝 潘宝才 潘宝昌 潘宝儿 潘宝峰 潘宝富 潘宝根 潘宝贵 潘宝宏 潘宝洪 潘宝华 潘宝军 潘宝良 潘宝林 潘宝玲 潘宝明 潘宝庆 潘宝全 潘宝泉 潘宝生 潘宝文 潘宝英 潘宝玉 潘宝珍 潘宝珠 潘保 潘保安 潘保春 潘保存 潘保芳 潘保国 潘保华 潘保良 潘保平 潘保清 潘保全 潘保田 潘保秀 潘豹 潘北来 潘贝 潘贝贝 潘贝儿 潘蓓蓓 潘蓓蕾 潘奔 潘必卿 潘必胜 潘必新 潘必兴 潘必正 潘弼健 潘碧 潘碧波 潘碧芳 潘碧华 潘碧丽 潘碧灵 潘碧琴 潘碧霞 潘碧玉 潘碧云 潘碧珍 潘彪 潘宾 潘彬 潘彬彬 潘斌 潘斌斌 潘斌龙 潘斌强 潘斌生 潘斌武 潘滨 潘滨滨 潘冰 潘冰冰 潘冰洁 潘冰清 潘冰心 潘兵 潘兵兵 潘秉臣 潘秉衡 潘炳财 潘炳辉 潘炳杰 潘炳康 潘炳良 潘炳林 潘炳强 潘炳权 潘炳森 潘炳生 潘炳文 潘炳炎 潘炳忠 潘波 潘波波 潘伯林 潘伯荣 潘伯申 潘伯英 潘伯振 潘勃 潘博 潘博文 潘博雅 潘博宇 潘搏 潘才 潘才东 潘才华 潘彩 潘彩娥 潘彩芬 潘彩峰 潘彩凤 潘彩红 潘彩虹 潘彩花 潘彩华 潘彩娇 潘彩娟 潘彩兰 潘彩连 潘彩萍 潘彩芹 潘彩群 潘彩霞 潘彩仙 潘彩英 潘彩云 潘彩珍 潘彩珠 潘灿 潘灿灿 潘灿辉 潘灿军 潘灿良 潘灿文 潘沧桑 潘曾 潘婵 潘婵婵 潘昌 潘昌峰 潘昌富 潘昌革 潘昌海 潘昌华 潘昌杰 潘昌锦 潘昌俊 潘昌坤 潘昌林 潘昌明 潘昌鹏 潘昌文 潘昌新 潘昌勇 潘昌玉 潘常乐 潘常青 潘嫦娥 潘昶 潘畅 潘超 潘超超 潘超峰 潘超杰 潘超敏 潘超平 潘超群 潘超然 潘超文 潘超英 潘超宇 潘超越 潘朝 潘朝斌 潘朝峰 潘朝锋 潘朝华 潘朝晖 潘朝辉 潘朝江 潘朝金 潘朝军 潘朝俊 潘朝林 潘朝霖 潘朝敏 潘朝明 潘朝荣 潘朝胜 潘朝文 潘朝曦 潘朝霞 潘朝阳 潘朝勇 潘潮 潘琛 潘琛琛 潘辰 潘辰辰 潘辰飞 潘辰雨 潘忱 潘陈 潘陈伟 潘晨 潘晨晨 潘晨光 潘晨晖 潘晨亮 潘晨曦 潘晨星 潘晨燕 潘晨阳 潘成 潘成安 潘成兵 潘成波 潘成成 潘成程 潘成春 潘成栋 潘成发 潘成芳 潘成飞 潘成根 潘成光 潘成国 潘成豪 潘成红 潘成虎 潘成华 潘成佳 潘成江 潘成杰 潘成兰 潘成丽 潘成良 潘成林 潘成龙 潘成秋 潘成群 潘成荣 潘成山 潘成松 潘成伟 潘成文 潘成武 潘成祥 潘成英 潘成玉 潘成园 潘成云 潘成忠 潘丞 潘诚 潘诚诚 潘诚立 潘承 潘承彪 潘承彬 潘承洞 潘承恩 潘承凡 潘承烈 潘承明 潘承思 潘承松 潘承祥 潘承玉 潘承志 潘城 潘乘风 潘程 潘程程 潘澄 潘澄清 潘池 潘驰 潘持平 潘赤诚 潘赤颖 潘冲 潘崇 潘崇根 潘崇辉 潘崇军 潘崇林 潘崇敏 潘楚楚 潘楚文 潘楚欣 潘楚颖 潘川 潘川川 潘传宝 潘传波 潘传东 潘传芳 潘传芬 潘传根 潘传国 潘传红 潘传华 潘传军 潘传坤 潘传明 潘传平 潘传权 潘传荣 潘传伟 潘传文 潘传贤 潘传英 潘传玉 潘传忠 潘闯 潘春 潘春宝 潘春波 潘春春 潘春娥 潘春发 潘春芳 潘春飞 潘春峰 潘春凤 潘春光 潘春海 潘春红 潘春宏 潘春花 潘春华 潘春晖 潘春辉 潘春吉 潘春健 潘春江 潘春娇 潘春杰 潘春娟 潘春军 潘春来 潘春兰 潘春雷 潘春丽 潘春莲 潘春良 潘春林 潘春琳 潘春玲 潘春柳 潘春龙 潘春梅 潘春妹 潘春明 潘春萍 潘春荣 潘春蓉 潘春生 潘春胜 潘春涛 潘春桃 潘春霞 潘春仙 潘春香 潘春祥 潘春新 潘春雄 潘春秀 潘春旭 潘春雪 潘春艳 潘春燕 潘春阳 潘春叶 潘春英 潘春勇 潘春宇 潘春雨 潘春园 潘春云 潘春枝 潘纯 潘纯纯 潘淳 潘慈 潘聪 潘聪聪 潘聪明 潘从贵 潘从虎 潘从军 潘从伟 潘从文 潘从武 潘丛丛 潘萃 潘翠 潘翠翠 潘翠娥 潘翠芳 潘翠红 潘翠华 潘翠环 潘翠娟 潘翠兰 潘翠丽 潘翠莲 潘翠玲 潘翠明 潘翠平 潘翠萍 潘翠清 潘翠霞 潘翠香 潘翠英 潘翠玉 潘翠云 潘翠珍 潘翠竹 潘存 潘存德 潘存刚 潘存华 潘存辉 潘存军 潘存君 潘存龙 潘存梅 潘存明 潘存实 潘存云 潘达 潘达超 潘达峰 潘达明 潘达生 潘大 潘大兵 潘大成 潘大春 潘大福 潘大富 潘大根 潘大海 潘大恒 潘大洪 潘大虎 潘大华 潘大江 潘大军 潘大钧 潘大可 潘大力 潘大林 潘大龙 潘大明 潘大年 潘大鹏 潘大平 潘大强 潘大庆 潘大荣 潘大山 潘大为 潘大维 潘大伟 潘大卫 潘大渭 潘大兴 潘大勇 潘大宇 潘大钊 潘大志 潘大中 潘岱 潘丹 潘丹丹 潘丹峰 潘丹凤 潘丹红 潘丹华 潘丹丽 潘丹妮 潘丹萍 潘丹琴 潘丹青 潘丹婷 潘丹霞 潘丹阳 潘旦 潘旦旦 潘道 潘道波 潘道东 潘道根 潘道军 潘道明 潘道平 潘道兴 潘道义 潘道源 潘道远 潘得国 潘得海 潘得胜 潘德 潘德安 潘德宝 潘德彬 潘德波 潘德才 潘德昌 潘德成 潘德芳 潘德凤 潘德孚 潘德福 潘德富 潘德刚 潘德贵 潘德国 潘德海 潘德红 潘德宏 潘德华 潘德辉 潘德惠 潘德金 潘德军 潘德俊 潘德兰 潘德良 潘德亮 潘德林 潘德龙 潘德炉 潘德民 潘德敏 潘德明 潘德鹏 潘德平 潘德强 潘德琴 潘德清 潘德全 潘德仁 潘德荣 潘德瑞 潘德润 潘德森 潘德生 潘德胜 潘德寿 潘德顺 潘德旺 潘德伟 潘德熙 潘德祥 潘德新 潘德鑫 潘德兴 潘德雄 潘德阳 潘德银 潘德英 潘德勇 潘德玉 潘德远 潘德运 潘德章 潘德珍 潘德志 潘德忠 潘登 潘登峰 潘登科 潘登明 潘登文 潘登宇 潘登云 潘狄 潘迪 潘迪迪 潘迪飞 潘迪华 潘迪生 潘荻萱 潘笛 潘笛站 潘地 潘娣 潘典媛 潘殿萍 潘殿卿 潘殿伟 潘蝶 潘丁 潘丁丁 潘鼎 潘鼎文 潘鼎新 潘定 潘定春 潘定刚 潘定国 潘定华 潘定水 潘定兴 潘东 潘东波 潘东东 潘东方 潘东飞 潘东芬 潘东海 潘东华 潘东杰 潘东军 潘东雷 潘东亮 潘东林 潘东玲 潘东妹 潘东明 潘东荣 潘东升 潘东生 潘东文 潘东霞 潘东晓 潘东兴 潘东旭 潘东阳 潘东英 潘东岳 潘东子 潘冬 潘冬冬 潘冬凤 潘冬华 潘冬菊 潘冬兰 潘冬莲 潘冬玲 潘冬梅 潘冬妹 潘冬明 潘冬妮 潘冬宁 潘冬琴 潘冬青 潘冬生 潘冬霞 潘冬雪 潘冬燕 潘冬英 潘冬玉 潘冬子 潘董 潘栋 潘栋栋 潘栋梁 潘栋平 潘都 潘渡娜 潘端 潘墩 潘多 潘多多 潘多玲 潘多娜 潘铎 潘朵 潘娥 潘恩 潘恩德 潘恩华 潘恩来 潘恩林 潘恩元 潘二 潘二矿 潘二龙 潘二伟 潘发俊 潘发林 潘发明 潘发生 潘发勇 潘帆 潘蕃 潘凡 潘凡凡 潘凡平 潘璠 潘方 潘方方 潘方磊 潘方明 潘方仁 潘方伟 潘方圆 潘芳 潘芳芳 潘芳丽 潘芳莉 潘芳敏 潘芳琴 潘芳艳 潘芳园 潘放 潘飞 潘飞飞 潘飞宏 潘飞鸿 潘飞虎 潘飞龙 潘飞鹏 潘飞翔 潘飞燕 潘飞扬 潘妃 潘非 潘非非 潘菲 潘菲菲 潘菲娜 潘霏 潘霏霏 潘斐 潘斐斐 潘翡 潘芬 潘芬芬 潘丰 潘丰华 潘丰年 潘丰泉 潘丰收 潘风 潘风华 潘风林 潘风山 潘风英 潘风云 潘枫 潘峰 潘峰峰 潘峰文 潘烽 潘锋 潘锋锋 潘逢春 潘逢卿 潘凤 潘凤春 潘凤娣 潘凤凤 潘凤花 潘凤华 潘凤娇 潘凤菊 潘凤娟 潘凤君 潘凤兰 潘凤莲 潘凤亮 潘凤林 潘凤玲 潘凤龙 潘凤马 潘凤梅 潘凤妹 潘凤明 潘凤鸣 潘凤平 潘凤萍 潘凤琴 潘凤清 潘凤霞 潘凤仙 潘凤香 潘凤祥 潘凤仪 潘凤英 潘凤玉 潘凤云 潘凤贞 潘凤珍 潘福 潘福安 潘福超 潘福春 潘福东 潘福刚 潘福根 潘福华 潘福金 潘福久 潘福娟 潘福军 潘福来 潘福兰 潘福亮 潘福林 潘福龙 潘福强 潘福琼 潘福全 潘福仁 潘福荣 潘福生 潘福胜 潘福喜 潘福祥 潘福星 潘福兴 潘福玉 潘福元 潘福珍 潘福忠 潘复生 潘富 潘富春 潘富恩 潘富贵 潘富华 潘富珉 潘富明 潘富强 潘富生 潘富友 潘嘎斌 潘淦 潘刚 潘刚儿 潘刚明 潘刚强 潘纲 潘钢 潘罡 潘岗 潘港 潘高 潘高超 潘高峰 潘高鹏 潘高平 潘高寿 潘高煊 潘高阳 潘镐 潘戈 潘革 潘阁 潘格 潘根 潘根发 潘根华 潘根林 潘根明 潘根平 潘根生 潘根顺 潘根兴 潘庚 潘更生 潘公凯 潘功 潘功成 潘功平 潘功胜 潘古 潘谷 潘谷平 潘关海 潘观福 潘观华 潘观辉 潘观林 潘观平 潘观胜 潘观文 潘冠 潘冠华 潘冠霖 潘冠男 潘冠群 潘冠文 潘冠英 潘冠宇 潘光 潘光碧 潘光晨 潘光成 潘光旦 潘光德 潘光东 潘光放 潘光福 潘光海 潘光红 潘光华 潘光辉 潘光建 潘光杰 潘光军 潘光俊 潘光雷 潘光磊 潘光亮 潘光林 潘光龙 潘光梅 潘光明 潘光平 潘光琴 潘光庆 潘光权 潘光荣 潘光胜 潘光松 潘光涛 潘光伟 潘光文 潘光武 潘光霞 潘光鑫 潘光秀 潘光旭 潘光学 潘光炎 潘光耀 潘光银 潘光英 潘光永 潘光勇 潘光宇 潘光元 潘光远 潘光云 潘光照 潘光志 潘广 潘广斌 潘广财 潘广超 潘广成 潘广春 潘广德 潘广东 潘广福 潘广海 潘广豪 潘广华 潘广辉 潘广慧 潘广建 潘广礼 潘广利 潘广林 潘广玲 潘广明 潘广宁 潘广鹏 潘广平 潘广升 潘广生 潘广田 潘广通 潘广伟 潘广文 潘广新 潘广旭 潘广学 潘广彦 潘广义 潘广益 潘广宇 潘广云 潘广志 潘贵 潘贵安 潘贵才 潘贵成 潘贵春 潘贵福 潘贵富 潘贵华 潘贵军 潘贵梁 潘贵林 潘贵平 潘贵清 潘贵泉 潘贵生 潘贵仙 潘贵兴 潘贵玉 潘贵珍 潘桂 潘桂春 潘桂方 潘桂芳 潘桂芬 潘桂凤 潘桂河 潘桂红 潘桂花 潘桂华 潘桂娟 潘桂兰 潘桂莲 潘桂林 潘桂玲 潘桂梅 潘桂妹 潘桂明 潘桂娜 潘桂平 潘桂萍 潘桂芹 潘桂琴 潘桂清 潘桂荣 潘桂棠 潘桂霞 潘桂香 潘桂新 潘桂兴 潘桂英 潘桂玉 潘桂云 潘桂珍 潘桂枝 潘桂珠 潘国 潘国安 潘国宝 潘国标 潘国宾 潘国彬 潘国斌 潘国兵 潘国才 潘国昌 潘国超 潘国潮 潘国臣 潘国成 潘国诚 潘国城 潘国春 潘国大 潘国定 潘国栋 潘国发 潘国芳 潘国飞 潘国芬 潘国峰 潘国锋 潘国富 潘国纲 潘国光 潘国海 潘国和 潘国红 潘国洪 潘国华 潘国辉 潘国基 潘国坚 潘国建 潘国健 潘国江 潘国杰 潘国金 潘国进 潘国静 潘国驹 潘国娟 潘国军 潘国钧 潘国俊 潘国凯 潘国礼 潘国立 潘国莉 潘国濂 潘国良 潘国梁 潘国亮 潘国林 潘国灵 潘国龙 潘国梅 潘国民 潘国敏 潘国明 潘国能 潘国宁 潘国平 潘国旗 潘国强 潘国琴 潘国青 潘国清 潘国庆 潘国权 潘国全 潘国仁 潘国荣 潘国森 潘国山 潘国生 潘国胜 潘国盛 潘国顺 潘国伟 潘国文 潘国霞 潘国贤 潘国祥 潘国新 潘国星 潘国兴 潘国雄 潘国秀 潘国耀 潘国义 潘国英 潘国营 潘国勇 潘国友 潘国玉 潘国云 潘国章 潘国珍 潘国正 潘国忠 潘国宗 潘果 潘果果 潘海 潘海彬 潘海斌 潘海滨 潘海兵 潘海波 潘海超 潘海潮 潘海成 潘海川 潘海东 潘海飞 潘海风 潘海峰 潘海锋 潘海光 潘海浩 潘海红 潘海虹 潘海花 潘海华 潘海辉 潘海建 潘海江 潘海娇 潘海杰 潘海洁 潘海金 潘海娟 潘海军 潘海俊 潘海兰 潘海浪 潘海丽 潘海良 潘海亮 潘海林 潘海玲 潘海龙 潘海伦 潘海梅 潘海妹 潘海敏 潘海明 潘海娜 潘海宁 潘海鸥 潘海鹏 潘海平 潘海萍 潘海强 潘海琴 潘海青 潘海清 潘海琼 潘海全 潘海荣 潘海山 潘海深 潘海生 潘海声 潘海松 潘海棠 潘海涛 潘海天 潘海伟 潘海文 潘海侠 潘海霞 潘海祥 潘海翔 潘海啸 潘海新 潘海星 潘海彦 潘海艳 潘海燕 潘海阳 潘海洋 潘海瑶 潘海英 潘海鹰 潘海莹 潘海颖 潘海永 潘海勇 潘海涌 潘海玉 潘海云 潘海忠 潘海珠 潘晗 潘涵 潘涵涵 潘寒 潘汉 潘汉斌 潘汉潮 潘汉成 潘汉春 潘汉东 潘汉杰 潘汉军 潘汉民 潘汉明 潘汉年 潘汉平 潘汉荣 潘汉生 潘汉源 潘翰 潘瀚 潘行 潘行健 潘行义 潘航 潘豪 潘好 潘好好 潘好龙 潘好涛 潘昊 潘昊旻 潘浩 潘浩彬 潘浩波 潘浩东 潘浩海 潘浩浩 潘浩辉 潘浩军 潘浩良 潘浩亮 潘浩林 潘浩明 潘浩泉 潘浩然 潘浩荣 潘浩儒 潘浩文 潘浩贤 潘浩宇 潘皓 潘颢 潘灏 潘合 潘何 潘和 潘和钧 潘和林 潘和平 潘和清 潘和英 潘和忠 潘河 潘河水 潘贺 潘赫 潘鹤 潘鹤林 潘鹤麟 潘鹤龄 潘鹤鸣 潘鹤年 潘恒 潘恒杰 潘恒生 潘恒伟 潘衡 潘蘅生 潘弘 潘红 潘红宾 潘红斌 潘红兵 潘红波 潘红春 潘红芳 潘红飞 潘红峰 潘红光 潘红红 潘红华 潘红江 潘红杰 潘红静 潘红菊 潘红娟 潘红军 潘红兰 潘红丽 潘红利 潘红莲 潘红良 潘红林 潘红玲 潘红梅 潘红妹 潘红苗 潘红敏 潘红明 潘红平 潘红萍 潘红旗 潘红青 潘红球 潘红伟 潘红卫 潘红霞 潘红仙 潘红香 潘红星 潘红艳 潘红燕 潘红英 潘红宇 潘红玉 潘红运 潘宏 潘宏彬 潘宏斌 潘宏波 潘宏博 潘宏达 潘宏飞 潘宏锋 潘宏福 潘宏光 潘宏辉 潘宏建 潘宏杰 潘宏军 潘宏利 潘宏亮 潘宏林 潘宏铭 潘宏强 潘宏清 潘宏涛 潘宏伟 潘宏霞 潘宏祥 潘宏宇 潘宏源 潘宏云 潘泓 潘泓霖 潘泓宇 潘虹 潘虹虹 潘虹君 潘虹燕 潘虹颖 潘虹羽 潘虹珍 潘洪 潘洪宝 潘洪彬 潘洪斌 潘洪波 潘洪昌 潘洪超 潘洪川 潘洪春 潘洪芳 潘洪峰 潘洪革 潘洪光 潘洪海 潘洪华 潘洪辉 潘洪建 潘洪江 潘洪军 潘洪凯 潘洪兰 潘洪磊 潘洪良 潘洪亮 潘洪林 潘洪梅 潘洪明 潘洪平 潘洪其 潘洪强 潘洪生 潘洪涛 潘洪伟 潘洪文 潘洪侠 潘洪霞 潘洪祥 潘洪星 潘洪艳 潘洪雁 潘洪业 潘洪英 潘洪玉 潘洪源 潘洪云 潘洪泽 潘洪志 潘洪忠 潘洪洲 潘鸿 潘鸿彬 潘鸿斌 潘鸿滨 潘鸿飞 潘鸿海 潘鸿辉 潘鸿杰 潘鸿钧 潘鸿强 潘鸿权 潘鸿霞 潘鸿翔 潘鸿雁 潘鸿云 潘厚任 潘湖 潘虎 潘花 潘花花 潘华 潘华彬 潘华斌 潘华波 潘华春 潘华东 潘华芬 潘华峰 潘华锋 潘华根 潘华光 潘华海 潘华华 潘华辉 潘华建 潘华杰 潘华娟 潘华军 潘华君 潘华良 潘华林 潘华美 潘华妹 潘华敏 潘华明 潘华南 潘华鹏 潘华平 潘华萍 潘华强 潘华琴 潘华清 潘华琼 潘华荣 潘华蓉 潘华胜 潘华盛 潘华庭 潘华仙 潘华兴 潘华燕 潘华阳 潘华英 潘华勇 潘华云 潘华珍 潘骅 潘化 潘桦 潘怀 潘怀林 潘怀宇 潘怀玉 潘淮宁 潘槐钰 潘欢 潘欢欢 潘环 潘环环 潘桓 潘寰 潘焕 潘焕焕 潘焕明 潘焕新 潘黄 潘黄龙 潘煌 潘晖 潘辉 潘辉煌 潘辉辉 潘辉明 潘辉强 潘辉雄 潘辉云 潘徽 潘卉 潘卉卉 潘汇 潘会 潘会芳 潘会华 潘会会 潘会军 潘会兰 潘会玲 潘会明 潘会宁 潘会霞 潘会云 潘惠 潘惠春 潘惠芳 潘惠芬 潘惠红 潘惠虹 潘惠惠 潘惠娟 潘惠君 潘惠兰 潘惠丽 潘惠玲 潘惠梅 潘惠美 潘惠民 潘惠敏 潘惠明 潘惠娜 潘惠平 潘惠萍 潘惠琴 潘惠清 潘惠琼 潘惠雯 潘惠霞 潘惠贤 潘惠欣 潘惠英 潘惠珍 潘惠忠 潘惠珠 潘惠子 潘慧 潘慧超 潘慧芳 潘慧芬 潘慧峰 潘慧和 潘慧红 潘慧虹 潘慧华 潘慧慧 潘慧洁 潘慧娟 潘慧君 潘慧兰 潘慧丽 潘慧琳 潘慧玲 潘慧龙 潘慧敏 潘慧明 潘慧鹏 潘慧平 潘慧萍 潘慧倩 潘慧强 潘慧琴 潘慧勤 潘慧卿 潘慧清 潘慧如 潘慧茹 潘慧婷 潘慧希 潘慧霞 潘慧燕 潘慧莹 潘慧媛 潘慧云 潘慧贞 潘慧珍 潘火 潘火兰 潘基文 潘吉 潘吉东 潘吉光 潘吉吉 潘吉林 潘吉龙 潘吉娜 潘吉平 潘吉庆 潘吉祥 潘吉星 潘佶 潘集阳 潘纪刚 潘纪根 潘纪文 潘际 潘际銮 潘际银 潘季 潘季伟 潘季训 潘济 潘继 潘继斌 潘继成 潘继东 潘继芳 潘继刚 潘继光 潘继红 潘继华 潘继军 潘继兰 潘继伦 潘继民 潘继明 潘继鹏 潘继平 潘继荣 潘继生 潘继伟 潘继文 潘继修 潘继业 潘霁 潘霁莹 潘冀 潘骥 潘加福 潘加利 潘加平 潘加荣 潘加英 潘加宇 潘佳 潘佳宝 潘佳晨 潘佳成 潘佳东 潘佳栋 潘佳宏 潘佳华 潘佳慧 潘佳佳 潘佳杰 潘佳俊 潘佳乐 潘佳磊 潘佳丽 潘佳亮 潘佳林 潘佳琳 潘佳玲 潘佳璐 潘佳美 潘佳敏 潘佳明 潘佳男 潘佳楠 潘佳宁 潘佳鹏 潘佳萍 潘佳奇 潘佳琪 潘佳琦 潘佳薇 潘佳伟 潘佳雯 潘佳欣 潘佳鑫 潘佳星 潘佳艳 潘佳燕 潘佳怡 潘佳音 潘佳莹 潘佳颖 潘佳宇 潘佳玉 潘佳媛 潘佳云 潘佳章 潘家宝 潘家兵 潘家辰 潘家德 潘家东 潘家栋 潘家发 潘家锋 潘家富 潘家海 潘家豪 潘家红 潘家华 潘家辉 潘家惠 潘家慧 潘家杰 潘家驹 潘家军 潘家君 潘家俊 潘家骏 潘家良 潘家梁 潘家亮 潘家林 潘家玲 潘家龙 潘家楼 潘家路 潘家明 潘家铭 潘家宁 潘家平 潘家萍 潘家琪 潘家琦 潘家强 潘家琴 潘家庆 潘家全 潘家仁 潘家任 潘家荣 潘家瑞 潘家森 潘家松 潘家堂 潘家头 潘家旺 潘家伟 潘家玮 潘家文 潘家武 潘家喜 潘家祥 潘家鑫 潘家兴 潘家雄 潘家秀 潘家旭 潘家洵 潘家燕 潘家扬 潘家怡 潘家宜 潘家永 潘家瑜 潘家宇 潘家裕 潘家源 潘家云 潘家哲 潘家珍 潘家铮 潘家洲 潘家柱 潘嘉 潘嘉宝 潘嘉斌 潘嘉诚 潘嘉德 潘嘉豪 潘嘉和 潘嘉华 潘嘉辉 潘嘉慧 潘嘉嘉 潘嘉杰 潘嘉俊 潘嘉骏 潘嘉丽 潘嘉良 潘嘉麟 潘嘉玲 潘嘉敏 潘嘉明 潘嘉楠 潘嘉琪 潘嘉祺 潘嘉荣 潘嘉茹 潘嘉维 潘嘉伟 潘嘉玮 潘嘉炜 潘嘉雯 潘嘉欣 潘嘉仪 潘嘉怡 潘嘉毅 潘嘉莹 潘嘉颖 潘甲 潘坚 潘坚平 潘坚强 潘俭伟 潘检 潘骞 潘见 潘建 潘建标 潘建彪 潘建斌 潘建波 潘建才 潘建成 潘建春 潘建达 潘建德 潘建东 潘建发 潘建芳 潘建芬 潘建丰 潘建峰 潘建锋 潘建福 潘建刚 潘建根 潘建光 潘建国 潘建行 潘建航 潘建浩 潘建红 潘建宏 潘建洪 潘建花 潘建华 潘建辉 潘建基 潘建建 潘建江 潘建杰 潘建军 潘建均 潘建君 潘建康 潘建坤 潘建雷 潘建磊 潘建丽 潘建利 潘建良 潘建林 潘建美 潘建妹 潘建民 潘建敏 潘建名 潘建明 潘建男 潘建南 潘建宁 潘建培 潘建鹏 潘建平 潘建萍 潘建强 潘建琴 潘建青 潘建清 潘建琼 潘建秋 潘建全 潘建群 潘建荣 潘建山 潘建生 潘建胜 潘建树 潘建涛 潘建廷 潘建亭 潘建婷 潘建威 潘建伟 潘建文 潘建武 潘建新 潘建兴 潘建雄 潘建勋 潘建阳 潘建耀 潘建业 潘建英 潘建莹 潘建勇 潘建友 潘建宇 潘建元 潘建岳 潘建章 潘建志 潘建中 潘建忠 潘建州 潘建宗 潘剑 潘剑斌 潘剑波 潘剑飞 潘剑峰 潘剑锋 潘剑光 潘剑辉 潘剑敏 潘剑明 潘剑平 潘剑清 潘剑秋 潘剑涛 潘剑伟 潘剑文 潘剑翔 潘剑英 潘剑勇 潘剑云 潘健 潘健成 潘健芳 潘健飞 潘健芬 潘健红 潘健华 潘健辉 潘健健 潘健君 潘健民 潘健敏 潘健强 潘健荣 潘健生 潘健伟 潘健翔 潘健忠 潘舰 潘涧 潘鉴 潘键 潘箭 潘江 潘江波 潘江川 潘江锋 潘江浩 潘江红 潘江虹 潘江洪 潘江华 潘江江 潘江雷 潘江理 潘江林 潘江龙 潘江梅 潘江南 潘江山 潘江涛 潘江伟 潘江文 潘江霞 潘江永 潘将 潘姜 潘娇 潘娇娇 潘姣 潘姣姣 潘姣莉 潘蛟 潘佼 潘皎 潘教武 潘节 潘杰 潘杰斌 潘杰峰 潘杰辉 潘杰客 潘杰英 潘洁 潘洁夫 潘洁华 潘洁慧 潘洁洁 潘洁萍 潘洁容 潘洁怡 潘洁英 潘洁莹 潘洁珍 潘洁兹 潘结 潘捷 潘婕 潘婕妤 潘金 潘金安 潘金宝 潘金保 潘金彪 潘金才 潘金财 潘金彩 潘金超 潘金诚 潘金城 潘金春 潘金弟 潘金娣 潘金娥 潘金发 潘金芳 潘金飞 潘金风 潘金峰 潘金凤 潘金福 潘金富 潘金刚 潘金根 潘金贵 潘金桂 潘金海 潘金和 潘金红 潘金洪 潘金花 潘金华 潘金环 潘金辉 潘金火 潘金金 潘金晶 潘金菊 潘金来 潘金兰 潘金利 潘金莉 潘金莲 潘金良 潘金亮 潘金林 潘金玲 潘金陵 潘金龙 潘金满 潘金梅 潘金美 潘金妹 潘金明 潘金铭 潘金培 潘金平 潘金强 潘金清 潘金全 潘金泉 潘金荣 潘金瑞 潘金山 潘金生 潘金盛 潘金水 潘金松 潘金堂 潘金涛 潘金土 潘金旺 潘金文 潘金霞 潘金香 潘金祥 潘金星 潘金亚 潘金炎 潘金艳 潘金叶 潘金英 潘金友 潘金玉 潘金元 潘金云 潘金枝 潘金忠 潘金钟 潘金珠 潘津 潘津津 潘津生 潘锦 潘锦标 潘锦波 潘锦超 潘锦成 潘锦程 潘锦春 潘锦芳 潘锦峰 潘锦锋 潘锦凤 潘锦洪 潘锦华 潘锦辉 潘锦江 潘锦锦 潘锦良 潘锦龙 潘锦梅 潘锦明 潘锦平 潘锦屏 潘锦萍 潘锦全 潘锦荣 潘锦松 潘锦堂 潘锦棠 潘锦添 潘锦伟 潘锦雯 潘锦霞 潘锦燕 潘锦阳 潘锦瑶 潘锦英 潘锦勇 潘谨 潘瑾 潘瑾瑾 潘瑾瑜 潘进 潘进华 潘进辉 潘进杰 潘进进 潘进军 潘进良 潘进霞 潘劲 潘劲东 潘劲松 潘晋 潘京 潘京海 潘京华 潘京京 潘京南 潘京文 潘经伟 潘经文 潘菁 潘菁菁 潘惊石 潘晶 潘晶晶 潘井 潘井龙 潘景 潘景春 潘景德 潘景娥 潘景峰 潘景红 潘景华 潘景林 潘景龙 潘景铭 潘景升 潘景涛 潘景韬 潘景伟 潘景新 潘景轩 潘景阳 潘景义 潘景寅 潘景云 潘景章 潘璟 潘径 潘竞 潘竞锵 潘竟 潘竟成 潘婧 潘婧婧 潘婧娴 潘婧怡 潘敬 潘敬东 潘敬华 潘敬辉 潘敬林 潘敬平 潘敬文 潘敬新 潘敬英 潘敬玉 潘靖 潘靖文 潘靖宇 潘静 潘静安 潘静波 潘静芬 潘静华 潘静慧 潘静静 潘静娜 潘静如 潘静茹 潘静文 潘静雯 潘静娴 潘静新 潘静雅 潘静仪 潘静怡 潘静宜 潘静云 潘镜 潘镜丞 潘镜全 潘炯 潘炯光 潘炯华 潘九根 潘久辉 潘久荣 潘玖玲 潘菊 潘菊芳 潘菊芬 潘菊红 潘菊花 潘菊华 潘菊兰 潘菊梅 潘菊香 潘菊英 潘举 潘巨华 潘巨利 潘巨龙 潘巨文 潘涓 潘娟 潘娟娟 潘娟英 潘珏 潘军 潘军波 潘军昌 潘军迪 潘军峰 潘军华 潘军杰 潘军军 潘军凯 潘军民 潘军明 潘军强 潘军伟 潘军武 潘军霞 潘军英 潘均 潘君 潘君芳 潘君骅 潘君君 潘君诺 潘君祥 潘君燕 潘君耀 潘钧 潘筠 潘俊 潘俊超 潘俊达 潘俊德 潘俊帆 潘俊峰 潘俊锋 潘俊刚 潘俊钢 潘俊豪 潘俊浩 潘俊恒 潘俊红 潘俊华 潘俊辉 潘俊慧 潘俊佳 潘俊坚 潘俊杰 潘俊俊 潘俊凯 潘俊坤 潘俊兰 潘俊丽 潘俊良 潘俊林 潘俊霖 潘俊岭 潘俊龙 潘俊民 潘俊敏 潘俊明 潘俊楠 潘俊宁 潘俊鹏 潘俊奇 潘俊琪 潘俊卿 潘俊清 潘俊权 潘俊荣 潘俊蓉 潘俊如 潘俊山 潘俊生 潘俊涛 潘俊伟 潘俊文 潘俊武 潘俊先 潘俊贤 潘俊祥 潘俊星 潘俊雄 潘俊旭 潘俊艳 潘俊伊 潘俊毅 潘俊英 潘俊佑 潘俊宇 潘俊羽 潘俊云 潘俊志 潘郡 潘峻 潘峻峰 潘隽 潘浚 潘骏 潘开成 潘开华 潘开林 潘开明 潘开文 潘开祥 潘开元 潘凯 潘凯华 潘凯凯 潘凯丽 潘凯伦 潘凯文 潘凯雄 潘凯旋 潘凯跃 潘恺 潘楷 潘楷发 潘楷文 潘锴 潘侃 潘康 潘康成 潘康健 潘康杰 潘康康 潘康乐 潘康明 潘康宁 潘康平 潘康强 潘康荣 潘珂 潘珂珂 潘柯 潘柯丞 潘轲 潘科 潘科成 潘科峰 潘科宏 潘科科 潘科林 潘科明 潘科宇 潘可 潘可夫 潘可佳 潘可可 潘可丽 潘可明 潘可钦 潘可人 潘可为 潘可心 潘可欣 潘克 潘克华 潘克林 潘克明 潘克强 潘克勤 潘克文 潘克武 潘克雄 潘克勋 潘克云 潘恪 潘宽 潘奎 潘逵 潘葵 潘魁 潘坤 潘坤坤 潘坤龙 潘坤明 潘昆 潘昆成 潘琨 潘锟 潘拉 潘腊梅 潘来 潘来保 潘来发 潘来英 潘兰 潘兰芳 潘兰芬 潘兰花 潘兰兰 潘兰香 潘兰燕 潘兰英 潘兰云 潘兰珍 潘岚 潘澜 潘郎 潘朗 潘朗清 潘浪 潘乐 潘乐乐 潘乐明 潘乐平 潘乐群 潘乐生 潘乐怡 潘雷 潘雷雷 潘雷明 潘垒 潘磊 潘磊磊 潘蕾 潘蕾蕾 潘黎 潘黎东 潘黎黎 潘黎敏 潘黎明 潘黎萍 潘礼 潘礼德 潘礼菊 潘礼明 潘李 潘李梅 潘里 潘力 潘力宏 潘力军 潘力平 潘力山 潘力维 潘力伟 潘历 潘厉 潘立 潘立本 潘立彬 潘立斌 潘立兵 潘立波 潘立超 潘立川 潘立春 潘立德 潘立东 潘立芳 潘立飞 潘立峰 潘立锋 潘立夫 潘立富 潘立刚 潘立光 潘立国 潘立恒 潘立华 潘立辉 潘立江 潘立杰 潘立炯 潘立娟 潘立军 潘立君 潘立兰 潘立立 潘立龙 潘立梅 潘立民 潘立敏 潘立铭 潘立平 潘立强 潘立群 潘立荣 潘立山 潘立生 潘立涛 潘立伟 潘立文 潘立祥 潘立新 潘立业 潘立勇 潘立志 潘丽 潘丽彬 潘丽冰 潘丽波 潘丽婵 潘丽嫦 潘丽晨 潘丽春 潘丽丹 潘丽娥 潘丽芳 潘丽飞 潘丽妃 潘丽芬 潘丽峰 潘丽锋 潘丽凤 潘丽红 潘丽花 潘丽华 潘丽桦 潘丽辉 潘丽慧 潘丽佳 潘丽杰 潘丽洁 潘丽金 潘丽锦 潘丽晶 潘丽静 潘丽娟 潘丽军 潘丽君 潘丽俊 潘丽丽 潘丽莉 潘丽连 潘丽玲 潘丽梅 潘丽美 潘丽妹 潘丽媚 潘丽敏 潘丽明 潘丽娜 潘丽平 潘丽屏 潘丽萍 潘丽芹 潘丽琴 潘丽勤 潘丽卿 潘丽清 潘丽琼 潘丽群 潘丽荣 潘丽容 潘丽蓉 潘丽如 潘丽莎 潘丽婷 潘丽文 潘丽雯 潘丽霞 潘丽仙 潘丽先 潘丽鲜 潘丽贤 潘丽娴 潘丽香 潘丽新 潘丽璇 潘丽雪 潘丽雅 潘丽娅 潘丽艳 潘丽燕 潘丽银 潘丽英 潘丽影 潘丽勇 潘丽云 潘丽芸 潘丽贞 潘丽珍 潘丽珠 潘利 潘利斌 潘利兵 潘利波 潘利丹 潘利东 潘利芳 潘利锋 潘利国 潘利红 潘利华 潘利辉 潘利娟 潘利军 潘利君 潘利利 潘利玲 潘利龙 潘利妹 潘利民 潘利敏 潘利明 潘利娜 潘利平 潘利强 潘利琴 潘利琼 潘利泉 潘利群 潘利婷 潘利伟 潘利新 潘利英 潘利勇 潘利云 潘利忠 潘荔 潘俐 潘俐君 潘俐娜 潘莉 潘莉芳 潘莉芬 潘莉华 潘莉娟 潘莉君 潘莉丽 潘莉莉 潘莉娜 潘莉萍 潘莉琴 潘莉青 潘莉莎 潘莉婷 潘栗 潘砺 潘连 潘连德 潘连根 潘连连 潘连妹 潘连生 潘连英 潘连中 潘莲 潘莲莲 潘莲香 潘莲英 潘联 潘濂 潘炼 潘恋 潘良 潘良成 潘良贵 潘良华 潘良坤 潘良良 潘良明 潘良平 潘良时 潘良文 潘良勇 潘良玉 潘梁 潘亮 潘亮亮 潘亮宇 潘靓 潘烈 潘林 潘林波 潘林超 潘林芳 潘林峰 潘林海 潘林花 潘林华 潘林江 潘林杰 潘林娟 潘林军 潘林丽 潘林莉 潘林林 潘林琳 潘林梅 潘林强 潘林青 潘林清 潘林荣 潘林生 潘林涛 潘林伟 潘林祥 潘林艳 潘林燕 潘林洋 潘林英 潘林元 潘林云 潘临 潘琳 潘琳琳 潘琳娜 潘琳元 潘霖 潘伶 潘伶俐 潘灵 潘灵波 潘灵辉 潘灵灵 潘灵芝 潘玲 潘玲娣 潘玲芳 潘玲飞 潘玲华 潘玲娟 潘玲君 潘玲丽 潘玲利 潘玲玲 潘玲梅 潘玲敏 潘玲娜 潘玲萍 潘玲艳 潘玲燕 潘玲玉 潘铃 潘铃炯 潘铃铃 潘凌 潘凌寒 潘凌宇 潘凌云 潘岭 潘令 潘令嘉 潘留明 潘留平 潘柳 潘柳芳 潘柳红 潘柳华 潘柳柳 潘柳萍 潘柳青 潘柳清 潘柳婷 潘柳霞 潘柳珍 潘龙 潘龙宝 潘龙兵 潘龙波 潘龙春 潘龙法 潘龙芳 潘龙飞 潘龙凤 潘龙刚 潘龙根 潘龙光 潘龙海 潘龙浩 潘龙华 潘龙辉 潘龙江 潘龙杰 潘龙金 潘龙俊 潘龙龙 潘龙美 潘龙淼 潘龙平 潘龙清 潘龙山 潘龙生 潘龙伟 潘龙武 潘龙祥 潘龙英 潘龙玉 潘龙云 潘隆 潘隆玉 潘楼 潘鲁 潘鲁青 潘鲁生 潘陆 潘陆平 潘路江 潘路路 潘璐 潘璐璐 潘璐琼 潘鹭 潘露 潘露露 潘露清 潘伦 潘罗 潘罗敏 潘洛 潘玛黎 潘满华 潘满香 潘曼 潘曼曼 潘曼霞 潘漫 潘漫红 潘漫漫 潘茂 潘茂华 潘茂辉 潘茂林 潘茂平 潘茂元 潘茂忠 潘懋 潘懋元 潘玫 潘眉 潘梅 潘梅芳 潘梅红 潘梅花 潘梅华 潘梅娟 潘梅兰 潘梅林 潘梅梅 潘梅仙 潘梅秀 潘梅英 潘梅玉 潘梅珍 潘美 潘美辰 潘美晨 潘美娥 潘美儿 潘美芳 潘美飞 潘美芬 潘美凤 潘美红 潘美花 潘美华 潘美慧 潘美杰 潘美洁 潘美静 潘美娟 潘美君 潘美兰 潘美丽 潘美莲 潘美林 潘美琳 潘美霖 潘美灵 潘美玲 潘美龄 潘美路 潘美梅 潘美美 潘美妹 潘美娜 潘美萍 潘美琪 潘美琴 潘美清 潘美荣 潘美如 潘美婷 潘美霞 潘美仙 潘美香 潘美欣 潘美璇 潘美燕 潘美仪 潘美怡 潘美英 潘美玉 潘美月 潘美云 潘美珍 潘妹英 潘媚 潘媚媚 潘萌 潘萌萌 潘蒙 潘蒙蒙 潘猛 潘孟文 潘孟阳 潘梦 潘梦华 潘梦佳 潘梦杰 潘梦婕 潘梦丽 潘梦梦 潘梦妮 潘梦琪 潘梦琦 潘梦婷 潘梦霞 潘梦阳 潘梦瑶 潘梦莹 潘梦颖 潘梦雨 潘梦媛 潘梦月 潘秘 潘密密 潘苗 潘苗苗 潘淼 潘妙玲 潘妙妙 潘妙婷 潘妙英 潘民 潘民生 潘旻 潘珉辉 潘闽 潘敏 潘敏超 潘敏聪 潘敏东 潘敏儿 潘敏芳 潘敏飞 潘敏峰 潘敏刚 潘敏行 潘敏华 潘敏慧 潘敏佳 潘敏捷 潘敏娟 潘敏立 潘敏丽 潘敏玲 潘敏敏 潘敏琪 潘敏强 潘敏清 潘敏锐 潘敏妍 潘敏仪 潘敏怡 潘敏芝 潘敏智 潘敏珠 潘名山 潘名哲 潘明 潘明宝 潘明波 潘明才 潘明昌 潘明成 潘明达 潘明道 潘明德 潘明栋 潘明发 潘明芳 潘明峰 潘明凤 潘明福 潘明光 潘明海 潘明红 潘明虎 潘明华 潘明辉 潘明慧 潘明蕙 潘明继 潘明建 潘明杰 潘明菊 潘明娟 潘明军 潘明君 潘明坤 潘明兰 潘明朗 潘明理 潘明丽 潘明利 潘明亮 潘明林 潘明敏 潘明明 潘明强 潘明琴 潘明清 潘明权 潘明泉 潘明荣 潘明山 潘明生 潘明顺 潘明涛 潘明旺 潘明伟 潘明文 潘明霞 潘明祥 潘明欣 潘明新 潘明鑫 潘明秀 潘明旭 潘明轩 潘明扬 潘明阳 潘明银 潘明英 潘明勇 潘明玉 潘明远 潘明月 潘明哲 潘明珍 潘明政 潘明志 潘明忠 潘明珠 潘鸣 潘鸣凤 潘鸣钟 潘铭 潘铭洁 潘铭铭 潘铭琪 潘铭仪 潘漠子 潘姆 潘木森 潘木生 潘木胜 潘木英 潘木子 潘沐 潘牧 潘慕华 潘那 潘纳 潘娜 潘娜娜 潘乃谷 潘南 潘南金 潘南南 潘楠 潘楠楠 潘能 潘能辉 潘能杰 潘能文 潘能艳 潘妮 潘妮娜 潘妮妮 潘霓 潘年 潘年英 潘念 潘念念 潘念之 潘念中 潘宁 潘宁东 潘宁静 潘宁玲 潘宁宁 潘宁通 潘宁霞 潘宁星 潘柠静 潘农 潘诺 潘攀 潘盼 潘盼盼 潘培 潘培成 潘培德 潘培东 潘培根 潘培华 潘培林 潘培铭 潘培培 潘培青 潘培荣 潘培生 潘培伟 潘培文 潘培新 潘培英 潘培育 潘培忠 潘沛沛 潘佩 潘佩聪 潘佩芳 潘佩芬 潘佩兰 潘佩玲 潘佩佩 潘佩琼 潘佩蓉 潘佩珊 潘佩仪 潘佩玉 潘佩珍 潘朋 潘朋朋 潘鹏 潘鹏程 潘鹏飞 潘鹏举 潘鹏凯 潘鹏鹏 潘鹏宇 潘澎 潘品 潘品方 潘品如 潘平 潘平芳 潘平辉 潘平平 潘平生 潘平洋 潘坪 潘萍 潘萍萍 潘坡 潘璞 潘齐 潘齐龙 潘齐齐 潘祁 潘岐 潘其 潘其彪 潘其彬 潘其昌 潘其成 潘其方 潘其风 潘其峰 潘其华 潘其俊 潘其兰 潘其乐 潘其良 潘其麟 潘其敏 潘其明 潘其武 潘其兴 潘其英 潘其源 潘其岳 潘其忠 潘奇 潘奇峰 潘奇奇 潘奇伟 潘奇志 潘崎 潘琪 潘琪琪 潘琦 潘琦琦 潘琦元 潘棋 潘祺 潘麒 潘麒麟 潘启 潘启彬 潘启才 潘启超 潘启迪 潘启峰 潘启富 潘启光 潘启宏 潘启华 潘启辉 潘启慧 潘启良 潘启亮 潘启林 潘启明 潘启仁 潘启荣 潘启胜 潘启伟 潘启文 潘启贤 潘启兴 潘启雄 潘启勇 潘启源 潘启云 潘启志 潘启忠 潘启柱 潘起 潘起露 潘绮红 潘绮琪 潘绮雯 潘千 潘千千 潘芊羽 潘谦 潘前 潘乾 潘乾坤 潘茜 潘茜茜 潘倩 潘倩倩 潘倩婷 潘倩文 潘倩仪 潘倩怡 潘倩瑜 潘倩玉 潘倩云 潘强 潘强斌 潘强龙 潘强强 潘乔 潘峤 潘巧 潘巧儿 潘巧凤 潘巧红 潘巧洁 潘巧兰 潘巧莲 潘巧玲 潘巧敏 潘巧萍 潘巧巧 潘巧琴 潘巧群 潘巧如 潘巧婷 潘巧燕 潘巧怡 潘巧英 潘巧媛 潘巧云 潘巧珍 潘俏俏 潘俏婷 潘钦 潘芹 潘芹妹 潘芹芹 潘琴 潘琴芳 潘琴芬 潘琴花 潘琴琴 潘琴英 潘勤 潘勤华 潘勤娟 潘勤勤 潘勤毅 潘沁 潘青 潘青海 潘青莲 潘青林 潘青龙 潘青萍 潘青青 潘青山 潘青松 潘青霞 潘青云 潘卿 潘清 潘清波 潘清娥 潘清福 潘清海 潘清河 潘清华 潘清江 潘清兰 潘清莲 潘清林 潘清明 潘清平 潘清清 潘清泉 潘清山 潘清水 潘清文 潘清源 潘情 潘晴 潘晴晴 潘晴雯 潘擎擎 潘庆 潘庆波 潘庆春 潘庆德 潘庆东 潘庆发 潘庆芳 潘庆飞 潘庆丰 潘庆峰 潘庆锋 潘庆福 潘庆国 潘庆海 潘庆宏 潘庆华 潘庆辉 潘庆建 潘庆杰 潘庆聚 潘庆军 潘庆坤 潘庆立 潘庆良 潘庆林 潘庆龙 潘庆民 潘庆明 潘庆平 潘庆庆 潘庆荣 潘庆生 潘庆松 潘庆涛 潘庆伟 潘庆文 潘庆武 潘庆祥 潘庆新 潘庆宇 潘庆玉 潘庆元 潘庆云 潘庆中 潘琼 潘琼芳 潘琼琼 潘琼瑶 潘琼英 潘琼云 潘琼珍 潘秋 潘秋晨 潘秋成 潘秋娥 潘秋芳 潘秋芬 潘秋贵 潘秋红 潘秋花 潘秋华 潘秋菊 潘秋丽 潘秋连 潘秋琳 潘秋玲 潘秋龙 潘秋梅 潘秋妹 潘秋明 潘秋平 潘秋萍 潘秋琴 潘秋秋 潘秋荣 潘秋生 潘秋实 潘秋霞 潘秋香 潘秋艳 潘秋燕 潘秋英 潘秋影 潘秋宇 潘秋玉 潘秋元 潘秋月 潘秋云 潘秋芸 潘求明 潘求仁 潘权 潘全 潘全全 潘全心 潘泉 潘群 潘群斌 潘群娣 潘群芳 潘群飞 潘群群 潘群星 潘群雄 潘群英 潘然 潘冉 潘人杰 潘人美 潘人木 潘仁 潘仁爱 潘仁东 潘仁芳 潘仁锋 潘仁华 潘仁杰 潘仁良 潘仁龙 潘仁美 潘仁清 潘仁山 潘仁伟 潘仁贤 潘仁义 潘仁俞 潘仁云 潘仁志 潘任 潘日波 潘日春 潘日芳 潘日红 潘日华 潘日辉 潘日昆 潘日明 潘日强 潘日润 潘日升 潘日旺 潘日兴 潘荣 潘荣彬 潘荣斌 潘荣波 潘荣才 潘荣福 潘荣光 潘荣贵 潘荣国 潘荣和 潘荣花 潘荣华 潘荣辉 潘荣记 潘荣江 潘荣杰 潘荣军 潘荣妹 潘荣平 潘荣奇 潘荣庆 潘荣荣 潘荣生 潘荣伟 潘荣文 潘荣武 潘荣香 潘荣祥 潘荣兴 潘荣幸 潘荣阳 潘荣勇 潘荣珍 潘容 潘容华 潘容容 潘蓉 潘蓉芳 潘蓉蓉 潘榕 潘榕榕 潘融 潘柔 潘如 潘如川 潘如虎 潘如娟 潘如龙 潘如如 潘如祥 潘如心 潘如意 潘如愿 潘茹 潘茹茹 潘儒 潘儒明 潘汝谦 潘蕊 潘锐 潘锐强 潘瑞 潘瑞波 潘瑞炽 潘瑞春 潘瑞东 潘瑞芳 潘瑞芬 潘瑞锋 潘瑞凤 潘瑞福 潘瑞光 潘瑞国 潘瑞红 潘瑞华 潘瑞吉 潘瑞娟 潘瑞康 潘瑞兰 潘瑞乐 潘瑞丽 潘瑞连 潘瑞莲 潘瑞林 潘瑞玲 潘瑞龙 潘瑞梅 潘瑞敏 潘瑞明 潘瑞鹏 潘瑞平 潘瑞萍 潘瑞琪 潘瑞强 潘瑞芹 潘瑞卿 潘瑞清 潘瑞琼 潘瑞荣 潘瑞瑞 潘瑞生 潘瑞涛 潘瑞文 潘瑞新 潘瑞兴 潘瑞雄 潘瑞雪 潘瑞英 潘瑞勇 潘瑞源 潘瑞云 潘瑞珍 潘瑞芝 潘睿 潘睿晗 潘润 潘润华 潘润兰 潘润林 潘润生 潘若凡 潘若飞 潘若谷 潘若兰 潘若琳 潘若男 潘若若 潘若愚 潘赛 潘赛花 潘赛君 潘赛丽 潘赛男 潘赛赛 潘三 潘三保 潘三毛 潘三梅 潘三明 潘三强 潘三省 潘桑 潘森 潘森林 潘森森 潘沙 潘沙沙 潘莎 潘莎莎 潘山 潘山山 潘杉 潘姗 潘姗姗 潘珊 潘珊珊 潘善龙 潘尚 潘尚宁 潘尚仁 潘尚荣 潘尚书 潘尚文 潘韶华 潘少彬 潘少斌 潘少兵 潘少波 潘少川 潘少春 潘少聪 潘少丹 潘少东 潘少芳 潘少飞 潘少芬 潘少峰 潘少锋 潘少凤 潘少红 潘少华 潘少辉 潘少杰 潘少娟 潘少军 潘少君 潘少俊 潘少康 潘少丽 潘少林 潘少玲 潘少龙 潘少梅 潘少媚 潘少敏 潘少明 潘少鹏 潘少平 潘少萍 潘少强 潘少琴 潘少青 潘少卿 潘少清 潘少琼 潘少群 潘少荣 潘少松 潘少婷 潘少微 潘少伟 潘少文 潘少武 潘少霞 潘少香 潘少雄 潘少燕 潘少阳 潘少英 潘少勇 潘少玉 潘少元 潘少云 潘少珍 潘绍斌 潘绍春 潘绍顿 潘绍光 潘绍国 潘绍华 潘绍军 潘绍敏 潘绍明 潘绍荣 潘绍松 潘绍伟 潘绍文 潘绍武 潘绍义 潘申军 潘深 潘深亮 潘慎 潘升 潘生 潘声 潘声安 潘圣 潘圣和 潘圣华 潘圣杰 潘圣洁 潘圣峤 潘圣伟 潘胜 潘胜斌 潘胜兵 潘胜国 潘胜华 潘胜军 潘胜兰 潘胜蓝 潘胜利 潘胜明 潘胜男 潘胜平 潘胜文 潘胜武 潘胜艳 潘胜勇 潘晟 潘盛 潘盛彬 潘盛华 潘盛杰 潘盛林 潘盛荣 潘盛盛 潘盛洲 潘师 潘诗 潘诗华 潘诗琪 潘诗诗 潘诗婷 潘诗宇 潘诗雨 潘诗韵 潘施施 潘石 潘石屹 潘时雨 潘时中 潘实 潘士超 潘士诚 潘士海 潘士杰 潘士金 潘士军 潘士君 潘士明 潘士平 潘士萍 潘士强 潘士权 潘士文 潘士贤 潘士勇 潘士远 潘世 潘世安 潘世宝 潘世标 潘世斌 潘世兵 潘世波 潘世才 潘世财 潘世昌 潘世超 潘世成 潘世春 潘世达 潘世东 潘世栋 潘世恩 潘世芳 潘世芬 潘世丰 潘世峰 潘世锋 潘世刚 潘世光 潘世贵 潘世国 潘世海 潘世豪 潘世红 潘世宏 潘世洪 潘世鸿 潘世华 潘世辉 潘世佳 潘世江 潘世杰 潘世娟 潘世军 潘世俊 潘世凯 潘世奎 潘世坤 潘世兰 潘世立 潘世良 潘世亮 潘世林 潘世玲 潘世龙 潘世纶 潘世梅 潘世美 潘世民 潘世敏 潘世明 潘世墨 潘世鹏 潘世平 潘世萍 潘世奇 潘世强 潘世琴 潘世清 潘世权 潘世全 潘世泉 潘世群 潘世荣 潘世生 潘世涛 潘世旺 潘世伟 潘世文 潘世武 潘世霞 潘世祥 潘世新 潘世鑫 潘世雄 潘世勋 潘世燕 潘世洋 潘世英 潘世勇 潘世友 潘世宇 潘世玉 潘世元 潘世征 潘世忠 潘仕 潘仕彬 潘仕成 潘仕华 潘仕明 潘仕平 潘仕强 潘仕荣 潘仕香 潘守波 潘守刚 潘守理 潘守前 潘守永 潘寿 潘寿华 潘寿君 潘寿民 潘寿荣 潘寿山 潘书 潘书成 潘书芳 潘书华 潘书京 潘书琴 潘书文 潘叔明 潘姝 潘姝妍 潘姝羽 潘淑 潘淑冰 潘淑芳 潘淑芬 潘淑红 潘淑花 潘淑华 潘淑惠 潘淑洁 潘淑静 潘淑娟 潘淑君 潘淑兰 潘淑丽 潘淑莲 潘淑玲 潘淑梅 潘淑媚 潘淑敏 潘淑萍 潘淑芹 潘淑琴 潘淑青 潘淑琼 潘淑荣 潘淑淑 潘淑婷 潘淑霞 潘淑贤 潘淑娴 潘淑艳 潘淑仪 潘淑怡 潘淑英 潘淑媛 潘淑云 潘淑贞 潘淑珍 潘淑真 潘淑芝 潘舒 潘舒婷 潘蜀健 潘曙 潘曙光 潘述 潘树 潘树才 潘树峰 潘树根 潘树广 潘树国 潘树红 潘树花 潘树华 潘树军 潘树立 潘树林 潘树龙 潘树茂 潘树明 潘树平 潘树强 潘树青 潘树清 潘树荣 潘树森 潘树生 潘树伟 潘树祥 潘树英 潘树云 潘树珍 潘恕 潘澍 潘帅 潘帅军 潘帅帅 潘双 潘双福 潘双红 潘双利 潘双林 潘双明 潘双平 潘双萍 潘双双 潘双喜 潘双燕 潘霜 潘霜霜 潘爽 潘水 潘水芳 潘水根 潘水华 潘水娇 潘水金 潘水锦 潘水兰 潘水连 潘水林 潘水龙 潘水妹 潘水明 潘水平 潘水琴 潘水清 潘水泉 潘水仙 潘水英 潘顺 潘顺宝 潘顺昌 潘顺成 潘顺法 潘顺华 潘顺利 潘顺明 潘顺强 潘顺荣 潘顺顺 潘顺兴 潘顺玉 潘舜 潘烁 潘朔端 潘硕 潘丝丝 潘思 潘思辰 潘思达 潘思凡 潘思宏 潘思佳 潘思洁 潘思敬 潘思静 潘思亮 潘思敏 潘思明 潘思宁 潘思齐 潘思琪 潘思强 潘思琴 潘思睿 潘思思 潘思婷 潘思同 潘思文 潘思娴 潘思旋 潘思雅 潘思怡 潘思颖 潘思予 潘思宇 潘思羽 潘思雨 潘思源 潘思远 潘思竹 潘斯 潘斯斯 潘四 潘四安 潘四海 潘四林 潘四毛 潘松 潘松柏 潘松波 潘松和 潘松华 潘松林 潘松茂 潘松年 潘松萍 潘松青 潘松松 潘松涛 潘松岩 潘嵩 潘颂 潘颂德 潘苏 潘苏华 潘苏平 潘苏苏 潘苏通 潘夙 潘素 潘素芳 潘素芬 潘素红 潘素花 潘素华 潘素静 潘素娟 潘素君 潘素兰 潘素玲 潘素梅 潘素敏 潘素平 潘素琴 潘素素 潘素文 潘素雅 潘素艳 潘素英 潘素莹 潘素云 潘素珍 潘速跃 潘绥铭 潘遂 潘穗华 潘太平 潘太水 潘泰 潘坛 潘潭 潘唐 潘堂 潘堂林 潘涛 潘涛涛 潘滔 潘韬 潘桃 潘桃红 潘陶 潘陶宇 潘淘 潘腾 潘腾达 潘腾飞 潘腾腾 潘天 潘天宝 潘天保 潘天成 潘天赐 潘天峰 潘天福 潘天耕 潘天贵 潘天红 潘天华 潘天慧 潘天乐 潘天良 潘天龙 潘天明 潘天鹏 潘天群 潘天寿 潘天舒 潘天天 潘天文 潘天星 潘天雄 潘天一 潘天佑 潘天宇 潘天雨 潘田 潘田田 潘恬 潘恬恬 潘甜 潘甜甜 潘铁 潘铁成 潘铁夫 潘铁军 潘铁民 潘铁文 潘铁柱 潘廷 潘廷贵 潘廷华 潘廷荣 潘廷祥 潘廷勇 潘亭 潘亭亭 潘婷 潘婷婷 潘婷玉 潘霆 潘挺 潘挺挺 潘挺宇 潘通 潘同 潘同春 潘彤 潘彤彤 潘桐 潘统衡 潘拓 潘湾 潘婉 潘婉静 潘婉玲 潘婉婷 潘婉婉 潘婉霞 潘皖江 潘万 潘万发 潘万华 潘万里 潘万雄 潘万英 潘王 潘王锋 潘旺 潘旺生 潘望 潘望博 潘威 潘威威 潘微 潘微微 潘薇 潘薇薇 潘巍 潘巍巍 潘韦 潘为 潘为华 潘为民 潘为明 潘唯 潘惟昕 潘维 潘维安 潘维成 潘维东 潘维芳 潘维刚 潘维国 潘维红 潘维华 潘维杰 潘维军 潘维君 潘维良 潘维敏 潘维明 潘维宁 潘维平 潘维强 潘维荣 潘维生 潘维胜 潘维松 潘维涛 潘维维 潘维新 潘维娅 潘维英 潘维忠 潘伟 潘伟安 潘伟柏 潘伟标 潘伟彬 潘伟斌 潘伟滨 潘伟波 潘伟伯 潘伟博 潘伟才 潘伟昌 潘伟超 潘伟城 潘伟川 潘伟聪 潘伟达 潘伟迪 潘伟东 潘伟芳 潘伟飞 潘伟芬 潘伟丰 潘伟锋 潘伟光 潘伟国 潘伟行 潘伟豪 潘伟红 潘伟洪 潘伟华 潘伟佳 潘伟坚 潘伟健 潘伟江 潘伟杰 潘伟娟 潘伟军 潘伟君 潘伟康 潘伟坤 潘伟良 潘伟烈 潘伟龙 潘伟伦 潘伟民 潘伟敏 潘伟明 潘伟宁 潘伟平 潘伟萍 潘伟奇 潘伟强 潘伟琴 潘伟清 潘伟权 潘伟荣 潘伟森 潘伟生 潘伟涛 潘伟庭 潘伟婷 潘伟伟 潘伟文 潘伟贤 潘伟祥 潘伟翔 潘伟新 潘伟雄 潘伟燕 潘伟阳 潘伟业 潘伟毅 潘伟勇 潘伟源 潘伟云 潘伟珍 潘伟中 潘伟忠 潘纬 潘玮 潘玮伯 潘玮博 潘玮玮 潘玮仪 潘炜 潘炜杰 潘炜炜 潘卫 潘卫斌 潘卫兵 潘卫东 潘卫芳 潘卫芬 潘卫丰 潘卫峰 潘卫锋 潘卫刚 潘卫国 潘卫红 潘卫华 潘卫杰 潘卫娟 潘卫军 潘卫利 潘卫玲 潘卫民 潘卫明 潘卫娜 潘卫平 潘卫萍 潘卫强 潘卫庆 潘卫三 潘卫卫 潘卫新 潘卫星 潘卫英 潘卫珍 潘卫忠 潘未 潘尉 潘渭水 潘蔚 潘蔚琳 潘蔚蔚 潘蔚颖 潘慰 潘文 潘文安 潘文柏 潘文宝 潘文标 潘文彬 潘文斌 潘文炳 潘文波 潘文博 潘文才 潘文灿 潘文昌 潘文超 潘文成 潘文春 潘文聪 潘文得 潘文迪 潘文东 潘文芳 潘文飞 潘文峰 潘文锋 潘文凤 潘文富 潘文刚 潘文高 潘文革 潘文阁 潘文光 潘文广 潘文圭 潘文贵 潘文国 潘文海 潘文豪 潘文昊 潘文浩 潘文洪 潘文虎 潘文华 潘文辉 潘文慧 潘文基 潘文佳 潘文剑 潘文健 潘文杰 潘文捷 潘文婕 潘文锦 潘文进 潘文晶 潘文静 潘文举 潘文娟 潘文军 潘文君 潘文俊 潘文凯 潘文科 潘文魁 潘文兰 潘文乐 潘文利 潘文莉 潘文良 潘文亮 潘文林 潘文琳 潘文玲 潘文龙 潘文梅 潘文美 潘文敏 潘文明 潘文年 潘文平 潘文萍 潘文琦 潘文倩 潘文强 潘文钦 潘文勤 潘文卿 潘文清 潘文庆 潘文权 潘文全 潘文荣 潘文山 潘文珊 潘文生 潘文胜 潘文盛 潘文石 潘文帅 潘文硕 潘文思 潘文松 潘文堂 潘文涛 潘文韬 潘文婷 潘文旺 潘文伟 潘文文 潘文武 潘文熙 潘文霞 潘文仙 潘文贤 潘文祥 潘文翔 潘文晓 潘文心 潘文新 潘文鑫 潘文兴 潘文秀 潘文轩 潘文学 潘文雅 潘文炎 潘文艳 潘文耀 潘文晔 潘文艺 潘文意 潘文英 潘文颖 潘文勇 潘文瑜 潘文宇 潘文玉 潘文渊 潘文元 潘文媛 潘文远 潘文云 潘文哲 潘文珍 潘文政 潘文志 潘文治 潘文智 潘文忠 潘文卓 潘文宗 潘闻起 潘闻特 潘闻艇 潘闻舟 潘雯 潘雯洁 潘雯锦 潘雯静 潘雯君 潘雯婷 潘雯文 潘雯雯 潘吾华 潘吴 潘五云 潘武 潘武杰 潘武强 潘武雄 潘悟云 潘西 潘西平 潘西西 潘希 潘希贵 潘希军 潘希亮 潘希明 潘希平 潘希强 潘希庆 潘希武 潘希希 潘希真 潘锡 潘锡春 潘锡锋 潘锡光 潘锡贵 潘锡海 潘锡豪 潘锡珩 潘锡华 潘锡辉 潘锡金 潘锡军 潘锡林 潘锡明 潘锡平 潘锡萍 潘锡强 潘锡堂 潘锡源 潘溪 潘熙 潘熙淦 潘熙宇 潘曦 潘习龙 潘玺 潘喜 潘喜凤 潘喜红 潘喜华 潘喜良 潘喜喜 潘喜英 潘细桂 潘细华 潘细梅 潘细妹 潘细平 潘侠风 潘侠宏 潘霞 潘霞飞 潘霞芬 潘霞霞 潘霞云 潘夏 潘仙红 潘仙华 潘仙娟 潘仙梅 潘仙仙 潘先 潘先德 潘先锋 潘先海 潘先红 潘先觉 潘先进 潘先林 潘先明 潘先平 潘先荣 潘先伟 潘先文 潘先英 潘贤 潘贤斌 潘贤波 潘贤春 潘贤达 潘贤庚 潘贤华 潘贤民 潘贤明 潘贤群 潘贤勇 潘咸 潘娴 潘显 潘显光 潘显浩 潘显红 潘显礼 潘显明 潘显文 潘险峰 潘宪 潘宪生 潘羡 潘献忠 潘相 潘相斌 潘相臣 潘相铭 潘相仁 潘相武 潘相宇 潘香 潘香春 潘香君 潘香兰 潘香莲 潘香琴 潘香香 潘香云 潘湘 潘湘虹 潘湘湘 潘祥 潘祥春 潘祥华 潘祥辉 潘祥亮 潘祥林 潘祥龙 潘祥明 潘祥生 潘祥松 潘翔 潘翔翔 潘想 潘向 潘向东 潘向光 潘向华 潘向军 潘向黎 潘向明 潘向前 潘向荣 潘向阳 潘向宇 潘肖 潘肖红 潘肖玲 潘肖鹏 潘肖肖 潘骁 潘萧 潘潇 潘潇汝 潘潇潇 潘霄 潘霄雷 潘晓 潘晓安 潘晓蓓 潘晓彬 潘晓斌 潘晓波 潘晓晨 潘晓成 潘晓川 潘晓春 潘晓纯 潘晓丹 潘晓东 潘晓冬 潘晓栋 潘晓芳 潘晓飞 潘晓菲 潘晓芬 潘晓峰 潘晓锋 潘晓凤 潘晓刚 潘晓光 潘晓航 潘晓红 潘晓宏 潘晓虹 潘晓虎 潘晓华 潘晓晖 潘晓辉 潘晓慧 潘晓佳 潘晓江 潘晓娇 潘晓杰 潘晓洁 潘晓金 潘晓瑾 潘晓菁 潘晓晶 潘晓静 潘晓娟 潘晓军 潘晓均 潘晓君 潘晓凯 潘晓兰 潘晓雷 潘晓磊 潘晓蕾 潘晓黎 潘晓丽 潘晓利 潘晓莉 潘晓莲 潘晓良 潘晓亮 潘晓林 潘晓琳 潘晓灵 潘晓玲 潘晓凌 潘晓龙 潘晓璐 潘晓露 潘晓梅 潘晓美 潘晓妹 潘晓萌 潘晓敏 潘晓明 潘晓鸣 潘晓铭 潘晓娜 潘晓楠 潘晓宁 潘晓诺 潘晓鸥 潘晓平 潘晓萍 潘晓琦 潘晓倩 潘晓强 潘晓琴 潘晓勤 潘晓青 潘晓清 潘晓晴 潘晓庆 潘晓琼 潘晓秋 潘晓泉 潘晓群 潘晓蕊 潘晓瑞 潘晓珊 潘晓生 潘晓松 潘晓棠 潘晓涛 潘晓婷 潘晓彤 潘晓威 潘晓薇 潘晓伟 潘晓文 潘晓雯 潘晓霞 潘晓夏 潘晓贤 潘晓娴 潘晓翔 潘晓晓 潘晓欣 潘晓旭 潘晓雪 潘晓亚 潘晓妍 潘晓艳 潘晓燕 潘晓扬 潘晓阳 潘晓杨 潘晓依 潘晓怡 潘晓毅 潘晓懿 潘晓英 潘晓莹 潘晓永 潘晓勇 潘晓瑜 潘晓宇 潘晓雨 潘晓玉 潘晓月 潘晓云 潘晓芸 潘晓珍 潘晓忠 潘晓竹 潘筱 潘筱颖 潘孝 潘孝斌 潘孝兵 潘孝财 潘孝成 潘孝国 潘孝海 潘孝华 潘孝军 潘孝兰 潘孝利 潘孝良 潘孝明 潘孝鹏 潘孝平 潘孝仁 潘孝生 潘孝伟 潘孝文 潘孝武 潘孝胤 潘孝勇 潘孝云 潘孝贞 潘孝珍 潘孝政 潘孝忠 潘校 潘笑 潘笑梅 潘笑笑 潘啸 潘啸虎 潘啸龙 潘协庆 潘心超 潘心城 潘心富 潘心如 潘心怡 潘心雨 潘心元 潘心悦 潘辛菱 潘辛平 潘昕 潘昕昕 潘昕怡 潘昕宇 潘欣 潘欣如 潘欣彤 潘欣欣 潘欣仪 潘欣怡 潘欣宇 潘欣雨 潘欣悦 潘新 潘新潮 潘新成 潘新初 潘新春 潘新东 潘新发 潘新芳 潘新丰 潘新峰 潘新凤 潘新刚 潘新国 潘新和 潘新红 潘新花 潘新华 潘新辉 潘新杰 潘新军 潘新丽 潘新良 潘新亮 潘新玲 潘新龙 潘新路 潘新梅 潘新妹 潘新民 潘新明 潘新年 潘新平 潘新萍 潘新桥 潘新群 潘新荣 潘新生 潘新胜 潘新水 潘新伟 潘新文 潘新霞 潘新祥 潘新新 潘新兴 潘新燕 潘新英 潘新颖 潘新宇 潘新元 潘新月 潘新云 潘新忠 潘馨 潘馨园 潘鑫 潘鑫华 潘鑫杰 潘鑫龙 潘鑫淼 潘鑫鑫 潘信 潘信福 潘信荣 潘信伟 潘信宇 潘星 潘星安 潘星辰 潘星光 潘星海 潘星华 潘星辉 潘星兰 潘星霖 潘星明 潘星星 潘星旭 潘星谊 潘星宇 潘星月 潘兴 潘兴超 潘兴德 潘兴发 潘兴峰 潘兴福 潘兴贵 潘兴国 潘兴海 潘兴宏 潘兴华 潘兴建 潘兴军 潘兴良 潘兴林 潘兴龙 潘兴隆 潘兴茂 潘兴梅 潘兴明 潘兴平 潘兴强 潘兴全 潘兴泉 潘兴荣 潘兴涛 潘兴旺 潘兴伟 潘兴文 潘兴午 潘兴武 潘兴祥 潘兴兴 潘兴业 潘兴瑜 潘兴元 潘杏 潘杏春 潘杏梅 潘杏萍 潘杏英 潘雄 潘雄飞 潘雄伟 潘雄雄 潘雄易 潘熊飞 潘修成 潘修雷 潘修龙 潘修平 潘修中 潘秀成 潘秀达 潘秀丹 潘秀东 潘秀娥 潘秀芳 潘秀芬 潘秀峰 潘秀凤 潘秀花 潘秀华 潘秀慧 潘秀江 潘秀杰 潘秀菁 潘秀菊 潘秀娟 潘秀君 潘秀兰 潘秀丽 潘秀连 潘秀莲 潘秀林 潘秀玲 潘秀龙 潘秀梅 潘秀美 潘秀敏 潘秀明 潘秀女 潘秀萍 潘秀芹 潘秀琴 潘秀青 潘秀清 潘秀琼 潘秀荣 潘秀容 潘秀茹 潘秀桃 潘秀婷 潘秀伟 潘秀文 潘秀霞 潘秀仙 潘秀秀 潘秀银 潘秀英 潘秀莺 潘秀云 潘秀贞 潘秀珍 潘秀芝 潘秀枝 潘徐 潘栩 潘旭 潘旭晨 潘旭初 潘旭东 潘旭芳 潘旭峰 潘旭光 潘旭华 潘旭晖 潘旭辉 潘旭澜 潘旭丽 潘旭亮 潘旭临 潘旭明 潘旭婷 潘旭伟 潘旭文 潘叙 潘勖 潘绪明 潘宣 潘萱 潘暄 潘煊 潘玄 潘旋 潘璇 潘璇璇 潘炫 潘学 潘学标 潘学彪 潘学彬 潘学斌 潘学兵 潘学才 潘学超 潘学成 潘学聪 潘学东 潘学芳 潘学飞 潘学峰 潘学锋 潘学广 潘学海 潘学宏 潘学洪 潘学华 潘学辉 潘学慧 潘学军 潘学君 潘学俊 潘学凯 潘学礼 潘学丽 潘学良 潘学林 潘学琳 潘学玲 潘学龙 潘学美 潘学民 潘学敏 潘学明 潘学模 潘学平 潘学强 潘学琴 潘学勤 潘学清 潘学仁 潘学荣 潘学诗 潘学松 潘学涛 潘学伟 潘学文 潘学武 潘学新 潘学燕 潘学义 潘学英 潘学勇 潘学元 潘学政 潘学志 潘学智 潘学忠 潘雪 潘雪春 潘雪东 潘雪娥 潘雪儿 潘雪芳 潘雪飞 潘雪芬 潘雪峰 潘雪凤 潘雪红 潘雪花 潘雪华 潘雪娇 潘雪静 潘雪娟 潘雪君 潘雪兰 潘雪丽 潘雪利 潘雪莉 潘雪连 潘雪莲 潘雪林 潘雪玲 潘雪梅 潘雪美 潘雪妹 潘雪明 潘雪平 潘雪萍 潘雪芹 潘雪琴 潘雪清 潘雪茹 潘雪松 潘雪婷 潘雪雪 潘雪艳 潘雪英 潘雪莹 潘雪玉 潘雪云 潘雪珍 潘雪珠 潘勋 潘洵 潘训 潘迅 潘逊 潘雅 潘雅芳 潘雅芬 潘雅红 潘雅婧 潘雅静 潘雅娟 潘雅君 潘雅丽 潘雅琳 潘雅玲 潘雅男 潘雅琪 潘雅清 潘雅琼 潘雅茹 潘雅婷 潘雅文 潘雅雯 潘雅欣 潘雅雅 潘亚 潘亚斌 潘亚成 潘亚丹 潘亚东 潘亚飞 潘亚芬 潘亚红 潘亚华 潘亚杰 潘亚静 潘亚菊 潘亚娟 潘亚军 潘亚君 潘亚奎 潘亚坤 潘亚兰 潘亚岚 潘亚磊 潘亚丽 潘亚利 潘亚梁 潘亚林 潘亚玲 潘亚梅 潘亚妹 潘亚敏 潘亚明 潘亚娜 潘亚男 潘亚南 潘亚楠 潘亚宁 潘亚鹏 潘亚平 潘亚萍 潘亚琴 潘亚青 潘亚群 潘亚茹 潘亚婷 潘亚威 潘亚文 潘亚雄 潘亚亚 潘亚英 潘亚中 潘娅 潘娅丽 潘娅娅 潘延 潘延芳 潘延华 潘延辉 潘延军 潘延龙 潘延平 潘延强 潘严 潘言 潘妍 潘妍妍 潘岩 潘岩松 潘岩岩 潘炎 潘炎冰 潘炎炎 潘研 潘衍 潘衍有 潘琰 潘演 潘彦 潘彦冰 潘彦辰 潘彦丞 潘彦芳 潘彦妃 潘彦华 潘彦君 潘彦霖 潘彦伶 潘彦玲 潘彦龙 潘彦霓 潘彦平 潘彦蓉 潘彦如 潘彦宇 潘彦昭 潘艳 潘艳冰 潘艳春 潘艳菲 潘艳芬 潘艳凤 潘艳刚 潘艳红 潘艳华 潘艳辉 潘艳娇 潘艳杰 潘艳娟 潘艳军 潘艳君 潘艳兰 潘艳丽 潘艳莉 潘艳玲 潘艳梅 潘艳敏 潘艳妮 潘艳平 潘艳萍 潘艳清 潘艳琼 潘艳秋 潘艳荣 潘艳如 潘艳茹 潘艳涛 潘艳霞 潘艳艳 潘艳阳 潘晏 潘雁 潘焱 潘燕 潘燕芳 潘燕飞 潘燕芬 潘燕红 潘燕华 潘燕辉 潘燕军 潘燕君 潘燕坤 潘燕林 潘燕龙 潘燕梅 潘燕明 潘燕南 潘燕妮 潘燕平 潘燕萍 潘燕卿 潘燕清 潘燕群 潘燕生 潘燕涛 潘燕婷 潘燕文 潘燕舞 潘燕霞 潘燕颜 潘燕燕 潘燕珍 潘燕子 潘央央 潘扬 潘扬扬 潘阳 潘阳林 潘阳生 潘阳阳 潘杨 潘杨柳 潘杨文 潘杨杨 潘洋 潘洋洋 潘尧 潘遥 潘瑶 潘瑶菁 潘瑶瑶 潘耀 潘耀滨 潘耀昌 潘耀焯 潘耀东 潘耀光 潘耀国 潘耀华 潘耀辉 潘耀军 潘耀龙 潘耀民 潘耀明 潘耀平 潘耀强 潘耀荣 潘耀伟 潘耀武 潘耀忠 潘耀宗 潘耀祖 潘业 潘业成 潘业峰 潘业美 潘叶 潘叶飞 潘叶锋 潘叶华 潘叶金 潘叶娟 潘叶琴 潘叶青 潘叶清 潘夜 潘晔 潘一 潘一波 潘一尘 潘一丹 潘一帆 潘一凡 潘一飞 潘一夫 潘一禾 潘一恒 潘一华 潘一军 潘一君 潘一龙 潘一鸣 潘一铭 潘一楠 潘一宁 潘一平 潘一萍 潘一山 潘一心 潘一新 潘一雄 潘一中 潘伊娜 潘伊文 潘依 潘依诺 潘依婷 潘依依 潘祎 潘漪 潘仪君 潘怡 潘怡冰 潘怡程 潘怡帆 潘怡婧 潘怡静 潘怡君 潘怡良 潘怡霖 潘怡蒙 潘怡如 潘怡婷 潘怡雯 潘怡萱 潘怡颖 潘宜 潘宜平 潘宜云 潘贻明 潘乙 潘义 潘义红 潘义明 潘义平 潘义清 潘义生 潘义勇 潘义友 潘艺 潘艺峰 潘艺林 潘艺婷 潘艺文 潘艺心 潘忆影 潘屹 潘亦 潘亦琳 潘亦松 潘异 潘易 潘轶 潘奕 潘奕帆 潘奕峰 潘奕君 潘奕钧 潘奕隽 潘奕霖 潘奕如 潘奕彤 潘奕奕 潘益 潘益斌 潘益波 潘益德 潘益峰 潘益锋 潘益红 潘益华 潘益杰 潘益龙 潘益民 潘益明 潘益平 潘益萍 潘益伟 潘逸 潘逸凡 潘逸飞 潘逸峰 潘逸华 潘逸婷 潘逸阳 潘意 潘意标 潘溢 潘毅 潘毅华 潘毅龙 潘毅琴 潘毅群 潘熠 潘翼 潘懿 潘因 潘茵茵 潘音 潘银 潘银钗 潘银芳 潘银海 潘银红 潘银花 潘银辉 潘银莲 潘银龙 潘银妹 潘银平 潘银萍 潘银生 潘银婷 潘银霞 潘银银 潘银英 潘寅 潘隐 潘印 潘胤 潘英 潘英才 潘英东 潘英豪 潘英红 潘英华 潘英慧 潘英杰 潘英俊 潘英丽 潘英良 潘英梅 潘英妹 潘英明 潘英男 潘英鹏 潘英涛 潘英伟 潘英霞 潘英贤 潘英英 潘英姿 潘英子 潘莺 潘莺莺 潘瑛 潘瑛瑛 潘缨 潘樱 潘樱子 潘鹰 潘迎 潘迎春 潘迎华 潘迎捷 潘迎宪 潘迎新 潘迎迎 潘迎紫 潘盈 潘盈如 潘盈盈 潘盈颖 潘莹 潘莹春 潘莹莹 潘营 潘滢 潘赢 潘颍 潘颖 潘颖超 潘颖晨 潘颖慧 潘颖秋 潘颖松 潘颖婷 潘颖欣 潘颖颖 潘颖展 潘影 潘应华 潘应龙 潘应强 潘映 潘映红 潘映霞 潘映新 潘映雪 潘庸 潘雍 潘永 潘永安 潘永标 潘永斌 潘永兵 潘永波 潘永才 潘永昌 潘永超 潘永成 潘永传 潘永春 潘永德 潘永东 潘永芳 潘永飞 潘永芬 潘永丰 潘永峰 潘永锋 潘永福 潘永富 潘永刚 潘永根 潘永光 潘永贵 潘永国 潘永海 潘永浩 潘永和 潘永恒 潘永红 潘永洪 潘永鸿 潘永华 潘永辉 潘永惠 潘永嘉 潘永坚 潘永建 潘永健 潘永江 潘永杰 潘永金 潘永进 潘永久 潘永娟 潘永军 潘永俊 潘永康 潘永宽 潘永坤 潘永兰 潘永乐 潘永利 潘永良 潘永亮 潘永林 潘永玲 潘永龙 潘永禄 潘永梅 潘永敏 潘永明 潘永年 潘永平 潘永萍 潘永奇 潘永强 潘永琴 潘永勤 潘永青 潘永清 潘永庆 潘永权 潘永全 潘永泉 潘永荣 潘永瑞 潘永森 潘永升 潘永生 潘永胜 潘永顺 潘永思 潘永松 潘永泰 潘永涛 潘永旺 潘永伟 潘永文 潘永祥 潘永翔 潘永新 潘永鑫 潘永兴 潘永雄 潘永秀 潘永耀 潘永怡 潘永英 潘永源 潘永长 潘永珍 潘永正 潘永志 潘永忠 潘永钟 潘咏 潘咏梅 潘泳 潘泳欣 潘泳仪 潘泳怡 潘勇 潘勇成 潘勇辉 潘勇坚 潘勇军 潘勇明 潘勇平 潘勇强 潘勇全 潘勇涛 潘勇勇 潘勇智 潘涌 潘优优 潘悠 潘友 潘友芳 潘友富 潘友宏 潘友华 潘友军 潘友良 潘友林 潘友民 潘友明 潘友文 潘友新 潘友谊 潘有 潘有财 潘有德 潘有军 潘有良 潘有梅 潘有强 潘有田 潘有为 潘有志 潘又安 潘佑 潘佑强 潘余 潘余庆 潘妤 潘鱼 潘渝 潘瑜 潘瑜华 潘榆文 潘予 潘宇 潘宇斌 潘宇超 潘宇晨 潘宇东 潘宇飞 潘宇海 潘宇涵 潘宇航 潘宇豪 潘宇恒 潘宇红 潘宇杰 潘宇俊 潘宇凌 潘宇明 潘宇鹏 潘宇琦 潘宇婷 潘宇文 潘宇翔 潘宇星 潘宇轩 潘宇阳 潘羽 潘羽琦 潘雨 潘雨辰 潘雨晨 潘雨风 潘雨红 潘雨虹 潘雨佳 潘雨露 潘雨茜 潘雨晴 潘雨杉 潘雨亭 潘雨婷 潘雨彤 潘雨桐 潘雨薇 潘雨馨 潘禹 潘禹辰 潘禹彤 潘语嫣 潘玉 潘玉宝 潘玉彬 潘玉斌 潘玉冰 潘玉兵 潘玉彩 潘玉婵 潘玉成 潘玉春 潘玉翠 潘玉丹 潘玉德 潘玉东 潘玉娥 潘玉儿 潘玉芳 潘玉芬 潘玉峰 潘玉锋 潘玉凤 潘玉福 潘玉根 潘玉贵 潘玉国 潘玉海 潘玉红 潘玉花 潘玉华 潘玉环 潘玉家 潘玉江 潘玉娇 潘玉姣 潘玉杰 潘玉洁 潘玉进 潘玉井 潘玉娟 潘玉军 潘玉君 潘玉奎 潘玉坤 潘玉兰 潘玉乐 潘玉利 潘玉莲 潘玉良 潘玉亮 潘玉林 潘玉琳 潘玉麟 潘玉玲 潘玉龙 潘玉梅 潘玉美 潘玉妹 潘玉民 潘玉敏 潘玉明 潘玉鹏 潘玉平 潘玉萍 潘玉琪 潘玉强 潘玉芹 潘玉琴 潘玉青 潘玉清 潘玉庆 潘玉琼 潘玉秋 潘玉全 潘玉泉 潘玉群 潘玉仁 潘玉荣 潘玉蓉 潘玉森 潘玉山 潘玉生 潘玉书 潘玉双 潘玉堂 潘玉涛 潘玉亭 潘玉婷 潘玉伟 潘玉文 潘玉玺 潘玉霞 潘玉仙 潘玉先 潘玉香 潘玉祥 潘玉欣 潘玉新 潘玉秀 潘玉艳 潘玉燕 潘玉英 潘玉莹 潘玉宇 潘玉玉 潘玉云 潘玉珍 潘玉芝 潘玉忠 潘玉珠 潘玉柱 潘郁 潘郁生 潘育超 潘育红 潘育伟 潘育英 潘昱 潘昱辰 潘昱含 潘昱廷 潘钰 潘喻 潘裕 潘裕柏 潘裕佳 潘裕昆 潘裕平 潘裕仁 潘裕生 潘裕文 潘裕钰 潘煜 潘誉 潘毓 潘毓刚 潘毓平 潘渊 潘元 潘元成 潘元春 潘元福 潘元甲 潘元军 潘元俊 潘元坤 潘元明 潘元培 潘元清 潘元生 潘元元 潘元忠 潘园 潘园园 潘垣 潘原 潘圆 潘圆圆 潘援朝 潘媛 潘媛媛 潘源 潘源良 潘源泉 潘源源 潘远 潘远波 潘远超 潘远东 潘远芳 潘远飞 潘远平 潘远洋 潘苑 潘苑苑 潘月 潘月娥 潘月芬 潘月峰 潘月凤 潘月桂 潘月红 潘月花 潘月华 潘月辉 潘月娇 潘月洁 潘月娟 潘月俊 潘月兰 潘月丽 潘月玲 潘月龙 潘月梅 潘月美 潘月妹 潘月明 潘月鹏 潘月芹 潘月琴 潘月亭 潘月婷 潘月霞 潘月仙 潘月香 潘月新 潘月瑶 潘月英 潘月月 潘月云 潘月珍 潘玥 潘岳 潘岳峰 潘岳华 潘岳军 潘岳林 潘岳明 潘钺 潘悦 潘跃 潘跃东 潘跃飞 潘跃国 潘跃红 潘跃华 潘跃进 潘跃军 潘跃林 潘跃龙 潘跃平 潘跃伟 潘跃新 潘跃勇 潘跃跃 潘越 潘越飞 潘越峰 潘越华 潘越男 潘越翔 潘越云 潘粤明 潘赟 潘云 潘云斌 潘云波 潘云超 潘云川 潘云娣 潘云东 潘云芳 潘云飞 潘云芬 潘云峰 潘云锋 潘云凤 潘云富 潘云贵 潘云国 潘云海 潘云浩 潘云鹤 潘云红 潘云华 潘云辉 潘云娇 潘云姣 潘云杰 潘云菊 潘云娟 潘云开 潘云兰 潘云良 潘云林 潘云龙 潘云梅 潘云鹏 潘云平 潘云萍 潘云强 潘云青 潘云清 潘云山 潘云生 潘云水 潘云松 潘云涛 潘云天 潘云曦 潘云喜 潘云侠 潘云霞 潘云仙 潘云香 潘云祥 潘云翔 潘云霄 潘云艳 潘云燕 潘云云 潘云召 潘云贞 潘云珍 潘云忠 潘芸 潘芸芸 潘昀 潘耘 潘鋆 潘允端 潘允康 潘允亮 潘运 潘运国 潘运华 潘运兰 潘运龙 潘运明 潘运生 潘韵 潘韵涵 潘韵如 潘韵雯 潘韵怡 潘韵芝 潘蕴 潘蕴如 潘再红 潘再平 潘再宇 潘在阳 潘赞 潘赞海 潘赞化 潘泽 潘泽波 潘泽成 潘泽东 潘泽峰 潘泽锋 潘泽海 潘泽华 潘泽辉 潘泽慧 潘泽金 潘泽军 潘泽林 潘泽龙 潘泽民 潘泽明 潘泽南 潘泽平 潘泽文 潘泽雄 潘泽亚 潘泽勇 潘泽宇 潘增弟 潘增华 潘增辉 潘增明 潘增源 潘瞻远 潘展 潘占军 潘占林 潘战伟 潘张 潘章 潘璋 潘长安 潘长春 潘长东 潘长发 潘长福 潘长根 潘长海 潘长浩 潘长红 潘长虹 潘长华 潘长江 潘长久 潘长军 潘长乐 潘长良 潘长林 潘长禄 潘长明 潘长平 潘长青 潘长清 潘长生 潘长胜 潘长水 潘长松 潘长旺 潘长伟 潘长文 潘长燕 潘长耀 潘长英 潘长勇 潘长有 潘长玉 潘长云 潘长臻 潘长征 潘钊 潘招娣 潘昭 潘昭晖 潘昭名 潘昭文 潘昭勋 潘昭颖 潘兆 潘兆丰 潘兆刚 潘兆光 潘兆华 潘兆辉 潘兆军 潘兆龙 潘兆民 潘兆明 潘兆鹏 潘兆平 潘兆清 潘兆伟 潘兆文 潘兆祥 潘兆英 潘兆云 潘赵华 潘赵嫔 潘照 潘照东 潘哲 潘哲明 潘哲宇 潘哲哲 潘喆 潘贞 潘贞贞 潘珍 潘珍华 潘珍兰 潘珍珍 潘真 潘真真 潘桢 潘臻 潘臻卿 潘振 潘振邦 潘振彬 潘振波 潘振成 潘振承 潘振东 潘振芳 潘振峰 潘振锋 潘振国 潘振海 潘振豪 潘振华 潘振环 潘振江 潘振节 潘振君 潘振亮 潘振龙 潘振梅 潘振民 潘振明 潘振南 潘振鹏 潘振平 潘振启 潘振强 潘振清 潘振球 潘振荣 潘振声 潘振涛 潘振伟 潘振武 潘振霞 潘振鑫 潘振兴 潘振亚 潘振业 潘振英 潘振宇 潘振玉 潘振云 潘振中 潘振洲 潘震 潘震飞 潘震寰 潘震伟 潘震亚 潘震宇 潘震中 潘震宙 潘镇 潘征 潘征军 潘峥 潘峥峥 潘铮 潘铮铮 潘正 潘正斌 潘正才 潘正潮 潘正道 潘正东 潘正方 潘正芳 潘正芬 潘正福 潘正富 潘正刚 潘正光 潘正国 潘正海 潘正浩 潘正红 潘正华 潘正江 潘正军 潘正君 潘正莲 潘正良 潘正亮 潘正林 潘正龙 潘正茂 潘正梅 潘正民 潘正明 潘正强 潘正权 潘正荣 潘正生 潘正涛 潘正伟 潘正炜 潘正文 潘正喜 潘正霞 潘正祥 潘正兴 潘正雄 潘正亚 潘正彦 潘正阳 潘正义 潘正英 潘正勇 潘正玉 潘正元 潘正源 潘正悦 潘正云 潘正洲 潘郑 潘政 潘政民 潘政权 潘政伟 潘政文 潘政扬 潘政宇 潘之恒 潘之磊 潘之琳 潘之敏 潘之清 潘之望 潘芝芬 潘芝莉 潘芝梅 潘芝英 潘枝 潘枝花 潘枝舰 潘知常 潘植 潘芷晴 潘芷珊 潘芷欣 潘芷莹 潘至诚 潘志 潘志安 潘志标 潘志彬 潘志斌 潘志兵 潘志才 潘志超 潘志琛 潘志成 潘志诚 潘志城 潘志春 潘志纯 潘志聪 潘志达 潘志德 潘志东 潘志栋 潘志发 潘志方 潘志芳 潘志飞 潘志芬 潘志峰 潘志锋 潘志福 潘志刚 潘志高 潘志根 潘志光 潘志广 潘志贵 潘志国 潘志豪 潘志浩 潘志和 潘志恒 潘志红 潘志宏 潘志洪 潘志虎 潘志华 潘志辉 潘志慧 潘志佳 潘志嘉 潘志坚 潘志建 潘志江 潘志杰 潘志洁 潘志金 潘志娟 潘志军 潘志君 潘志俊 潘志凯 潘志兰 潘志立 潘志良 潘志亮 潘志林 潘志琳 潘志龙 潘志梅 潘志妹 潘志猛 潘志民 潘志敏 潘志明 潘志铭 潘志南 潘志能 潘志鹏 潘志平 潘志强 潘志琴 潘志勤 潘志卿 潘志清 潘志权 潘志全 潘志泉 潘志群 潘志仁 潘志荣 潘志山 潘志升 潘志生 潘志胜 潘志涛 潘志威 潘志伟 潘志炜 潘志文 潘志武 潘志贤 潘志香 潘志祥 潘志翔 潘志新 潘志星 潘志兴 潘志雄 潘志秀 潘志岩 潘志艳 潘志义 潘志艺 潘志毅 潘志英 潘志永 潘志勇 潘志宇 潘志源 潘志远 潘志云 潘志珍 潘志中 潘志忠 潘治 潘治富 潘治贵 潘治国 潘治明 潘治平 潘治清 潘治宇 潘致平 潘致文 潘致远 潘智 潘智彪 潘智超 潘智聪 潘智芳 潘智峰 潘智刚 潘智华 潘智慧 潘智军 潘智敏 潘智鹏 潘智强 潘智群 潘智荣 潘智生 潘智威 潘智伟 潘智文 潘智妍 潘智毅 潘智英 潘智勇 潘中 潘中海 潘中华 潘中兰 潘中良 潘中亮 潘中林 潘中明 潘中南 潘中平 潘中强 潘中伟 潘中耀 潘中义 潘中英 潘中元 潘中允 潘中泽 潘忠 潘忠宝 潘忠才 潘忠诚 潘忠党 潘忠国 潘忠海 潘忠华 潘忠辉 潘忠乐 潘忠礼 潘忠良 潘忠林 潘忠民 潘忠明 潘忠平 潘忠仁 潘忠伟 潘忠文 潘忠武 潘忠祥 潘忠孝 潘忠义 潘忠勇 潘忠宇 潘忠元 潘仲 潘仲华 潘仲良 潘仲林 潘仲明 潘仲平 潘仲文 潘仲贤 潘仲宇 潘重 潘重阳 潘州 潘周 潘周清 潘洲 潘朱 潘珠 潘竹 潘竹林 潘竹梅 潘竹生 潘竹松 潘主兰 潘柱 潘柱廷 潘祝朝 潘祝平 潘祝英 潘专 潘壮 潘壮志 潘壮壮 潘卓 潘卓然 潘卓颖 潘姿 潘滋培 潘子 潘子安 潘子昂 潘子彬 潘子超 潘子成 潘子初 潘子涵 潘子豪 潘子浩 潘子灏 潘子和 潘子恒 潘子衡 潘子红 潘子华 潘子骅 潘子辉 潘子佳 潘子建 潘子健 潘子杰 潘子敬 潘子军 潘子君 潘子俊 潘子兰 潘子良 潘子林 潘子龙 潘子民 潘子明 潘子鹏 潘子平 潘子奇 潘子琪 潘子琦 潘子强 潘子清 潘子晴 潘子荣 潘子威 潘子文 潘子祥 潘子兴 潘子轩 潘子璇 潘子扬 潘子阳 潘子洋 潘子一 潘子仪 潘子怡 潘子毅 潘子英 潘子玉 潘子月 潘梓 潘梓年 潘紫君 潘紫微 潘紫薇 潘自达 潘自力 潘自立 潘自林 潘自强 潘自文 潘宗 潘宗白 潘宗光 潘宗海 潘宗辉 潘宗杰 潘宗亮 潘宗林 潘宗明 潘宗奇 潘宗强 潘宗伟 潘宗阳 潘宗义 潘宗英 潘宗友 潘宗远 潘宗泽 潘祖安 潘祖德 潘祖芳 潘祖峰 潘祖高 潘祖光 潘祖国 潘祖华 潘祖辉 潘祖杰 潘祖军 潘祖良 潘祖亮 潘祖烈 潘祖林 潘祖龙 潘祖明 潘祖鹏 潘祖平 潘祖强 潘祖仁 潘祖荣 潘祖山 潘祖顺 潘祖文 潘祖霞 潘祖信 潘祖兴 潘祖言 潘祖荫 潘祖英 潘祖勇 潘祖友 潘最飞 潘左 潘佐华 潘佐林 潘作良 潘作梅 潘作敏\n","description":"\n","tags":[],"title":"\n名字","uri":"/posts/post-20/"},{"categories":["默认分类"],"content":"系统环境介绍以及准备 查看系统版本 [root@xmg-hk ~]# cat /etc/redhat-release CentOS Linux release 7.9.2009 (Core) 查看openssl版本 [root@xmg-hk ~]# openssl version OpenSSL 1.0.2k-fips 26 Jan 2017 官网下载openssl-1.1.1k 其他版本可参考下载： https://www.openssl.org/source/openssl-1.1.1k.tar.gz\n详细操作步骤 先备份 mv /usr/bin/openssl /usr/bin/openssl.bak mv /usr/include/openssl /usr/include/openssl.bak 进入目录并编译 cd /usr/local/openssl-1.1.1k ./config --prefix=/usr/local/openssl make \u0026\u0026 make install 建立链接 ln -s /usr/local/openssl/bin/openssl /usr/bin/openssl ln -s /usr/local/openssl/include/openssl /usr/include/openssl echo “/usr/local/openssl/lib” \u003e\u003e /etc/ld.so.conf ldconfig -v 查看是否升级成功 [root@xmg-hk ~]# openssl version OpenSSL 1.1.1k 25 Mar 2021 说明：需要先进行备份，备份需要在\"建立链接\"操作以前完成。\n","description":"\n","tags":[],"title":"\nCentOS7.9下升级OpenSSL到OpenSSL 1.1.1k","uri":"/posts/post-271/"},{"categories":["默认分类"],"content":"CentOS安装noVNC，以Web方式交付VNC远程连接 什么是noVNC noVNC 是一个 HTML5 VNC 客户端，采用 HTML 5 WebSockets, Canvas 和 JavaScript 实现，noVNC 被普遍用在各大云计算、虚拟机控制面板中，比如 OpenStack Dashboard 和 OpenNebula Sunstone 都用的是 noVNC。 noVNC 采用 WebSockets 实现，但是目前大多数 VNC 服务器都不支持 WebSockets，所以 noVNC 是不能直接连接 VNC 服务器的，需要一个代理来做 WebSockets 和 TCP sockets 之间的转换。这个代理在 noVNC 的目录里，叫做 websockify 。\n实验环境 VMware Workstations 带桌面的CentOS7虚拟机 Windows 10 宿主机 + Google Chrome浏览器 关闭防火墙 1 2 3 setenforce 0 systemctl stop firewalld systemctl disable firewalld 安装noVNC 安装依赖软件包\n1 2 3 yum install -y epel* yum install -y git yum install -y tigervnc-server 执行以下命令并输入密码启动服务\n1 vncserver :1 安装noVNC\n1 git clone git://github.com/kanaka/noVNC 创建安全连接（一路回车下去…）\n1 2 cd ./noVNC/utils/ openssl req -new -x509 -days 365 -nodes -out self.pem -keyout self.pem 注： VNC的默认会话不是安全的，需要创建一个安全的VNC连接。创建完毕的证书 self.pem 需要放置到 noVNC/utils 目录下，当启动 noVNC 时，websockify将自动装载证书。\n运行noVNC\n1 2 # 在noVNC目录下，执行 ./utils/launch.sh --vnc localhost:5901 测试连接 在浏览器访问（注意替换成自己的IP地址） http://192.168.204.10:6080/vnc.html 输入密码，连接成功！\n当有请求访问vnc时，控制台会显示日志\nCentOS 7 的安装脚本 #!/bin/bash # stop selinux and iptables setenforce 0 systemctl stop firewalld systemctl disable firewalld # install vncserver and git yum install -y epel* yum install tigervnc-server git -y vncserver :1 # 此时会提示输入密码 # download noVNC git clone git://github.com/kanaka/noVNC # create secure connection cd ./noVNC/utils/ openssl req -new -x509 -days 365 -nodes -out self.pem -keyout self.pem # run noVNC cd ../ ./utils/launch.sh --vnc localhost:5901 # running ","description":"\n","tags":[],"title":"\nCentOS安装noVNC，以Web方式交付VNC远程连接","uri":"/posts/post-272/"},{"categories":["默认分类"],"content":"有天，在群晖的 Web 界面，看到网络监控那里，上传速度竟然有 5M/s，漏油器上也看到群晖的上传很高，也就是说流量上传到了外网，卧槽，这到底是哪个进程吃我带宽的，找出来我非得杀掉不可。 可惜，群晖自带的 “资源监控” 无法查看进程对网络的占用。\n因为群晖的系统，虽然是基于 debian，但是默认没有包管理器，无法通过 apt/yum 安装 iftop。不过群晖支持 docker。\n群晖 - 套件中心 - docker - 安装\nssh 连接群晖 janten/iftop 这个镜像为我们提供了 iftop 命令\ndocker run -it --rm --net host janten/iftop -P -i eth0 如果本地没有没有这个镜像，会自动进行拉取，拉取镜像完成后，就可以看到 iftop 的运行界面\n使用 netstat 定位进程\nnetstat -pantu | grep [port] ","description":"\n","tags":[],"title":"\n群晖上查找占用带宽最大的进程的一种解决方案","uri":"/posts/post-273/"},{"categories":["默认分类"],"content":"拉取获取centos7镜像 docker pull centos:7 可以从https://hub.docker.com/_/centos?tab=tags查询拉取需要的镜像版本\n启动容器 指定容器的名称为centos-desktop-vnc，并暴露宿主机的5901来连接vnc\ndocker run --name centos-desktop-vnc --privileged -d -p 5901:5901 --ulimit memlock=-1 -td centos:7 /usr/sbin/init 配置desktop环境 进入容器环境 docker exec -it centos-desktop-vnc bash 默认的镜像不带desktop环境，需要手动安装\n查看支持的环境 会出现很多结果，我们这里选择的是gnome环境\nyum grouplist 安装gnome环境 yum groupinstall GNOME Desktop -y 配置系统默认的启动模式 我们这里需要设置启动模式为图形化\n# 获取当前启动模式 systemctl get-default # 修改启动模式为图形化 systemctl set-default graphical.target # 修改启动模式为命令行 systemctl set-default multi-user.target 配置vnc服务端 安装vnc server、vim、net-tools yum -y install tigervnc-server tigervnc-server-module vim net-tools 配置vnc server 复制配置文件模板 cp /lib/systemd/system/vncserver@.service /lib/systemd/system/vncserver@:1.service 设置生效用户-修改配置文件 vim /lib/systemd/system/vncserver\\@\\:1.service 将配置文件的 修改为root，由于root的home路径是/root，不是/home/root，因此注意修改PIDFILE的路径 改好之后如下\n[Unit] Description=Remote desktop service (VNC) After=syslog.target network.target [Service] Type=forking # Clean any existing files in /tmp/.X11-unix environment ExecStartPre=/bin/sh -c '/usr/bin/vncserver -kill %i \u003e /dev/null 2\u003e\u00261 || :' ExecStart=/usr/sbin/runuser -l root -c \"/usr/bin/vncserver %i\" PIDFile=/root/.vnc/%H%i.pid ExecStop=/bin/sh -c '/usr/bin/vncserver -kill %i \u003e /dev/null 2\u003e\u00261 || :' [Install] WantedBy=multi-user.target 修改vnc server密码 vncpasswd 生效vnc配置 systemctl daemon-reload 配置vnc开机启动 # 启动服务 systemctl start vncserver@:1 # 设为开机启动 systemctl enable vncserver@:1 检查vnc server是否启动 netstat -lnpt|grep Xvnc 出现下图结果说明启动成功\n[root@011ff517ebf7 /]# netstat -lnpt|grep Xvnc tcp 0 0 0.0.0.0:5901 0.0.0.0:* LISTEN 4658/Xvnc tcp 0 0 0.0.0.0:6001 0.0.0.0:* LISTEN 4658/Xvnc tcp6 0 0 :::5901 :::* LISTEN 4658/Xvnc tcp6 0 0 :::6001 :::* LISTEN 4658/Xvnc 关闭防火墙 1 2 3 4 # 关闭防火墙 systemctl stop firewalld # 禁止防火墙开机启动 systemctl disable firewalld vnc客户端发起连接 下载vnc client 连接vnc server 修改色彩质量 初次连接上去可以看到桌面的色彩很模糊 解决办法是在建立好的远程连接点右键，选择 Properties，再选择 Options 选项卡，在 General 下面的 Picture quality 选择 High，保存。然后就可以看到图象变清晰了。\n保存镜像 1 2 3 4 # 1、查询container id，出现的第一个字符串就是container id，我这里是011ff517ebf7 docker ps -a | grep centos-desktop-vnc # 2、提交作为本地镜像 docker commit 011ff517ebf7 centos:7-vnc 中文安装 查看当前字符集 $ echo $LANG en_US.UTF-8 安装字符集 使用locale命令看看当前系统所使用的字符集\n$ locale LANG=en_US.UTF-8 LC_CTYPE=\"en_US.UTF-8\" LC_NUMERIC=\"en_US.UTF-8\" LC_TIME=\"en_US.UTF-8\" LC_COLLATE=\"en_US.UTF-8\" LC_MONETARY=\"en_US.UTF-8\" LC_MESSAGES=\"en_US.UTF-8\" LC_PAPER=\"en_US.UTF-8\" LC_NAME=\"en_US.UTF-8\" LC_ADDRESS=\"en_US.UTF-8\" LC_TELEPHONE=\"en_US.UTF-8\" LC_MEASUREMENT=\"en_US.UTF-8\" LC_IDENTIFICATION=\"en_US.UTF-8\" LC_ALL= 查看系统是否安装中文字符集支持 # locale -a | grep CN bo_CN bo_CN.utf8 ug_CN ug_CN.utf8 zh_CN zh_CN.gb18030 zh_CN.gb2312 zh_CN.gbk zh_CN.utf8 若没有执行以下命令进行安装 yum install -y kde-l10n-Chinese yum reinstall -y glibc-common #定义字符集 localedef -c -f UTF-8 -i zh_CN zh_CN.UFT-8 #确认载入成功 locale -a 修改系统字符集 修改系统字符集的配置文件：\n# echo 'LANG=\"zh_CN.UTF-8\"' \u003e /etc/locale.conf # source /etc/locale.conf 验证字符集修改 # echo $LANG zh_CN.UTF-8 # locale LANG=zh_CN.UTF-8 LC_CTYPE=\"zh_CN.UTF-8\" LC_NUMERIC=\"zh_CN.UTF-8\" LC_TIME=\"zh_CN.UTF-8\" LC_COLLATE=\"zh_CN.UTF-8\" LC_MONETARY=\"zh_CN.UTF-8\" LC_MESSAGES=\"zh_CN.UTF-8\" LC_PAPER=\"zh_CN.UTF-8\" LC_NAME=\"zh_CN.UTF-8\" LC_ADDRESS=\"zh_CN.UTF-8\" LC_TELEPHONE=\"zh_CN.UTF-8\" LC_MEASUREMENT=\"zh_CN.UTF-8\" LC_IDENTIFICATION=\"zh_CN.UTF-8\" LC_ALL= ","description":"\n","tags":[],"title":"\n在Docker搭建centos7远程桌面环境","uri":"/posts/post-274/"},{"categories":["默认分类"],"content":"下载镜像 在Docker的注册表中下载官方镜像\n创建文件夹 先在FIle Station中创建两个文件夹，用于存放配置和数据，如图所示\n添加文件夹 /docker/minio/data (可以与我相同的方式进行新建，也可以根据自己的习惯创建)，这个目录主要是用来存放我们的上传文件的。\n添加文件夹 /docker/minio/config，这个目录主要是用来存放我们的配置文件的。\n配置容器 在下载完成后，在 映像 中可以看到已经下载好的镜像文件，双击它来选择高就设置来配置容器。\n自动启动 存储空间 添加映射的文件夹\n/docker/minio/data配置装载路径 /data\n/docker/minio/config 配置装载路径 /root/.minio (其中 . 千万不能漏)\n端口设置 选择 端口设置 设置本地端口为 9000 （当然其他端口也可以，这也是我们的访问端口，如果此处修改了，访问时就使用修改后的端口进行访问。\n一个静态端口，如果不配置此端口程序可以系统，没有报错，但是访问不到后台界面。这个端口可以是自己未占用的任意端口我用的9001端口\n环境 在命令出添加一下命令，其中端口号为刚才设置的静态端口号\nserver --console-address '0.0.0.0:9001' /data 登录后台 通过 http://NAS的IP:9000 访问到minio的登录页面，默认账号 minioadmin ， minioadmin\n修改账号密码 修改配置文件 通过 File Station 找到文件 docker/minIO/data/.minio.sys/config/config.json 文件\n找到其中的内容 credentials ，修改 access_key 的 value 为你自己想要的，譬如：xiaomage-user，修改其中 secret_key 的 value 为你自己想要的，譬如：xiaomage-password，最后变成如下（为了提高可读性，我这边对文件进行了格式化处理）\n\"credentials\": { \"_\": [ { \"key\": \"access_key\", \"value\": \"xiaomage-user\" }, { \"key\": \"secret_key\", \"value\": \"xiaomage-password\" } ] }, 重新启动 此时重新访问 可以使用新的账号密码！\n","description":"\n","tags":[],"title":"\n群晖使用Docker安装Minio","uri":"/posts/post-275/"},{"categories":["默认分类"],"content":"代码先行 demo地址\n文件上传，服务器异步处理文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @PostMapping(consumes = MediaType.MULTIPART_FORM_DATA_VALUE, produces = MediaType.APPLICATION_JSON_VALUE) public String uploadFile(MultipartFile file){ System.out.println(\"request start: file.isEmpty=\"+file.isEmpty()); new Thread(()-\u003e{ try { Thread.sleep(1000); // why file is empty? System.out.println(\"detail request: file.isEmpty=\"+file.isEmpty()); } catch (InterruptedException e) { e.printStackTrace(); } }).start(); System.out.println(\"request end: file.isEmpty=\"+file.isEmpty()); return \"{\"msg\":\"success!\"}\"; } 结果输出：\nrequest start: file.isEmpty=false request end: file.isEmpty=false detail request: file.isEmpty=true 原因：\nresponse之后，会clear临时数据（包含临时文件），所以异步出去的逻辑在response之后去读文件，将会读不到文件。\n","description":"\n","tags":["文件上传","异步处理文件"],"title":"\n文件上传，服务器异步处理文件导致异常","uri":"/posts/post-19/"},{"categories":["默认分类"],"content":"1.我们点击菜单栏中的File–\u003e选择Project Structure…(Ctrl+Alt+Shift+S)进入到设置页面，或者在IntelliJ IDEA页面右侧点击右上角的按钮也可到配置页面。\n2.我们在Project Structure的设置页面选择Artifacts，然后点击右侧的绿色“+”号，接下来我们选择JAR–\u003eFrom modules with dependencies…进入到设置页面。\n3.接下来是最重要的步骤，下图中modules一般会自动生成，Main class我们需要点击右侧的按钮，找到项目工程中含有main方法的那个类。JAR文件设置我们选择extract to the target JAR，打包时可将代码依赖的包也打入。最后META-INF/MANIFEST.MF的设置，我们选择项目的根路径即可。\n4.需要注意的是，如果项目中已经有META-INF/MANIFEST.MF文件的话是设置不成功的，我们需要先找到项目在磁盘中的位置，然后删掉该文件再重复上述的步骤才可以。\n5.设置完成后我们便可以执行生成jar包的操作了，点击菜单栏中的Build–\u003eBuild Artifacts…，然后我们在下方代码区便可以看到Build Artifact 选择之前创建的Artifacts然后点击Build即可。t,\n6.在Build JAR文件后下方会有已完成的提示，我们找到项目所在的磁盘位置，在项目根路径下的out/artifacts/目录下便是新生成的jar文件。\n","description":"\n","tags":[],"title":"\nIntelliJ IDEA如何把java源代码打包成jar包","uri":"/posts/post-277/"},{"categories":["默认分类"],"content":"在ssh远程连接192.168.2.1这台主机时，出现Permission denied，please try again。同样scp 远程拷贝也出现Permission denied，please try again。遇到这样的情况，如果不是密码错误，并且192.168.2.1的sshd服务开启，则需要修改这台主机的配置文件：\nvim /etc/ssh/sshd_config # 修改PermitRootLogin yes # 重启服务 systemctl restart sshd ","description":"\n","tags":[],"title":"\nssh scp出现Permission denied","uri":"/posts/post-278/"},{"categories":["默认分类","java"],"content":"简介 介绍 LITIENGINE是一个免费、开源且易于学习的2D Java 游戏引擎。它提供了使用基础 Java 来创建基于图块的 2D 游戏的所有基础结构，无论游戏平台、自上而下的射击游戏还是RPG。其主要功能包括一个2D物理引擎、一个2D渲染引擎、一个2D声音引擎、一个粒子系统（Particle System）、对平铺地图 (.tmx) 的支持和用于基本游戏开发的基本且干净的API。由于没有外部库而保持高可移植性，所以LITIENGINE原生支持所有常见的桌面操作系统。\n同其他引擎的相比，LITIENGINE有一个特点，它是完全基于纯Java AWT图形的2D渲染引擎。如果您目前已经学习或正要学习Java，这将立即为您提供出色的结果和高度优化的渲染性能。我们认为这是学习制作视频游戏的绝佳而简单的方法，而无需关心大量矢量数学或“OpenGL shenanigans”。而且通过**粒子系统（Particle System）**创建漂亮的视觉效果（如火或烟）可以进一步增强图形。\nLITIENGINE中的环境是基于.tmx贴图（可以用著名的 Tiled Level Editor创建和编辑，并使用LITIENGINE实体赋予其生命）。\n此外，SoundEngine支持二维音频，可以相对于环境中的某个位置播放。\n作者和社区 LITIENGINE是由巴伐利亚两兄弟（Steffen 和 Matthias）发明、编写和维护，它已成为一个相当受欢迎的开源项目，贡献者数量不断增加，社区活跃。\n示例项目 “Gurk Nukem” - 用 LITIENGINE 制作的 2-bit平台射击游戏\n开源游戏 在 LDJAM 42 的“GoIn -Behave or GET LOST!” 在 LDJAM 44 的“Servus Bonus” 在 LDJAM 46 的“南瓜守护者” ","description":"\n","tags":["游戏引擎","Java 2D","LITIENGINE","java"],"title":"\nLITIENGINE 纯 Java 2D 游戏引擎 （一）","uri":"/posts/post-18/"},{"categories":["默认分类"],"content":"核心区别 NIO是以块的方式处理数据，但是IO是以最基础的字节流的形式去写入和读出的。所以在效率上的话，肯定是NIO效率比IO效率会高出很多。 NIO不在是和IO一样用OutputStream和InputStream 输入流的形式来进行处理数据的，但是又是基于这种流的形式，而是采用了通道和缓冲区的形式来进行处理数据的。 还有一点就是NIO的通道是可以双向的，但是IO中的流只能是单向的。 还有就是NIO的缓冲区（其实也就是一个字节数组）还可以进行分片，可以建立只读缓冲区、直接缓冲区和间接缓冲区，只读缓冲区很明显就是字面意思，直接缓冲区是为加快 I/O 速度，而以一种特殊的方式分配其内存的缓冲区。 NIO比传统的BIO核心区别就是，NIO采用的是多路复用的IO模型，普通的IO用的是阻塞的IO模型，两个之间的效率肯定是多路复用效率更高 通道 通道是对原 I/O 包中的流的模拟。到任何目的地(或来自任何地方)的所有数据都必须通过一个 Channel 对象（通道）。\n一个 Buffer 实质上是一个容器对象。发送给一个通道的所有对象都必须首先放到缓冲区中；同样地，从通道中读取的任何数据都要读到缓冲区中。Channel是一个对象，可以通过它读取和写入数据。拿 NIO 与原来的 I/O 做个比较，通道就像是流。\n正如前面提到的，所有数据都通过 Buffer 对象来处理。您永远不会将字节直接写入通道中，相反，您是将数据写入包含一个或者多个字节的缓冲区。同样，您不会直接从通道中读取字节，而是将数据从通道读入缓冲区，再从缓冲区获取这个字节。\n缓冲区 Buffer 是一个对象， 它包含一些要写入或者刚读出的数据。在 NIO 中加入 Buffer 对象，体现了新库与原 I/O 的一个重要区别。在面向流的 I/O 中，您将数据直接写入或者将数据直接读到 Stream 对象中 在 NIO 库中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的。在写入数据时，它是写入到缓冲区中的。任何时候访问 NIO 中的数据，您都是将它放到缓冲区中。 缓冲区实质上是一个数组。通常它是一个字节数组，但是也可以使用其他种类的数组。但是一个缓冲区不 仅仅 是一个数组。缓冲区提供了对数据的结构化访问，而且还可以跟踪系统的读/写进程 缓冲区类型 CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer NIO的工作原理 缓冲区的工作机制 capacity 缓冲区数组的总长度\nposition 下一个要操作的数据元素的位置\nlimit 缓冲区数组中不可操作的下一个元素的位置，limit\u003c=capacity\nmark 用于记录当前 position 的前一个位置或者默认是 0\n1.这一步其实是当我们刚开始初始化这个buffer数组的时候，开始默认是这样的\n2、但是当你往buffer数组中开始写入的时候几个字节的时候就会变成下面的图，position会移动你数据的结束的下一个位置，这个时候你需要把buffer中的数据写到channel管道中，所以此时我们就需要用这个buffer.flip()方法\n3、当你调用完2中的方法时，这个时候就会变成下面的图了，这样的话其实就可以知道你刚刚写到buffer中的数据是在position—-\u003elimit之间，然后下一步调用clear（）\n4、这时底层操作系统就可以从缓冲区中正确读取这 5 个字节数据发送出去了。在下一次写数据之前我们在调一下 clear() 方法。缓冲区的索引状态又回到初始位置。（其实这一步有点像IO中的把转运字节数组char[] buf = new char[1024]不足1024字节的部分给强制刷新出去的意思）\n说明 1、这里还要说明一下 mark，当我们调用mark()时，它将记录当前 position 的前一个位置，当我们调用 reset 时，position 将恢复 mark 记录下来的值\n2.clear()方法会：清空整个缓冲区。position将被设回0，limit被设置成 capacity的值（这个个人的理解就是当你在flip（）方法的基础上已经记住你写入了多少字节数据，直接把position到limit之间的也就是你写入已经记住的数据给“复制”到管道中）\n3.当你把缓冲区的数局写入到管道中的时候，你需要调用flip()方法将Buffer从写模式切换到读模式，调用flip()方法会将position设回0，并将limit设置成之前position的值。buf.flip();（其实我个人理解的就相当于先记住缓冲区缓冲了多少数据）\n工作代码示例 public void selector() throws IOException { //先给缓冲区申请内存空间 ByteBuffer buffer = ByteBuffer.allocate(1024); //打开Selector为了它可以轮询每个 Channel 的状态 Selector selector = Selector.open(); ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.configureBlocking(false);//设置为非阻塞方式 ssc.socket().bind(new InetSocketAddress(8080)); ssc.register(selector, SelectionKey.OP_ACCEPT);//注册监听的事件 while (true) { Set selectedKeys = selector.selectedKeys();//取得所有key集合 Iterator it = selectedKeys.iterator(); while (it.hasNext()) { SelectionKey key = (SelectionKey) it.next(); if ((key.readyOps() \u0026 SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT) { ServerSocketChannel ssChannel = (ServerSocketChannel) key.channel(); SocketChannel sc = ssChannel.accept();//接受到服务端的请求 sc.configureBlocking(false); sc.register(selector, SelectionKey.OP_READ); it.remove(); } else if ((key.readyOps() \u0026 SelectionKey.OP_READ) == SelectionKey.OP_READ) { SocketChannel sc = (SocketChannel) key.channel(); while (true) { buffer.clear(); int n = sc.read(buffer);//读取数据 if (n \u003c= 0) { break; } buffer.flip(); } it.remove(); } } } } NIO的示意图 NIO和Netty的工作模型对比？ NIO的工作流程步骤 首先是先创建ServerSocketChannel 对象，和真正处理业务的线程池 然后给刚刚创建的ServerSocketChannel 对象进行绑定一个对应的端口，然后设置为非阻塞 然后创建Selector对象并打开，然后把这Selector对象注册到ServerSocketChannel 中，并设置好监听的事件，监听 SelectionKey.OP_ACCEPT 接着就是Selector对象进行死循环监听每一个Channel通道的事件，循环执行 Selector.select() 方法，轮询就绪的 Channel 从Selector中获取所有的SelectorKey（这个就可以看成是不同的事件），如果SelectorKey是处于 OP_ACCEPT 状态，说明是新的客户端接入，调用 ServerSocketChannel.accept 接收新的客户端。 然后对这个把这个接受的新客户端的Channel通道注册到ServerSocketChannel上，并且把之前的OP_ACCEPT 状态改为SelectionKey.OP_READ读取事件状态，并且设置为非阻塞的，然后把当前的这个SelectorKey给移除掉，说明这个事件完成了 如果第5步的时候过来的事件不是OP_ACCEPT 状态，那就是OP_READ读取数据的事件状态，然后调用本文章的上面的那个读取数据的机制就可以了 Netty的工作流程步骤 创建 NIO 线程组 EventLoopGroup 和 ServerBootstrap。 设置 ServerBootstrap 的属性：线程组、SO_BACKLOG 选项，设置 NioServerSocketChannel 为 Channel，设置业务处理 Handler 绑定端口，启动服务器程序。 在业务处理 TimeServerHandler 中，读取客户端发送的数据，并给出响应 两者之间的区别： OP_ACCEPT 的处理被简化，因为对于 accept 操作的处理在不同业务上都是一致的。 在 NIO 中需要自己构建 ByteBuffer 从 Channel 中读取数据，而 Netty 中数据是直接读取完成存放在 ByteBuf 中的。相当于省略了用户进程从内核中复制数据的过程。 在 Netty 中，我们看到有使用一个解码器 FixedLengthFrameDecoder，可以用于处理定长消息的问题，能够解决 TCP 粘包读半包问题，十分方便。 ","description":"\n","tags":[],"title":"\n什么是NIO？NIO的原理是什么机制？","uri":"/posts/post-279/"},{"categories":["语言"],"content":"并发\nJava内存模型 Java 内存模型（JMM）是一种抽象的概念，并不真实存在，它描述了一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段、静态字段和构成数组对象的元素）的访问方式。试图屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。\n注意JMM与JVM内存区域划分的区别：\nJMM描述的是一组规则，围绕原子性、有序性和可见性展开；\n相似点：存在共享区域和私有区域\n主内存与工作内存 处理器上的寄存器的读写的速度比内存快几个数量级，为了解决这种速度矛盾，在它们之间加入了高速缓存。\n加入高速缓存带来了一个新的问题：缓存一致性。如果多个缓存共享同一块主内存区域，那么多个缓存的数据可能会不一致，需要一些协议来解决这个问题。\n所有的变量都存储在主内存中，每个线程还有自己的工作内存，工作内存存储在高速缓存或者寄存器中，保存了该线程使用的变量的主内存副本拷贝。\n线程只能直接操作工作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。\n数据存储类型以及操作方式 方法中的基本类型本地变量将直接存储在工作内存的栈帧结构中；\n引用类型的本地变量：引用存储在工作内存，实际存储在主内存；\n成员变量、静态变量、类信息均会被存储在主内存中；\n主内存共享的方式是线程各拷贝一份数据到工作内存中，操作完成后就刷新到主内存中。\n内存间交互操作 Java 内存模型定义了 8 个操作来完成主内存和工作内存的交互操作。\nread：把一个变量的值从主内存传输到工作内存（CPU级别的缓存）中\nload：在 read 之后执行，把 read 得到的值放入工作内存的变量副本中\nuse：把工作内存中一个变量的值传递给执行引擎\nassign：把一个从执行引擎接收到的值赋给工作内存的变量\nstore：把工作内存的一个变量的值传送到主内存中\nwrite：在 store 之后执行，把 store 得到的值放入主内存的变量中\nlock：作用于主内存的变量\nunlock\n内存模型三大特性 原子性 // 先看一下代码： public class Main { private static int cnt = 0; public static void main(String[] args) { Runnable runnable = () -\u003e { for (int j = 0; j \u003c 100; j++) { cnt++; try { Thread.sleep(30); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(cnt); }; new Thread(runnable).start(); new Thread(runnable).start(); } } // 发现上面代码输出并没有等于200； Java 内存模型保证了 read、load、use、assign、store、write、lock 和 unlock 操作具有原子性，例如对一个 int 类型的变量执行 assign 赋值操作，这个操作就是原子性的。但是 Java 内存模型允许虚拟机将没有被 volatile 修饰的 64 位数据（long，double）的读写操作划分为两次 32 位的操作来进行，即 load、store、read 和 write 操作可以不具备原子性。\n有一个错误认识就是，int 等原子性的类型在多线程环境中不会出现线程安全问题。前面的线程不安全示例代码中，cnt 属于 int 类型变量，2 个线程对它进行自增操作之后，得到的值为 1 而不是 2。\n为了方便讨论，将内存间的交互操作简化为 3 个：load、assign、store。\n下图演示了两个线程同时对 cnt 进行操作，load、assign、store 这一系列操作整体上看不具备原子性，那么在 T1 修改 cnt 并且还没有将修改后的值写入主内存，T2 依然可以读入旧值。可以看出，这两个线程虽然执行了两次自增运算，但是主内存中 cnt 的值最后为 1 而不是 2。因此对 int 类型读写操作满足原子性只是说明 load、assign、store 这些单个操作具备原子性。\nAtomicInteger 能保证多个线程修改的原子性。\n使用 AtomicInteger 重写之前线程不安全的代码之后得到以下线程安全实现：\nimport java.util.concurrent.atomic.AtomicInteger; public class Main { private static AtomicInteger cnt = new AtomicInteger(); public static void main(String[] args) { Runnable runnable = () -\u003e { for (int j = 0; j \u003c 100; j++) { cnt.getAndIncrement(); try { Thread.sleep(30); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(cnt.get()); }; new Thread(runnable).start(); new Thread(runnable).start(); } } 除了使用原子类之外还可以使用 synchronized 互斥锁来保证操作的原子性。它对应的内存间交互操作为：lock 和 unlock，在虚拟机实现上对应的字节码指令为 monitorenter 和 monitorexit。\npublic class Main1 { private static int cnt = 0; public synchronized void add() { cnt++; } public static void main(String[] args) { Main1 main1 =new Main1(); Runnable runnable = () -\u003e { for (int j = 0; j \u003c 100; j++) { main1.add(); try { Thread.sleep(30); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(cnt); }; new Thread(runnable).start(); new Thread(runnable).start(); } } 可见性 可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。\n主要有有三种实现可见性的方式：\nvolatile，会强制将该变量自己和当时其他变量的状态都刷出缓存。\nsynchronized，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存。\nfinal，被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。\n对前面的线程不安全示例中的 cnt 变量使用 volatile 修饰，不能解决线程不安全问题，因为 volatile 并不能保证操作的原子性。\n有序性 有序性是指：在本线程内观察，所有操作都是有序的。在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序。在 Java 内存模型中，允许编译器和处理器对指令进行重排序，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。\n简单来说：对于代码有个问题就是指令重排序，编译器和指令器有时候为了提高代码执行效率会将指令重新排序。\nflag = false; //线程1： //准备资源 prepare() flag = true; //线程2： while(!flag){ Thread.sleep(1000) } //基于准备好的资源执行操作 execute() 指令重排序后，让flag=true 先执行了，会导致线程2 直接跳过while等待，执行某段代码，结果prepare()方法还没有执行，资源没有准备好，此时就会导致代码逻辑出现异常！\nJMM 内部的实现通常是依赖于所谓的内存屏障，通过禁止某些重排序的方式，提供内存可见性保证，也就是实现了各种 happen-before 规则。与此同时，更多复杂度在于，需要尽量确保各种编译器、各种体系结构的处理器，都能够提供一致的行为。\n先行发生原则(Happen-Before)\nJSR-133内存模型使用先行发生原则在Java内存模型中保证多线程操作可见性的机制，也是对早期语言规范中含糊的可见性概念的一个精确定义。上面提到了可以用 volatile 和 synchronized 来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。\n由于指令重排序的存在，两个操作之间有happen-before关系，并不意味着前一个操作必须要在后一个操作之前执行。 仅仅要求前一个操作的执行结果对于后一个操作是可见的，并且前一个操作 按顺序 排在第二个操作之前。\n单一线程原则（程序员顺序规则）Single Thread rule 在一个线程内，按照代码顺序，书写在程序前面的操作先行发生于书写后面的操作。\n管程锁定规则（监视器锁规则）Monitor Lock Rule 一个 unlock（解锁） 操作先行发生于后面对同一个锁的 lock（加锁）操作。比如代码里面先对一个lock.lock()然后lock.unlock(),然后lock.lock()\nvolatile 变量规则 Volatile Variable Rule 对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。\n线程启动规则Thread Start Rule Thread 对象的 start() 方法调用先行发生于此线程的每一个动作。比如Thread.start() interrupt()\n线程加入规则 Thread Join Rule Thread 对象的结束先行发生于 join() 方法返回。\n线程中断规则 Thread Interruption Rule 对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 interrupted() 方法检测到是否有中断发生。\n对象终结规则 Finalizer Rule 一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize() 方法的开始。\n传递性 Transitivity 如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。\n总结：这些规则制定了在一些特殊情况下，不允许编译机，指令器对你写的代码进行指令重排，必须保证你的代码的有序性\n指令重排序的条件\n在单线程环境下不能改变程序的运行结果；\n存在数据依赖关系的不允许重排序；\n无法通过Happens-before原则推到出来的，才能进行指令的重排序。\nvolatile 可见性 public class Main { private volatile static int i = 0; public static void main(String[] args) { new Thread(()-\u003e{ i++ ; }).start(); new Thread(()-\u003e{ // volatile 修饰后 当线程1 操作i++ 刷新到主内存中后，会让线程2工作内存的缓存失效 // 此时会读取到 i=1 while (i ==0){ Thread.sleep(1000); } i++ ; }).start(); } } 常用场景：一个系统 中间连接各种中间件系统，不能直接结束主进程，在结束主进程的时候要把里面的各个中间件系统关闭后，在结束主进程，不然可能会消息丢失，或者数据不一致等现象.\npublic class Kafka{ private volatile boolean running =true ; // 这是一个接口 public void shutdown(){ //关闭这个系统了，shutdown.sh脚本，来调用这个shutdown接口 // 最后运行状态置为false running =false ; } public static void main(){ //启动kafka , rocketmq ,会运行一大堆代码，中间件系统不能直接停掉 Kafka kafka= new Kafka(); // 监控kafka 是否关闭 ，未关闭则需要等待！ while(kafka.running){ Thread.sleep(1000); } } } 如果不加volatile修饰 ，则有可能一直不会关闭，拿到的running状态 一直是true\n有序性 前面的案例使用volatile 优化后\nvolatile boolean flag = false; //线程1： //准备资源 prepare() flag = true; //线程2： while(!flag){ Thread.sleep(1000) } //基于准备好的资源执行操作 execute() 比如这个例子，如果使用 volatile来修饰flag变量，一定可以让prepare() 在flag = true;之前先执行，这就禁止指令重排，因为volatile变量规则要求的是，volatile前面的代码一定不能指令重排到volatile变量操作后面，volatile后面的代码也不能指令重排到volatile前面\n也可以通过 synchronized 来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码。\n原子性 volatile 不能保证原子性，在有些情况下，可以有限的保证原子性，它主要不是用来保证原子性的！ 比如oracle 64位的long 数字进行操作的时候\n保证原子性还是需要synchronized，lock 进行加锁\n原理 volatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。\nlock指令（保证可见性） 对 volatile修饰的变量,执行写操作的话,JVM会发送一条lock前缀指令给CPU,CPU在计算完之后会立即将这个值写回主内存,同时因为有MESI缓存一致性协议,所以各个CPU都会对总线进行嗅探,自己本地缓存中的数据是否被别人修改如果发现别人修改了某个缓存的数据,那么CPU就会将自己本地缓存的数据过期掉,然后这个CPU上执行的线程在读取那个变量的时候,就会从主内存重新加载最新的数据了\n内存屏障：禁止重排序（保证有序性） Load1: int localVar = this.variable; Load2: int localVar = this.variable2; Loadload屏障:Load1; LoadLoad;Load2,确保Load1数据的装载先于Load2后所有装载指令,他的意思,Load1对应的代码和Load2对应的代码,是不能指令重排的\nStore1: this.variable=1; StoreStore屏障 Store2: this.variable2=2; StoreStore屏障: Store1; StoreStore; Store2,确保 Store1的数据一定刷回主存,对其他cpu 可见,先于 Store2以及后续指令\nLoadStore屏障:Load1; LoadStore; Store2,确保Load1指令的数据装载,先于 Store2以及 后续指令\nStoreload屏障: Store1; Storeload;Load2,确保 Store1指令的数据一定刷回主存,对其他 cpu可见,先于Load2以及后续指令的数据装载\n作用 volatile variable =1 this variable=2=\u003e store操作 int localvariable= this variable=\u003eload操作 对于 volatile修改变量的读写操作,都会加入内存屏障,每个 volatile写操作前面,加 Store Store屏障,禁止上面的普通写和他重排;每个 volatile写操作后面,加 Storeload屏障,禁止跟下面的 volatile读/写重排←\n","description":"\n","tags":[],"title":"\nJava volatile关键字","uri":"/posts/post-280/"},{"categories":["架构设计"],"content":"微服务分布式事务\n分布式事务基础 事务 事务指的就是一个操作单元，在这个操作单元中的所有操作最终要保持一致的行为，要么所有操作都成功，要么所有的操作都被撤销。简单地说，事务提供一种“要么什么都不做，要么做全套”机制。\n本地事务 本地事物其实可以认为是数据库提供的事务机制。说到数据库事务就不得不说，数据库事务中的四大特性:\nA:原子性(Atomicity)，一个事务中的所有操作，要么全部完成，要么全部不完成\nC:一致性(Consistency)，在一个事务执行之前和执行之后数据库都必须处于一致性状态\nI:隔离性(Isolation)，在并发环境中，当不同的事务同时操作相同的数据时，事务之间互不影响\nD:持久性(Durability)，指的是只要事务成功结束，它对数据库所做的更新就必须永久的保存下来\n数据库事务在实现时会将一次事务涉及的所有操作全部纳入到一个不可分割的执行单元，该执行单元中 的所有操作要么都成功，要么都失败，只要其中任一操作执行失败，都将导致整个事务的回滚\n分布式事务 分布式事务指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。\n简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同 的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。\n本质上来说，分布式事务就是为了保证不同数据库的数据一致性。\n分布式事务的场景 单体系统访问多个数据库\n一个服务需要调用多个数据库实例完成数据的增删改操作\n多个微服务访问同一个数据库\n多个服务需要调用一个数据库实例完成数据的增删改操作\n多个微服务访问多个数据库\n多个服务需要调用一个数据库实例完成数据的增删改操作\n分布式事务解决方案 全局事务 全局事务基于DTP模型实现。DTP是由X/Open组织提出的一种分布式事务模型——X/Open Distributed Transaction Processing Reference Model。它规定了要实现分布式事务，需要三种角色:\nAP: Application 应用系统 (微服务) TM: Transaction Manager 事务管理器 (全局事务管理) RM: Resource Manager 资源管理器 (数据库) 整个事务分成两个阶段:\n阶段一: 表决阶段，所有参与者都将本事务执行预提交，并将能否成功的信息反馈发给协调者。\n阶段二: 执行阶段，协调者根据所有参与者的反馈，通知所有参与者，步调一致地执行提交或者回\n滚。\n优点\n提高了数据一致性的概率，实现成本较低 缺点\n单点问题: 事务协调者宕机 同步阻塞: 延迟了提交时间，加长了资源阻塞时间 数据不一致: 提交第二阶段，依然存在commit结果未知的情况，有可能导致数据不一致 可靠消息服务 基于可靠消息服务的方案是通过消息中间件保证上、下游应用数据操作的一致性。假设有A和B两个系 统，分别可以处理任务A和任务B。此时存在一个业务流程，需要将任务A和任务B在同一个事务中处 理。就可以使用消息中间件来实现这种分布式事务。\n第一步:消息由系统A投递到中间件\n在系统A处理任务A前，首先向消息中间件发送一条消息\n消息中间件收到后将该条消息持久化，但并不投递。持久化成功后，向A回复一个确认应答\n系统A收到确认应答后，则可以开始处理任务A\n任务A处理完成后，向消息中间件发送Commit或者Rollback请求。该请求发送完成后，对系统A而\n言，该事务的处理过程就结束了\n如果消息中间件收到Commit，则向B系统投递消息;如果收到Rollback，则直接丢弃消息。但是\n如果消息中间件收不到Commit和Rollback指令，那么就要依靠\"超时询问机制\"。\n超时询问机制\n系统A除了实现正常的业务流程外，还需提供一个事务询问的接口，供消息中间件调用。当消息中 间件收到发布消息便开始计时，如果到了超时没收到确认指令，就会主动调用系统A提供的事务询 问接口询问该系统目前的状态。该接口会返回三种结果，中间件根据三种结果做出不同反应:\n提交:将该消息投递给系统B 回滚:直接将条消息丢弃 处理中:继续等待\n第二步:消息由中间件投递到系统B\n消息中间件向下游系统投递完消息后便进入阻塞等待状态，下游系统便立即进行任务的处理，任务处理完成后便向消息中间件返回应答。\n如果消息中间件收到确认应答后便认为该事务处理完毕\n如果消息中间件在等待确认应答超时之后就会重新投递，直到下游消费者返回消费成功响应为止。\n一般消息中间件可以设置消息重试的次数和时间间隔，如果最终还是不能成功投递，则需要手工干预。 这里之所以使用人工干预，而不是使用让A系统回滚，主要是考虑到整个系统设计的复杂度问题。\n基于可靠消息服务的分布式事务，前半部分使用异步，注重性能;后半部分使用同步，注重开发成本。\n最大努力通知 最大努力通知也被称为定期校对，其实是对第二种解决方案的进一步优化。它引入了本地消息表来记录错误消息，然后加入失败消息的定期校对功能，来进一步保证消息会被下游系统消费。\n第一步:消息由系统A投递到中间件\n处理业务的同一事务中，向本地消息表中写入一条记录\n准备专门的消息发送者不断地发送本地消息表中的消息到消息中间件，如果发送失败则重试\n第二步:消息由中间件投递到系统B\n消息中间件收到消息后负责将该消息同步投递给相应的下游系统，并触发下游系统的任务执行\n当下游系统处理成功后，向消息中间件反馈确认应答，消息中间件便可以将该条消息删除，从而该 事务完成\n对于投递失败的消息，利用重试机制进行重试，对于重试失败的，写入错误消息表\n消息中间件需要提供失败消息的查询接口，下游系统会定期查询失败消息，并将其消费\n这种方式的优缺点:\n优点: 一种非常经典的实现，实现了最终一致性。\n缺点: 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。\nTCC事务 TCC即为Try Confifirm Cancel，它属于补偿型分布式事务。TCC实现分布式事务一共有三个步骤:\nTry: 尝试待执行的业务:这个过程并未执行业务，只是完成所有业务的一致性检查，并预留好执 行所需的全部资源\nConfifirm: 确认执行业务:确认执行业务操作，不做任何业务检查， 只使用Try阶段预留的业务 资源。通常情况下，采用TCC则认为 Confifirm阶段是不会出错的。即:只要Try成功，Confifirm 一定成功。若Confifirm阶段真的出错了，需引入重试机制或人工处理。\nCancel: 取消待执行的业务:取消Try阶段预留的业务资源。通常情况下，采用TCC则认为Cancel 阶段也是一定成功的。若Cancel阶段真的出错了，需引入重试机制或人工处理\nTCC两阶段提交与XA两阶段提交的区别是:\nXA是资源层面的分布式事务，强一致性，在两阶段提交的整个过程中，一直会持有资源的锁。\nTCC是业务层面的分布式事务，最终一致性，不会一直持有资源的锁。\nTCC事务的优缺点:\n优点:把数据库层的二阶段提交上提到了应用层来实现，规避了数据库层的2PC性能低下问题。 缺点:TCC的Try、Confifirm和Cancel操作功能需业务提供，开发成本高。 Seata介绍 2019 年 1 月，阿里巴巴中间件团队发起了开源项目 Fescar(Fast \u0026 EaSy Commit AndRollback)， 其愿景是让分布式事务的使用像本地事务的使用一样，简单和高效，并逐步解决开发者们遇到的分布式 事务方面的所有难题。后来更名为 Seata，意为:Simple Extensible Autonomous Transaction Architecture，是一套分布式事务解决方案。\nSeata的设计目标是对业务无侵入，因此从业务无侵入的2PC方案着手，在传统2PC的基础上演进。它把 一个分布式事务理解成一个包含了若干分支事务的全局事务。全局事务的职责是协调其下管辖的分支事 务达成一致，要么一起成功提交，要么一起失败回滚。此外，通常分支事务本身就是一个关系数据库的 本地事务。\nSeata主要由三个重要组件组成:\nTC:Transaction Coordinator 事务协调器，管理全局的分支事务的状态，用于全局性事务的提交 和回滚。\nTM:Transaction Manager 事务管理器，用于开启、提交或者回滚全局事务。\nRM:Resource Manager 资源管理器，用于分支事务上的资源管理，向TC注册分支事务，上报分 支事务的状态，接受TC的命令来提交或者回滚分支事务。\nSeata的执行流程如下:\nA服务的TM向TC申请开启一个全局事务，TC就会创建一个全局事务并返回一个唯一的XID A服务的RM向TC注册分支事务，并及其纳入XID对应全局事务的管辖 A服务执行分支事务，向数据库做操作 A服务开始远程调用B服务，此时XID会在微服务的调用链上传播 B服务的RM向TC注册分支事务，并将其纳入XID对应的全局事务的管辖 B服务执行分支事务，向数据库做操作 全局事务调用链处理完毕，TM根据有无异常向TC发起全局事务的提交或者回滚 TC协调其管辖之下的所有分支事务， 决定是否回滚 Seata实现2PC与传统2PC的差别:\n架构层次方面，传统2PC方案的 RM 实际上是在数据库层，RM本质上就是数据库自身，通过XA协 议实现，而 Seata的RM是以jar包的形式作为中间件层部署在应用程序这一侧的。 两阶段提交方面，传统2PC无论第二阶段的决议是commit还是rollback，事务性资源的锁都要保 持到Phase2完成才释放。而Seata的做法是在Phase1 就将本地事务提交，这样就可以省去Phase2 持锁的时间，整体提高效率 Seata实现分布式事务控制 本示例通过Seata中间件实现分布式事务，模拟电商中的下单和扣库存的过程\n我们通过订单微服务执行下单操作，然后由订单微服务调用商品微服务扣除库存\n案例基本代码 修改order微服务 controller\n@RestController @Slf4j public class OrderController5 { @Autowired private OrderServiceImpl5 orderService; //下单 @RequestMapping(\"/order/prod/{pid}\") public Order order(@PathVariable(\"pid\") Integer pid) { log.info(\"接收到{}号商品的下单请求,接下来调用商品微服务查询此商品信息\", pid); return orderService.createOrder(pid); } } OrderService\n@Service @Slf4j public class OrderServiceImpl5{ @Autowired private OrderDao orderDao; @Autowired private ProductService productService; @Autowired private RocketMQTemplate rocketMQTemplate; @GlobalTransactional public Order createOrder(Integer pid) { //1 调用商品微服务,查询商品信息 Product product = productService.findByPid(pid); log.info(\"查询到{}号商品的信息,内容是:{}\", pid, JSON.toJSONString(product)); //2 下单(创建订单) Order order = new Order(); order.setUid(1); order.setUsername(\"测试用户\"); order.setPid(pid); order.setPname(product.getPname()); order.setPprice(product.getPprice()); order.setNumber(1); orderDao.save(order); log.info(\"创建订单成功,订单信息为{}\", JSON.toJSONString(order)); //3 扣库存 productService.reduceInventory(pid, order.getNumber()); //4 向mq中投递一个下单成功的消息 rocketMQTemplate.convertAndSend(\"order-topic\", order); return order; } } ProductService\n@FeignClient(value = \"service-product\") public interface ProductService { //减库存 @RequestMapping(\"/product/reduceInventory\") void reduceInventory(@RequestParam(\"pid\") Integer pid,@RequestParam(\"num\") } 修改Product微服务 controller\n//减少库存 @RequestMapping(\"/product/reduceInventory\") public void reduceInventory(Integer pid, int num) { productService.reduceInventory(pid, num); } service\n@Override public void reduceInventory(Integer pid, int num) { Product product = productDao.findById(pid).get(); product.setStock(product.getStock() - num); //减库存 productDao.save(product); } 异常模拟 在ProductServiceImpl的代码中模拟一个异常, 然后调用下单接口\n@Override public void reduceInventory(Integer pid, Integer number) { Product product = productDao.findById(pid).get(); if (product.getStock() \u003c number) { throw new RuntimeException(\"库存不足\"); } int i = 1 / 0; product.setStock(product.getStock() - number); productDao.save(product); } 启动Seata 下载seata 下载地址:https://github.com/seata/seata/releases/v0.9.0/\n修改配置文件 将下载得到的压缩包进行解压，进入conf目录，调整下面的配置文件:\nregistry.conf\nregistry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = \"nacos\" nacos { serverAddr = \"localhost\" namespace = \"\" cluster = \"default\" } } config { # file、nacos 、apollo、zk、consul、etcd3 type = \"nacos\" nacos { serverAddr = \"localhost\" namespace = \"\" } } nacos-confifig.txt\nservice.vgroup_mapping.service-product=default service.vgroup_mapping.service-order=default 初始化seata在nacos的配置 # 初始化seata 的nacos配置 # 注意: 这里要保证nacos是已经正常运行的 cd conf nacos-config.sh 127.0.0.1 执行成功后可以打开Nacos的控制台，在配置列表中，可以看到初始化了很多Group为SEATA_GROUP 的配置。\n启动seata服务 cd bin seata-server.bat -p 9000 -m file 启动后在 Nacos 的服务列表下面可以看到一个名为 serverAddr 的服务。\n使用Seata实现事务控制 初始化数据表 在我们的数据库中加入一张undo_log表,这是Seata记录事务日志要用到的表\nCREATE TABLE `undo_log`( `id` BIGiNT(20) NOT NULL AUTO_INCREMENT, `branch_id` BIGiNT(20) NOT NULL, `xid` VARcHAR(100) NOT NULL, `context` VARcHAR(128) NOT NULL, `rollback_info` LONGBLOB NOT NULL, `log_status` iNT(11) NOT NULL, `log_created` DATETIME NOT NULL, `log_modified` DATETIME NOT NULL, `ext` VARcHAR(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`) ) ENGINE = INNODB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8; 添加配置 在需要进行分布式控制的微服务中进行下面几项配置:\n添加依赖\n\u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-seata\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-nacos-config\u003c/artifactId\u003e \u003c/dependency\u003e DataSourceProxyConfifig\nSeata 是通过代理数据源实现事务分支的，所以需要配置 io.seata.rm.datasource.DataSourceProxy 的 Bean，且是 @Primary默认的数据源，否则事务不会回滚，无法实现分布式事务\n@Configuration public class DataSourceProxyConfig { @Bean @ConfigurationProperties(prefix = \"spring.datasource\") public DruidDataSource druidDataSource() { return new DruidDataSource(); } @Primary @Bean public DataSourceProxy dataSource(DruidDataSource druidDataSource) { return new DataSourceProxy(druidDataSource); } } registry.conf\n在resources下添加Seata的配置文件 registry.conf\nregistry { type = \"nacos\" nacos { serverAddr = \"localhost\" namespace = \"public\" cluster = \"default\" } } config { type = \"nacos\" nacos { serverAddr = \"localhost\" namespace = \"public\" cluster = \"default\" } } bootstrap.yaml\nspring: application: name: service-product cloud: nacos: config: server-addr: localhost:8848 # nacos的服务端地址 namespace: public group: SEATA_GROUP alibaba: seata: tx-service-group: ${spring.application.name } 在order微服务开启全局事务 @GlobalTransactional//全局事务控制 public Order createOrder(Integer pid) {} 测试 再次下单测试\nseata运行流程分析 要点说明:\n每个RM使用DataSourceProxy连接数据库，其目的是使用ConnectionProxy，使用数据源和数据 连接代理的目的就是在第一阶段将undo_log和业务数据放在一个本地事务提交，这样就保存了只 要有业务操作就一定有undo_log。 在第一阶段undo_log中存放了数据修改前和修改后的值，为事务回滚作好准备，所以第一阶段完 成就已经将分支事务提交，也就释放了锁资源。 TM开启全局事务开始，将XID全局事务id放在事务上下文中，通过feign调用也将XID传入下游分支 事务，每个分支事务将自己的Branch ID分支事务ID与XID关联。 第二阶段全局事务提交，TC会通知各各分支参与者提交分支事务，在第一阶段就已经提交了分支 事务，这里各各参与者只需要删除undo_log即可，并且可以异步执行，第二阶段很快可以完成。 第二阶段全局事务回滚，TC会通知各各分支参与者回滚分支事务，通过 XID 和 Branch ID 找到相 应的回滚日志，通过回滚日志生成反向的 SQL 并执行，以完成分支事务回滚到之前的状态，如果 回滚失败则会重试回滚操作 ","description":"\n","tags":[],"title":"\nSeata–分布式事务","uri":"/posts/post-281/"},{"categories":["架构设计"],"content":"微服务\n服务配置中心介绍 首先我们来看一下,微服务架构下关于配置文件的一些问题:\n配置文件相对分散。在一个微服务架构下，配置文件会随着微服务的增多变的越来越多，而且分散 在各个微服务中，不好统一配置和管理。 配置文件无法区分环境。微服务项目可能会有多个环境，例如:测试环境、预发布环境、生产环 境。每一个环境所使用的配置理论上都是不同的，一旦需要修改，就需要我们去各个微服务下手动 维护，这比较困难。 配置文件无法实时更新。我们修改了配置文件之后，必须重新启动微服务才能使配置生效，这对一 个正在运行的项目来说是非常不友好的。 基于上面这些问题，我们就需要配置中心的加入来解决这些问题。\n配置中心的思路是:\n首先把项目中各种配置全部都放到一个集中的地方进行统一管理，并提供一套标准的接口。\n当各个服务需要获取配置的时候，就来配置中心的接口拉取自己的配置。\n当配置中心中的各种参数有更新的时候，也能通知到各个服务实时的过来同步最新的信息，使之动态更新。\n当加入了服务配置中心之后，我们的系统架构图会变成下面这样\n在业界常见的服务配置中心，有下面这些:\nApollo Apollo是由携程开源的分布式配置中心。特点有很多，比如:配置更新之后可以实时生效，支持灰度发 布功能，并且能对所有的配置进行版本管理、操作审计等功能，提供开放平台API。并且资料也写的很 详细。\nDisconf Disconf是由百度开源的分布式配置中心。它是基于Zookeeper来实现配置变更后实时通知和生效的。\nSpringCloud Confifig 这是Spring Cloud中带的配置中心组件。它和Spring是无缝集成，使用起来非常方便，并且它的配置存 储支持Git。不过它没有可视化的操作界面，配置的生效也不是实时的，需要重启或去刷新。\nNacos 这是SpingCloud alibaba技术栈中的一个组件，前面我们已经使用它做过服务注册中心。其实它也集成 了服务配置的功能，我们可以直接使用它作为服务配置中心。\nNacos Config 入门 使用nacos作为配置中心，其实就是将nacos当做一个服务端，将各个微服务看成是客户端，我们将各个微服务的配置文件统一存放在nacos上，然后各个微服务从nacos上拉取配置即可。\n接下来我们以商品微服务为例，学习nacos confifig的使用。\n搭建nacos环境【使用现有的nacos环境即可】 在微服务中引入nacos的依赖 \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-nacos-config\u003c/artifactId\u003e \u003c/dependency\u003e 在微服务中添加nacos confifig的配置 注意:不能使用原来的application.yml作为配置文件，而是新建一个bootstrap.yml作为配置文件\n配置文件优先级(由高到低):\nbootstrap.properties -\u003e bootstrap.yml -\u003e application.properties -\u003e application.yml\nspring: application: name: service-product cloud: nacos: config: server-addr: 127.0.0.1:8848 #nacos中心地址 file-extension: yaml # 配置文件格式 profiles: profiles: active: dev # 环境标识 在nacos中添加配置 点击配置列表，点击右边+号，新建配置。在新建配置过程中，要注意下面的细节:\n1)Data ID不能随便写，要跟配置文件中的对应，对应关系如图所示\n2)配置文件格式要跟配置文件的格式对应，且目前仅仅支持YAML和Properties\n3)配置内容按照上面选定的格式书写\n注释本地的application.yam中的内容， 启动程序进行测试 如果依旧可以成功访问程序，说明我们nacos的配置中心功能已经实现\nNacos Config 深入 配置动态刷新 在入门案例中，我们实现了配置的远程存放，但是此时如果修改了配置，我们的程序是无法读取到的， 因此，我们需要开启配置的动态刷新功能。\n在nacos中的service-product-dev.yaml配置项中添加下面配置:\nconfig: appName: product 方式一:硬编码方式\n@RestController public class NacosConfigController { @Autowired private ConfigurableApplicationContext applicationContext; @GetMapping( \"/nacos-config-test1\" ) public String nacosConfingTest1(){ return (applicationContext.getEnvironment().getProperty(\"config.appName\")); } } 方式二:注解方式(推荐)\n@RestController @RefreshScope /* 只需要在需要动态读取配置的类上添加此注解就可以 */ public class NacosConfigController { @Value(\"${config.appName}\") private String appName; @GetMapping(\"/nacos-config-test2\") public String nacosConfingTest2(){ return(appName); } } 配置共享 当配置越来越多的时候，我们就发现有很多配置是重复的，这时候就考虑可不可以将公共配置文件提取出来，然后实现共享呢?当然是可以的。接下来我们就来探讨如何实现这一功能。\n同一个微服务的不同环境之间共享配置\n如果想在同一个微服务的不同环境之间实现配置共享，其实很简单。只需要提取一个以 spring.application.name 命名的配置文件，然后将其所有环境的公共配置放在里面即可。\n新建一个名为service-product.yaml配置存放商品微服务的公共配置 新建一个名为service-product-test.yaml配置存放测试环境的配置 新建一个名为service-productr-dev.yaml配置存放开发环境的配置 添加测试方法 @RestController @RefreshScope public class NacosConfigController { @Value( \"${config.env}\" ) private String env; /* 3 同一微服务的不同环境下共享配置 */ @GetMapping( \"/nacos-config-test3\" ) public String nacosConfingTest3(){ return(env); } } 访问测试 接下来，修改bootstrap.yml中的配置，将active设置成test，再次访问，观察结果 spring: profiles: active: test # 环境标识 不同微服务中间共享配置\n不同为服务之间实现配置共享的原理类似于文件引入，就是定义一个公共配置，然后在当前配置中引 入。\n在nacos中定义一个DataID为all-service.yaml的配置，用于所有微服务共享 spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://shop?serverTimezone=UTC\u0026useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=true username: root password: root jpa: properties: hibernate: hbm2ddl: auto: update dialect: org.hibernate.dialect.MySQL5InnoDBDialect cloud: nacos: discovery: server-addr: 127.0.0.1:8848 在nacos的中修改service-product.yaml中为下面内容 server: port: 8081 config: appName: product 修改bootstrap.yaml spring: application: name: service-product profiles: active: dev # 环境标识 cloud: nacos: config: server-addr: 127.0.0.1:8848 #nacos中心地址 file-extension: yaml # 配置文件格式 shared-dataids: all-service.yaml # 配置要引入的配置 refreshable-dataids: all-service.yaml # 配置要实现动态配置刷新的配置 启动商品微服务进行测试 Nacos 的几个概念 命名空间(Namespace) 命名空间可用于进行不同环境的配置隔离。一般一个环境划分到一个命名空间\n配置分组(Group) 配置分组用于将不同的服务可以归类到同一分组。一般将一个项目的配置分到一组\n配置集(Data ID) 在系统中，一个配置文件通常就是一个配置集。一般微服务的配置就是一个配置集\n结果如下\n# all-service.yaml spring: zipkin: #开启zipkin分析 enabled: true #让nacos把它当成一个URL，而不要当做服务名 discoveryClientEnabled: false sleuth: sampler: #限速器，每秒采集10个请求，防止大并发过载。推荐 #rate: 10 #采集率，大并发可能采集率数量也会很高。采样的百分比 probability: 0.1 application: name: service-product datasource: driver-class-name: com.mysql.cj.jdbc.Driver jpa: database-platform: org.hibernate.dialect.MySQL5InnoDBDialect show-sql: true hibernate: ddl-auto: update use-new-id-generator-mappings: false # service-product.yaml config: appName: product # service-product-dev.yaml config: env: dev server: port: 8081 spring: zipkin: #zipkin服务地址 baseUrl: http://127.0.0.1:9411/ datasource: url: jdbc:mysql://127.0.0.1:3306/spring-cloud?serverTimezone=UTC\u0026useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=true username: root password: Mrf12345 cloud: nacos: discovery: server-addr: 127.0.0.1:8848 # service-product-test.yaml config: env: test server: port: 8081 spring: zipkin: #zipkin服务地址 baseUrl: http://127.0.0.1:9411/ datasource: url: jdbc:mysql://127.0.0.1:3306/spring-cloud?serverTimezone=UTC\u0026useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=true username: root password: Mrf12345 cloud: nacos: discovery: server-addr: 127.0.0.1:8848 ","description":"\n","tags":[],"title":"\nNacos Config–服务配置","uri":"/posts/post-282/"},{"categories":["架构设计","语言"],"content":"微服务短信\n短信服务介绍 短信服务（Short Message Service）是阿里云为用户提供的一种通信服务的能力。\n产品优势：覆盖全面、高并发处理、消息堆积处理、开发管理简单、智能监控调度\n产品功能：短信通知、短信验证码、推广短信、异步通知、数据统计\n应用场景：短信验证码、系统信息推送、推广短信等\n短信服务使用 接下来,我们使用短信验证码功能来演示短信服务的使用。流程如下:\n准备工作 实名认证 https://help.aliyun.com/document_detail/48263.html?spm=5176.11533457.J_1089570.9.15da5333ZUkUdR\n开通短信服务 https://www.aliyun.com/product/sms?spm=5176.11533457.J_1089570.9.15da5333ZUkUdR\n申请认证秘钥 https://ram.console.aliyun.com/manage/ak\n申请短信签名 申请短信模板 短信服务 API 介绍 短信发送 调用SendSms发送短信。\n请求参数\n名称 **类型 ** 是否必选 **示例值 ** 描述 PhoneNumbers String 是 15900000000 接收短信的手机号码。 SignName String 是 阿里云 短信签名名称。 TemplateCode String 是 SMS_153055065 短信模板ID。 TemplateParam String 否 {“code”:“1111”} 短信模板变量的值，JSON格式 返回数据\n名称 类型 示例值 描述 BizId String 900619746936498440 发送回执ID，可根据它查询具体的发 送 Code String OK 请求状态码。返回OK代表请求成功。 Message String OK 状态码的描述。 RequestId String F655A8D5-B967-440B- 8683 请求ID。 短信查询 调用QuerySendDetails接口查看短信发送记录和发送状态。\n请求参数\n名称 类型 是否必选 示例值 描述 CurrentPage Long 是 1 分页查看发送记录，指定发送记录的当前页码。 PageSize Long 是 10 分页查看发送记录，指定每页显示的短信记录数量。取值范围为1~50。 PhoneNumber String 是 1590000**** 接收短信的手机号码。格式：国内短信：11位手机号码，例如1590000****。国际/港澳台消息：国际区号+号码，例如8520000****。 SendDate String 是 20181228 短信发送日期，支持查询最近30天的记录。格式为yyyyMMdd，例如20181225。 BizId String 否 134523^4351232 发送回执ID，即发送流水号。调用发送接口SendSms或SendBatchSms发送短信时，返回值中的BizId字段。 返回数据\n名称 类型 示例值 描述 Code String OK 请求状态码。返回OK代表请求成功。其他错误码，请参见错误码列表。 Message String OK 状态码的描述。 RequestId String 819BE656-D2E0-4858-8B21-B2E477085AAF 请求ID。 SmsSendDetailDTOs Array of SmsSendDetailDTO 短信发送明细。 TotalCount String 1 短信发送总条数。 功能测试 第1步: 引入阿里云服务依赖\n\u003c!--短信发送--\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-alicloud-sms\u003c/artifactId\u003e \u003c/dependency\u003e 第2步: 使用阿里云提供的Demo测试短信发送\nimport com.aliyuncs.DefaultAcsClient; import com.aliyuncs.IAcsClient; import com.aliyuncs.dysmsapi.model.v20170525.QuerySendDetailsRequest; import com.aliyuncs.dysmsapi.model.v20170525.QuerySendDetailsResponse; import com.aliyuncs.dysmsapi.model.v20170525.SendSmsRequest; import com.aliyuncs.dysmsapi.model.v20170525.SendSmsResponse; import com.aliyuncs.exceptions.ClientException; import com.aliyuncs.profile.DefaultProfile; import com.aliyuncs.profile.IClientProfile; import java.text.SimpleDateFormat; import java.util.Date; public class SmsDemo { //产品名称:云通信短信API产品,开发者无需替换 static final String product = \"Dysmsapi\"; //产品域名,开发者无需替换 static final String domain = \"dysmsapi.aliyuncs.com\"; // TODO 此处需要替换成开发者自己的AK(在阿里云访问控制台寻找) static final String accessKeyId = \"yourAccessKeyId\"; static final String accessKeySecret = \"yourAccessKeySecret\"; //短信发送 public static SendSmsResponse sendSms() throws ClientException { //可自助调整超时时间 System.setProperty(\"sun.net.client.defaultConnectTimeout\", \"10000\"); System.setProperty(\"sun.net.client.defaultReadTimeout\", \"10000\"); //初始化acsClient,暂不支持region化 IClientProfile profile = DefaultProfile.getProfile(\"cn-hangzhou\",accessKeyId, accessKeySecret); DefaultProfile.addEndpoint(\"cn-hangzhou\", \"cn-hangzhou\", product, domain); IAcsClient acsClient = new DefaultAcsClient(profile); //组装请求对象-具体描述见控制台-文档部分内容 SendSmsRequest request = new SendSmsRequest(); //必填:待发送手机号 request.setPhoneNumbers(\"15000000000\"); //必填:短信签名-可在短信控制台中找到 request.setSignName(\"中古盲盒\"); //必填:短信模板-可在短信控制台中找到 request.setTemplateCode(\"SMS_1000000\"); // 可选:模板中的变量替换JSON串,如模板内容为\"亲爱的${name},您的验证码为${code}\"时,此处的值为 request.setTemplateParam(\"{\"name\":\"Tom\", \"code\":\"123\"}\"); /** * 选填-上行短信扩展码(无特殊需求用户请忽略此字段) * request.setSmsUpExtendCode(\"90997\") */ // 可选:outId为提供给业务方扩展字段,最终在短信回执消息中将此值带回给调用者 request.setOutId(\"yourOutId\"); // hint 此处可能会抛出异常,注意catch SendSmsResponse sendSmsResponse = acsClient.getAcsResponse(request); return sendSmsResponse; } //短信查询 public static QuerySendDetailsResponse querySendDetails(String bizId) throws ClientException { //可自助调整超时时间 System.setProperty(\"sun.net.client.defaultReadTimeout\", \"10000\"); System.setProperty(\"sun.net.client.defaultConnectTimeout\", \"10000\"); //初始化acsClient,暂不支持region化 IClientProfile profile = DefaultProfile.getProfile(\"cn-hangzhou\",accessKeyId, accessKeySecret); DefaultProfile.addEndpoint(\"cn-hangzhou\", \"cn-hangzhou\", product,domain); IAcsClient acsClient = new DefaultAcsClient(profile); //组装请求对象 QuerySendDetailsRequest request = new QuerySendDetailsRequest(); //必填-号码 request.setPhoneNumber(\"15000000000\"); //可选-流水号 request.setBizId(bizId); //必填-发送日期 支持30天内记录查询,格式yyyyMMdd SimpleDateFormat ft = new SimpleDateFormat(\"yyyyMMdd\"); request.setSendDate(ft.format(new Date())); //必填-页大小 request.setPageSize(10L); //必填-当前页码从1开始计数 request.setCurrentPage(1L); //hint 此处可能会抛出异常,注意catch QuerySendDetailsResponse querySendDetailsResponse =acsClient.getAcsResponse(request); return querySendDetailsResponse; } public static void main(String[] args) throws ClientException, InterruptedException { //发短信 SendSmsResponse response = sendSms(); System.out.println(\"短信接口返回的数据----------------\"); System.out.println(\"Code=\" + response.getCode()); System.out.println(\"Message=\" + response.getMessage()); System.out.println(\"RequestId=\" + response.getRequestId()); System.out.println(\"BizId=\" + response.getBizId()); Thread.sleep(3000L); //查明细 if (response.getCode() != null \u0026\u0026 response.getCode().equals(\"OK\")) { QuerySendDetailsResponse querySendDetailsResponse = querySendDetails(response.getBizId()); System.out.println(\"短信明细查询接口返回数据----------------\"); System.out.println(\"Code=\" + querySendDetailsResponse.getCode()); System.out.println(\"Message=\" + querySendDetailsResponse.getMessage()); int i = 0; for (QuerySendDetailsResponse.SmsSendDetailDTO smsSendDetailDTO : querySendDetailsResponse.getSmsSendDetailDTOs()) { System.out.println(\"SmsSendDetailDTO[\" + i + \"]:\"); System.out.println(\"Content=\" + smsSendDetailDTO.getContent()); System.out.println(\"ErrCode=\" + smsSendDetailDTO.getErrCode()); System.out.println(\"OutId=\" + smsSendDetailDTO.getOutId()); System.out.println(\"PhoneNum=\" + smsSendDetailDTO.getPhoneNum()); System.out.println(\"ReceiveDate=\" + smsSendDetailDTO.getReceiveDate()); System.out.println(\"SendDate=\" + smsSendDetailDTO.getSendDate()); System.out.println(\"SendStatus=\" + smsSendDetailDTO.getSendStatus()); System.out.println(\"Template=\" + smsSendDetailDTO.getTemplateCode()); } System.out.println(\"TotalCount=\" + querySendDetailsResponse.getTotalCount()); System.out.println(\"RequestId=\" + querySendDetailsResponse.getRequestId()); } } } 下单之后发送短信 在 shop-user 模块中加入sms依赖\n\u003c!--短信发送--\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-alicloud-sms\u003c/artifactId\u003e \u003c/dependency\u003e 将阿里短信给出的demo封装成工具类\nimport com.aliyuncs.DefaultAcsClient; import com.aliyuncs.IAcsClient; import com.aliyuncs.dysmsapi.model.v20170525.SendSmsRequest; import com.aliyuncs.dysmsapi.model.v20170525.SendSmsResponse; import com.aliyuncs.profile.DefaultProfile; import com.aliyuncs.profile.IClientProfile; public class SmsUtil { //替换成自己申请的accessKeyId private static String accessKeyId = \"\"; //替换成自己申请的accessKeySecret private static String accessKeySecret = \"\"; static final String product = \"Dysmsapi\"; static final String domain = \"dysmsapi.aliyuncs.com\"; /** * \\* 发送短信 * * \\* @param phoneNumbers 要发送短信到哪个手机号 * \\* @param signName 短信签名[必须使用前面申请的] * \\* @param templateCode 短信短信模板ID[必须使用前面申请的] * \\* @param param 模板中${code}位置传递的内容 */ public static void sendSms(String phoneNumbers, String signName, String templateCode, String param) { try { System.setProperty(\"sun.net.client.defaultConnectTimeout\", \"10000\"); System.setProperty(\"sun.net.client.defaultReadTimeout\", \"10000\"); //初始化acsClient,暂不支持region化 IClientProfile profile = DefaultProfile.getProfile(\"cn-hangzhou\", accessKeyId, accessKeySecret); DefaultProfile.addEndpoint(\"cn-hangzhou\", \"cn-hangzhou\", product, domain); IAcsClient acsClient = new DefaultAcsClient(profile); SendSmsRequest request = new SendSmsRequest(); request.setPhoneNumbers(phoneNumbers); request.setSignName(signName); request.setTemplateCode(templateCode); request.setTemplateParam(param); request.setOutId(\"yourOutId\"); SendSmsResponse sendSmsResponse = acsClient.getAcsResponse(request); if (!\"OK\".equals(sendSmsResponse.getCode())) { throw new RuntimeException(sendSmsResponse.getMessage()); } } catch (Exception e) { e.printStackTrace(); throw new RuntimeException(\"发送短信失败\"); } } } 修改短信发送的服务\n/* 发送短信的服务 */ @Slf4j @Service( \"shopSmsService\" ) @RocketMQMessageListener( consumerGroup = \"shop-user\", /* 消费组名 */ topic = \"order-topic\", /* 消费主题 */ consumeMode = ConsumeMode.CONCURRENTLY, /* 消费模式 */ messageModel = MessageModel.CLUSTERING /* 消息模式 */ ) public class SmsService implements RocketMQListener\u003cOrder\u003e { @Autowired private UserDao userDao; @Override public void onMessage(Order message) { log.info(\"接收到了一个订单信息{},接下来就可以发送短信通知了\", message); // 根据uid 获取手机号 User user = userDao.findById(message.getUid()).get(); // 生成验证码 StringBuilder builder = new StringBuilder(); for (int i = 0; i \u003c 6; i++) { builder.append(new Random().nextInt(9) + 1); } String smsCode = builder.toString(); Param param = new Param(smsCode); try { // 发送短信 {\"code\":\"123456\"} SmsUtil.sendSms(user.getTelephone(), \"黑马旅游网\", \"SMS_170836451\", JSON.toJSONString(param)); log.info(\"短信发送成功\"); } catch (Exception e) { e.printStackTrace(); } } @Data @AllArgsConstructor @NoArgsConstructor class Param { private String code; } } ","description":"\n","tags":[],"title":"\nSMS–短信服务","uri":"/posts/post-283/"},{"categories":["NAS"],"content":"好玩\n群晖使用ali-webdav 首先你的群晖支持docker\nali-webdav下载 在docker的注册表搜索 ali-webdav 如图所示然后点击下载\nali-webdava安装 映像中选中ali-webdava 点击启动\n高级设置 启用自动重新启动 作用是开机启动不用每次重新启动\n挂载文件夹路径 /usr/local/java/docker/\n作用是1.如果token 失效可以直接替换文件夹中的token。2.可以直接查看日志\n设置端口 作用 后面可以页面访问，防止端口变化\n设置参数 # ALIYUNDRIVE_REFRESH_TOKEN 是你的refreshToken 必填参数 # 下面三个参数可以不做修改 # ALIYUNDRIVE_AUTH_ENABLE 是否开启WebDav账户验证，默认开启true 选填 # ALIYUNDRIVE_AUTH_USERNAME WebDav账户，默认admin 选填 # ALIYUNDRIVE_AUTH_PASSWORD WebDav密码，默认admin 选填 验证是否成功 输入你的群晖IP 加上刚才设置的端口号 我的地址是 http://192.168.2.153:8088/\n如果出现访问页面则代表成功，如果不是的话 看一下日志提示的什么错误。\n本地硬盘映射 我使用的是RaiDrive 工具，windos自带的有点卡，这个很流畅，每秒拷贝 10M/s 左右\n","description":"\n","tags":[],"title":"\n使用群晖把阿里云盘挂载为本地系统的磁盘","uri":"/posts/post-284/"},{"categories":["默认分类"],"content":"这里只提供申请地址，申请教程就不写了，排名无先后。\n其中部分可免费申请多域名通配符证书\n腾讯云：https://cloud.tencent.com/product/ssl\n阿里云：https://www.aliyun.com/product/cas\n又拍云：https://www.upyun.com/products/ssl\n沃通：https://freessl.wosign.com/\n七牛云：https://www.qiniu.com/ssl\nFreeSSL：https://freessl.cn/\nLet’s Encrypt：https://letsencrypt.org/\ncloudflare：https://www.cloudflare.com/\nFreeSSL：https://freessl.org\nBuypass： https://www.buypass.com/\nAMH: https://amh.sh/ssl.htm\n","description":"\n","tags":[],"title":"\n免费的SSL证书申请地址分享","uri":"/posts/post-285/"},{"categories":["好玩技巧"],"content":"好玩\n网上也发布过类似的文章，不过很多网站更换域名或停止访问不能用了；近期网友又整理了14个网址，可以用来免费在线接收验证码使用，可以防止自己隐私泄露；国内外手机号码都有，严禁用于非法使用，后果由使用者自担承担！\n接码地址 以下网站可用于在线接收验证码（网页界面广告广告有点多，但不影响使用）\nhttps://www.bfkdim.com\nhttps://www.materialtools.com\nhttp://www.z-sms.com\nhttps://www.yinsiduanxin.com/china-phone-number.html\nhttps://www.zusms.com/phone/china\nhttps://jieduanxin.com/China-Phone-Number\nhttps://jiemahao.com\nhttps://sms-receive.net\nhttps://getfreesmsnumber.com (ua设置成pc或者电脑打开)\nhttp://receive-sms-online.info\nhttps://sms-online.co/receive-free-sms\nhttps://f4.work/list_free.php?\nhttp://lothelper.com/cn/shownumber?page=1list=PHONELIST_1_1_44\nhttps://smsreceivefree.com\n","description":"\n","tags":[],"title":"\n国内外在线接收短信验证码大全","uri":"/posts/post-286/"},{"categories":["默认分类"],"content":"好玩\n有人问我我手机号怎么买了，怎么这么好记，现在分享给大家！\n今天分享给大家一个免费申请 联通手机15555AA手机靓号的方法，不要钱。网上很多人再买 几十 几百 几千 都有，其实这些号码都可以不要钱申请到的！不要再花钱买手机靓号啦，比如教程上面可以申请的 1565555这样的号码在“某宝”上面卖一千多呢。\n今天教大家如何免费申请！！\n第一步：找到联通官网免费选号链接 百度搜索“联通大新思维” 五个字，就可以看到联通的一个最新官方申请链接。\n或者直接打开下面链接\nhttp://www.10010.com/goodsdetail/301904268051.html\n第二步：选择对应号码地区 1555533/15555345选“芜湖”。\n1555522/15555234选“宣城”\n1555511/166551155选“合肥”。\n1555525/185551888选“亳州”\n1565555/1865555/1315555选“马鞍山”。\n（马鞍山的有的有最低消费和预存款其他的不需要，号码都是全国通用的，发全国的，而且以后也可以携号转网。\n所以地区不需要纠结，号码喜欢就好.\n第四步：选择自己喜欢的号码 可以多选几页，多选几个上面的地区，然后看看有没有自己喜欢的。\n然后确定喜欢号码，加入备选 下单就好了，不要钱的！赶快去看看吧！\n","description":"\n","tags":[],"title":"\n联通官网免费申请155555手机靓号","uri":"/posts/post-287/"},{"categories":["默认分类"],"content":"JDK 下载 官网下载 JDK8：http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\n安装 # 创建目录 mkdir /usr/local/java # 拷贝安装包到指定目录 cp jdk-8u301-linux-x64.tar.gz /usr/local/java/ # 进入java安装目录 cd /usr/local/java/ # 解压jdk安装包 tar -zxvf jdk-8u301-linux-x64.tar.gz # 删除安装包（可选） rm -rf jdk-8u301-linux-x64.tar.gz 配置环境变量 # 编辑配置文件 vim /etc/profile # 最下面添加如下内容： export JAVA_HOME=/usr/local/java/jdk1.8.0_301 export CLASSPATH=$JAVA_HOME/lib/ export PATH=$PATH:$JAVA_HOME/bin **************** 或者添加下面这种 JAVA_HOME=/usr/local/java/jdk1.8.0_301 CLASSPATH=$JAVA_HOME/lib/ PATH=$PATH:$JAVA_HOME/bin export PATH JAVA_HOME CLASSPATH # 然后ESC :wq保存退出 :wq # 配置生效 source /etc/profile # 检查安装情况 java -version Maven 下载 官网下载地址： https://maven.apache.org/download.cgi\n安装 # 创建目录 mkdir /usr/local/maven # 解压到创建目录下 tar -zxvf apache-maven-3.8.2-bin.tar.gz -C /usr/local/maven/ # 进入maven安装目录 下面有文件则没有问题 cd /usr/local/maven/apache-maven-3.8.2 ********************************************************* [root@xmg-gz apache-maven-3.8.2]# ls bin boot conf lib LICENSE NOTICE README.txt 配置 # 编辑配置文件 vim /etc/profile # 最下面添加如下内容： export MAVEN_HOME=/usr/local/maven/apache-maven-3.8.2 export MAVEN_HOME export PATH=$PATH:$MAVEN_HOME/bin # 然后ESC :wq保存退出 :wq # 配置生效 source /etc/profile # 检查配置情况 mvn -version MYSQL 背景信息 MySQL：5.7.33\nMySQL相关安装路径说明如下：\n配置文件：/etc/my.cnf 数据存储：/var/lib/mysql 命令文件：/usr/bin和/usr/sbin 数据库端口：3306\n安装mysql # 更新YUM源 rpm -Uvh https://dev.mysql.com/get/mysql57-community-release-el7-9.noarch.rpm # 安装MySQL yum -y install mysql-community-server # 查看MySQL版本号 mysql -V 配置MySQL # 启动MySQL服务 systemctl start mysqld # 设置MySQL服务开机自启动 systemctl enable mysqld # 查看/var/log/mysqld.log文件，获取并记录root用户的初始密码 grep 'temporary password' /var/log/mysqld.log # 执行命令结果示例如下。 2020-04-08T08:12:07.893939Z 1 [Note] A temporary password is generated for root@localhost: xvlo1lZ12\u003euI # 对MySQL进行安全性配置需要初始密码 mysql_secure_installation 安全性配置 重置root用户的密码 #确保MySQL服务器部署的安全。 Securing the MySQL server deployment. #输入root用户的密码: 输入上一步获取的root用户初始密码 Enter password for user root: #root用户的密码已经过期。请设置新密码。 The existing password for the user account root has expired. Please set a new password. #新密码: New password: #重新输入新密码: Re-enter new password: #'validate_password'插件安装在服务器上。 The 'validate_password' plugin is installed on the server. #后续步骤将使用现有配置运行的插件。 The subsequent steps will run with the existing configuration of the plugin. #使用现有的root密码。 Using existing password for root. #估计密码强度:100 Estimated strength of the password: 100 #修改root用户密码?(按y| y表示是，其他任何键表示否):y Change the password for root ? ((Press y|Y for Yes, any other key for No) : y #新密码: 长度为8至30个字符，必须同时包含大小写英文字母、数字和特殊符号。特殊符号可以是()` ~!@#$%^\u0026*-+=|{}[]:;‘\u003c\u003e,.?/ New password: #重新输入新密码: Re-enter new password: #估计密码强度:100 Estimated strength of the password: 100 #您希望继续使用所提供的密码吗?(按y| y为Yes，按其他键为No): y Do you wish to continue with the password provided?(Press y|Y for Yes, any other key for No) : y 删除匿名用户账号 #默认情况下，MySQL安装有一个匿名用户，允许任何人登录到MySQL，而无需为他们创建用户帐户。这只用于测试，并使安装过程更顺畅。您应该在转移到生产环境之前删除它们。 By default, a MySQL installation has an anonymous user, allowing anyone to log into MySQL without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. #删除匿名用户?(按y| y为Yes，按其他键为No): Remove anonymous users? (Press y|Y for Yes, any other key for No) : Y #是否删除匿名用户，输入Y Success. 禁止root账号远程登录 # 通常，根应该只允许从“localhost”。这就保证了别人猜不到来自网络的根密码。 Normally, root should only be allowed to connect from 'localhost'. This ensures that someone cannot guess at the root password from the network. #禁止root远程登录?(按y| y表示是，其他键表示否): Disallow root login remotely? (Press y|Y for Yes, any other key for No) : Y #禁止root远程登录，输入Y Success. 删除test库以及对test库的访问权限 默认情况下，MySQL自带一个名为“test”的数据库任何人都可以访问。这也仅用于测试，并且应该在进入生产之前被删除环境。 By default, MySQL comes with a database named 'test' that anyone can access. This is also intended only for testing,and should be removed before moving into a production environment. 删除测试数据库并访问它?(按y| y表示是，其他键表示否) Remove test database and access to it? (Press y|Y for Yes, any other key for No) : Y #是否删除test库和对它的访问权限，输入Y - Dropping test database... Success. 重新加载授权表 #重新加载特权表将确保所有更改到目前为止所做的将立即生效。 Reloading the privilege tables will ensure that all changes made so far will take effect immediately. #现在重新加载特权表?(按y| y表示是，其他键表示否) Reload privilege tables now? (Press y|Y for Yes, any other key for No) : Success. All done! 安全性配置的更多信息，请参见MySQL官方文档。\n远程访问MySQL数据库 配置安全组策略 阿里云服务器安全组配置\u003e配置规则\u003e添加安全组 授权对象 0.0.0.0/0表示任意的IP。\n授权策略 优先级 协议类型 端口范围 授权对象 描述 创建时间 操作 允许 1 自定义 TCP 目的: 3306/3306 源: 0.0.0.0/0 mysql数据库 2021年7月21日13:04:05 编辑复制删除 修改表法 # 进入mysql 输入密码 mysql -u root -p # 切换数据库 use mysql; # 修改数据库数据 update user set host = '%' where user = 'root'; # 查询修改结果 select host,user from user where user = 'root'; 授权法 #你想myuser使用mypassword（密码）从任何主机连接到mysql服务器的话。 grant all on *.* to 'myuser'@'%' IDENTIFIED BY 'mypassword'; #使用root替换 myuser，可设置为允许root账号远程登录。 #如果你想允许用户myuser从ip为192.168.1.6的主机连接到mysql服务器，并使用mypassword作为密码 grant all on *.* to 'myuser'@'192.168.1.6' IDENTIFIED BY 'mypassword'; #使修改生效 FLUSH PRIVILEGES 在采用授权法之后，无法在本地登录mysql 提示ERROR 1045 (28000): Access denied for user ‘root’@’loadb116’ (using password: YES) 上例中loadb116是主机名. 这时可以使用root进入后授权\ngrant all privileges on *.* to 'root'@'loadb116' identified by '123456' with grant option; flush privileges; 或者使用本地IP登录\n重启服务 systemctl start mysqld 如果此时连不上，重启一下 reboot\nRedis redis下载 下载地址：http://redis.io/download，下载最新稳定版本。\nmkdir /usr/local/redis/ wget http://download.redis.io/releases/redis-6.0.8.tar.gz tar xzf redis-6.0.8.tar.gz 安装 # 进入redis目录 cd redis-6.0.8 # 安装 gcc 则直接进行编译 make yum -y install gcc # 如果不安装会编译报错 # -------------如果还报错 临时升级版本 start gcc -v # 查看gcc版本 yum -y install centos-release-scl # 升级到9.1版本 yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils scl enable devtoolset-9 bash # -------------如果还报错 临时升级版本 end # 编译 make 安装成功会出现：Hint: It’s a good idea to run ‘make test’\n执行make test 进行测试，如果出现如下错误：\n[root@localhost redis-6.0.1]# make test cd src \u0026\u0026 make test make[1]: 进入目录“/usr/redis-6.0.1/src” CC Makefile.dep make[1]: 离开目录“/usr/redis-6.0.1/src” make[1]: 进入目录“/usr/redis-6.0.1/src” You need tcl 8.5 or newer in order to run the Redis test make[1]: *** [test] 错误 1 make[1]: 离开目录“/usr/redis-6.0.1/src” make: *** [test] 错误 2 解决办法\n# 安装 tcl yum install tcl make test 修改配置文件 # 修改配置文件 vi redis.conf # 修改 #bind 127.0.0.1 为bind 0.0.0.0 -\u003e 允许所有主机访问 69 # bind 127.0.0.1 70 bind 0.0.0.0 # 将daemonize no 改成 daemonize yes -\u003e 设置redis可以一直在后台运行，以守护进程方式运行 225 daemonize yes # 密码设置，将”#requirepass foobared“ 取掉注释改成 requirepass 123456(或者其它你需要的密码) 791 requirepass 123456 GZA$bXZwnbe!6j 设置开机启动 # 创建存放redis的配置文件 mkdir /etc/redis # 创建存放redis的持久化文件 （可选） mkdir /var/redis/ mkdir /var/redis/6379 # 拷贝配置文件 cp /usr/local/redis/redis-6.0.8/redis.conf /etc/redis/6379.conf # 检查一下配置 daemonize\tyes\t#让redis以daemon进程运行 pidfile\t/var/run/redis_6379.pid #设置redis的pid文件位置 port\t6379\t#设置redis的监听端口号 dir /var/redis/6379\t#设置持久化文件的存储位置 （可选） # 拷贝脚本到开机启动脚本目录下 cp /usr/local/redis/redis-6.0.8/utils/redis_init_script /etc/init.d/redis_6379 cd /etc/init.d/ vim redis_6379 # 最上面，加入两行注释 # chkconfig: 2345 90 10 # description: Redis is a persistent key-value database # 修改 以下两个地址 为自己的文件地址 EXEC=/usr/local/redis/redis-6.0.8/src/redis-server CLIEXEC=/usr/local/redis/redis-6.0.8/src/redis-cli # 授权 chmod 777 redis_6379 # 启动 redis ./redis_6379 start # 执行 加入开机启动 chkconfig redis_6379 on ","description":"\n","tags":[],"title":"\nCentos7搭建JDK+Mysql+Redis","uri":"/posts/post-288/"},{"categories":["默认分类"],"content":"问题，在使用FreeMarker时遇见了一个问题 **现象：**在服务启动后，第一次渲染文件（多线程并发进行）时，出现部分线程报中断异常，再次触发时正常完成渲染。\n详细内容见代码的HELP.md\n问题复现代码地址： https://www.pfinfo.com.cn/blog/upload/2021/06/0cv4s1umsujfqrlal4rcppr684.zip\n测试入口： DemoApplicationTests#template()\n","description":"\n","tags":["FreeMarker","中断异常"],"title":"\nFreeMarker首次渲染文件（并发），部分线程报中断异常","uri":"/posts/post-15/"},{"categories":["Docker"],"content":"Kubernetesdocker\nWhat is Kubernetes？\nKubernetes这个单词来自于希腊语，含义是 舵手 或 领航员\n简介说明 Production-Grade Container Orchestration Automated container deployment, scaling, and management\n生产级的容器编排 自动化的容器部署、扩展和管理\nKubernetes，也称为K8S，其中8是代表中间“ubernete”的8个字符，是Google在2014年开源的一个容器编排引擎，用于自动化容器化应用程序的部署、规划、扩展和管理，它将组成应用程序的容器分组为逻辑单元，以便于管理和发现，用于管理云平台中多个主机上的容器化的应用，Kubernetes 的目标是让部署容器化的应用简单并且高效，很多细节都不需要运维人员去进行复杂的手工配置和处理；\nKubernetes拥有Google在生产环境上15年运行的经验，并结合了社区中最佳实践；\nK8S是 CNCF 毕业的项目，本来Kubernetes是Google的内部项目，后来开源出来，又后来为了其茁壮成长，捐给了CNCF；\nCNCF全称Cloud Native Computing Foundation（云原生计算基金会）\n官网：https://kubernetes.io/\n代码：https://github.com/kubernetes/kubernetes\nKubernetes是采用Go语言开发的，Go语言是谷歌2009发布的一款开源编程语言；\n编排是什么意思？\n按照一定的目的依次排列；\n调配、安排；\n整体架构 Master k8s集群控制节点，对集群进行调度管理，接受集群外用户去集群操作请求；\nMaster Node 由 API Server、Scheduler、ClusterState Store（ETCD 数据库）和 Controller MangerServer 所组成；\nNodes 集群工作节点，运行用户业务应用容器；\nNodes节点也叫Worker Node，包含kubelet、kube proxy 和 Pod（Container Runtime）；\n搭建方式 部署 Kubernetes 环境（集群）主要有多种方式：\nminikube minikube可以在本地运行Kubernetes的工具，minikube可以在个人计算机（包括Windows，macOS和Linux PC）上运行一个单节点Kubernetes集群，以便您可以试用Kubernetes或进行日常开发工作；\nhttps://kubernetes.io/docs/tutorials/hello-minikube/\nkind Kind和minikube类似的工具，让你在本地计算机上运行Kubernetes，此工具需要安装并配置Docker；\nhttps://kind.sigs.k8s.io/\nkubeadm Kubeadm是一个K8s部署工具，提供kubeadm init 和 kubeadm join两个操作命令，可以快速部署一个Kubernetes集群；\n官方地址：\nhttps://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/\nhttps://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\n二进制包 从Github下载发行版的二进制包，手动部署安装每个组件，组成Kubernetes集群，步骤比较繁琐，但是能让你对各个组件有更清晰的认识；\nyum安装 通过yum安装Kubernetes的每个组件，组成Kubernetes集群，不过yum源里面的k8s版本已经比较老了，所以这种方式用得也比较少了；\n第三方工具 有一些大神封装了一些工具，利用这些工具进行k8s环境的安装；\n花钱购买 直接购买类似阿里云这样的公有云平台k8s，一键搞定；\nKubeadm部署 kubeadm是官方社区推出的一个用于快速部署 kubernetes 集群的工具，这个工具能通过两条指令完成一个kubernetes集群的部署；\n创建一个Master节点：\nkubeadm init 将Node节点加入到Master集群中：\n$ kubeadm join \u003cMaster节点的IP和端口\u003e 环境要求 一台或多台机器，操作系统CentOS 7.x-86_x64\n硬件配置：内存2GB或2G+，CPU 2核或CPU 2核+；\n集群内各个机器之间能相互通信；\n集群内各个机器可以访问外网，需要拉取镜像；(非必须)\n禁止swap分区；\n如果环境不满足要求，会报错，比如：\n环境准备 关闭防火墙\nsystemctl stop firewalld systemctl disable firewalld 关闭selinux\nsed -i 's/enforcing/disabled/' /etc/selinux/config #永久 setenforce 0 #临时 关闭swap（k8s禁止虚拟内存以提高性能）\nsed -ri 's/.*swap.*/#\u0026/' /etc/fstab #永久 swapoff -a #临时 在master添加hosts\ncat \u003e\u003e /etc/hosts \u003c\u003c EOF 172.16.45.131 k8smaster 172.16.45.132 k8snode1 172.16.45.133 k8snode2 EOF 设置网桥参数\nsystemctl stop firewalld systemctl disable firewalld 时间同步\nsystemctl stop firewalld systemctl disable firewalld 安装步骤 所有服务器节点安装 Docker/kubeadm/kubelet/kubectl\nKubernetes 默认容器运行环境是Docker，因此首先需要安装Docker；\n安装 Docker #更新docker的yum源 yum install wget -y wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo #安装指定版本的docker： yum install docker-ce-19.03.13 -y #yum install docker -y （这个安装的Docker版本偏旧） 1.13.x #配置加速器加速下载 登录该网址获取加速地址（https://cr.console.aliyun.com/） sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u003c\u003c-'EOF' { \"registry-mirrors\": [\"https://bz93554o.mirror.aliyuncs.com\"] } EOF sudo systemctl daemon-reload sudo systemctl restart docker #然后执行以下命令不然会提示警告； systemctl enable docker.service #那么接下来需要搭建：kubeadm、kubelet、kubectl 配置k8s的阿里云YUM源 cat \u003e /etc/yum.repos.d/kubernetes.repo \u003c\u003c EOF [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF 到时候下载k8s的相关组件才能找到下载源；\n安装 kubeadm，kubelet 和 kubectl yum install kubelet-1.19.4 kubeadm-1.19.4 kubectl-1.19.4 -y #然后执行以下命令不然会提示警告； systemctl enable kubelet.service #查看有没有安装： yum list installed | grep kubelet yum list installed | grep kubeadm yum list installed | grep kubectl #查看安装的版本： kubelet --version Kubelet：运行在cluster所有节点上，负责启动POD和容器；\nKubeadm：用于初始化cluster的一个工具；\nKubectl：kubectl是kubenetes命令行工具，通过kubectl可以部署和管理应用，查看各种资源，创建，删除和更新组件；\n切记：此时应该重启一下centos；\n切记：此时应该重启一下centos；\n切记：此时应该重启一下centos；\n重要的事情说三遍！！！\n部署Master主节点 在master机器上执行以下命令；\nkubeadm init --apiserver-advertise-address=172.16.45.131 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.19.4 --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16 说明：\nservice-cidr 的选取不能和PodCIDR及本机网络有重叠或者冲突，一般可以选择一个本机网络和PodCIDR都没有用到的私网地址段，比如PODCIDR使用10.244.0.0/16, 那么service cidr可以选择10.96.0.0/12，网络无重叠冲突即可；\n执行成功后会显示以下信息\n[root@k8smaster ~]# kubeadm init --apiserver-advertise-address=172.16.45.131 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.19.4 --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16 W0602 21:10:27.153412 8853 configset.go:348] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io] [init] Using Kubernetes version: v1.19.4 [preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/ [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using 'kubeadm config images pull' [certs] Using certificateDir folder \"/etc/kubernetes/pki\" [certs] Generating \"ca\" certificate and key [certs] Generating \"apiserver\" certificate and key [certs] apiserver serving cert is signed for DNS names [k8smaster kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.16.45.131] [certs] Generating \"apiserver-kubelet-client\" certificate and key [certs] Generating \"front-proxy-ca\" certificate and key [certs] Generating \"front-proxy-client\" certificate and key [certs] Generating \"etcd/ca\" certificate and key [certs] Generating \"etcd/server\" certificate and key [certs] etcd/server serving cert is signed for DNS names [k8smaster localhost] and IPs [172.16.45.131 127.0.0.1 ::1] [certs] Generating \"etcd/peer\" certificate and key [certs] etcd/peer serving cert is signed for DNS names [k8smaster localhost] and IPs [172.16.45.131 127.0.0.1 ::1] [certs] Generating \"etcd/healthcheck-client\" certificate and key [certs] Generating \"apiserver-etcd-client\" certificate and key [certs] Generating \"sa\" key and public key [kubeconfig] Using kubeconfig folder \"/etc/kubernetes\" [kubeconfig] Writing \"admin.conf\" kubeconfig file [kubeconfig] Writing \"kubelet.conf\" kubeconfig file [kubeconfig] Writing \"controller-manager.conf\" kubeconfig file [kubeconfig] Writing \"scheduler.conf\" kubeconfig file [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Starting the kubelet [control-plane] Using manifest folder \"/etc/kubernetes/manifests\" [control-plane] Creating static Pod manifest for \"kube-apiserver\" [control-plane] Creating static Pod manifest for \"kube-controller-manager\" [control-plane] Creating static Pod manifest for \"kube-scheduler\" [etcd] Creating static Pod manifest for local etcd in \"/etc/kubernetes/manifests\" [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \"/etc/kubernetes/manifests\". This can take up to 4m0s [apiclient] All control plane components are healthy after 14.502742 seconds [upload-config] Storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace [kubelet] Creating a ConfigMap \"kubelet-config-1.19\" in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node k8smaster as control-plane by adding the label \"node-role.kubernetes.io/master=''\" [mark-control-plane] Marking the node k8smaster as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: uk5qox.2z2gpcq1qtjl7hlr [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] Creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace [kubelet-finalize] Updating \"/etc/kubernetes/kubelet.conf\" to point to a rotatable kubelet client certificate and key [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 172.16.45.131:6443 --token uk5qox.2z2gpcq1qtjl7hlr \\ --discovery-token-ca-cert-hash sha256:ce6240b7d71a93309c46e99d450028d2d36fcb508960c557e6ce56bfaf0b1c58 接下来在master机器上继续执行：\nmkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 查看节点\nkubectl get nodes 部署Node节点 kubeadm join 172.16.45.131:6443 --token uk5qox.2z2gpcq1qtjl7hlr \\ --discovery-token-ca-cert-hash sha256:ce6240b7d71a93309c46e99d450028d2d36fcb508960c557e6ce56bfaf0b1c58 成功后会显示以下信息\n[root@k8snode1 ~]# kubeadm join 172.16.45.131:6443 --token uk5qox.2z2gpcq1qtjl7hlr \\ \u003e --discovery-token-ca-cert-hash sha256:ce6240b7d71a93309c46e99d450028d2d36fcb508960c557e6ce56bfaf0b1c58 [preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/ [preflight] Reading configuration from the cluster... [preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -oyaml' [kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\" [kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\" [kubelet-start] Starting the kubelet [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap... This node has joined the cluster: * Certificate signing request was sent to apiserver and a response was received. * The Kubelet was informed of the new secure connection details. Run 'kubectl get nodes' on the control-plane to see this node join the cluster. 此时在master上查看节点显示以下信息说明加入成功\n[root@k8smaster ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION k8smaster NotReady master 172m v1.19.4 k8snode1 NotReady \u003cnone\u003e 120m v1.19.4 k8snode2 NotReady \u003cnone\u003e 120m v1.19.4 部署网络插件 下载kube-flannel.yml文件\nwget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 应用kube-flannel.yml文件得到运行时容器\n#在master机器上执行 kubectl apply -f kube-flannel.yml [root@k8smaster ~]# kubectl apply -f kube-flannel.yml podsecuritypolicy.policy/psp.flannel.unprivileged created clusterrole.rbac.authorization.k8s.io/flannel created clusterrolebinding.rbac.authorization.k8s.io/flannel created serviceaccount/flannel created configmap/kube-flannel-cfg created daemonset.apps/kube-flannel-ds created #（稍等几分钟后） 查看节点信息 会看见状态发生变化 [root@k8smaster ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION k8smaster Ready master 172m v1.19.4 k8snode1 Ready \u003cnone\u003e 120m v1.19.4 k8snode2 Ready \u003cnone\u003e 120m v1.19.4 至此我们的k8s环境就搭建好了；\n查看运行时容器pod （一个pod里面运行了多个docker容器）\nkubectl get pods -n kube-system 部署容器化应用 #部署nginx kubectl create deployment nginx --image=nginx kubectl expose deployment nginx --port=80 --type=NodePort kubectl get pod,svc #访问地址：http://NodeIP:Port #部署Tomcat： kubectl create deployment tomcat --image=tomcat kubectl expose deployment tomcat --port=8080 --type=NodePort #访问地址：http://NodeIP:Port K8s部署微服务 1、项目打包（jar、war）–\u003e可以采用一些工具git、maven、jenkins\n2、制作Dockerfile文件，生成镜像；\n3、kubectl create deployment nginx –image= 你的镜像\n4、你的springboot就部署好了，是以docker容器的方式运行在pod里面的；\n","description":"\n","tags":[],"title":"\nKubernetes简介和安装","uri":"/posts/post-289/"},{"categories":["默认分类"],"content":"把网络配置改成nat模式 获取网关地址和子网掩码 通过Mac终端进入VMware Fusion的vmnet8目录\ncd /Library/Preferences/VMware\\ Fusion/vmnet8 查看nat.conf\ncat nat.conf 记住红框中的数据，下面配置时需要用到\n获取可用IP地址 查看cat dhcpd.conf\ncat dhcpd.conf 注意range 这个是虚拟机允许选择的静态ip地址范围，自定义的静态ip地址必须要在这个范围内(本文打算使用172.16.104.130为例介绍)\n获取DNS1地址 mac系统偏好设置—\u003e网络—\u003e\n配置CentOS7网络配置 登录CentOS7进入虚拟机的network-scripts目录\ncd /etc/sysconfig/network-scripts 找到ifcfg-en开头的文件,上图中我的是ifcfg-ens33\n通过vi编辑该文件\n下图是默认配置\n我们将它改成如下配置\n重启服务使修改生效 service network restart 测试配置是否成功 ping一下百度看看，成功Ping到\n其他网络上网连接问题 接下来我们就可以通过SecureCRT等工具远程连接了，有一点请记住，如果你换了一个地方上网的话，可能会发现你的虚拟机有不通了，那是因为DNS地址发生了变化，此时只需要再次编辑ifcfg-enxxx文件，然后加上你现在网络的DNS地址即可\n如:\nDNS1=192.168.0.1 DNS2=114.114.114.114 我们通过SecureCRT连接测试一下\n其他命令 ifconfig #查询自己的IP地址 netstat -rn #查询自己的默认网关和 #子网掩码 cat /etc/resolv.conf #查询自己的 DNS 配置 ","description":"\n","tags":[],"title":"\nMac VM CentOS7配置静态IP","uri":"/posts/post-290/"},{"categories":["Docker"],"content":"Docker\nDocker常用安装 总体步骤 搜索镜像-\u003e拉取镜像-\u003e查看镜像-\u003e启动镜像-\u003e停止容器-\u003e移除容器\n安装tomcat 1.docker hub上面查找tomcat镜像\ndocker search tomcat\n2.从docker hub上拉取tomcat镜像到本地\ndocker pull tomcat\n官网命令：\n3.docker images查看是否有拉取到的tomcat\ndocker images\n4.使用tomcat镜像创建容器(也叫运行镜像)\ndocker run -it -p 8080:8080 tomcat # -p 主机端口:docker容器端口 # -P 随机分配端口 # i:交互 # t:终端 安装mysql docker hub上面查找mysql镜像 从docker hub上(阿里云加速器)拉取mysql镜像到本地标签为5.6 使用mysql5.6镜像创建容器(也叫运行镜像)\n使用mysql镜像\ndocker run -p 12345:3306 --name mysql -v /zzyyuse/mysql/conf:/etc/mysql/conf.d -v /zzyyuse/mysql/logs:/logs -v /zzyyuse/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.6 #命令说明： #-p 12345:3306：将主机的12345端口映射到docker容器的3306端口。 #--name mysql：运行服务名字 #-v /zzyyuse/mysql/conf:/etc/mysql/conf.d ：将主机/zzyyuse/mysql录下的conf/my.cnf 挂载到容器的 /etc/mysql/conf.d #-v /zzyyuse/mysql/logs:/logs：将主机/zzyyuse/mysql目录下的 logs 目录挂载到容器的 /logs。 #-v /zzyyuse/mysql/data:/var/lib/mysql ：将主机/zzyyuse/mysql目录下的data目录挂载到容器的 /var/lib/mysql #-e MYSQL_ROOT_PASSWORD=123456：初始化 root 用户的密码。 #-d mysql:5.6 : 后台程序运行mysql5.6 docker exec -it MySQL运行成功后的容器ID /bin/bash 数据备份\ndocker exec myql服务容器ID sh -c ' exec mysqldump --all-databases -uroot -p\"123456\" ' \u003e /zzyyuse/all-databases.sql 安装redis 从docker hub上(阿里云加速器)拉取redis镜像到本地标签为3.2\n使用redis3.2镜像创建容器(也叫运行镜像)\n使用镜像\ndocker run -p 6379:6379 -v /zzyyuse/myredis/data:/data -v /zzyyuse/myredis/conf/redis.conf:/usr/local/etc/redis/redis.conf -d redis:3.2 redis-server /usr/local/etc/redis/redis.conf --appendonly yes 在主机/zzyyuse/myredis/conf/redis.conf目录下新建redis.conf文件\nvim /zzyyuse/myredis/conf/redis.conf/redis.conf # Redis configuration file example. # Note that in order to read the configuration file, Redis must be # started with the file path as first argument: # # ./redis-server /path/to/redis.conf # Note on units: when memory size is needed, it is possible to specify # it in the usual form of 1k 5GB 4M and so forth: # # 1k =\u003e 1000 bytes # 1kb =\u003e 1024 bytes # 1m =\u003e 1000000 bytes # 1mb =\u003e 1024*1024 bytes # 1g =\u003e 1000000000 bytes # 1gb =\u003e 1024*1024*1024 bytes # # units are case insensitive so 1GB 1Gb 1gB are all the same. ################################## INCLUDES ################################### # Include one or more other config files here. This is useful if you # have a standard template that goes to all Redis servers but also need # to customize a few per-server settings. Include files can include # other files, so use this wisely. # # Notice option \"include\" won't be rewritten by command \"CONFIG REWRITE\" # from admin or Redis Sentinel. Since Redis always uses the last processed # line as value of a configuration directive, you'd better put includes # at the beginning of this file to avoid overwriting config change at runtime. # # If instead you are interested in using includes to override configuration # options, it is better to use include as the last line. # # include /path/to/local.conf # include /path/to/other.conf ################################## NETWORK ##################################### # By default, if no \"bind\" configuration directive is specified, Redis listens # for connections from all the network interfaces available on the server. # It is possible to listen to just one or multiple selected interfaces using # the \"bind\" configuration directive, followed by one or more IP addresses. # # Examples: # # bind 192.168.1.100 10.0.0.1 # bind 127.0.0.1 ::1 # # ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the # internet, binding to all the interfaces is dangerous and will expose the # instance to everybody on the internet. So by default we uncomment the # following bind directive, that will force Redis to listen only into # the IPv4 lookback interface address (this means Redis will be able to # accept connections only from clients running into the same computer it # is running). # # IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES # JUST COMMENT THE FOLLOWING LINE. # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #bind 127.0.0.1 # Protected mode is a layer of security protection, in order to avoid that # Redis instances left open on the internet are accessed and exploited. # # When protected mode is on and if: # # 1) The server is not binding explicitly to a set of addresses using the # \"bind\" directive. # 2) No password is configured. # # The server only accepts connections from clients connecting from the # IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain # sockets. # # By default protected mode is enabled. You should disable it only if # you are sure you want clients from other hosts to connect to Redis # even if no authentication is configured, nor a specific set of interfaces # are explicitly listed using the \"bind\" directive. protected-mode yes # Accept connections on the specified port, default is 6379 (IANA #815344). # If port 0 is specified Redis will not listen on a TCP socket. port 6379 # TCP listen() backlog. # # In high requests-per-second environments you need an high backlog in order # to avoid slow clients connections issues. Note that the Linux kernel # will silently truncate it to the value of /proc/sys/net/core/somaxconn so # make sure to raise both the value of somaxconn and tcp_max_syn_backlog # in order to get the desired effect. tcp-backlog 511 # Unix socket. # # Specify the path for the Unix socket that will be used to listen for # incoming connections. There is no default, so Redis will not listen # on a unix socket when not specified. # # unixsocket /tmp/redis.sock # unixsocketperm 700 # Close the connection after a client is idle for N seconds (0 to disable) timeout 0 # TCP keepalive. # # If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence # of communication. This is useful for two reasons: # # 1) Detect dead peers. # 2) Take the connection alive from the point of view of network # equipment in the middle. # # On Linux, the specified value (in seconds) is the period used to send ACKs. # Note that to close the connection the double of the time is needed. # On other kernels the period depends on the kernel configuration. # # A reasonable value for this option is 300 seconds, which is the new # Redis default starting with Redis 3.2.1. tcp-keepalive 300 ################################# GENERAL ##################################### # By default Redis does not run as a daemon. Use 'yes' if you need it. # Note that Redis will write a pid file in /var/run/redis.pid when daemonized. #daemonize no # If you run Redis from upstart or systemd, Redis can interact with your # supervision tree. Options: # supervised no - no supervision interaction # supervised upstart - signal upstart by putting Redis into SIGSTOP mode # supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET # supervised auto - detect upstart or systemd method based on # UPSTART_JOB or NOTIFY_SOCKET environment variables # Note: these supervision methods only signal \"process is ready.\" # They do not enable continuous liveness pings back to your supervisor. supervised no # If a pid file is specified, Redis writes it where specified at startup # and removes it at exit. # # When the server runs non daemonized, no pid file is created if none is # specified in the configuration. When the server is daemonized, the pid file # is used even if not specified, defaulting to \"/var/run/redis.pid\". # # Creating a pid file is best effort: if Redis is not able to create it # nothing bad happens, the server will start and run normally. pidfile /var/run/redis_6379.pid # Specify the server verbosity level. # This can be one of: # debug (a lot of information, useful for development/testing) # verbose (many rarely useful info, but not a mess like the debug level) # notice (moderately verbose, what you want in production probably) # warning (only very important / critical messages are logged) loglevel notice # Specify the log file name. Also the empty string can be used to force # Redis to log on the standard output. Note that if you use standard # output for logging but daemonize, logs will be sent to /dev/null logfile \"\" # To enable logging to the system logger, just set 'syslog-enabled' to yes, # and optionally update the other syslog parameters to suit your needs. # syslog-enabled no # Specify the syslog identity. # syslog-ident redis # Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7. # syslog-facility local0 # Set the number of databases. The default database is DB 0, you can select # a different one on a per-connection basis using SELECT \u003cdbid\u003e where # dbid is a number between 0 and 'databases'-1 databases 16 ################################ SNAPSHOTTING ################################ # # Save the DB on disk: # # save \u003cseconds\u003e \u003cchanges\u003e # # Will save the DB if both the given number of seconds and the given # number of write operations against the DB occurred. # # In the example below the behaviour will be to save: # after 900 sec (15 min) if at least 1 key changed # after 300 sec (5 min) if at least 10 keys changed # after 60 sec if at least 10000 keys changed # # Note: you can disable saving completely by commenting out all \"save\" lines. # # It is also possible to remove all the previously configured save # points by adding a save directive with a single empty string argument # like in the following example: # # save \"\" save 120 1 save 300 10 save 60 10000 # By default Redis will stop accepting writes if RDB snapshots are enabled # (at least one save point) and the latest background save failed. # This will make the user aware (in a hard way) that data is not persisting # on disk properly, otherwise chances are that no one will notice and some # disaster will happen. # # If the background saving process will start working again Redis will # automatically allow writes again. # # However if you have setup your proper monitoring of the Redis server # and persistence, you may want to disable this feature so that Redis will # continue to work as usual even if there are problems with disk, # permissions, and so forth. stop-writes-on-bgsave-error yes # Compress string objects using LZF when dump .rdb databases? # For default that's set to 'yes' as it's almost always a win. # If you want to save some CPU in the saving child set it to 'no' but # the dataset will likely be bigger if you have compressible values or keys. rdbcompression yes # Since version 5 of RDB a CRC64 checksum is placed at the end of the file. # This makes the format more resistant to corruption but there is a performance # hit to pay (around 10%) when saving and loading RDB files, so you can disable it # for maximum performances. # # RDB files created with checksum disabled have a checksum of zero that will # tell the loading code to skip the check. rdbchecksum yes # The filename where to dump the DB dbfilename dump.rdb # The working directory. # # The DB will be written inside this directory, with the filename specified # above using the 'dbfilename' configuration directive. # # The Append Only File will also be created inside this directory. # # Note that you must specify a directory here, not a file name. dir ./ ################################# REPLICATION ################################# # Master-Slave replication. Use slaveof to make a Redis instance a copy of # another Redis server. A few things to understand ASAP about Redis replication. # # 1) Redis replication is asynchronous, but you can configure a master to # stop accepting writes if it appears to be not connected with at least # a given number of slaves. # 2) Redis slaves are able to perform a partial resynchronization with the # master if the replication link is lost for a relatively small amount of # time. You may want to configure the replication backlog size (see the next # sections of this file) with a sensible value depending on your needs. # 3) Replication is automatic and does not need user intervention. After a # network partition slaves automatically try to reconnect to masters # and resynchronize with them. # # slaveof \u003cmasterip\u003e \u003cmasterport\u003e # If the master is password protected (using the \"requirepass\" configuration # directive below) it is possible to tell the slave to authenticate before # starting the replication synchronization process, otherwise the master will # refuse the slave request. # # masterauth \u003cmaster-password\u003e # When a slave loses its connection with the master, or when the replication # is still in progress, the slave can act in two different ways: # # 1) if slave-serve-stale-data is set to 'yes' (the default) the slave will # still reply to client requests, possibly with out of date data, or the # data set may just be empty if this is the first synchronization. # # 2) if slave-serve-stale-data is set to 'no' the slave will reply with # an error \"SYNC with master in progress\" to all the kind of commands # but to INFO and SLAVEOF. # slave-serve-stale-data yes # You can configure a slave instance to accept writes or not. Writing against # a slave instance may be useful to store some ephemeral data (because data # written on a slave will be easily deleted after resync with the master) but # may also cause problems if clients are writing to it because of a # misconfiguration. # # Since Redis 2.6 by default slaves are read-only. # # Note: read only slaves are not designed to be exposed to untrusted clients # on the internet. It's just a protection layer against misuse of the instance. # Still a read only slave exports by default all the administrative commands # such as CONFIG, DEBUG, and so forth. To a limited extent you can improve # security of read only slaves using 'rename-command' to shadow all the # administrative / dangerous commands. slave-read-only yes # Replication SYNC strategy: disk or socket. # # ------------------------------------------------------- # WARNING: DISKLESS REPLICATION IS EXPERIMENTAL CURRENTLY # ------------------------------------------------------- # # New slaves and reconnecting slaves that are not able to continue the replication # process just receiving differences, need to do what is called a \"full # synchronization\". An RDB file is transmitted from the master to the slaves. # The transmission can happen in two different ways: # # 1) Disk-backed: The Redis master creates a new process that writes the RDB # file on disk. Later the file is transferred by the parent # process to the slaves incrementally. # 2) Diskless: The Redis master creates a new process that directly writes the # RDB file to slave sockets, without touching the disk at all. # # With disk-backed replication, while the RDB file is generated, more slaves # can be queued and served with the RDB file as soon as the current child producing # the RDB file finishes its work. With diskless replication instead once # the transfer starts, new slaves arriving will be queued and a new transfer # will start when the current one terminates. # # When diskless replication is used, the master waits a configurable amount of # time (in seconds) before starting the transfer in the hope that multiple slaves # will arrive and the transfer can be parallelized. # # With slow disks and fast (large bandwidth) networks, diskless replication # works better. repl-diskless-sync no # When diskless replication is enabled, it is possible to configure the delay # the server waits in order to spawn the child that transfers the RDB via socket # to the slaves. # # This is important since once the transfer starts, it is not possible to serve # new slaves arriving, that will be queued for the next RDB transfer, so the server # waits a delay in order to let more slaves arrive. # # The delay is specified in seconds, and by default is 5 seconds. To disable # it entirely just set it to 0 seconds and the transfer will start ASAP. repl-diskless-sync-delay 5 # Slaves send PINGs to server in a predefined interval. It's possible to change # this interval with the repl_ping_slave_period option. The default value is 10 # seconds. # # repl-ping-slave-period 10 # The following option sets the replication timeout for: # # 1) Bulk transfer I/O during SYNC, from the point of view of slave. # 2) Master timeout from the point of view of slaves (data, pings). # 3) Slave timeout from the point of view of masters (REPLCONF ACK pings). # # It is important to make sure that this value is greater than the value # specified for repl-ping-slave-period otherwise a timeout will be detected # every time there is low traffic between the master and the slave. # # repl-timeout 60 # Disable TCP_NODELAY on the slave socket after SYNC? # # If you select \"yes\" Redis will use a smaller number of TCP packets and # less bandwidth to send data to slaves. But this can add a delay for # the data to appear on the slave side, up to 40 milliseconds with # Linux kernels using a default configuration. # # If you select \"no\" the delay for data to appear on the slave side will # be reduced but more bandwidth will be used for replication. # # By default we optimize for low latency, but in very high traffic conditions # or when the master and slaves are many hops away, turning this to \"yes\" may # be a good idea. repl-disable-tcp-nodelay no # Set the replication backlog size. The backlog is a buffer that accumulates # slave data when slaves are disconnected for some time, so that when a slave # wants to reconnect again, often a full resync is not needed, but a partial # resync is enough, just passing the portion of data the slave missed while # disconnected. # # The bigger the replication backlog, the longer the time the slave can be # disconnected and later be able to perform a partial resynchronization. # # The backlog is only allocated once there is at least a slave connected. # # repl-backlog-size 1mb # After a master has no longer connected slaves for some time, the backlog # will be freed. The following option configures the amount of seconds that # need to elapse, starting from the time the last slave disconnected, for # the backlog buffer to be freed. # # A value of 0 means to never release the backlog. # # repl-backlog-ttl 3600 # The slave priority is an integer number published by Redis in the INFO output. # It is used by Redis Sentinel in order to select a slave to promote into a # master if the master is no longer working correctly. # # A slave with a low priority number is considered better for promotion, so # for instance if there are three slaves with priority 10, 100, 25 Sentinel will # pick the one with priority 10, that is the lowest. # # However a special priority of 0 marks the slave as not able to perform the # role of master, so a slave with priority of 0 will never be selected by # Redis Sentinel for promotion. # # By default the priority is 100. slave-priority 100 # It is possible for a master to stop accepting writes if there are less than # N slaves connected, having a lag less or equal than M seconds. # # The N slaves need to be in \"online\" state. # # The lag in seconds, that must be \u003c= the specified value, is calculated from # the last ping received from the slave, that is usually sent every second. # # This option does not GUARANTEE that N replicas will accept the write, but # will limit the window of exposure for lost writes in case not enough slaves # are available, to the specified number of seconds. # # For example to require at least 3 slaves with a lag \u003c= 10 seconds use: # # min-slaves-to-write 3 # min-slaves-max-lag 10 # # Setting one or the other to 0 disables the feature. # # By default min-slaves-to-write is set to 0 (feature disabled) and # min-slaves-max-lag is set to 10. # A Redis master is able to list the address and port of the attached # slaves in different ways. For example the \"INFO replication\" section # offers this information, which is used, among other tools, by # Redis Sentinel in order to discover slave instances. # Another place where this info is available is in the output of the # \"ROLE\" command of a masteer. # # The listed IP and address normally reported by a slave is obtained # in the following way: # # IP: The address is auto detected by checking the peer address # of the socket used by the slave to connect with the master. # # Port: The port is communicated by the slave during the replication # handshake, and is normally the port that the slave is using to # list for connections. # # However when port forwarding or Network Address Translation (NAT) is # used, the slave may be actually reachable via different IP and port # pairs. The following two options can be used by a slave in order to # report to its master a specific set of IP and port, so that both INFO # and ROLE will report those values. # # There is no need to use both the options if you need to override just # the port or the IP address. # # slave-announce-ip 5.5.5.5 # slave-announce-port 1234 ################################## SECURITY ################################### # Require clients to issue AUTH \u003cPASSWORD\u003e before processing any other # commands. This might be useful in environments in which you do not trust # others with access to the host running redis-server. # # This should stay commented out for backward compatibility and because most # people do not need auth (e.g. they run their own servers). # # Warning: since Redis is pretty fast an outside user can try up to # 150k passwords per second against a good box. This means that you should # use a very strong password otherwise it will be very easy to break. # # requirepass foobared # Command renaming. # # It is possible to change the name of dangerous commands in a shared # environment. For instance the CONFIG command may be renamed into something # hard to guess so that it will still be available for internal-use tools # but not available for general clients. # # Example: # # rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52 # # It is also possible to completely kill a command by renaming it into # an empty string: # # rename-command CONFIG \"\" # # Please note that changing the name of commands that are logged into the # AOF file or transmitted to slaves may cause problems. ################################### LIMITS #################################### # Set the max number of connected clients at the same time. By default # this limit is set to 10000 clients, however if the Redis server is not # able to configure the process file limit to allow for the specified limit # the max number of allowed clients is set to the current file limit # minus 32 (as Redis reserves a few file descriptors for internal uses). # # Once the limit is reached Redis will close all the new connections sending # an error 'max number of clients reached'. # # maxclients 10000 # Don't use more memory than the specified amount of bytes. # When the memory limit is reached Redis will try to remove keys # according to the eviction policy selected (see maxmemory-policy). # # If Redis can't remove keys according to the policy, or if the policy is # set to 'noeviction', Redis will start to reply with errors to commands # that would use more memory, like SET, LPUSH, and so on, and will continue # to reply to read-only commands like GET. # # This option is usually useful when using Redis as an LRU cache, or to set # a hard memory limit for an instance (using the 'noeviction' policy). # # WARNING: If you have slaves attached to an instance with maxmemory on, # the size of the output buffers needed to feed the slaves are subtracted # from the used memory count, so that network problems / resyncs will # not trigger a loop where keys are evicted, and in turn the output # buffer of slaves is full with DELs of keys evicted triggering the deletion # of more keys, and so forth until the database is completely emptied. # # In short... if you have slaves attached it is suggested that you set a lower # limit for maxmemory so that there is some free RAM on the system for slave # output buffers (but this is not needed if the policy is 'noeviction'). # # maxmemory \u003cbytes\u003e # MAXMEMORY POLICY: how Redis will select what to remove when maxmemory # is reached. You can select among five behaviors: # # volatile-lru -\u003e remove the key with an expire set using an LRU algorithm # allkeys-lru -\u003e remove any key according to the LRU algorithm # volatile-random -\u003e remove a random key with an expire set # allkeys-random -\u003e remove a random key, any key # volatile-ttl -\u003e remove the key with the nearest expire time (minor TTL) # noeviction -\u003e don't expire at all, just return an error on write operations # # Note: with any of the above policies, Redis will return an error on write # operations, when there are no suitable keys for eviction. # # At the date of writing these commands are: set setnx setex append # incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd # sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby # zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby # getset mset msetnx exec sort # # The default is: # # maxmemory-policy noeviction # LRU and minimal TTL algorithms are not precise algorithms but approximated # algorithms (in order to save memory), so you can tune it for speed or # accuracy. For default Redis will check five keys and pick the one that was # used less recently, you can change the sample size using the following # configuration directive. # # The default of 5 produces good enough results. 10 Approximates very closely # true LRU but costs a bit more CPU. 3 is very fast but not very accurate. # # maxmemory-samples 5 ############################## APPEND ONLY MODE ############################### # By default Redis asynchronously dumps the dataset on disk. This mode is # good enough in many applications, but an issue with the Redis process or # a power outage may result into a few minutes of writes lost (depending on # the configured save points). # # The Append Only File is an alternative persistence mode that provides # much better durability. For instance using the default data fsync policy # (see later in the config file) Redis can lose just one second of writes in a # dramatic event like a server power outage, or a single write if something # wrong with the Redis process itself happens, but the operating system is # still running correctly. # # AOF and RDB persistence can be enabled at the same time without problems. # If the AOF is enabled on startup Redis will load the AOF, that is the file # with the better durability guarantees. # # Please check http://redis.io/topics/persistence for more information. appendonly no # The name of the append only file (default: \"appendonly.aof\") appendfilename \"appendonly.aof\" # The fsync() call tells the Operating System to actually write data on disk # instead of waiting for more data in the output buffer. Some OS will really flush # data on disk, some other OS will just try to do it ASAP. # # Redis supports three different modes: # # no: don't fsync, just let the OS flush the data when it wants. Faster. # always: fsync after every write to the append only log. Slow, Safest. # everysec: fsync only one time every second. Compromise. # # The default is \"everysec\", as that's usually the right compromise between # speed and data safety. It's up to you to understand if you can relax this to # \"no\" that will let the operating system flush the output buffer when # it wants, for better performances (but if you can live with the idea of # some data loss consider the default persistence mode that's snapshotting), # or on the contrary, use \"always\" that's very slow but a bit safer than # everysec. # # More details please check the following article: # http://antirez.com/post/redis-persistence-demystified.html # # If unsure, use \"everysec\". # appendfsync always appendfsync everysec # appendfsync no # When the AOF fsync policy is set to always or everysec, and a background # saving process (a background save or AOF log background rewriting) is # performing a lot of I/O against the disk, in some Linux configurations # Redis may block too long on the fsync() call. Note that there is no fix for # this currently, as even performing fsync in a different thread will block # our synchronous write(2) call. # # In order to mitigate this problem it's possible to use the following option # that will prevent fsync() from being called in the main process while a # BGSAVE or BGREWRITEAOF is in progress. # # This means that while another child is saving, the durability of Redis is # the same as \"appendfsync none\". In practical terms, this means that it is # possible to lose up to 30 seconds of log in the worst scenario (with the # default Linux settings). # # If you have latency problems turn this to \"yes\". Otherwise leave it as # \"no\" that is the safest pick from the point of view of durability. no-appendfsync-on-rewrite no # Automatic rewrite of the append only file. # Redis is able to automatically rewrite the log file implicitly calling # BGREWRITEAOF when the AOF log size grows by the specified percentage. # # This is how it works: Redis remembers the size of the AOF file after the # latest rewrite (if no rewrite has happened since the restart, the size of # the AOF at startup is used). # # This base size is compared to the current size. If the current size is # bigger than the specified percentage, the rewrite is triggered. Also # you need to specify a minimal size for the AOF file to be rewritten, this # is useful to avoid rewriting the AOF file even if the percentage increase # is reached but it is still pretty small. # # Specify a percentage of zero in order to disable the automatic AOF # rewrite feature. auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb # An AOF file may be found to be truncated at the end during the Redis # startup process, when the AOF data gets loaded back into memory. # This may happen when the system where Redis is running # crashes, especially when an ext4 filesystem is mounted without the # data=ordered option (however this can't happen when Redis itself # crashes or aborts but the operating system still works correctly). # # Redis can either exit with an error when this happens, or load as much # data as possible (the default now) and start if the AOF file is found # to be truncated at the end. The following option controls this behavior. # # If aof-load-truncated is set to yes, a truncated AOF file is loaded and # the Redis server starts emitting a log to inform the user of the event. # Otherwise if the option is set to no, the server aborts with an error # and refuses to start. When the option is set to no, the user requires # to fix the AOF file using the \"redis-check-aof\" utility before to restart # the server. # # Note that if the AOF file will be found to be corrupted in the middle # the server will still exit with an error. This option only applies when # Redis will try to read more data from the AOF file but not enough bytes # will be found. aof-load-truncated yes ################################ LUA SCRIPTING ############################### # Max execution time of a Lua script in milliseconds. # # If the maximum execution time is reached Redis will log that a script is # still in execution after the maximum allowed time and will start to # reply to queries with an error. # # When a long running script exceeds the maximum execution time only the # SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be # used to stop a script that did not yet called write commands. The second # is the only way to shut down the server in the case a write command was # already issued by the script but the user doesn't want to wait for the natural # termination of the script. # # Set it to 0 or a negative value for unlimited execution without warnings. lua-time-limit 5000 ################################ REDIS CLUSTER ############################### # # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ # WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however # in order to mark it as \"mature\" we need to wait for a non trivial percentage # of users to deploy it in production. # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ # # Normal Redis instances can't be part of a Redis Cluster; only nodes that are # started as cluster nodes can. In order to start a Redis instance as a # cluster node enable the cluster support uncommenting the following: # # cluster-enabled yes # Every cluster node has a cluster configuration file. This file is not # intended to be edited by hand. It is created and updated by Redis nodes. # Every Redis Cluster node requires a different cluster configuration file. # Make sure that instances running in the same system do not have # overlapping cluster configuration file names. # # cluster-config-file nodes-6379.conf # Cluster node timeout is the amount of milliseconds a node must be unreachable # for it to be considered in failure state. # Most other internal time limits are multiple of the node timeout. # # cluster-node-timeout 15000 # A slave of a failing master will avoid to start a failover if its data # looks too old. # # There is no simple way for a slave to actually have a exact measure of # its \"data age\", so the following two checks are performed: # # 1) If there are multiple slaves able to failover, they exchange messages # in order to try to give an advantage to the slave with the best # replication offset (more data from the master processed). # Slaves will try to get their rank by offset, and apply to the start # of the failover a delay proportional to their rank. # # 2) Every single slave computes the time of the last interaction with # its master. This can be the last ping or command received (if the master # is still in the \"connected\" state), or the time that elapsed since the # disconnection with the master (if the replication link is currently down). # If the last interaction is too old, the slave will not try to failover # at all. # # The point \"2\" can be tuned by user. Specifically a slave will not perform # the failover if, since the last interaction with the master, the time # elapsed is greater than: # # (node-timeout * slave-validity-factor) + repl-ping-slave-period # # So for example if node-timeout is 30 seconds, and the slave-validity-factor # is 10, and assuming a default repl-ping-slave-period of 10 seconds, the # slave will not try to failover if it was not able to talk with the master # for longer than 310 seconds. # # A large slave-validity-factor may allow slaves with too old data to failover # a master, while a too small value may prevent the cluster from being able to # elect a slave at all. # # For maximum availability, it is possible to set the slave-validity-factor # to a value of 0, which means, that slaves will always try to failover the # master regardless of the last time they interacted with the master. # (However they'll always try to apply a delay proportional to their # offset rank). # # Zero is the only value able to guarantee that when all the partitions heal # the cluster will always be able to continue. # # cluster-slave-validity-factor 10 # Cluster slaves are able to migrate to orphaned masters, that are masters # that are left without working slaves. This improves the cluster ability # to resist to failures as otherwise an orphaned master can't be failed over # in case of failure if it has no working slaves. # # Slaves migrate to orphaned masters only if there are still at least a # given number of other working slaves for their old master. This number # is the \"migration barrier\". A migration barrier of 1 means that a slave # will migrate only if there is at least 1 other working slave for its master # and so forth. It usually reflects the number of slaves you want for every # master in your cluster. # # Default is 1 (slaves migrate only if their masters remain with at least # one slave). To disable migration just set it to a very large value. # A value of 0 can be set but is useful only for debugging and dangerous # in production. # # cluster-migration-barrier 1 # By default Redis Cluster nodes stop accepting queries if they detect there # is at least an hash slot uncovered (no available node is serving it). # This way if the cluster is partially down (for example a range of hash slots # are no longer covered) all the cluster becomes, eventually, unavailable. # It automatically returns available as soon as all the slots are covered again. # # However sometimes you want the subset of the cluster which is working, # to continue to accept queries for the part of the key space that is still # covered. In order to do so, just set the cluster-require-full-coverage # option to no. # # cluster-require-full-coverage yes # In order to setup your cluster make sure to read the documentation # available at http://redis.io web site. ################################## SLOW LOG ################################### # The Redis Slow Log is a system to log queries that exceeded a specified # execution time. The execution time does not include the I/O operations # like talking with the client, sending the reply and so forth, # but just the time needed to actually execute the command (this is the only # stage of command execution where the thread is blocked and can not serve # other requests in the meantime). # # You can configure the slow log with two parameters: one tells Redis # what is the execution time, in microseconds, to exceed in order for the # command to get logged, and the other parameter is the length of the # slow log. When a new command is logged the oldest one is removed from the # queue of logged commands. # The following time is expressed in microseconds, so 1000000 is equivalent # to one second. Note that a negative number disables the slow log, while # a value of zero forces the logging of every command. slowlog-log-slower-than 10000 # There is no limit to this length. Just be aware that it will consume memory. # You can reclaim memory used by the slow log with SLOWLOG RESET. slowlog-max-len 128 ################################ LATENCY MONITOR ############################## # The Redis latency monitoring subsystem samples different operations # at runtime in order to collect data related to possible sources of # latency of a Redis instance. # # Via the LATENCY command this information is available to the user that can # print graphs and obtain reports. # # The system only logs operations that were performed in a time equal or # greater than the amount of milliseconds specified via the # latency-monitor-threshold configuration directive. When its value is set # to zero, the latency monitor is turned off. # # By default latency monitoring is disabled since it is mostly not needed # if you don't have latency issues, and collecting data has a performance # impact, that while very small, can be measured under big load. Latency # monitoring can easily be enabled at runtime using the command # \"CONFIG SET latency-monitor-threshold \u003cmilliseconds\u003e\" if needed. latency-monitor-threshold 0 ############################# EVENT NOTIFICATION ############################## # Redis can notify Pub/Sub clients about events happening in the key space. # This feature is documented at http://redis.io/topics/notifications # # For instance if keyspace events notification is enabled, and a client # performs a DEL operation on key \"foo\" stored in the Database 0, two # messages will be published via Pub/Sub: # # PUBLISH __keyspace@0__:foo del # PUBLISH __keyevent@0__:del foo # # It is possible to select the events that Redis will notify among a set # of classes. Every class is identified by a single character: # # K Keyspace events, published with __keyspace@\u003cdb\u003e__ prefix. # E Keyevent events, published with __keyevent@\u003cdb\u003e__ prefix. # g Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ... # $ String commands # l List commands # s Set commands # h Hash commands # z Sorted set commands # x Expired events (events generated every time a key expires) # e Evicted events (events generated when a key is evicted for maxmemory) # A Alias for g$lshzxe, so that the \"AKE\" string means all the events. # # The \"notify-keyspace-events\" takes as argument a string that is composed # of zero or multiple characters. The empty string means that notifications # are disabled. # # Example: to enable list and generic events, from the point of view of the # event name, use: # # notify-keyspace-events Elg # # Example 2: to get the stream of the expired keys subscribing to channel # name __keyevent@0__:expired use: # # notify-keyspace-events Ex # # By default all notifications are disabled because most users don't need # this feature and the feature has some overhead. Note that if you don't # specify at least one of K or E, no events will be delivered. notify-keyspace-events \"\" ############################### ADVANCED CONFIG ############################### # Hashes are encoded using a memory efficient data structure when they have a # small number of entries, and the biggest entry does not exceed a given # threshold. These thresholds can be configured using the following directives. hash-max-ziplist-entries 512 hash-max-ziplist-value 64 # Lists are also encoded in a special way to save a lot of space. # The number of entries allowed per internal list node can be specified # as a fixed maximum size or a maximum number of elements. # For a fixed maximum size, use -5 through -1, meaning: # -5: max size: 64 Kb \u003c-- not recommended for normal workloads # -4: max size: 32 Kb \u003c-- not recommended # -3: max size: 16 Kb \u003c-- probably not recommended # -2: max size: 8 Kb \u003c-- good # -1: max size: 4 Kb \u003c-- good # Positive numbers mean store up to _exactly_ that number of elements # per list node. # The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size), # but if your use case is unique, adjust the settings as necessary. list-max-ziplist-size -2 # Lists may also be compressed. # Compress depth is the number of quicklist ziplist nodes from *each* side of # the list to *exclude* from compression. The head and tail of the list # are always uncompressed for fast push/pop operations. Settings are: # 0: disable all list compression # 1: depth 1 means \"don't start compressing until after 1 node into the list, # going from either the head or tail\" # So: [head]-\u003enode-\u003enode-\u003e...-\u003enode-\u003e[tail] # [head], [tail] will always be uncompressed; inner nodes will compress. # 2: [head]-\u003e[next]-\u003enode-\u003enode-\u003e...-\u003enode-\u003e[prev]-\u003e[tail] # 2 here means: don't compress head or head-\u003enext or tail-\u003eprev or tail, # but compress all nodes between them. # 3: [head]-\u003e[next]-\u003e[next]-\u003enode-\u003enode-\u003e...-\u003enode-\u003e[prev]-\u003e[prev]-\u003e[tail] # etc. list-compress-depth 0 # Sets have a special encoding in just one case: when a set is composed # of just strings that happen to be integers in radix 10 in the range # of 64 bit signed integers. # The following configuration setting sets the limit in the size of the # set in order to use this special memory saving encoding. set-max-intset-entries 512 # Similarly to hashes and lists, sorted sets are also specially encoded in # order to save a lot of space. This encoding is only used when the length and # elements of a sorted set are below the following limits: zset-max-ziplist-entries 128 zset-max-ziplist-value 64 # HyperLogLog sparse representation bytes limit. The limit includes the # 16 bytes header. When an HyperLogLog using the sparse representation crosses # this limit, it is converted into the dense representation. # # A value greater than 16000 is totally useless, since at that point the # dense representation is more memory efficient. # # The suggested value is ~ 3000 in order to have the benefits of # the space efficient encoding without slowing down too much PFADD, # which is O(N) with the sparse encoding. The value can be raised to # ~ 10000 when CPU is not a concern, but space is, and the data set is # composed of many HyperLogLogs with cardinality in the 0 - 15000 range. hll-sparse-max-bytes 3000 # Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in # order to help rehashing the main Redis hash table (the one mapping top-level # keys to values). The hash table implementation Redis uses (see dict.c) # performs a lazy rehashing: the more operation you run into a hash table # that is rehashing, the more rehashing \"steps\" are performed, so if the # server is idle the rehashing is never complete and some more memory is used # by the hash table. # # The default is to use this millisecond 10 times every second in order to # actively rehash the main dictionaries, freeing memory when possible. # # If unsure: # use \"activerehashing no\" if you have hard latency requirements and it is # not a good thing in your environment that Redis can reply from time to time # to queries with 2 milliseconds delay. # # use \"activerehashing yes\" if you don't have such hard requirements but # want to free memory asap when possible. activerehashing yes # The client output buffer limits can be used to force disconnection of clients # that are not reading data from the server fast enough for some reason (a # common reason is that a Pub/Sub client can't consume messages as fast as the # publisher can produce them). # # The limit can be set differently for the three different classes of clients: # # normal -\u003e normal clients including MONITOR clients # slave -\u003e slave clients # pubsub -\u003e clients subscribed to at least one pubsub channel or pattern # # The syntax of every client-output-buffer-limit directive is the following: # # client-output-buffer-limit \u003cclass\u003e \u003chard limit\u003e \u003csoft limit\u003e \u003csoft seconds\u003e # # A client is immediately disconnected once the hard limit is reached, or if # the soft limit is reached and remains reached for the specified number of # seconds (continuously). # So for instance if the hard limit is 32 megabytes and the soft limit is # 16 megabytes / 10 seconds, the client will get disconnected immediately # if the size of the output buffers reach 32 megabytes, but will also get # disconnected if the client reaches 16 megabytes and continuously overcomes # the limit for 10 seconds. # # By default normal clients are not limited because they don't receive data # without asking (in a push way), but just after a request, so only # asynchronous clients may create a scenario where data is requested faster # than it can read. # # Instead there is a default limit for pubsub and slave clients, since # subscribers and slaves receive data in a push fashion. # # Both the hard or the soft limit can be disabled by setting them to zero. client-output-buffer-limit normal 0 0 0 client-output-buffer-limit slave 256mb 64mb 60 client-output-buffer-limit pubsub 32mb 8mb 60 # Redis calls an internal function to perform many background tasks, like # closing connections of clients in timeout, purging expired keys that are # never requested, and so forth. # # Not all tasks are performed with the same frequency, but Redis checks for # tasks to perform according to the specified \"hz\" value. # # By default \"hz\" is set to 10. Raising the value will use more CPU when # Redis is idle, but at the same time will make Redis more responsive when # there are many keys expiring at the same time, and timeouts may be # handled with more precision. # # The range is between 1 and 500, however a value over 100 is usually not # a good idea. Most users should use the default of 10 and raise this up to # 100 only in environments where very low latency is required. hz 10 # When a child rewrites the AOF file, if the following option is enabled # the file will be fsync-ed every 32 MB of data generated. This is useful # in order to commit the file to the disk more incrementally and avoid # big latency spikes. aof-rewrite-incremental-fsync yes 测试redis-cli连接上来\ndocker exec -it 运行着Rediis服务的容器ID redis-cli 测试持久化文件生成\n本地镜像发布到阿里云 本地镜像发布到阿里云流程 镜像的生成方法 前面的DockerFile\n从容器创建一个新的镜像\ndocker commit [OPTIONS] 容器ID [REPOSITORY[:TAG]] # OPTIONS说明： # -a :提交的镜像作者； # -m :提交时的说明文字； 本地镜像推送到阿里云 本地镜像素材原型 阿里云开发者平台 https://dev.aliyun.com/search.html\n创建仓库镜像 将镜像推送到registry\n公有云可以查询到\n查看详情\n将阿里云上的镜像下载到本地 下载到本地\n","description":"\n","tags":[],"title":"\nDocker-常用安装与镜像发布到阿里云（四）","uri":"/posts/post-291/"},{"categories":["Docker"],"content":"Docker\nDocker容器数据卷 是什么？ 先来看看Docker的理念：\n将运用与运行的环境打包形成容器运行 ，运行可以伴随着容器，但是我们对数据的要求希望是持久化的\n容器之间希望有可能共享数据\nDocker容器产生的数据，如果不通过docker commit生成新的镜像，使得数据做为镜像的一部分保存下来，那么当容器删除后，数据自然也就没有了。\n为了能保存数据在docker中我们使用卷。\n一句话：有点类似我们Redis里面的rdb和aof文件\n能干嘛？ 卷就是目录或文件，存在于一个或多个容器中，由docker挂载到容器，但不属于联合文件系统，因此能够绕过Union File System提供一些用于持续存储或共享数据的特性：\n卷的设计目的就是数据的持久化，完全独立于容器的生存周期，因此Docker不会在容器删除时删除其挂载的数据卷\n特点：\n数据卷可在容器之间共享或重用数据\n卷中的更改可以直接生效\n数据卷中的更改不会包含在镜像的更新中\n数据卷的生命周期一直持续到没有容器使用它为止\n容器的持久化\n容器间继承+共享数据\n数据卷 容器内直接命令添加 命令\ndocker run -it -v /宿主机绝对路径目录:/容器内目录 镜像名 /bin/bash 查看数据卷是否挂载成功\ndocker inspect 容器ID 容器和宿主机之间数据共享\n容器停止退出后，主机修改后数据是否同步\ndocker run -it -v /宿主机绝对路径目录:/容器内目录:ro 镜像名 DockerFile添加 根目录下新建mydocker文件夹并进入\n可在Dockerfile中使用VOLUME指令来给镜像添加一个或多个数据卷\nVOLUME[\"/dataVolumeContainer\",\"/dataVolumeContainer2\",\"/dataVolumeContainer3\"]\n说明：\n出于可移植和分享的考虑，用-v 主机目录:容器目录这种方法不能够直接在Dockerfile中实现。\n由于宿主机目录是依赖于特定宿主机的，并不能够保证在所有的宿主机上都存在这样的特定目录。\nFile构建 [root@maruifu mydocker]# pwd /mydocker [root@maruifu mydocker]# cat dockerfile2 # volume test FROM centos VOLUME [\"/dataVolumeContainer1\",\"/dataVolumeContainer2\"] CMD echo \"finished,--------success1\" CMD /bin/bash build后生成镜像 获得一个新镜像zzyy/centos\nrun容器 对应的主机目录地址\n主机对应默认地址\nDocker挂载主机目录Docker访问出现cannot open directory .: Permission denied\n解决办法：在挂载目录后多加一个–privileged=true参数即可\n数据卷容器 是什么？ 命名的容器挂载数据卷，其它容器通过挂载这个(父容器)实现数据共享，挂载数据卷的容器，称之为数据卷容器\n总体介绍 以上一步新建的镜像zzyy/centos为模板并运行容器dc01/dc02/dc03\n它们已经具有容器卷 /dataVolumeContainer1 和 /dataVolumeContainer2\n容器间传递共享 先启动一个父容器dc01 在dataVolumeContainer2新增内容\ndc02/dc03继承自dc01\n--volumes-from\ndocker run -it --name dc02 --volumes-from dc01 zzyy/centos\ndc02/dc03分别在dataVolumeContainer2各自新增内容\n回到dc01可以看到02/03各自添加的都能共享了\n删除dc01，dc02修改后dc03可否访问\n新建dc04继承dc03后再删除dc03\n结论：容器之间配置信息的传递，数据卷的生命周期一直持续到没有容器使用它为止\nDockerFile解析 是什么？ Dockerfile是用来构建Docker镜像的构建文件，是由一系列命令和参数构成的脚本。\n构建三步骤\n编写Dockerfile文件 -\u003edocker build-\u003edocker run\n样例：以我们熟悉的CentOS为例\nDockerFile构建过程解析 Dockerfile内容基础知识 1：每条保留字指令都必须为大写字母且后面要跟随至少一个参数\n2：指令按照从上到下，顺序执行\n3：#表示注释\n4：每条指令都会创建一个新的镜像层，并对镜像进行提交\nDocker执行Dockerfile的大致流程 （1）docker从基础镜像运行一个容器\n（2）执行一条指令并对容器作出修改\n（3）执行类似docker commit的操作提交一个新的镜像层\n（4）docker再基于刚提交的镜像运行一个新容器\n（5）执行dockerfile中的下一条指令直到所有指令都执行完成\n总结 从应用软件的角度来看，Dockerfile、Docker镜像与Docker容器分别代表软件的三个不同阶段，\n* Dockerfile是软件的原材料\n* Docker镜像是软件的交付品\n* Docker容器则可以认为是软件的运行态。\nDockerfile面向开发，Docker镜像成为交付标准，Docker容器则涉及部署与运维，三者缺一不可，合力充当Docker体系的基石。\nDockerfile，需要定义一个Dockerfile，Dockerfile定义了进程需要的一切东西。Dockerfile涉及的内容包括执行代码或者是文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版、服务进程和内核进程(当应用进程需要和系统服务和内核进程打交道，这时需要考虑如何设计namespace的权限控制)等等;\nDocker镜像，在用Dockerfile定义一个文件之后，docker build时会产生一个Docker镜像，当运行 Docker镜像时，会真正开始提供服务;\nDocker容器，容器是直接提供服务的。\nDockerFile体系结构(保留字指令） FROM #基础镜像，当前新镜像是基于哪个镜像的 MAINTAINER #镜像维护者的姓名和邮箱地址 RUN #容器构建时需要运行的命令 EXPOSE #容器构建时需要运行的命令 WOEKDIR #指定在创建容器后，终端默认登陆的进来工作目录，一个落脚点 ENV #用来在构建镜像过程中设置环境变量 #ENV MY_PATH /usr/mytest #这个环境变量可以在后续的任何RUN指令中使用，这就如同在命令前面指定了环境变量前缀一样； #也可以在其它指令中直接使用这些环境变量， #比如：WORKDIR $MY_PATH ADD #将宿主机目录下的文件拷贝进镜像且ADD命令会自动处理URL和解压tar压缩包 COPY #类似ADD，拷贝文件和目录到镜像中。将从构建上下文目录中 \u003c源路径\u003e 的文件/目录复制到新的一层的镜像内的 \u003c目标路径\u003e 位置 #COPY src dest #COPY [\"src\", \"dest\"] VOLUME #容器数据卷，用于数据保存和持久化工作 CMD #指定一个容器启动时要运行的命令 #CMD指令的格式和RUN相似，也是两种格式 #shell格式：CMD\u003c命令\u003e #exec格式：CMD[\"可执行文件\",\"参数1\",\"参数2\"...] #参数列表格式：CMD[\"参数1\",\"参数2\"...]。在指定了ENTRYPOINT指令后，用CMD指定具体的参数。 ENTRYPOINT #指定一个容器启动时要运行的命令 ，ENTRYPOINT的目的和 CMD 一样都是在指定容器启动程序及参数 ONBUILD # 当构建一个被继承的Dockerfile时运行命令，父镜像在被子继承后父镜像的onbuild被触发 总结：\n案例 Base镜像(scratch) Docker Hub 中 99% 的镜像都是通过在 base 镜像中安装和配置需要的软件构建出来的\n自定义镜像mycentos 编写 1.Hub默认CentOS镜像什么情况\n自定义mycentos目的使我们自己的镜像具备如下：\n登陆后的默认路径\nvim编辑器\n查看网络配置ifconfig支持\n2.准备编写DockerFile文件\n3.myCentOS内容DockerFile\nFROM centos MAINTAINER zzyy\u003czzyy167@126.com\u003e ENV MYPATH /usr/local WORKDIR $MYPATH RUN yum -y install vim RUN yum -y install net-tools EXPOSE 80 CMD echo $MYPATH CMD echo \"success--------------ok\" CMD /bin/bash 构建 docker build -t 新镜像名字:TAG . 会看到 docker build 命令最后有一个 .\n. 表示当前目录\n运行 docker run -it 新镜像名字 :TAG 可以看到，我们自己的新镜像已经支持vim/ifconfig命令，扩展成功了。\n变更历史 docker history 镜像名 CMD/ENTRYPOINT 镜像 都是指定一个容器启动时要运行的命令\nCMD:Dockerfile 中可以有多个 CMD 指令，但只有最后一个生效，CMD 会被 docker run 之后的参数替换\nENTRYPOINT:docker run 之后的参数会被当做参数传递给 ENTRYPOINT，之后形成新的命令组合\n自定义镜像Tomcat9 mkdir -p /maruifu/mydockerfile/tomcat9\n在上述目录下touch c.txt\n将jdk和tomcat安装的压缩包拷贝进上一步目录\ncp apache-tomcat-9.0.8.tar.gz /maruifu/mydockerfile/tomcat9 cp jdk-8u171-linux-x64.tar.gz /maruifu/mydockerfile/tomcat9 在/maruifu/mydockerfile/tomcat9目录下新建Dockerfile文件\nFROM centos MAINTAINER zzyy\u003czzyybs@126.com\u003e #把宿主机当前上下文的c.txt拷贝到容器/usr/local/路径下 COPY c.txt /usr/local/cincontainer.txt #把java与tomcat添加到容器中 ADD jdk-8u171-linux-x64.tar.gz /usr/local/ ADD apache-tomcat-9.0.8.tar.gz /usr/local/ #安装vim编辑器 RUN yum -y install vim #设置工作访问时候的WORKDIR路径，登录落脚点 ENV MYPATH /usr/local WORKDIR $MYPATH #配置java与tomcat环境变量 ENV JAVA_HOME /usr/local/jdk1.8.0_171 ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar ENV CATALINA_HOME /usr/local/apache-tomcat-9.0.8 ENV CATALINA_BASE /usr/local/apache-tomcat-9.0.8 ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin #容器运行时监听的端口 EXPOSE 8080 #启动时运行tomcat # ENTRYPOINT [\"/usr/local/apache-tomcat-9.0.8/bin/startup.sh\" ] # CMD [\"/usr/local/apache-tomcat-9.0.8/bin/catalina.sh\",\"run\"] CMD /usr/local/apache-tomcat-9.0.8/bin/startup.sh \u0026\u0026 tail -F /usr/local/apache-tomcat-9.0.8/bin/logs/catalina.out 构建 构建完成：docker image\nrun\ndocker run -d -p 9080:8080 --name myt9 -v /zzyyuse/mydockerfile/tomcat9/test:/usr/local/apache-tomcat-9.0.8/webapps/test -v /zzyyuse/mydockerfile/tomcat9/tomcat9logs/:/usr/local/apache-tomcat-9.0.8/logs --privileged=true zzyytomcat9 Docker挂载主机目录Docker访问出现cannot open directory .: Permission denied\n解决办法：在挂载目录后多加一个–privileged=true参数即可\n验证 结合前述的容器卷将测试的web服务test发布\n总体概述\nweb.xml\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cweb-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\" id=\"WebApp_ID\" version=\"2.5\"\u003e \u003cdisplay-name\u003etest\u003c/display-name\u003e \u003c/web-app\u003e a.jsp\n\u003c%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%\u003e \u003c!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\"\u003e \u003chtml\u003e \u003chead\u003e \u003cmeta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"\u003e \u003ctitle\u003eInsert title here\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e -----------welcome------------ \u003c%=\"i am in docker tomcat self \"%\u003e \u003cbr\u003e \u003cbr\u003e \u003c% System.out.println(\"=============docker tomcat self\");%\u003e \u003c/body\u003e \u003c/html\u003e 测试\n总结 ","description":"\n","tags":[],"title":"\nDocker-容器数据卷与DockerFile解析（三）","uri":"/posts/post-292/"},{"categories":["Docker"],"content":"Docker\nDocker常用命令 帮助命令 docker version docker info docker --help 镜像命令 列出本地主机上的镜像\ndocker images #各个选项说明: # - REPOSITORY：表示镜像的仓库源 # - TAG：镜像的标签 # - IMAGE ID：镜像ID # - CREATED：镜像创建时间 # - SIZE：镜像大小 #同一仓库源可以有多个 TAG，代表这个仓库源的不同个版本，我们使用 REPOSITORY:TAG 来定义不同的镜像。 #如果你不指定一个镜像的版本标签，例如你只使用 ubuntu，docker 将默认使用 ubuntu:latest 镜像 #OPTIONS说明 # - -a :列出本地所有的镜像（含中间映像层） # - -q :只显示镜像ID。 # - --digests :显示镜像的摘要信息 # - --no-trunc :显示完整的镜像信息 docker search 某个XXX镜像名字\n#地址：https://hub.docker.com docker search [OPTIONS] 镜像名字 # OPTIONS说明： # --no-trunc : 显示完整的镜像描述 # -s : 列出收藏数不小于指定值的镜像。 # --automated : 只列出 automated build类型的镜像； docker pull 某个XXX镜像名字\n#下载镜像 docker pull 镜像名字 [:TAG] docker rmi 某个XXX镜像名字ID\n#删除单个 docker rmi -f 镜像ID #删除多个 docker rmi -f 镜像名1:TAG 镜像名2:TAG #删除全部 docker rmi -f $(docker images -qa) 容器命令 有镜像才能创建容器，这是根本前提(下载一个CentOS镜像演示)\ndocker pull centos\n新建并启动容器 docker run [OPTIONS] IMAGE [COMMAND][ARG...] # OPTIONS说明（常用）：有些是一个减号，有些是两个减号 #--name=\"容器新名字\": 为容器指定一个名称； #-d: 后台运行容器，并返回容器ID，也即启动守护式容器； #-i：以交互模式运行容器，通常与 -t 同时使用； #-t：为容器重新分配一个伪输入终端，通常与 -i 同时使用； #-P: 随机端口映射； #-p: 指定端口映射，有以下四种格式 # ip:hostPort:containerPort # ip::containerPort # hostPort:containerPort # containerPort #使用镜像centos:latest以交互模式启动一个容器,在容器内执行/bin/bash命令。 docker run -it centos /bin/bash 列出当前所有正在运行的容器 docker ps [OPTIONS] # OPTIONS说明（常用）： # -a :列出当前所有正在运行的容器+历史上运行过的 # -l :显示最近创建的容器。 # -n：显示最近n个创建的容器。 # -q :静默模式，只显示容器编号。 # --no-trunc :不截断输出。 退出容器 #两种退出方式 #容器停止退出 exit #容器不停止退出 ctrl+P+Q 启动容器 docker start 容器ID或者容器名 重启容器 docker restart 容器ID或者容器名 停止容器 docker stop 容器ID或者容器名 强制停止容器 docker kill 容器ID或者容器名 删除已停止容器 # 删除单个容器 docker rm 容器ID #一次删除多个容器 docker rm -f $(docker ps -a -q) docker ps -a -q | xargs docker rm 重要 启动守护式容器\n#启动守护式容器 docker run -d 容器名 使用镜像centos:latest以后台模式启动一个容器docker run -d centos\n问题：然后docker ps -a 进行查看, 会发现容器已经退出很重要的要说明的一点: Docker容器后台运行,就必须有一个前台进程.容器运行的命令如果不是那些一直挂起的命令（比如运行top，tail），就是会自动退出的。\n这个是docker的机制问题,比如你的web容器,我们以nginx为例，正常情况下,我们配置启动服务只需要启动响应的service即可。例如service nginx start但是,这样做,nginx为后台进程模式运行,就导致docker前台没有运行的应用,这样的容器后台启动后,会立即自杀因为他觉得他没事可做了.所以，最佳的解决方案是,将你要运行的程序以前台进程的形式运行\n查看容器日志\ndocker logs -f -t --tail 容器ID docker run -d centos /bin/sh -c \"while true;do echo hello zzyy;sleep 2;done\" # -t 是加入时间戳 # -f 跟随最新的日志打印 # --tail 数字 显示最后多少条 查看容器内运行的进程\ndocker top 容器ID 查看容器内部细节\ndocker inspect 容器ID 进入正在运行的容器并以命令行交互\n#直接进入 docker exec -it 容器ID bash #重新进入 docker attach 容器ID #区别 exec是在容器中打开新的终端，并且可以启动新的进程 attach直接进入容器启动命令的终端，不会启动新的进程 从容器内拷贝文件到主机上\ndocker cp 容器ID:容器内路径 目的主机路径 总结 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 attach Attach to a running container # 当前 shell 下 attach 连接指定运行镜像 build Build an image from a Dockerfile # 通过 Dockerfile 定制镜像 commit Create a new image from a container changes # 提交当前容器为新的镜像 cp Copy files/folders from the containers filesystem to the host path #从容器中拷贝指定文件或者目录到宿主机中 create Create a new container # 创建一个新的容器，同 run，但不启动容器 diff Inspect changes on a container's filesystem # 查看 docker 容器变化 events Get real time events from the server # 从 docker 服务获取容器实时事件 exec Run a command in an existing container # 在已存在的容器上运行命令 export Stream the contents of a container as a tar archive # 导出容器的内容流作为一个 tar 归档文件[对应 import ] history Show the history of an image # 展示一个镜像形成历史 images List images # 列出系统当前镜像 import Create a new filesystem image from the contents of a tarball # 从tar包中的内容创建一个新的文件系统映像[对应export] info Display system-wide information # 显示系统相关信息 inspect Return low-level information on a container # 查看容器详细信息 kill Kill a running container # kill 指定 docker 容器 load Load an image from a tar archive # 从一个 tar 包中加载一个镜像[对应 save] login Register or Login to the docker registry server # 注册或者登陆一个 docker 源服务器 logout Log out from a Docker registry server # 从当前 Docker registry 退出 logs Fetch the logs of a container # 输出当前容器日志信息 port Lookup the public-facing port which is NAT-ed to PRIVATE_PORT # 查看映射端口对应的容器内部源端口 pause Pause all processes within a container # 暂停容器 ps List containers # 列出容器列表 pull Pull an image or a repository from the docker registry server # 从docker镜像源服务器拉取指定镜像或者库镜像 push Push an image or a repository to the docker registry server # 推送指定镜像或者库镜像至docker源服务器 restart Restart a running container # 重启运行的容器 rm Remove one or more containers # 移除一个或者多个容器 rmi Remove one or more images # 移除一个或多个镜像[无容器使用该镜像才可删除，否则需删除相关容器才可继续或 -f 强制删除] run Run a command in a new container # 创建一个新的容器并运行一个命令 save Save an image to a tar archive # 保存一个镜像为一个 tar 包[对应 load] search Search for an image on the Docker Hub # 在 docker hub 中搜索镜像 start Start a stopped containers # 启动容器 stop Stop a running containers # 停止容器 tag Tag an image into a repository # 给源中镜像打标签 top Lookup the running processes of a container # 查看容器中运行的进程信息 unpause Unpause a paused container # 取消暂停容器 version Show the docker version information # 查看 docker 版本号 wait Block until a container stops, then print its exit code # 截取容器停止时的退出状态值 Docker镜像 是什么？ 镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。\nUnionFS（联合文件系统） UnionFS（联合文件系统）：Union文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。Union 文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。\n特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录\nDocker镜像加载原理 Docker镜像加载原理：docker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。\nbootfs(boot file system)主要包含bootloader和kernel, bootloader主要是引导加载kernel, Linux刚启动时会加载bootfs文件系统，在Docker镜像的最底层是bootfs。这一层与我们典型的Linux/Unix系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs。\nrootfs (root file system) ，在bootfs之上。包含的就是典型 Linux 系统中的 /dev, /proc, /bin, /etc 等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。\n平时我们安装进虚拟机的CentOS都是好几个G，为什么docker这里才200M？？\n对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令、工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供 rootfs 就行了。由此可见对于不同的linux发行版, bootfs基本是一致的, rootfs会有差别, 因此不同的发行版可以公用bootfs。\n分层的镜像 以我们的pull为例，在下载的过程中我们可以看到docker的镜像好像是在一层一层的在下载\nDocker 镜像为啥采用分层结构 最大的一个好处就是 - 共享资源\n比如：有多个镜像都从相同的 base 镜像构建而来，那么宿主机只需在磁盘上保存一份base镜像，同时内存中也只需加载一份 base 镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。\n特点 Docker镜像都是只读的\n当容器启动时，一个新的可写层被加载到镜像的顶部。\n这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。\nDocker镜像commit操作补充 docker commit提交容器副本使之成为一个新的镜像 docker commit -m=“提交的描述信息” -a=“作者” 容器ID 要创建的目标镜像名:[标签名] 案例演示\n从Hub上下载tomcat镜像到本地并成功运行\ndocker run -it -p 8080:8080 tomcat # -p 主机端口:docker容器端口 # -P 随机分配端口 # i:交互 # t:终端 故意删除上一步镜像生产tomcat容器的文档\n也即当前的tomcat运行实例是一个没有文档内容的容器，以它为模板commit一个没有doc的tomcat新镜像atguigu/tomcat02\n启动我们的新镜像并和原来的对比\n启动atguigu/tomcat02，它没有docs\n新启动原来的tomcat，它有docs\n","description":"\n","tags":[],"title":"\nDocker-命令与镜像（二）","uri":"/posts/post-293/"},{"categories":["Docker"],"content":"Docker\nDocker简介 是什么？ 为什么会有docker？ 一款产品从开发到上线，从操作系统，到运行环境，再到应用配置。作为开发+运维之间的协作我们需要关心很多东西，这也是很多互联网公司都不得不面对的问题，特别是各种版本的迭代之后，不同版本环境的兼容，对运维人员都是考验\nDocker之所以发展如此迅速，也是因为它对此给出了一个标准化的解决方案。\n环境配置如此麻烦，换一台机器，就要重来一次，费力费时。很多人想到，能不能从根本上解决问题，软件可以带环境安装？也就是说，安装的时候，把原始环境一模一样地复制过来。开发人员利用 Docker 可以消除协作编码时“在我的机器上可正常工作”的问题。\n之前在服务器配置一个应用的运行环境，要安装各种软件，就拿尚硅谷电商项目的环境来说吧，Java/Tomcat/MySQL/JDBC驱动包等。安装和配置这些东西有多麻烦就不说了，它还不能跨平台。假如我们是在 Windows 上安装的这些环境，到了 Linux 又得重新装。况且就算不跨操作系统，换另一台同样操作系统的服务器，要移植应用也是非常麻烦的。\n传统上认为，软件编码开发/测试结束后，所产出的成果即是程序或是能够编译执行的二进制字节码等(java为例)。而为了让这些程序可以顺利执行，开发团队也得准备完整的部署文件，让维运团队得以部署应用程式，开发需要清楚的告诉运维部署团队，用的全部配置文件+所有软件环境。不过，即便如此，仍然常常发生部署失败的状况。Docker镜像的设计，使得Docker得以打破过去「程序即应用」的观念。透过镜像(images)将作业系统核心除外，运作应用程式所需要的系统环境，由下而上打包，达到应用程式跨平台间的无缝接轨运作。\ndocker理念？ Docker是基于Go语言实现的云开源项目。\nDocker的主要目标是“Build，Ship and Run Any App,Anywhere”，也就是通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的APP（可以是一个WEB应用或数据库应用等等）及其运行环境能够做到“一次封装，到处运行”。\nLinux 容器技术的出现就解决了这样一个问题，而 Docker 就是在它的基础上发展过来的。将应用运行在 Docker 容器上面，而 Docker 容器在任何操作系统上都是一致的，这就实现了跨平台、跨服务器。只需要一次配置好环境，换到别的机子上就可以一键部署好，大大简化了操作\n一句话解决了运行环境和配置问题软件容器，方便做持续集成并有助于整体发布的容器虚拟化技术。\n能干嘛？ 之前的虚拟机技术 虚拟机（virtual machine）就是带环境安装的一种解决方案。\n它可以在一种操作系统里面运行另一种操作系统，比如在Windows 系统里面运行Linux 系统。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。这类虚拟机完美的运行了另一套系统，能够使应用程序，操作系统和硬件三者之间的逻辑不变。\n虚拟机的缺点：\n资源占用多 冗余步骤多 启动慢 容器虚拟化技术 由于前面虚拟机存在这些缺点，Linux 发展出了另一种虚拟化技术：Linux 容器（Linux Containers，缩写为 LXC）。\nLinux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。有了容器，就可以将软件运行所需的所有资源打包到一个隔离的容器中。容器与虚拟机不同，不需要捆绑一整套操作系统，只需要软件工作所需的库资源和设置。系统因此而变得高效轻量并保证部署在任何环境中的软件都能始终如一的运行\n比较了 Docker 和传统虚拟化方式的不同之处：\n传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程； 而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。 每个容器之间互相隔离，每个容器有自己的文件系统 ，容器之间进程不会相互影响，能区分计算资源。 开发/运维(DevOps) 一次构建，随处运行\n更快速的应用交付和部署 传统的应用开发完成后，需要提供一堆安装程序和配置说明文档，安装部署后需根据配置文档进行繁杂的配置才能正常运行。Docker化之后只需要交付少量容器镜像文件，在正式生产环境加载镜像并运行即可，应用安装配置在镜像里已经内置好，大大节省部署配置和测试验证时间。\n更便捷的升级和扩缩容 随着微服务架构和Docker的发展，大量的应用会通过微服务方式架构，应用的开发构建将变成搭乐高积木一样，每个Docker容器将变成一块“积木”，应用的升级将变得非常容易。当现有的容器不足以支撑业务处理时，可通过镜像运行新的容器进行快速扩容，使应用系统的扩容从原先的天级变成分钟级甚至秒级。\n更简单的系统运维 应用容器化运行后，生产环境运行的应用可与开发、测试环境的应用高度一致，容器会将应用程序相关的环境和状态完全封装起来，不会因为底层基础架构和操作系统的不一致性给应用带来影响，产生新的BUG。当出现程序异常时，也可以通过测试环境的相同容器进行快速定位和修复。\n更高效的计算资源利用 Docker是内核级虚拟化，其不像传统的虚拟化技术一样需要额外的Hypervisor支持，所以在一台物理机上可以运行很多个容器实例，可大大提升物理服务器的CPU和内存的利用率。\n企业级 新浪\n美团\n蘑菇街\n去那下？ 官网 docker官网：http://www.docker.com docker中文网站：https://www.docker-cn.com/ 仓库 Docker Hub官网: https://hub.docker.com/ Docker安装 前提说明 CentOS Docker 安装\nDocker支持以下的CentOS版本：\nCentOS 7 (64-bit)\nCentOS 6.5 (64-bit) 或更高的版本\n前提条件\n目前，CentOS 仅发行版本中的内核支持 Docker。\nDocker 运行在 CentOS 7 上，要求系统为64位、系统内核版本为 3.10 以上。\nDocker 运行在 CentOS-6.5 或更高的版本的 CentOS 上，要求系统为64位、系统内核版本为 2.6.32-431 或者更高版本。\n查看自己的内核\nuname命令用于打印当前系统相关信息（内核版本号、硬件架构、主机名称和操作系统类型等）。\n查看已安装的CentOS版本信息（CentOS6.8有，CentOS7无该命令）\nDocker的基本组成 镜像(image) Docker 镜像（Image）就是一个只读的模板。镜像可以用来创建 Docker 容器，一个镜像可以创建很多容器。\n容器(container) Docker 利用容器（Container）独立运行的一个或一组应用。容器是用镜像创建的运行实例。\n它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。\n可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。\n容器的定义和镜像几乎一模一样，也是一堆层的统一视角，唯一区别在于容器的最上面那一层是可读可写的。\n仓库(repository)\n仓库（Repository）是集中存放镜像文件的场所。\n仓库(Repository)和仓库注册服务器（Registry）是有区别的。仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。\n仓库分为公开仓库（Public）和私有仓库（Private）两种形式。\n最大的公开仓库是 Docker Hub(https://hub.docker.com/)，\n存放了数量庞大的镜像供用户下载。国内的公开仓库包括阿里云 、网易云 等\nDocker 本身是一个容器运行载体或称之为管理引擎。我们把应用程序和配置依赖打包好形成一个可交付的运行环境，这个打包好的运行环境就似乎 image镜像文件。只有通过这个镜像文件才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。\nimage 文件生成的容器实例，本身也是一个文件，称为镜像文件。 一个容器运行一种服务，当我们需要的时候，就可以通过docker客户端创建一个对应的运行实例，也就是我们的容器 至于仓储，就是放了一堆镜像的地方，我们可以把镜像发布到仓储中，需要的时候从仓储中拉下来就可以了。 Docker架构图\n安装步骤 CentOS6.8安装Docker yum install -y epel-release Docker使用EPEL发布，RHEL系的OS首先要确保已经持有EPEL仓库，否则先检查OS的版本，然后安装相应的EPEL包。 yum install -y docker-io 安装后的配置文件：/etc/sysconfig/docker 启动Docker后台服务：service docker start docker version验证 CentOS7安装Docker 官网中文安装参考手册 https://docs.docker-cn.com/engine/installation/linux/docker-ce/centos/#prerequisites\n确定你是CentOS7及以上版本\ncat /etc/redhat-release\nyum安装gcc相关\nyum -y install gcc yum -y install gcc-c++ 卸载旧版本\n1 yum -y remove docker docker-common docker-selinux docker-engine 2018.3官网版本\n1 yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-selinux docker-engine-selinux docker-engine 安装需要的软件包\nyum install -y yum-utils device-mapper-persistent-data lvm2 设置stable镜像仓库\n大坑：\nyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 报错： 1 [Errno 14] curl#35 - TCP connection reset by peer 2 [Errno 12] curl#35 - Timeout 推荐：\nyum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 更新yum软件包索引\nyum makecache fast\n安装DOCKER CE\nyum -y install docker-ce\n启动docker\nsystemctl start docker\n测试\n```shell docker version docker run hello-world ``` 配置镜像加速 ```shell #创建目录 mkdir -p /etc/docker #创建配置文件 vim /etc/docker/daemon.json #网易云 {\"registry-mirrors\": [\"http://hub-mirror.c.163.com\"] } #阿里云 {\"registry-mirrors\": [\"https://｛自已的编码｝.mirror.aliyuncs.com\"]} #重载加速域名 systemctl daemon-reload #重启docker systemctl restart docker ``` 卸载 ```shell systemctl stop docker yum -y remove docker-ce rm -rf /var/lib/docker ``` 永远的HelloWorld 阿里云镜像加速 登录https://dev.aliyun.com/search.html\n注册一个属于自己的阿里云账户(可复用淘宝账号)\n获得加速器地址连接（镜像加速器-专属加速器地址）\n配置本机Docker运行镜像加速器 鉴于国内网络问题，后续拉取 Docker 镜像十分缓慢，我们可以需要配置加速器来解决， 我使用的是阿里云的本人自己账号的镜像地址(需要自己注册有一个属于你自己的)： https://xxxx.mirror.aliyuncs.com vim /etc/sysconfig/docker 将获得的自己账户下的阿里云加速地址配置进 other_args=\"--registry-mirror=https://你自己的账号加速信息.mirror.aliyuncs.com\"\n重新启动Docker后台服务：service docker restart\nLinux 系统下配置完加速器需要检查是否生效\n如果从结果中看到了配置的–registry-mirror参数说明配置成功，如下所示:\n网易云加速 同上述阿里云，只是配置Json串的地方不同了:\n1 2 3 4 vim /etc/docker/daemon.json { \"registry-mirrors\": [\"http://hub-mirror.c.163.com\"] } 启动Docker后台容器 docker run hello-world 输出这段提示以后，hello world就会停止运行，容器自动终止。\nrun干了什么？ 底层原理 Docker是怎么工作的？\nDocker是一个Client-Server结构的系统，Docker守护进程运行在主机上， 然后通过Socket连接从客户端访问，守护进程从客户端接受命令并管理运行在主机上的容器。 容器，是一个运行时环境，就是我们前面说到的集装箱\n为什么Docker比VM快？\n(1)docker有着比虚拟机更少的抽象层。由亍docker不需要Hypervisor实现硬件资源虚拟化,运行在docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上docker将会在效率上有明显优势。\n(2)docker利用的是宿主机的内核,而不需要Guest OS。因此,当新建一个容器时,docker不需要和虚拟机一样重新加载一个操作系统内核。仍而避免引寻、加载操作系统内核返个比较费时费资源的过程,当新建一个虚拟机时,虚拟机软件需要加载Guest OS,返个新建过程是分钟级别的。而docker由于直接利用宿主机的操作系统,则省略了返个过程,因此新建一个docker容器只需要几秒钟。\n","description":"\n","tags":[],"title":"\nDocker-简介与安装（一）","uri":"/posts/post-294/"},{"categories":["默认分类"],"content":"MQ\nMQ简介 什么是MQ MQ(Message Queue)是一种跨进程的通信机制，用于传递消息。通俗点说，就是一个先进先出的数\n据结构。\nMQ的应用场景 异步解耦 最常见的一个场景是用户注册后，需要发送注册邮件和短信通知，以告知用户注册成功。传统的做法如 下:\n此架构下注册、邮件、短信三个任务全部完成后，才返回注册结果到客户端，用户才能使用账号登录。 但是对于用户来说，注册功能实际只需要注册系统存储用户的账户信息后，该用户便可以登录，而后续 的注册短信和邮件不是即时需要关注的步骤。\n所以实际当数据写入注册系统后，注册系统就可以把其他的操作放入对应的消息队列 MQ 中然后马上返 回用户结果，由消息队列 MQ 异步地进行这些操作。架构图如下:\n异步解耦是消息队列 MQ 的主要特点，主要目的是减少请求响应时间和解耦。主要的使用场景就是将比 较耗时而且不需要即时(同步)返回结果的操作作为消息放入消息队列。同时，由于使用了消息队列 MQ，只要保证消息格式不变，消息的发送方和接收方并不需要彼此联系，也不需要受对方的影响，即 解耦合。\n流量削峰 流量削峰也是消息队列 MQ 的常用场景，一般在秒杀或团队抢购(高并发)活动中使用广泛。在秒杀或团 队抢购活动中，由于用户请求量较大，导致流量暴增，秒杀的应用在处理如此大量的访问流量后，下游 的通知系统无法承载海量的调用量，甚至会导致系统崩溃等问题而发生漏通知的情况。为解决这些问 题，可在应用和下游通知系统之间加入消息队列 MQ。\n秒杀处理流程如下所述:\n用户发起海量秒杀请求到秒杀业务处理系统。\n秒杀处理系统按照秒杀处理逻辑将满足秒杀条件的请求发送至消息队列 MQ。\n下游的通知系统订阅消息队列 MQ 的秒杀相关消息，再将秒杀成功的消息发送到相应用户。\n用户收到秒杀成功的通知。\n常见的MQ产品 目前业界有很多MQ产品，比较出名的有下面这些:\nZeroMQ 号称最快的消息队列系统，尤其针对大吞吐量的需求场景。扩展性好，开发比较灵活，采用C语言实 现，实际上只是一个socket库的重新封装，如果做为消息队列使用，需要开发大量的代码。ZeroMQ仅 提供非持久性的队列，也就是说如果down机，数据将会丢失。\nRabbitMQ 使用erlang语言开发，性能较好，适合于企业级的开发。但是不利于做二次开发和维护。\nActiveMQ 历史悠久的Apache开源项目。已经在很多产品中得到应用，实现了JMS1.1规范，可以和spring-jms轻 松融合，实现了多种协议，支持持久化到数据库，对队列数较多的情况支持不好。\nRocketMQ 阿里巴巴的MQ中间件，由java语言开发，性能非常好，能够撑住双十一的大流量，而且使用起来很简 单。\nKafka Kafka是Apache下的一个子项目，是一个高性能跨语言分布式Publish/Subscribe消息队列系统，相对 于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。\nRocketMQ入门 RocketMQ是阿里巴巴开源的分布式消息中间件，现在是Apache的一个顶级项目。在阿里内部使用非常广泛，已经经过了\"双11\"这种万亿级的消息流转。\nRocketMQ环境搭建 接下来我们先在linux平台下安装一个RocketMQ的服务\n环境准备 下载RocketMQ\nhttp://rocketmq.apache.org/release_notes/release-notes-4.4.0/\n环境要求\nLinux 64位操作系统 64bit\nJDK 1.8+\n安装RocketMQ 1 上传文件到Linux系统\n1 2 [root@maruifu rocketmq]# ls /usr/local/src/ rocketmq-all-4.4.0-bin-release.zip 2 解压到安装目录\n1 2 3 [root@maruifu src]# unzip rocketmq-all-4.4.0-bin-release.zip [root@maruifu src]# mv rocketmq-all-4.4.0-bin-release ../rocketmq 启动RocketMQ 1切换到安装目录\n1 2 [root@maruifu rocketmq]# ls benchmark bin conf lib LICENSE NOTICE README.md 2 启动NameServer\n1 2 3 4 [root@maruifu rocketmq]# nohup ./bin/mqnamesrv \u0026 [1] 1467 # 只要进程不报错,就应该是启动成功了,可以查看一下日志 [root@maruifu rocketmq]# tail -f /root/logs/rocketmqlogs/namesrv.log 3 启动Broker\n1 2 3 4 5 # 编辑bin/runbroker.sh 和 bin/runserver.sh文件,修改里面的 # JAVA_OPT=\"${JAVA_OPT} -server -Xms8g -Xmx8g -Xmn4g\" # 为JAVA_OPT=\"${JAVA_OPT} -server -Xms256m -Xmx256m -Xmn128m\" [root@maruifu rocketmq]# nohup bin/mqbroker -n localhost:9876 \u0026 [root@maruifu rocketmq]# tail -f /root/logs/rocketmqlogs/broker.log 测试RocketMQ 1 测试消息发送\n1 2 3 [root@maruifu rocketmq]# export NAMESRV_ADDR=localhost:9876 [root@maruifu rocketmq]# bin/tools.sh org.apache.rocketmq.example.quickstart.Producer 2 测试消息接收\n1 2 [root@maruifu rocketmq]# export NAMESRV_ADDR=localhost:9876 [root@maruifu rocketmq]# bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer 关闭RocketMQ 1 2 [root@maruifu rocketmq]# bin/mqshutdown broker [root@maruifu rocketmq]# bin/mqshutdown namesrv RocketMQ的架构及概念 如上图所示，整体可以分成4个角色，分别是:NameServer，Broker，Producer，Consumer。\nBroker(邮递员):Broker是RocketMQ的核心，负责消息的接收，存储，投递等功能\n**NameServer(邮局):**消息队列的协调者，Broker向它注册路由信息，同时Producer和Consumer 向其获取路由信息Producer(寄件人)消息的生产者，需要从NameServer获取Broker信息，然后与 Broker建立连接，向Broker发送消息\nConsumer(收件人) :消息的消费者，需要从NameServer获取Broker信息，然后与Broker建立连 接，从Broker获取消息\n**Topic(地区):**用来区分不同类型的消息，发送和接收消息前都需要先创建Topic，针对Topic来发送 和接收消息Message Queue(邮件)为了提高性能和吞吐量，引入了Message Queue，一个Topic可 以设置一个或多个Message Queue，这样消息就可以并行往各个Message Queue发送消息，消费 者也可以并行的从多个Message Queue读取消息\n**Message:**Message 是消息的载体。\nProducer Group:生产者组，简单来说就是多个发送同一类消息的生产者称之为一个生产者组。\nConsumer Group:消费者组，消费同一类消息的多个 consumer 实例组成一个消费者组。\nRocketMQ控制台安装 1 下载\n1 2 # 在git上下载下面的工程 rocketmq-console-1.0.0 https://github.com/apache/rocketmq-externals/releases 2 修改配置文件\n1 2 3 4 5 # 修改配置文件 rocketmq-console\\src\\main\\resources\\application.properties #项目启动后的端口号 server.port=7777 #nameserv的地址，注意防火墙要开启 9876端口 rocketmq.config.namesrvAddr=192.168.109.131:9876 3 打成jar包，并启动\n1 2 3 4 # 进入控制台项目，将工程打成jar包 mvn clean package -Dmaven.test.skip=true # 启动控制台 java -jar target/rocketmq-console-ng-1.0.0.jar 4 访问控制台\n消息发送和接收演示 接下来我们使用Java代码来演示消息的发送和接收\n1 2 3 4 5 \u003cdependency\u003e \u003cgroupId\u003eorg.apache.rocketmq\u003c/groupId\u003e \u003cartifactId\u003erocketmq-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e2.0.2\u003c/version\u003e \u003c/dependency\u003e 发送消息 消息发送步骤:\n创建消息生产者, 指定生产者所属的组名 指定Nameserver地址 启动生产者 创建消息对象，指定主题、标签和消息体 发送消息 关闭生产者 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //发送消息 public class RocketMQSendTest { public static void main(String[] args) throws Exception { //1. 创建消息生产者, 指定生产者所属的组名 DefaultMQProducer producer = new DefaultMQProducer(\"myproducer-group\"); //2. 指定Nameserver地址 producer.setNamesrvAddr(\"192.168.109.131:9876\"); //3. 启动生产者 producer.start(); //4. 创建消息对象，指定主题、标签和消息体 Message msg = new Message(\"myTopic\", \"myTag\", (\"RocketMQ Message\").getBytes()); //5. 发送消息 SendResult sendResult = producer.send(msg, 10000); System.out.println(sendResult); //6. 关闭生产者 producer.shutdown(); } } 接收消息 消息接收步骤:\n创建消息消费者, 指定消费者所属的组名 指定Nameserver地址 指定消费者订阅的主题和标签 设置回调函数，编写处理消息的方法 启动消息消费者 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public static void main(String[] args) throws MQClientException { //1. 创建消息消费者, 指定消费者所属的组名 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer( \"myconsumer- group\"); //2. 指定Nameserver地址 consumer.setNamesrvAddr(\"192.168.109.131:9876\"); //3. 指定消费者订阅的主题和标签 consumer.subscribe(\"myTopic\", \"*\"); //4. 设置回调函数，编写处理消息的方法 consumer.registerMessageListener(new MessageListenerConcurrently() { @Override public ConsumeConcurrentlyStatus consumeMessage( List\u003cMessageExt\u003e msgs, ConsumeConcurrentlyContext context) { System.out.println(\"Receive New Messages: \" + msgs); //返回消费状态 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; } }); //5. 启动消息消费者 consumer.start(); System.out.println(\"Consumer Started.\"); } 案例 接下来我们模拟一种场景: 下单成功之后，向下单用户发送短信。设计图如下\n订单微服务发送消息 1 在 shop-order 中添加rocketmq的依赖\n1 2 3 4 5 6 7 8 9 10 11 \u003c!--rocketmq--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.rocketmq\u003c/groupId\u003e \u003cartifactId\u003erocketmq-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e2.0.2\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.rocketmq\u003c/groupId\u003e \u003cartifactId\u003erocketmq-client\u003c/artifactId\u003e \u003cversion\u003e4.4.0\u003c/version\u003e \u003c/dependency\u003e 2 添加配置\n1 2 3 4 5 6 rocketmq: #rocketMQ服务的地址 name-server: 192.168.109.131:9876 producer: # 生产者组 group: shop-order 3 编写测试代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @RestController @Slf4j public class OrderController2 { @Autowired private OrderService orderService; @Autowired private ProductService productService; @Autowired private RocketMQTemplate rocketMQTemplate; //准备买1件商品 @GetMapping(\"/order/prod/{pid}\") public Order order(@PathVariable(\"pid\") Integer pid) { log.info(\"\u003e\u003e客户下单,这时候要调用商品微服务查询商品信息\"); //通过fegin调用商品微服务 Product product = productService.findByPid(pid); if (product == null) { Order order = new Order(); order.setPname(\"下单失败\"); return order; } log.info(\"\u003e\u003e商品信息,查询结果:\" + JSON.toJSONString(product)); Order order = new Order(); order.setUid(1); order.setUsername(\"测试用户\"); order.setPid(product.getPid()); order.setPname(product.getPname()); order.setPprice(product.getPprice()); order.setNumber(1); orderService.save(order); //下单成功之后,将消息放到mq中 rocketMQTemplate.convertAndSend(\"order-topic\", order); return order; } } 用户微服务订阅消息 1 修改 shop-user 模块配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cparent\u003e \u003cartifactId\u003espringcloud-alibaba\u003c/artifactId\u003e \u003cgroupId\u003ecn.maruifu\u003c/groupId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/parent\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cartifactId\u003eshop-user\u003c/artifactId\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003ecn.maruifu\u003c/groupId\u003e \u003cartifactId\u003eshop-common\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-nacos- discovery\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.rocketmq\u003c/groupId\u003e \u003cartifactId\u003erocketmq-spring-boot-starter\u003c/artifactId\u003e \u003cversion\u003e2.0.2\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.rocketmq\u003c/groupId\u003e \u003cartifactId\u003erocketmq-client\u003c/artifactId\u003e \u003cversion\u003e4.4.0\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e 2 修改主类\n1 2 3 4 5 6 7 @SpringBootApplication @EnableDiscoveryClient public class UserApplication { public static void main(String[] args) { SpringApplication.run(UserApplication.class, args); } } 3 修改配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 server: port: 8071 spring: application: name: service-user datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql:///shop? serverTimezone=UTC\u0026useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=true username: root password: root jpa: properties: hibernate: hbm2ddl: auto: update dialect: org.hibernate.dialect.MySQL5InnoDBDialect cloud: nacos: discovery: server-addr: 127.0.0.1:8848 rocketmq: name-server: 192.168.109.131:9876 4 编写消息接收服务\n1 2 3 4 5 6 7 8 9 10 11 package cn.maruifu.service; //发送短信的服务 @Slf4j @Service @RocketMQMessageListener(consumerGroup = \"shop-user\", topic = \"order-topic\") public class SmsService implements RocketMQListener\u003cOrder\u003e { @Override public void onMessage(Order order) { log.info(\"收到一个订单信息{},接下来发送短信\", JSON.toJSONString(order)); } } 5 启动服务，执行下单操作，观看后台输出\n发送不同类型的消息 普通消息 RocketMQ提供三种方式来发送普通消息:可靠同步发送、可靠异步发送和单向发送。\n可靠同步发送\n同步发送是指消息发送方发出数据后，会在收到接收方发回响应之后才发下一个数据包的通讯方式。此种方式应用场景非常广泛，例如重要通知邮件、报名短信通知、营销短信系统等。\n可靠异步发送\n异步发送是指发送方发出数据后，不等接收方发回响应，接着发送下个数据包的通讯方式。发送 方通过回调接口接收服务器响应，并对响应结果进行处理。\n异步发送一般用于链路耗时较长，对 RT 响应时间较为敏感的业务场景，例如用户视频上传后通知 启动转码服务，转码完成后通知推送转码结果等。\n单向发送\n单向发送是指发送方只负责发送消息，不等待服务器回应且没有回调函数触发，即只发送请求不 等待应答。\n适用于某些耗时非常短，但对可靠性要求并不高的场景，例如日志收集。\n1 2 3 4 5 6 7 8 9 \u003c!--依赖--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ejunit\u003c/groupId\u003e \u003cartifactId\u003ejunit\u003c/artifactId\u003e \u003c/dependency\u003e 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 //测试 @RunWith(SpringRunner.class) @SpringBootTest(classes = OrderApplication.class) public class MessageTypeTest { @Autowired private RocketMQTemplate rocketMQTemplate; //同步消息 @Test public void testSyncSend() { //参数一: topic， 如果想添加tag 可以使用\"topic:tag\"的写法 // 参数二: 消息内容 SendResult sendResult = rocketMQTemplate.syncSend(\"test-topic-1\", \"这是一条同步消息\"); System.out.println(sendResult); } //异步消息 @Test public void testSyncSendMsg () { //参数一: topic, 如果想添加tag 可以使用\"topic:tag\"的写法 //参数二: 消息内容 //参数三: 回调函数, 处理返回结果 rocketMQTemplate.asyncSend(\"test-topic-1\", \"这是一条异步消息\", new SendCallback() { @Override public void onSuccess(SendResult sendResult) { System.out.println(sendResult); } @Override public void onException(Throwable throwable) { System.out.println(throwable); } } ); //让线程不要终止 Thread.sleep(30000000); } //单向消息 @Test public void testOneWay () { rocketMQTemplate.sendOneWay(\"test-topic-1\", \"这是一条单向消息\"); } } 三种发送方式的对比\n发送方式 发送 TPS 发送结果反馈 可靠性 同步发送 快 有 不丢失 异步发送 快 有 不丢失 单向发送 最快 无 不丢失 顺序消息 顺序消息是消息队列提供的一种严格按照顺序来发布和消费的消息类型\n//同步顺序消息[异步顺序 单向顺序写法类似] public void testSyncSendOrderly() { //第三个参数用于队列的选择 rocketMQTemplate.syncSendOrderly(\"test-topic-1\", \"这是一条异步顺序消息\", \"xxxx\"); } 事务消息 RocketMQ提供了事务消息，通过事务消息就能达到分布式事务的最终一致。\n事务消息交互流程:\n两个概念:\n半事务消息:暂不能投递的消息，发送方已经成功地将消息发送到了RocketMQ服务端，但是服务端未 收到生产者对该消息的二次确认，此时该消息被标记成“暂不能投递”状态，处于该种状态下的消息即半 事务消息。\n消息回查:由于网络闪断、生产者应用重启等原因，导致某条事务消息的二次确认丢失，RocketMQ服 务端通过扫描发现某条消息长期处于“半事务消息”时，需要主动向消息生产者询问该消息的最终状态 (Commit 或是 Rollback)，该询问过程即消息回查。\n事务消息发送步骤:\n发送方将半事务消息发送至RocketMQ服务端。 RocketMQ服务端将消息持久化之后，向发送方返回Ack确认消息已经发送成功，此时消息为半事务消息。 发送方开始执行本地事务逻辑。 发送方根据本地事务执行结果向服务端提交二次确认(Commit 或是 Rollback)，服务端收到Commit 状态则将半事务消息标记为可投递，订阅方最终将收到该消息;服务端收到 Rollback 状 态则删除半事务消息，订阅方将不会接受该消息。 事务消息回查步骤:\n在断网或者是应用重启的特殊情况下，上述步骤4提交的二次确认最终未到达服务端，经过固定时 间后服务端将对该消息发起消息回查。 发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果。 发送方根据检查得到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤4对半事务消息进行操作。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 //事物日志 @Entity(name = \"shop_txlog\") @Data public class TxLog { @Id private String txLogId; private String content; private Date date; } @Service public class OrderServiceImpl4 { @Autowiredprivate OrderDao orderDao; @Autowired private TxLogDao txLogDao; @Autowired private RocketMQTemplate rocketMQTemplate; public void createOrderBefore(Order order) { String txId = UUID.randomUUID().toString(); //发送半事务消息 rocketMQTemplate.sendMessageInTransaction( \"tx_producer_group\",\"tx_topic\", MessageBuilder.withPayload(order).setHeader(\"txId\", txId).build(),order); } //本地事物 @Transactional public void createOrder(String txId, Order order) { //本地事物代码 orderDao.save(order); // 记录日志到数据库,回查使用 TxLog txLog = new TxLog(); txLog.setTxLogId(txId); txLog.setContent(\"事物测试\"); txLog.setDate(new Date()); txLogDao.save(txLog); } } @RocketMQTransactionListener(txProducerGroup = \"tx_producer_group\") public class OrderServiceImpl4Listener implements RocketMQLocalTransactionListener { @Autowired private TxLogDao txLogDao; @Autowired private OrderServiceImpl4 orderServiceImpl4; //执行本地事物 @Override public RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) { try { //本地事物 orderServiceImpl4.createOrder((String) msg.getHeaders().get(\"txId\"), (Order) arg); return RocketMQLocalTransactionState.COMMIT; } catch (Exception e) { return RocketMQLocalTransactionState.ROLLBACK; } } //消息回查 @Override public RocketMQLocalTransactionState checkLocalTransaction(Message msg) { //查询日志记录 TxLog txLog = txLogDao.findById((String) msg.getHeaders().get(\"txId\")).get(); if (txLog == null) { return RocketMQLocalTransactionState.COMMIT; } else { return RocketMQLocalTransactionState.ROLLBACK; } } } 消息消费要注意的细节 @RocketMQMessageListener( consumerGroup = \"shop\",//消费者分组 topic = \"order-topic\",//要消费的主题 consumeMode = ConsumeMode.CONCURRENTLY, //消费模式:无序和有序 messageModel = MessageModel.CLUSTERING, //消息模式:广播和集群,默认是集群 ) public class SmsService implements RocketMQListener\u003cOrder\u003e { } RocketMQ支持两种消息模式:\n广播消费: 每个消费者实例都会收到消息,也就是一条消息可以被每个消费者实例处理; 集群消费: 一条消息只能被一个消费者实例消费 ","description":"\n","tags":[],"title":"\nRocketmq–消息驱动","uri":"/posts/post-295/"},{"categories":["架构设计"],"content":"微服务\n链路追踪介绍 在大型系统的微服务化构建中，一个系统被拆分成了许多模块。这些模块负责不同的功能，组合成系 统，最终可以提供丰富的功能。在这种架构中，一次请求往往需要涉及到多个服务。互联网应用构建在 不同的软件模块集上，这些软件模块，有可能是由不同的团队开发、可能使用不同的编程语言来实现、 有可能布在了几千台服务器，横跨多个不同的数据中心，也就意味着这种架构形式也会存在一些问题:\n如何快速发现问题? 如何判断故障影响范围? 如何梳理服务依赖以及依赖的合理性? 如何分析链路性能问题以及实时容量规划? 分布式链路追踪(Distributed Tracing)，就是将一次分布式请求还原成调用链路，进行日志记录，性 能监控并将一次分布式请求的调用情况集中展示。比如各个服务节点上的耗时、请求具体到达哪台机器 上、每个服务节点的请求状态等等。\n常见的链路追踪技术有下面这些:\ncat 由大众点评开源，基于Java开发的实时应用监控平台，包括实时应用监控，业务监控 。 集成 方案是通过代码埋点的方式来实现监控，比如: 拦截器，过滤器等。 对代码的侵入性很大，集成 成本较高。风险较大。 zipkin 由Twitter公司开源，开放源代码分布式的跟踪系统，用于收集服务的定时数据，以解决微 服务架构中的延迟问题，包括:数据的收集、存储、查找和展现。该产品结合spring-cloud-sleuth 使用较为简单， 集成很方便， 但是功能较简单。 pinpoint :Pinpoint是韩国人开源的基于字节码注入的调用链分析，以及应用监控分析工具。特点 是支持多种插件，UI功能强大，接入端无代码侵入。 skywalking:SkyWalking是本土开源的基于字节码注入的调用链分析，以及应用监控分析工具。 特点是支持多种插件，UI功能较强，接入端无代码侵入。目前已加入Apache孵化器。 Sleuth:SpringCloud 提供的分布式系统中链路追踪解决方案。 注意:SpringCloud alibaba技术栈中并没有提供自己的链路追踪技术的，我们可以采用Sleuth +Zinkin来做链路追踪解决方案\nSleuth入门 Sleuth介绍 SpringCloud Sleuth主要功能就是在分布式系统中提供追踪解决方案。它大量借用了Google Dapper的 设计， 先来了解一下Sleuth中的术语和相关概念。\nTrace 由一组Trace Id相同的Span串联形成一个树状结构。为了实现请求跟踪，当请求到达分布式系统 的入口端点时，只需要服务跟踪框架为该请求创建一个唯一的标识(即TraceId)，同时在分布式系统 内部流转的时候，框架始终保持传递该唯一值，直到整个请求的返回。那么我们就可以使用该唯一标识 将所有的请求串联起来，形成一条完整的请求链路。\nSpan 代表了一组基本的工作单元。为了统计各处理单元的延迟，当请求到达各个服务组件的时候，也 通过一个唯一标识(SpanId)来标记它的开始、具体过程和结束。通过SpanId的开始和结束时间戳， 就能统计该span的调用时间，除此之外，我们还可以获取如事件的名称。请求信息等元数据。\nAnnotation\n用它记录一段时间内的事件，内部使用的重要注释:\ncs(Client Send)客户端发出请求，开始一个请求的生命 sr(Server Received)服务端接受到请求开始进行处理， sr-cs = 网络延迟(服务调用的时间) ss(Server Send)服务端处理完毕准备发送到客户端，ss - sr = 服务器上的请求处理时间 cr(Client Reveived)客户端接受到服务端的响应，请求结束。 cr - sr = 请求的总时间 Sleuth入门 微服务名称, traceId, spanid,是否将链路的追踪结果输出到第三方平台\n[api-gateway,3977125f73391553,3977125f73391553,false]\n[service-order,3977125f73391553,57547b5bf71f8242,false]\n[service-product,3977125f73391553,449f5b3f3ef8d5c5,false]\n接下来通过之前的项目案例整合Sleuth，完成入门案例的编写。 修改common父工程引入Sleuth依赖\n\u003c!--链路追踪 Sleuth--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-sleuth\u003c/artifactId\u003e \u003c/dependency\u003e 启动微服务，调用之后，我们可以在控制台观察到sleuth的日志输出\n其中 5399d5cb061971bd 是TraceId， 5399d5cb061971bd 是SpanId，依次调用有一个全局的 TraceId，将调用链路串起来。仔细分析每个微服务的日志，不难看出请求的具体过程。\n查看日志文件并不是一个很好的方法，当微服务越来越多日志文件也会越来越多，通过Zipkin可以将日 志聚合，并进行可视化展示和全文检索。\nZipkin的集成 ZipKin介绍 Zipkin 是 Twitter 的一个开源项目，它基于Google Dapper实现，它致力于收集服务的定时数据，以解 决微服务架构中的延迟问题，包括数据的收集、存储、查找和展现。\n我们可以使用它来收集各个服务器上请求链路的跟踪数据，并通过它提供的REST API接口来辅助我们查 询跟踪数据以实现对分布式系统的监控程序，从而及时地发现系统中出现的延迟升高问题并找出系统性 能瓶颈的根源。\n除了面向开发的 API 接口之外，它也提供了方便的UI组件来帮助我们直观的搜索跟踪信息和分析请求链 路明细，比如:可以查询某段时间内各用户请求的处理时间等。\nZipkin 提供了可插拔数据存储方式:In-Memory、MySql、Cassandra 以及 Elasticsearch。\n上图展示了 Zipkin 的基础架构，它主要由 4 个核心组件构成:\nCollector:收集器组件，它主要用于处理从外部系统发送过来的跟踪信息，将这些信息转换为 Zipkin内部处理的 Span 格式，以支持后续的存储、分析、展示等功能。\nStorage:存储组件，它主要对处理收集器接收到的跟踪信息，默认会将这些信息存储在内存中， 我们也可以修改此存储策略，通过使用其他存储组件将跟踪信息存储到数据库中。\nRESTful API:API 组件，它主要用来提供外部访问接口。比如给客户端展示跟踪信息，或是外接 系统访问以实现监控等。\nWeb UI:UI 组件， 基于API组件实现的上层应用。通过UI组件用户可以方便而有直观地查询和分 析跟踪信息。\nZipkin分为两端，一个是 Zipkin服务端，一个是 Zipkin客户端，客户端也就是微服务的应用。 客户端会 配置服务端的 URL 地址，一旦发生服务间的调用的时候，会被配置在微服务里面的 Sleuth 的监听器监 听，并生成相应的 Trace 和 Span 信息发送给服务端。\nZipKin服务端安装 第1步: 下载ZipKin的jar包\nhttps://search.maven.org/remote_content?g=io.zipkin.java\u0026a=zipkin-server\u0026v=LATEST\u0026c=exec 第2步: 通过命令行，输入下面的命令启动ZipKin Server\njava -jar zipkin-server-2.12.9-exec.jar 第3步:通过浏览器访问 http://localhost:9411访问\nZipkin客户端集成 ZipKin客户端和Sleuth的集成非常简单，只需要在微服务中添加其依赖和配置即可。\n第1步:在每个微服务上添加依赖\n\u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-zipkin\u003c/artifactId\u003e \u003c/dependency\u003e 第2步:添加配置\nspring: zipkin: #开启zipkin分析 enabled: true #zipkin服务地址 baseUrl: http://127.0.0.1:9411/ #让nacos把它当成一个URL，而不要当做服务名 discoveryClientEnabled: false sleuth: sampler: #限速器，每秒采集10个请求，防止大并发过载。推荐 #rate: 10 #采集率，大并发可能采集率数量也会很高。采样的百分比 probability: 0.1 第3步: 访问微服务\nhttp://localhost:7000/order-serv/order/prod/1 第4步: 访问zipkin的UI界面，观察效果\n第5步:点击其中一条记录，可观察一次访问的详细线路。\nZipKin数据持久化 Zipkin Server默认会将追踪数据信息保存到内存，但这种方式不适合生产环境。Zipkin支持将追踪数据持久化到mysql数据库或elasticsearch中。\n使用mysql实现数据持久化 CREATE TABLE IF NOT EXISTS zipkin_spans ( `trace_id_high` BIGINT NOT NULL DEFAULT 0 COMMENT 'If non zero, this means the trace uses 128 bit traceIds instead of 64 bit', `trace_id` BIGINT NOT NULL, `id` BIGINT NOT NULL, `name` VARCHAR(255) NOT NULL, `parent_id` BIGINT, `debug` BIT(1), `start_ts` BIGINT COMMENT 'Span.timestamp(): epoch micros used for endTs query and to implement TTL',`duration` BIGINT COMMENT 'Span.duration(): micros used for minDuration and maxDuration query' ) ENGINE=InnoDB ROW_FORMAT=COMPRESSED CHARACTER SET=utf8 COLLATE utf8_general_ci; ALTER TABLE zipkin_spans ADD UNIQUE KEY(`trace_id_high`, `trace_id`, `id`) COMMENT 'ignore insert on duplicate'; ALTER TABLE zipkin_spans ADD INDEX(`trace_id_high`, `trace_id`, `id`) COMMENT 'for joining with zipkin_annotations'; ALTER TABLE zipkin_spans ADD INDEX(`trace_id_high`, `trace_id`) COMMENT 'for getTracesByIds'; ALTER TABLE zipkin_spans ADD INDEX(`name`) COMMENT 'for getTraces and getSpanNames'; ALTER TABLE zipkin_spans ADD INDEX(`start_ts`) COMMENT 'for getTraces ordering and range'; CREATE TABLE IF NOT EXISTS zipkin_annotations ( `trace_id_high` BIGINT NOT NULL DEFAULT 0 COMMENT 'If non zero, this means the trace uses 128 bit traceIds instead of 64 bit', `trace_id` BIGINT NOT NULL COMMENT 'coincides with zipkin_spans.trace_id', `span_id` BIGINT NOT NULL COMMENT 'coincides with zipkin_spans.id', `a_key` VARCHAR(255) NOT NULL COMMENT 'BinaryAnnotation.key or Annotation.value if type == -1', `a_value` BLOB COMMENT 'BinaryAnnotation.value(), which must be smaller than 64KB', `a_type` INT NOT NULL COMMENT 'BinaryAnnotation.type() or -1 if Annotation', `a_timestamp` BIGINT COMMENT 'Used to implement TTL; Annotation.timestamp or zipkin_spans.timestamp', `endpoint_ipv4` INT COMMENT 'Null when Binary/Annotation.endpoint is null', `endpoint_ipv6` BINARY(16) COMMENT 'Null when Binary/Annotation.endpoint is null, or no IPv6 address', `endpoint_port` SMALLINT COMMENT 'Null when Binary/Annotation.endpoint is null', `endpoint_service_name` VARCHAR(255) COMMENT 'Null when Binary/Annotation.endpoint is null' ) ENGINE=InnoDB ROW_FORMAT=COMPRESSED CHARACTER SET=utf8 COLLATE utf8_general_ci; ALTER TABLE zipkin_annotations ADD UNIQUE KEY(`trace_id_high`, `trace_id`, `span_id`, `a_key`, `a_timestamp`) COMMENT 'Ignore insert on duplicate'; ALTER TABLE zipkin_annotations ADD INDEX(`trace_id_high`, `trace_id`, `span_id`) COMMENT 'for joining with zipkin_spans'; ALTER TABLE zipkin_annotations ADD INDEX(`trace_id_high`, `trace_id`) COMMENT 'for getTraces/ByIds'; ALTER TABLE zipkin_annotations ADD INDEX(`endpoint_service_name`) COMMENT 'for getTraces and getServiceNames'; ALTER TABLE zipkin_annotations ADD INDEX(`a_type`) COMMENT 'for getTraces'; ALTER TABLE zipkin_annotations ADD INDEX(`a_key`) COMMENT 'for getTraces'; ALTER TABLE zipkin_annotations ADD INDEX(`trace_id`, `span_id`, `a_key`) COMMENT 'for dependencies job'; CREATE TABLE IF NOT EXISTS zipkin_dependencies ( `day` DATE NOT NULL, `parent` VARCHAR(255) NOT NULL, `child` VARCHAR(255) NOT NULL, `call_count` BIGINT ) ENGINE=InnoDB ROW_FORMAT=COMPRESSED CHARACTER SET=utf8 COLLATE utf8_general_ci; ALTER TABLE zipkin_dependencies ADD UNIQUE KEY(`day`, `parent`,`child`); 第2步: 在启动ZipKin Server的时候,指定数据保存的mysql的信息\njava -jar zipkin-server-2.12.9-exec.jar --STORAGE_TYPE=mysql -- MYSQL_HOST=127.0.0.1 --MYSQL_TCP_PORT=3306 --MYSQL_DB=zipkin --MYSQL_USER=root - -MYSQL_PASS=root 使用elasticsearch实现数据持久化 第1步: 下载elasticsearch 下载地址:https://www.elastic.co/cn/downloads/past-releases/elasticsearch-6-8-4 第2步: 启动elasticsearch\n第3步: 在启动ZipKin Server的时候，指定数据保存的elasticsearch的信息\njava -jar zipkin-server-2.12.9-exec.jar --STORAGE_TYPE=elasticsearch --ES- HOST=localhost:9200 ","description":"\n","tags":[],"title":"\nSleuth–链路追踪","uri":"/posts/post-296/"},{"categories":["默认分类"],"content":" QPS、TPS、PV、UV、GMV、IP、RPS等各种名词，外行看起来很牛X，实际上每个程序员都是必懂知识点。下面我来一一解释一下。\nQPS Queries Per Second，每秒查询数。每秒能够响应的查询次数。\nQPS 是一台服务器每秒能够相应的查询次数，即1秒内完成的请求数量，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准\nQPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。每秒的响应请求数，也即是最大吞吐能力。\nTPS Transactions Per Second 的缩写，每秒处理的事务数目。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数，最终利用这些信息作出的评估分。\nTPS 的过程包括：客户端请求服务端、服务端内部处理、服务端返回客户端。\n例如，访问一个 Index 页面会请求服务器 3 次，包括一次 html，一次 css，一次 js，那么访问这一个页面就会产生一个“T”，产生三个“Q”。\nQPS 与 TPS 区别 QPS基本类似于TPS，但是不同的是，对于一个Web页面的一次访问，形成一个TPS（就做一件事儿，打开Web网页）；但一次Web页面请求，可能产生多次对服务器的请求（html、css、js、images、files等），服务器对这些请求，就可计入QPS之中。每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。\n一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。\n如果是对一个接口（单场景）压测，且这个接口内部不会再去请求其它接口，那么TPS等于QPS，否则，若这个接口内部还会再去请求其它接口（下载图片、文件等服务器接口），那么 TPS不等于QPS，通常是 QPS会大于TPS\nPV page view即页面浏览量\n通常是衡量一个网络新闻频道或网站甚至一条网络新闻的主要指标。\n用户每一次对网站中的每个页面访问均被记录 1 次。\n用户对同一页面的多次刷新，访问量累计。\n根据这个特性，刷网站的 PV 就很好刷了。\n与 PV 相关的还有 RV，即重复访问者数量（repeat visitors）。\nUV Unique Visitor 指独立访客访问数，统计1天内访问某站点的用户数(以 cookie 为依据)，一台电脑终端为一个访客。\nIP Internet Protocol独立 IP 数\n是指 1 天内多少个独立的 IP 浏览了页面，即统计不同的 IP 浏览用户数量。\n同一 IP 不管访问了几个页面，独立 IP 数均为 1；\n不同的 IP 浏览页面，计数会加 1。\nIP 是基于用户广域网 IP 地址来区分不同的访问者的，所以，多个用户（多个局域网 IP）在同一个路由器（同一个广域网 IP）内上网，可能被记录为一个独立 IP 访问者。如果用户不断更换 IP，则有可能被多次统计。\nRT Response Time 响应时间是一个系统最重要的指标之一，它的数值大小直接反应了系统的快慢。\n响应时间是指系统对请求作出响应的时间。直观上看，这个指标与人对软件性能的主观感受是非常一致的，因为它完整地记录了整个计算机系统处理请求的时间。由于一个系统通常会提供许多功能，而不同功能的处理逻辑也千差万别，因而不同功能的响应时间也不尽相同，甚至同一功能在不同输入数据的情况下响应时间也不相同。所以，在讨论一个系统的响应时间时，人们通常是指该系统所有功能的平均时间或者所有功能的最大响应时间。当然，往往也需要对每个或每组功能讨论其平均响应时间和最大响应时间。\n对于单机的没有并发操作的应用系统而言，人们普遍认为响应时间是一个合理且准确的性能指标。需要指出的是，响应时间的绝对值并不能直接反映软件的性能的高低，软件性能的高低实际上取决于用户对该响应时间的接受程度。对于一个游戏软件来说，响应时间小于100毫秒应该是不错的，响应时间在1秒左右可能属于勉强可以接受，如果响应时间达到3秒就完全难以接受了。而对于编译系统来说，完整编译一个较大规模软件的源代码可能需要几十分钟甚至更长时间，但这些响应时间对于用户来说都是可以接受的。\n响应时间是指执行一个请求从开始到最后收到响应数据所花费的总体时间,即从客户端发起请求到收到服务器响应结果的时间\nGMV Gross Merchandise Volume 的简称。只要是订单，不管消费者是否付款、卖家是否发货、是否退货，都可放进 GMV 。\nRPS RPS 代表吞吐率，即 Requests Per Second 的缩写。吞吐率是服务器并发处理能力的量化描述，单位是 reqs/s，指的是某个并发用户数下单位时间内处理的请求数。\n某个并发用户数下单位时间内能处理的最大的请求数，称之为最大吞吐率。\n有人把 RPS 说等效于 QPS。其实可以看作同一个统计方式，只是叫法不同而已。RPS/QPS，可以使用 apche ab 工具进行测量。\nQPS、PV 、RT 之间的关系 在进行系统性能压测和系统性能优化的时候，会涉及到QPS,PV,RT相关的概念， QPS,PV,RT之间的关系\n对于大部分web系统，响应时间一般由CPU执行时间，线程等待时间（IO等待，sleep, wait）时间组成，QPS和RT成反比关系\n在实际的测试环境中，QPS和RT并不是非常直接的反比关系\nQPS 是什么\nQPS：单个进程每秒请求服务器的成功次数 QPS = req/sec = 请求数/秒\nQPS如何统计\nQPS统计方式 [一般使用 http_load 进行统计] QPS = 总请求数 / ( 进程总数 * 请求时间 )\n根据QPS推算PV：\n单台服务器每天PV计算:\n公式1：每天总PV = QPS * 3600 * 6 公式2：每天总PV = QPS * 3600 * 8\n根据QPS，PV推算服务器数量\n服务器数量 = 每天总PV / 单台服务器每天总PV\n峰值QPS和机器计算公式：\n原理：每天80%的访问集中在20%的时间里，这20%时间叫做峰值时间\n峰值时间每秒请求数(QPS)：( 总PV数 * 80% ) / ( 每天秒数 * 20% )\n峰值机器数量：峰值时间QPS / 单台机器的QPS\n例子：\n问：每天300w PV 的在单台机器上，这台机器需要多少QPS？\n答：( 3000000 * 0.8 ) / (86400 * 0.2 ) = 139 (QPS)\n问：如果一台机器的QPS是58，需要几台机器来支持？\n答：139 / 58 = 3\n对于大部分web系统，响应时间一般由CPU执行时间，线程等待时间（IO等待，sleep, wait）时间组成，QPS和RT成反比关系\n在实际的测试环境中，QPS和RT并不是非常直接的反比关系\n最佳线程数 性能压测的情况下，起初随着用户数的增加，QPS会上升，当到了一定的阀值之后，用户数量增加QPS并不会增加，或者增加不明显，同时请求的响应时间却大幅增加，这个阀值我们认为是最佳线程数。\n刚好消耗完服务器的瓶颈资源的临界线程数，公式如下\n最佳线程数量 =（（线程等待时间 + 线程CPU执行时间）/ 线程CPU执行时间）* CPU数量\n特性：\n在达到最佳线程数的时候，线程数量继续递增，则QPS不变，而响应时间变长，持续递增线程数量，则QPS开始下降\n每个系统都有其最佳线程数量，但是不同状态下，最佳线程数量是会变化的\n瓶颈资源可以是CPU,可以是内存，可以是锁资源，IO资源\n超过最佳线程数，会导致资源的竞争；超过最佳线程数，会响应时间递增。\n为什么要找最佳线程数 过多的线程只会造成，更多的内存开销，更多的CPU开销，但是对提升QPS确毫无帮助\n找到最佳线程数后通过简单的设置，可以让web系统更加稳定，得到最高，最稳定的QPS输出\n最佳线程数的获取： 通过用户慢慢递增来进行性能压测，观察QPS，响应时间\n根据公式计算:服务器端最佳线程数量=((线程等待时间+线程cpu时间)/线程cpu时间) * cpu数量\n单用户压测，查看CPU的消耗，然后直接乘以百分比，再进行压测，一般这个值的附近应该就是最佳线程数量。\n影响最佳线程数的主要因素 IO IO开销较多的应用其CPU线程等待时间会比较长，所以线程数量可以开的多一些，相反则线程数量要少一些，其实有两种极端，纯IO的应用，比如proxy，则线程数量可以开到非常大（实在太大了则需要考虑线程切换的开销），这种应用基本上后端（比如这个proxy是代理搜索的）的QPS能有多少，proxy就有多少。\nCPU 对于耗CPU的计算，这种情况一般来讲只能开到CPU个数的线程数量。但是并不是说这种应用的QPS就不高，往往这种应用的QPS可以很高，因为耗CPU计算的应用，往往处理单次请求的时间会很短。\nQPS和线程数的关系 在最佳线程数量之前，QPS和线程是互相递增的关系，线程数量到了最佳线程之后，QPS持平，不在上升，甚至略有下降，同时响应时间持续上升。\n同一个系统而言，最佳线程数越多，QPS越高\n并发数（Parallels） 并发数是指系统同时能处理的请求数量，一般跟CPU个数，线程数有关，这反应了系统的负载能力\n并发用户数是指系统可以同时承载的正常使用系统功能的用户的数量。与吞吐量相比，并发用户数是一个更直观但也更笼统的性能指标。实际上，并发用户数是一个非常不准确的指标，因为用户不同的使用模式会导致不同用户在单位时间发出不同数量的请求。一网站系统为例，假设用户只有注册后才能使用，但注册用户并不是每时每刻都在使用该网站，因此具体一个时刻只有部分注册用户同时在线，在线用户就在浏览网站时会花很多时间阅读网站上的信息，因而具体一个时刻只有部分在线用户同时向系统发出请求。这样，对于网站系统我们会有三个关于用户数的统计数字：注册用户数、在线用户数和同时发请求用户数。由于注册用户可能长时间不登陆网站，使用注册用户数作为性能指标会造成很大的误差。而在线用户数和同事发请求用户数都可以作为性能指标。相比而言，以在线用户作为性能指标更直观些，而以同时发请求用户数作为性能指标更准确些。\n吞吐量（Throughput） 吞吐量是指单位时间内系统能处理的请求数量，体现系统处理请求的能力，这是目前最常用的性能测试指标\n吞吐量是指系统在单位时间内处理请求的数量。对于无并发的应用系统而言，吞吐量与响应时间成严格的反比关系，实际上此时吞吐量就是响应时间的倒数。前面已经说过，对于单用户的系统，响应时间（或者系统响应时间和应用延迟时间）可以很好地度量系统的性能，但对于并发系统，通常需要用吞吐量作为性能指标。\n对于一个多用户的系统，如果只有一个用户使用时系统的平均响应时间是t，当有你n个用户使用时，每个用户看到的响应时间通常并不是n×t，而往往比n×t小很多（当然，在某些特殊情况下也可能比n×t大，甚至大很多）。这是因为处理每个请求需要用到很多资源，由于每个请求的处理过程中有许多不走难以并发执行，这导致在具体的一个时间点，所占资源往往并不多。也就是说在处理单个请求时，在每个时间点都可能有许多资源被闲置，当处理多个请求时，如果资源配置合理，每个用户看到的平均响应时间并不随用户数的增加而线性增加。实际上，不同系统的平均响应时间随用户数增加而增长的速度也不大相同，这也是采用吞吐量来度量并发系统的性能的主要原因。一般而言，吞吐量是一个比较通用的指标，两个具有不同用户数和用户使用模式的系统，如果其最大吞吐量基本一致，则可以判断两个系统的处理能力基本一致。\n并发量、QPS、RT 之间的关系： QPS = 并发量 / 平均响应时间 （推荐）\n并发量 = QPS * 平均响应时间\n假设每天80%的访问集中在20%的时间里，这20%时间叫做峰值时间\n公式：( 总PV数 * 80% ) / ( 每天秒数 * 20% ) = 峰值时间每秒请求数(QPS)\n机器：峰值时间每秒QPS / 单台机器的QPS = 需要的机器\n每天300w PV 的在单台机器上，这台机器需要多少QPS？\n( 3000000 * 0.8 ) / (86400 * 0.2 ) = 139 (QPS)\n如果一台机器的QPS是58，需要几台机器来支持？\n139 / 58 = 3 （进一法，取上限）\n单线程QPS公式，QPS=1000ms/RT,对同一个系统而言，支持的线程数越多，QPS越高。\n假设一个RT是80ms,则可以很容易的计算出QPS,QPS = 1000/80 = 12.5\n多线程场景，如果把服务端的线程数提升到2，那么整个系统的QPS则为 2*（1000/80） = 25,\n可见QPS随着线程的增加而线性增长，那QPS上不去就加线程呗，听起来很有道理，公司也说的通，但是往往现实并非如此。\n如何提升RT（响应时间） 减少 IO 的响应时间，减少 IO 的调用次数 并发HTTP请求，无上下文依赖，多个连接，一个线程\nHTTP连接池（长连接，keep-alive）\n减少 CPU 的使用时间 forest 循环的例子\n如何提升 QPS（每秒查询数） 减少 CPU 的使用时间\n增加 CPU 的数量\n减少同步锁\n如果 CPU 不能被压到 85% 以上，并且此时的OPS已经达到了峰值，则说明另有瓶颈，接下去要重点关注内存\n排查内存是否有瓶颈\n判断依据，是在最佳线程数量 * 5 左右的情况下，进行压测，观察 Old 区内存增长是否正常\n性能压测要关注使用了多少用户数，目前的压测方式容易遗漏内存瓶颈\n总结 Proxy 应用（耗IO）的线程越多越好，当线程达到过多时，线程本身资源的开销也会成为瓶颈，线程本身也是一个资源。 所以这类Proxy应用一般采取轻程模型，NIO解决，如 nginx\n计算型应用（耗CPU），线程数量就是CPU的核数，如搜索索引服务器，需要做大量的计算排序，非常耗CPU资源 ","description":"\n","tags":[],"title":"\n秒懂QPS、TPS、PV、UV、GMV、IP、RPS","uri":"/posts/post-297/"},{"categories":["默认分类"],"content":" 后台开发作为互联网技术领域的掌上明珠，一直都是开发者们的追逐的高峰。本文将从后台开发所涉及到的技术术语出发，基于系统开发、架构设计、网络通信等几个方面让大家对后台来发有一个清晰的了解，讲解全面易懂。\n系统开发 高内聚/低耦合 高内聚指一个软件模块是由相关性很强的代码组成，只负责一项任务，也就是常说的单一责任原则。模块的内聚反映模块内部联系的紧密程度。\n模块之间联系越紧密，其耦合性就越强，模块的独立性则越差。模块间耦合高低取决于模块间接口的复杂性、调用的方式及传递的信息。一个完整的系统，模块与模块之间，尽可能的使其独立存在。**通常程序结构中各模块的内聚程度越高，模块间的耦合程度就越低。\n过度设计 过度设计就是进行了过多的面向未来的设计或者说把相对简单的事情想复杂了，过度追求模块化、可扩展性、设计模式等，为系统增加了不必要的复杂度。\n过早优化 过早指的不是在开发过程的早期，而是在还没弄清楚需求未来的变化的走向的时候。你的优化不仅可能导致你无法很好地实现新的需求，而且你对优化的预期的猜测有可能还是错的，导致实际上你除了把代码变复杂以外什么都没得到。\n正确的方法是，先有质量地实现你的需求，写够testcase，然后做profile去找到性能的瓶颈，这个时候才做优化。\n重构 (Refactoring) 重构（Refactoring）就是通过调整程序代码改善软件的质量、性能，使其程序的设计模式和架构更趋合理，提高软件的扩展性和维护性。\n破窗效应 又称破窗理论，破窗效应（Broken windows theory）是犯罪学的一个理论。此理论认为环境中的不良现象如果被放任存在，会诱使人们仿效，甚至变本加厉。一幢有少许破窗的建筑为例，如果那些窗不被修理好，可能将会有破坏者破坏更多的窗户。最终他们甚至会闯入建筑内，如果发现无人居住，也许就在那里定居或者纵火。\n应用在软件工程上就是，一定不能让系统代码或者架构设计的隐患有冒头的机会，否则随着时间的推移，隐患会越来越重。反之，一个本身优质的系统，会让人不由自主的写出优质的代码。\n互不信任原则 指在程序运行上下游的整个链路中，每个点都是不能保证绝对可靠的，任何一个点都可能随时发生故障或者不可预知的行为，包括机器网络、服务本身、依赖环境、输入和请求等，因此要处处设防。\n持久化 (Persistence) 持久化是将程序数据在临时状态和持久状态间转换的机制。通俗的讲，就是临时数据（比如内存中的数据，是不能永久保存的）持久化为持久数据（比如持久化至数据库或者本地磁盘中，能够长久保存）。\n临界区 临界区用来表示一种公共资源或者说是共享数据，可以被多个线程使用，但是每一次，只能有一个线程使用它，一旦临界区资源被占用，其他线程要想使用这个资源，就必须等待。\n阻塞/非阻塞 阻塞和非阻塞通常形容多线程间的相互影响。比如一个线程占用了临界区资源，那么其它所有需要这个资源的线程就必须在这个临界区中进行等待，等待会导致线程挂起。这种情况就是阻塞。此时，如果占用资源的线程一直不愿意释放资源，那么其它所有阻塞在这个临界区上的线程都不能工作。而非阻塞允许多个线程同时进入临界区。\n同步/异步 通常同步和异步是指函数/方法调用方面。\n同步就是在发出一个函数调用时，在没有得到结果之前，该调用就不返回。异步调用会瞬间返回，但是异步调用瞬间返回并不代表你的任务就完成了，他会在后台起个线程继续进行任务，等任务执行完毕后通过回调callback或其他方式通知调用方。\n并发/并行 **并行(parallel)**指在同一时刻，有多条指令在多个处理器上同时执行。所以无论从微观还是从宏观来看，二者都是一起执行的。\n**并发(concurrency)**指在同一时刻只能有一条指令执行，但多个进程指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执行的，只是把时间分成若干段，使多个进程快速交替的执行。\n架构设计 高并发 (High Concurrency) 由于分布式系统的问世，高并发（High Concurrency）通常是指通过设计保证系统能够同时并行处理很多请求。通俗来讲，高并发是指在同一个时间点，有很多用户同时的访问同一 API 接口或者 Url 地址。它经常会发生在有大活跃用户量，用户高聚集的业务场景中。\n高可用 (High Availability) 高可用HA（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，一个系统经过专门的设计，以减少停工时间，而保持其服务的高度可用性。\n读写分离 为了确保数据库产品的稳定性，很多数据库拥有双机热备功能。也就是，第一台数据库服务器，是对外提供增删改业务的生产服务器；第二台数据库服务器，主要进行读的操作。\n冷备/热备 冷备：两个服务器，一台运行，一台不运行做为备份。这样一旦运行的服务器宕机，就把备份的服务器运行起来。冷备的方案比较容易实现，但冷备的缺点是主机出现故障时备机不会自动接管，需要主动切换服务。 热备：即是通常所说的active/standby方式，服务器数据包括数据库数据同时往两台或多台服务器写。当active服务器出现故障的时候，通过软件诊测（一般是通过心跳诊断）将standby机器激活，保证应用在短时间内完全恢复正常使用。当一台服务器宕机后，自动切换到另一台备用机使用。 异地多活 异地多活一般是指在不同城市建立独立的数据中心，“活”是相对于冷备份而言的，冷备份是备份全量数据，平时不支撑业务需求，只有在主机房出现故障的时候才会切换到备用机房，而多活，是指这些机房在日常的业务中也需要走流量，做业务支撑。\n负载均衡 (Load Balance) 负载均衡，是对多台服务器进行流量分发的负载均衡服务。可在多个实例间自动分配应用程序的对外服务能力，通过消除单点故障提升应用系统的可用性，让您实现更高水平的应用程序容错能力，从而无缝提供分配应用程序流量所需的负载均衡容量，为您提供高效、稳定、安全的服务。\n动静分离 动静分离是指在web服务器架构中，将静态页面与动态页面或者静态内容接口和动态内容接口分开不同系统访问的架构设计方法，进而提升整个服务访问性能和可维护性。\n集群 单台服务器的并发承载能力总是有限的，当单台服务器处理能力达到性能瓶颈的时，将多台服务器组合起来提供服务，这种组合方式称之为集群，集群中每台服务器就叫做这个集群的一个“节点”，每个节点都能提供相同的服务，从而成倍的提升整个系统的并发处理能力。\n分布式 分布式系统就是将一个完整的系统按照业务功能拆分成很多独立的子系统，每个子系统就被称为“服务”，分布式系统将请求分拣和分发到不同的子系统，让不同的服务来处理不同的请求。在分布式系统中，子系统独立运行，它们之间通过网络通信连接起来实现数据互通和组合服务。\nCAP理论 CAP理论，指的是在一个分布式系统中，Consistency(一致性)、Availability(可用性)、Partition Tolerance(分区容错性)，不能同时成立。\n**一致性：**它要求在同一时刻点，分布式系统中的所有数据备份都相同或者都处于同一状态。\n**可用性：**在系统集群的一部分节点宕机后，系统依然能够正确的响应用户的请求。\n**分区容错性：**系统能够容忍节点之间的网络通信的故障。\n简单的来说，**在一个分布式系统中，最多能支持上面的两种属性。**但显然既然是分布式注定我们是必然要进行分区，既然分区，我们就无法百分百避免分区的错误。因此，我们只能在一致性和可用性去作出选择。\n在分布式系统中，我们往往追求的是可用性，它的重要性比一致性要高，那么如何实现高可用，这里又有一个理论，就是 BASE 理论，它给 CAP 理论做了进一步的扩充。\nBASE理论 BASE 理论指出：\nBasically Available（基本可用）\nSoft state（软状态）\nEventually consistent（最终一致性）\nBASE 理论是对 CAP 中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。\n水平扩展/垂直扩展 水平扩展 Scale Out通过增加更多的服务器或者程序实例来分散负载，从而提升存储能力和计算能力。\n垂直扩展 Scale Up 提升单机处理能力。\n垂直扩展的方式又有两种：\n（1）增强单机硬件性能，例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G;\n（2）提升单机软件或者架构性能，例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间；\n平行扩容 与水平扩展类似。集群服务器中的节点均为平行对等节点，当需要扩容时，可以通过添加更多节点以提高集群的服务能力。一般来说服务器中关键路径（如服务器中的登录、支付、核心业务逻辑等）都需要支持运行时动态平行扩容。\n弹性扩容 指对部署的集群进行动态在线扩容。弹性扩容系统可以根据实际业务环境按照一定策略自动地添加更多的节点（包括存储节点、计算节点、网络节点）来增加系统容量、提高系统性能或者增强系统可靠性，或者同时完成这三个目标。\n状态同步/帧同步 **状态同步：**状态同步是指服务器负责计算全部的游戏逻辑，并且广播这些计算的结果，客户端仅仅负责发送玩家的操作，以及表现收到的游戏结果。 **特征：**状态同步安全性高，逻辑更新方便，断线重连快，但是开发效率较低，网络流量随游戏复杂度增加，服务器需要承载更大压力。\n**帧同步：**服务端只转发消息，不做任何逻辑处理，各客户端每秒帧数一致，在每一帧都处理同样的输入数据。 **特征：**帧同步需要保证系统在相同的输入下，要有相同的输出。帧同步开发效率高，流量消耗低而且稳定，对服务器的压力非常小。但是网络要求高，断线重连时间长，客户端计算压力大。\n网络通信 连接池 预先建立一个连接缓冲池，并提供一套连接使用、分配、管理策略，使得该连接池中的连接可以得到高效、安全的复用，避免了连接频繁建立、关闭的开销。\n断线重连 由于网络波动造成用户间歇性的断开与服务器的连接，待网络恢复之后服务器尝试将用户连接到上次断开时的状态和数据。\n会话保持 会话保持是指在负载均衡器上的一种机制，可以识别客户端与服务器之间交互过程的关连性，在作负载均衡的同时还保证一系列相关连的访问请求都会分配到一台机器上。用人话来表述就是：在一次会话过程中发起的多个请求都会落到同一台机器上。\n长连接/短连接 通常是指TCP的长连接和短连接。长连接就是建立TCP连接后，一直保持这个连接，一般会中间彼此发送心跳来确认对应的存在，中间会做多次业务数据传输，一般不会主动断开连接。短连接一般指建立连接后，执行一次事务后（如：http请求），然后就关掉这个连接。\n流量控制/拥塞控制 流量控制防止发送方发的太快，耗尽接收方的资源，从而使接收方来不及处理。 拥塞控制防止发送方发的太快，使得网络来不及处理产生拥塞，进而引起这部分乃至整个网络性能下降的现象，严重时甚至会导致网络通信业务陷入停顿。 惊群效应 惊群效应也有人叫做雷鸣群体效应，不过叫什么，简言之，惊群现象就是多进程（多线程）在同时阻塞等待同一个事件的时候（休眠状态），如果等待的这个事件发生，那么他就会唤醒等待的所有进程（或者线程），但是最终却只可能有一个进程（线程）获得这个时间的“控制权”，对该事件进行处理，而其他进程（线程）获取“控制权”失败，只能重新进入休眠状态，这种现象和性能浪费就叫做惊群。\nNAT NAT（Network Address Translation，网络地址转换），就是替换IP报文头部的地址信息。NAT通常部署在一个组织的网络出口位置，通过将内部网络IP地址替换为出口的IP地址提供公网可达性和上层协议的连接能力。\n故障异常 宕机 宕机，一般情况下指的就是计算机主机出现意外故障而死机。其次，一些服务器例如数据库死锁也可以称为宕机，一些服务器的某些服务挂掉了，就可以这么说。\ncoredump 当程序出错而异常中断时，OS会把程序工作的当前状态存储成一个coredunmp文件。通常情况下coredump文件包含了程序运行时的内存，寄存器状态，堆栈指针，内存管理信息等。\n缓存穿透/击穿/雪崩 **缓存穿透：**缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，进而给数据库带来压力。 **缓存击穿：**缓存击穿是指热点key在某个时间点过期的时候，而恰好在这个时间点对这个Key有大量的并发请求过来，从而大量的请求打到db。 **缓存雪崩：**缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。 **与缓存击穿不同的是：**存击穿是热点key失效，缓存雪崩是大量的key同时失效。 500/501/502/503/504/505 **500 Internal Server Error：**内部服务错误，一般是服务器遇到意外情况，而无法完成请求。可能原因: 1、程序错误，例如：ASP或者PHP语法错误；2、高并发导致，系统资源限制不能打开过多的文件所致。 **501Not implemented：**服务器不理解或不支持请求的HTTP请求。 **502Bad Gateway：**WEB服务器故障，可能是由于程序进程不够，请求的php-fpm已经执行，但是由于某种原因而没有执行完毕，最终导致php-fpm进程终止。可能原因：1、Nginx服务器，php-cgi进程数不够用；2、PHP执行时间过长；3、php-cgi进程死掉； **503Service Unavailable：**服务器目前无法使用。系统维护服务器暂时的无法处理客户端的请求，这只是暂时状态。可以联系下服务器提供商。 **504Gateway Timeout：**服务器504错误表示超时，是指客户端所发出的请求没有到达网关，请求没有到可以执行的php-fpm，一般是与nginx.conf的配置有关。 **505HTTP Version Not Supported：**服务器不支持请求中所用的 HTTP 协议版本。（HTTP 版本不受支持） 除了500错误可能是程序语言错误，其余的报错，都大概可以理解为服务器或者服务器配置出现问题。\n内存溢出/内存泄漏 **内存溢出：**内存溢出（Out Of Memory）指程序申请内存时，没有足够的内存供申请者使用，或者说，给了你一块存储int类型数据的存储空间，但是你却存储long类型的数据，那么结果就是内存不够用，此时就会报错OOM,即所谓的内存溢出。 **内存泄漏：**内存泄漏（Memory Leak）指程序中己动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。 句柄泄漏 句柄泄漏是进程在调用系统文件之后，没有释放已经打开的文件句柄。一般句柄泄漏后的现象是，机器变慢，CPU飙升，出现句柄泄漏的cgi或server的CPU使用率增加。\n死锁 死锁是指两个或两个以上的线程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都抑制处于阻塞状态并无法进行下去，此时称系统处于死锁状态或系统产生了死锁。\n软中断/硬中断 **硬中断：**我们通常所说的中断指的是硬中断(hardirq)。由与系统相连的外设(比如网卡、硬盘)自动产生的。主要是用来通知操作系统系统外设状态的变化。 **软中断：**1、通常是硬中断服务程序对内核的中断；2、为了满足实时系统的要求，中断处理应该是越快越好。 linux为了实现这个特点，当中断发生的时候，硬中断处理那些短时间就可以完成的工作，而将那些处理事件比较长的工作，放到中断之后来完成，也就是软中断(softirq)来完成。\n毛刺 在短暂的某一刻，服务器性能指标（如流量、磁盘IO、CPU使用率等）远大于该时刻前后时间段。毛刺的出现代表这服务器资源利用不均匀，不充分，容易诱发其他更严重的问题。\n重放攻击 攻击者发送一个目的主机已接收过的包，来达到欺骗系统的目的，主要用于身份认证过程，破坏认证的正确性。它是一种攻击类型，这种攻击会不断恶意或欺诈性地重复一个有效的数据传输，重放攻击可以由发起者，也可以由拦截并重发该数据的敌方进行。攻击者利用网络监听或者其他方式盗取认证凭据，之后再把它重新发给认证服务器。\n网络孤岛 网络孤岛指集群环境中，部分机器与整个集群失去网络连接，分裂为一个小集群并且发生数据不一致的状况。\n数据倾斜 对于集群系统，一般缓存是分布式的，即不同节点负责一定范围的缓存数据。我们把缓存数据分散度不够，导致大量的缓存数据集中到了一台或者几台服务节点上，称为数据倾斜。一般来说数据倾斜是由于负载均衡实施的效果不好引起的。\n脑裂 脑裂是指在集群系统中，部分节点之间网络不可达而引起的系统分裂，不同分裂的小集群会按照各自的状态提供服务，原本的集群会同时存在不一致的反应，造成节点之间互相争抢资源，系统混乱，数据损坏。\n监控告警 服务监控 服务监控主要目的在服务出现问题或者快要出现问题时能够准确快速地发现以减小影响范围。服务监控一般有多种手段，按层次可划分为：\n系统层（CPU、网络状态、IO、机器负载等） 应用层（进程状态、错误日志、吞吐量等） 业务层（服务/接口的错误码、响应时间） 用户层（用户行为、舆情监控、前端埋点） 全链路监控 **服务拨测：**服务拨测是探测服务（应用）可用性的监控方式，通过拨测节点对目标服务进行周期性探测，主要通过可用性和响应时间来度量，拨测节点通常有异地多个。 **节点探测：**节点探测是用来发现和追踪不同的机房（数据中心）节点之间网络可用性和通畅性的监控方式，主要通过响应时间、丢包率、跳数来度量，探测方法一般是ping、mtr或其他私有协议。 **告警过滤：**对某些可预知的告警进行过滤，不进入告警统计的数据，如少量爬虫访问导致的http响应500错误，业务系统自定义异常信息等。 **告警去重：**当一个告警通知负责人后，在这个告警恢复之前，不会继续收到相同的告警。 **告警抑制：**为了减少由于系统抖动带来的干扰，还需要实现抑制，例如服务器瞬间高负载，可能是正常的，只有持续一段时间的高负载才需要得到重视。 **告警恢复：**开发/运维人员不仅需要收到告警通知，还需要收到故障消除告警恢复正常的通知。 **告警合并：**对同一时刻产生的多条相同告警进行合并，如某个微服务集群同一时刻出现多个子服务负载过高的告警，需要合并成为一条告警。 **告警收敛：**有时某个告警产生时，往往会伴随着其它告警。这时可以只对根本原因产生告警，其它告警收敛为子告警一并发送通知。如云服务器出现CPU负载告警时往往伴随其搭载的所有系统的可用性告警。 **故障自愈：**实时发现告警，预诊断分析，自动恢复故障，并打通周边系统实现整个流程的闭环。 服务治理 微服务 微服务架构是一种架构模式，它提倡将单一应用程序划分成一组小的服务，服务之间相互协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务和服务之间采用轻量级的通信机制相互沟通（通常是基于HTTP的Restful API).每个服务都围绕着具体的业务进行构建，并且能够被独立的部署到生产环境、类生产环境等。\n服务发现 服务发现是指使用一个注册中心来记录分布式系统中的全部服务的信息，以便其他服务能够快速的找到这些已注册的服务。服务发现是支撑大规模 SOA 和微服务架构的核心模块，它应该尽量做到高可用。\n流量削峰 如果观看抽奖或秒杀系统的请求监控曲线，你就会发现这类系统在活动开放的时间段内会出现一个波峰，而在活动未开放时，系统的请求量、机器负载一般都是比较平稳的。为了节省机器资源，我们不可能时时都提供最大化的资源能力来支持短时间的高峰请求。所以需要使用一些技术手段，来削弱瞬时的请求高峰，让系统吞吐量在高峰请求下保持可控。削峰也可用于消除毛刺，使服务器资源利用更加均衡和充分。常见的削峰策略有队列，限频，分层过滤，多级缓存等。\n版本兼容 在升级版本的过程中，需要考虑升级版本后，新的数据结构是否能够理解和解析旧数据，新修改的协议是否能够理解旧的协议以及做出预期内合适的处理。这就需要在服务设计过程中做好版本兼容。\n过载保护 过载是指当前负载已经超过了系统的最大处理能力，过载的出现，会导致部分服务不可用，如果处置不当，极有可能引起服务完全不可用，乃至雪崩。过载保护正是针对这种异常情况做的措施，防止出现服务完全不可用的现象。\n服务熔断 服务熔断的作用类似于我们家用的保险丝，当某服务出现不可用或响应超时的情况时，为了防止整个系统出现雪崩，暂时停止对该服务的调用。\n服务降级 服务降级是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。降级往往会指定不同的级别，面临不同的异常等级执行不同的处理。\n根据服务方式：可以拒接服务，可以延迟服务，也有时候可以随机服务。 根据服务范围：可以砍掉某个功能，也可以砍掉某些模块。 总之服务降级需要根据不同的业务需求采用不同的降级策略。主要的目的就是服务虽然有损但是总比没有好。\n熔断VS降级 相同点：目标一致，都是从可用性和可靠性出发，为了防止系统崩溃；用户体验类似，最终都让用户体验到的是某些功能暂时不可用； 不同点：触发原因不同，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑； 服务限流 限流可以认为服务降级的一种，限流就是限制系统的输入和输出流量已达到保护系统的目的。一般来说系统的吞吐量是可以被测算的，为了保证系统的稳定运行，一旦达到的需要限制的阈值，就需要限制流量并采取一些措施以完成限制流量的目的。比如：延迟处理，拒绝处理，或者部分拒绝处理等等。\n故障屏蔽 将故障机器从集群剔除，以保证新的请求不会分发到故障机器。\n测试方法 黑盒/白盒测试 黑盒测试不考虑程序内部结构和逻辑结构，主要是用来测试系统的功能是否满足需求规格说明书。一般会有一个输入值，一个输入值，和期望值做比较。\n白盒测试主要应用在单元测试阶段，主要是对代码级的测试，针对程序内部逻辑结构，测试手段有：语句覆盖、判定覆盖、条件覆盖、路径覆盖、条件组合覆盖\n单元/集成/系统/验收测试 软件测试一般分为4个阶段：单元测试、集成测试、系统测试、验收测试。\n**单元测试：**单元测试是对软件中的最小可验证单元进行检查和验证，如一个模块、一个过程、一个方法等。单元测试粒度最小，一般由开发小组采用白盒方式来测试，主要测试单元是否符合“设计”。 **集成测试：**集成测试也叫做组装测试，通常在单元测试的基础上，将所有的程序模块进行有序的、递增的测试。集成测试界于单元测试和系统测试之间，起到“桥梁作用”，一般由开发小组采用白盒加黑盒的方式来测试，既验证“设计”，又验证“需求”。 **系统测试：**系统测试时将经过集成测试的软件，作为计算机系统的一部分，与系统中其他部分结合起来，在实际运行环境下进行一系列严格有效的测试，以发现软件潜在的问题，保证系统的正常运行。系统测试的粒度最大，一般由独立测试小组采用黑盒方式来测试，主要测试系统是否符合“需求规格说明书”。 **验收测试：**验收测试也称交付测试，是针对用户需求、业务流程进行的正式的测试，以确定系统是否满足验收标准，由用户、客户或其他授权机构决定是否接受系统。验收测试与系统测试相似，主要区别是测试人员不同，验收测试由用户执行。 回归测试 当发现并修改缺陷后，或在软件中添加新的功能后，重新测试。用来检查被发现的缺陷是否被改正，并且所做的修改没有引发新的问题。\n冒烟测试 这一术语源自硬件行业。对一个硬件或硬件组件进行更改或修复后，直接给设备加电。如果没有冒烟，则该组件就通过了测试。在软件中，“冒烟测试”这一术语描述的是在将代码更改嵌入到产品的源树中之前对这些更改进行验证的过程。\n冒烟测试是在软件开发过程中的一种针对软件版本包的快速基本功能验证策略，是对软件基本功能进行确认验证的手段，并非对软件版本包的深入测试。\n比如：对于一个登录系统的冒烟测试，我们只需测试输入正确的用户名、密码，验证登录这一个核心功能点，至于输入框、特殊字符等，可以在冒烟测试之后进行。\n性能测试 性能测试是通过自动化的测试工具模拟多种正常、峰值以及异常负载条件来对系统的各项性能指标进行测试。负载测试和压力测试都属于性能测试，两者可以结合进行。\n通过负载测试，确定在各种工作负载下系统的性能，目标是测试当负载逐渐增加时，系统各项性能指标的变化情况。 压力测试是通过确定一个系统的瓶颈或者不能接受的性能点，来获得系统能提供的最大服务级别的测试。 基准测试 基准测试（Benchmark）也是一种性能测试方式，用来测量机器的硬件最高实际运行性能，以及软件优化的性能提升效果, 同时也可以用来识别某段代码的CPU或者内存效率问题. 许多开发人员会用基准测试来测试不同的并发模式, 或者用基准测试来辅助配置工作池的数量, 以保证能最大化系统的吞吐量.\nA/B测试 A/B测试，是用两组及以上随机分配的、数量相似的样本进行对比，如果实验组和对比组的实验结果相比，在目标指标上具有统计显著性，那就可以说明实验组的功能可以导致你想要的结果，从而帮你验证假设或者做出产品决定。\n代码覆盖测试 代码覆盖（Code coverage）是软件测试中的一种度量，描述程式中源代码被测试的比例和程度，所得比例称为代码覆盖率。在做单元测试时，代码覆盖率常常被拿来作为衡量测试好坏的指标，甚至，用代码覆盖率来考核测试任务完成情况，比如，代码覆盖率必须达到80%或 90%。于是乎，测试人员费尽心思设计案例覆盖代码。\n发布部署 DEV/PRO/FAT/UAT pro（Production environment）：生产环境，面向外部用户的环境，正式环境，连接上互联网即可访问。\nsit(System Integration Test ): 系统集成测试，开发人员自己测试流程是否走通。\nuat(User Acceptance Test environment): 用户验收测试环境，用于生产环境下的软件测试者测试使用。\ntest: 测试环境，外部用户无法访问，专门给测试人员使用的，版本相对稳定。\npre ：灰度环境，外部用户可以访问，但是服务器配置相对低，其它和生产一样，外部用户可以访问，版本发布初期，正式版本发布前。\ndev （Development environment） ： 开发环境，外部用户无法访问，开发人员使用，版本变动很大。\nfat (Feature Acceptance Test environment) : 功能验收测试环境，用于软件测试者测试使用\n灰度发布 灰度发布是指在升级版本过程中，通过分区控制，白名单控制等方式对一部分用户先升级产品特性，而其余用户则保持不变，当一段时间后升级产品特性的用户没有反馈问题，就逐步扩大范围，最终向所有用户开放新版本特性，灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、修改问题，以保证其影响度。\n回滚 (Rollback) 指的是程序或数据处理错误时，将程序或数据恢复到上一次正确状态(或者是上一个稳定版本)的行为。\n","description":"\n","tags":[],"title":"\n后端开发术语","uri":"/posts/post-298/"},{"categories":["语言"],"content":"为什么要看JDK源码 一，JDK源码是其它所有源码的基础，看懂了JDK源码再看其它的源码会达到事半功倍的效果。\n二，JDK源码中包含大量的数据结构知识，是学习数据结构很好的资料，比如，链表、队列、散列表、红黑树、跳表、桶、堆、双端队列等。\n三、JDK源码中包含大量的设计模式，是学习设计模式很好的资料，比如，适配器模式、模板方法模式、装饰器模式、迭代器模式、代理模式、工厂模式、命令模式、状态模式等。\n三，JDK源码中包含大量Java的高阶知识，比如弱引用、Unsafe、CAS、锁原理、伪共享等，不看源码是很难学会这些知识的。\n四，面试时更好地收割offer，这可能是很多同学最初的想法，其实真正看多了源码，这一点可能并不是太重要了，因为你会发现更广阔的世界。\n五，我认为最重要的，阅读源码是对思维的一种锻炼，是学习优秀设计的最佳途径\nJDK源码的阅读顺序 JDK 中的代码非常多，不可能、也没必要全部读完，因此要有的放矢。从整体上来讲，我分成了以下几个部分：\n基础类 基础类，是指组成JDK源码地基的一部分类。\n比如包装类、反射类、工具类等，这些类有个共同点，就是代码逻辑相对简单，不存在数据结构、复杂运算等问题。\n对于基础类，我的建议是自己从头到尾浏览一遍，对于看不懂的地方可以写测试用例或者上网查查资料。比如，Integer里面有个IntegerCache内部类你可能不知道干嘛的，这时候光看代码是没用的，只能上网查查资料了，也不能盲目地死磕。\n简单集合 简单集合，是指不存在多线程安全问题的集合。\n这部分集合一般用在单线程中，或者方法体中，但是他们用到了很多的数据结构，所以需要一定的数据结构知识。\n对于简单集合，我的建议是先弄明白底层的数据结构知识，再去看源码，这样可能会轻松一些。当然，我后面也会出数据结构系列的。\n原子类 原子类，是指在多线程环境下能够保证原子性的类。\n这部分类主要包括Atomic_开头和_Adder结尾的类，位于juc下面的atomic包中。\n对于原子类，我的建议是先去了解底层的Unsafe、CAS、伪共享等概念，再去看最简单的AtomicInteger，最后再看LongAdder这种复杂的类。其中，断点调试是不可或缺的手段。\n说句实话，LongAdder这个类能学到很多高阶的知识，非常推荐把这个类研究透彻，后面再去看Disruptor、Netty等源码会事半功倍。\n同步器 同步器，是指为了控制多个线程的竞争关系而存在的类或者关键字等， ，它们可以说是Java中最重要的内容，没有它们就无法控制多线程的正常运转。\n这部分内容主要包括synchronized关键字、volatile关键字、重入锁、读写锁、倒计时器、信号量、回环栅栏、阶段器、分布式锁的实现等等。\n对于同步器，我的建议是先了解内存模型、可见性、原子性、有序性、Happens-Before等基本概念，再尝试阅读这部分的源码，最后再归纳出属于你自己理解的“同步器的原理”。\n并发集合 并发集合，是指多线程环境下能够保证数据一致性的集合。\n这部分集合主要是运用在多线程环境下，只有极个别类牵涉到高级的数据结构，更多的是锁、CAS、volatile、自旋等高阶技巧的运用。\n对于并发集合，我的建议有三点：\n一定要在同步器之后阅读\n数据结构先搞透，比如ConcurrentSkipList\n利用IDEA的Thread级别的断点，不断调试，不断调试，不断调试\n线程（池）类 线程（池）类，是指跟线程和线程池相关的类。\n这部分类主要包含Thread、ThreadLocal、三种线程池等。\n对于线程（池）类，我的建议是先从整体上把握，再分成几个块来看，看哪块的东西就只看那块的东西，不要管其它的代码，即要搞清楚你的重点在哪里，比如，看线程运行的流程就不要管状态的事，凡是牵涉到状态的代码全部跳过，反之亦然，都看完了，再串一起看。\nIO/NIO类 IO类，是指跟输入输出流相关的类，这部分类主要包括文件操作相关的类以及网络IO相关的类。\n对于IO类，我的建议是简单浏览，做到心里有数即可，用到的时候再去查都可以。\n但是对于nio相关的类，还是要好好研究的，这部分类我们放在Netty源码阅读的相关章节中一起学习。\n其它类 其它类，工作中遇到了可以点进去看看，但是不建议抽出时间单独去研究，比如，时间类、awt类，看的必要性不是很大。\n如何阅读集合 首页了解各个集合特点，可以画个思维导图或者啥的助于理解\n如何阅读具体一个类 如何阅读一个类的源码呢？主要步骤大概是：\n先读接口代码。包括接口说明文档、各个方法的定义和说明文档。 再读实现类的主要方法实现，通常有以下两条主线入口：构造方法和 常用方法 在 Java 中，接口通常意味着是一种“标准”、或者“协议”。一个接口可以有多个实现类，它们都会按照接口的这种标准来实现接口的各个方法。因此，理解了一个方法的定义，再去看它的实现会更容易理解。\n下面以常用的 ArrayList 为例，分析如何去阅读它的源码。\n继承结构 首先看下 ArrayList 的继承结构：\nArrayList：可以看到它实现了很多接口，其中三个接口 Cloneable、RandomAccess、Serializable 都是空的，可以暂时忽略。主要去看 Iterable、Collection 以及 List 接口的方法定义。\nIterable 接口：\nCollection 接口：\nList 接口：\n看起来方法挺多，其实不少都是我们平时会用到的，大部分理解起来并不困难，而且方法也都有注释。这部分难度不大。\n接下来根据前面提到的两条主线入口，分析 ArrayList 的源码如何阅读。\n构造器 分析一个类的源码时，构造器通常是一个好的切入点。比如 ArrayList 的三个构造器如下：\npublic ArrayList() { this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } public ArrayList(int initialCapacity) { if (initialCapacity \u003e 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); } } public ArrayList(Collection\u003c? extends E\u003e c) { elementData = c.toArray(); if ((size = elementData.length) != 0) { // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); } else { // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; } } 构造器中有不少成员变量，比如 elementData、EMPTY_ELEMENTDATA、DEFAULTCAPACITY_EMPTY_ELEMENTDATA 等，继续跟进这几个变量：\nprivate static final Object[] EMPTY_ELEMENTDATA = {}; private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; transient Object[] elementData; // non-private to simplify nested class access 由此可以得知，当我们写了 new ArrayList() 时，它的内部到底做了些什么。\n常用方法 除了构造器，常用方法也是一个主要的入口，比如 add、remove 等。\nadd 方法实现：\npublic boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; } private void ensureCapacityInternal(int minCapacity) { ensureExplicitCapacity(calculateCapacity(elementData, minCapacity)); } 可以一行行跟进代码，查看 add 方法内部到底做了什么。 其他方法的套路也是如此，不再一一说明。 按照这样一条条主线走下来，就可以对 ArrayList 的实现原理有个整体的认知了。整体部分搞清楚之后，接下来还可以去读一些不太常用的方法，包括剩余的所有部分。\nJDK源码的阅读方法 一，设定目标，目标越明确越好，不要设定得过于虚无缥缈。比如，熟悉HashMap的数据结构，这就是一个很明确的目标；再比如，看懂HashMap的源码，这就很缥缈了。\n二，尝试自己提出问题，先自己根据某个知识点发散提出问题。比如，关于HashMap你能想到哪些知识点，这部分可以借助思维导图无限想象，后面有机会我给大家分享一下思维导图联想法。\n三，尝试网络查询问题，打开度娘，输入你要学习的知识点，把前面几页统统点开，看看别人都遇到了哪些问题，当然，能力强的同学也可以使用Google，这部分查询出来的问题也可以补充到你的思维导图中去。\n四，尝试阅读源码，对于上面的问题，一个一个尝试去源码中寻找答案，由点及面，最后再总结整个大的知识点。\n五，不断发现问题，在阅读源码的过程中可能又会发现新的问题，先跳过去，而是把它加到思维导图中，等当前的问题解决完了再去解决。\n六，专注你的问题，在阅读源码的时候一定要专注于你当前的问题，不要受其它问题的干扰，比如看线程池任务执行的流程，你就不要管线程池状态的事情。\n七，多做比较，横向比较和纵向比较，从多维度去比较 。\n八，多做实验，多多利用IDE的调试模式，不断修改断点，不断调试。\n九，多与人交流，如果条件允许的话，多与周边的人一起交流，当然，也可以来骚扰我。\n十，多做总结，对于自己解决的问题，一定要学会总结，多做学习笔记，当然，也欢迎来我这里投稿。\n十一，耐心\u0026坚持，阅读源码是一件非常枯燥而且枯燥的事情，一定要坚持坚持坚持。\n","description":"\n","tags":[],"title":"\n关于JDK源码：我想聊聊如何更高效地阅读","uri":"/posts/post-299/"},{"categories":["默认分类"],"content":"最近开发中，发现一个奇怪的问题，用idea 的maven ，编译，打包都能够成功，项目中也没有爆红出错，但是你运行/调式SpringBoot的启动类的时候，会提示包**不存在。网上找了很多解决方案 都没成功。最后终于成功了，特此记录分享下：\nIdea Terminal 中 输入 mvn idea:idea File-Invadiate Cache/Restart ，清除缓存，重启 ","description":"\n","tags":[],"title":"\nIdea 打包成功，运行失败","uri":"/posts/post-300/"},{"categories":["默认分类"],"content":"Spring Boot 参数校验\n前言 搭建springboot项目，我们都是采用的Restful接口，那么问题来了，当前端调用接口或者是其他项目调用时，我们不能单一靠调用方来控制参数的准确性，自己也要对一些非空的 值进行判定。\n方案 按照我们以往的做法，都是对request中的参数一个一个进行非空判定。\nModel:\n1 2 3 4 5 publicclassOrder{ private Long userID; private Long addressID; private String comment; } Controller:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @PostMapping(\"/createOrders\") publicStringcreateOrders(@RequestBodyOrderdto){ if(dto.getUserID==null){ return \"userID不能为空\"; } if(dto.getAddressID==null){ return \"addressID不能为空\"; } if(dto.getComment==null){ return \"comment不能为空\"; } return \"sucess\"; } 这种做法首先是可取的，能达到我们的要求，但是这样如果model字段过多，判定的就很 多，相对维护起来就不是那么方便，其次增加controller层的负担，既然我们来到spring4 的时代，就应该适应使用注解的趋势，下面是使用注解后的比变化。\nModel:\n1 2 3 4 5 6 7 8 9 10 11 publicclassOrder{ @NotNull(message = \"用户ID不能为空\") private Long userID; @NotNull(message = \"收货人地址id不能为空\") private Long addressID; @NotBlank(message = \"备注不为空\") private String comment; } Controller:\n1 2 3 4 5 6 7 8 9 @PostMapping(\"/createOrders\") publicStringcreateOrders(@RequestBody @Valid Order dto,BindingResult results) { if (results.hasErrors()){ return results.getFieldError().getDefaultMessage(); } return \"success\"; } 这样我们就只需要在model字段上加上非空验证和相应提示语就好了。 备注:@Valid 和@Validated效果一样，可以加在controller中，也可以加载dto上\n常用的校验注解 1. javax.validation.constraints.NotNull 2. @Null 被注释的元素必须为null 3. @NotNull 被注释的元素不能为null 4. @AssertTrue 被注释的元素必须为true 5. @AssertFalse 被注释的元素必须为false 6. @Min(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最小值 7. @Max(value) 被注释的元素必须是一个数字，其值必须大于等于指定的最大值 8. @DecimalMin(value) 被注释的元素必须是一个数字，其值必须大于等于指定的 最小值 9. @DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的 最大值 10. @Size(max,min) 被注释的元素的大小必须在指定的范围内。 11. @Digits(integer,fraction) 被注释的元素必须是一个数字，其值必须在可接 受的范围内 12. @Past 被注释的元素必须是一个过去的日期 13. @Future 被注释的元素必须是一个将来的日期 14. @Pattern(regexp) 被注释的元素必须符合指定的正则表达式。 15. @Email 被注释的元素必须是电子邮件地址 16. @Length 被注释的字符串的大小必须在指定的范围内 17. @NotEmpty 被注释的字符串必须非空 18. @Range 被注释的元素必须在合适的范围内 其他 @Valid 注解类型的使用: @Null 限制只能为null @NotNull 限制必须不为null @AssertFalse 限制必须为false, @AssertTrue 限制必须为true, @DecimalMax(value) 限制必须为一个不大于指定值的数字 @DecimalMin(value) 限制必须为一个不小于指定值的数字 @Digits(integer,fraction) 限制必须为一个小数，且整数部分的位数不能超过integer，小数部分的位数不能超过 fraction @Future 限制必须是一个将来的日期 @Max(value) 限制必须为一个不大于指定值的数字 @Min(value) 限制必须为一个不小于指定值的数字 @Past 限制必须是一个过去的日期 @Pattern(value) 限制必须符合指定的正则表达式 @Size(max,min) 限制字符长度必须在min到max之间 @Past 验证注解的元素值(日期类型)比当前时间早 @NotEmpty 验证注解的元素值不为null且不为空(字符串长度不为0、集合大小不为0) @NotBlank 验证注解的元素值不为空(不为null、去除首位空格后长度为0)，不同于@NotEmpty， @NotBlank只应用于字符串且在比较时会去除字符串的空格 @Email 验证注解的元素值是Email，也可以通过正则表达式和flag指定自定义的email格式 问题 @NotBlank无效 可能你为了使用@NotBlank引入了包\n\u003cdependency\u003e \u003cgroupId\u003ejakarta.validation\u003c/groupId\u003e \u003cartifactId\u003ejakarta.validation‐api\u003c/arti \u003cversion\u003e2.0.2\u003c/version\u003e \u003c/dependency\u003e 之所以需要引入这个包，是因为你的spring boot 版本是2.3.1或者更高，此时的spring boot 已经不在内置验证。 此时需要引入包 哪怕与@Valid搭配也是没有效果，大概率是因为我们少导入了一个包hibernate- validator，我们需要同时导入以下两个包\n\u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring‐boot‐starter‐validation\u003c/artifactId\u003e \u003c/dependency\u003e \u003c!-- https://mvnrepository.com/artifact/org.hibernate.validator/hibernate-validator --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.hibernate.validator\u003c/groupId\u003e \u003cartifactId\u003ehibernate-validator\u003c/artifactId\u003e \u003cversion\u003e6.0.2.Final\u003c/version\u003e \u003c/dependency\u003e 或者是不导入以上两个包，直接将spring boot修改为2.1.1均可以解决此问题\n\u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring‐boot‐starter‐web\u003c/artifactId\u003e \u003cversion\u003e2.1.1.RELEASE\u003c/version\u003e \u003c/dependency\u003e 扩展 1.@NotNull:不能为null，但可以为empty (\"\",\"\",\" \") 2.@NotEmpty:不能为null，而且长度必须大于0 (\" \",\" \") 3.@NotBlank:只能作用在String上，不能为null，而且调用trim()后，长度必须大于0(\"test\") 即:必须有实际字符 @NotNull:The CharSequence,Collection,Map or Array object is not null,but can be empty. @NotEmpty:The CharSequence,Collection,Map or Array object is not null and size \u003e 0 . @NotBlank:The string is not null and the trimmed length is greater than zero. Stringname=null; @NotNull:false @NotEmpty:false @NotBlank:false Stringname=\"\"; @NotNull:true @NotEmpty:false @NotBlank:false Stringname=\" \"; @NotNull:true @NotEmpty:true @NotBlank:false Stringname=\"Greatanswer!\"; @NotNull:true @NotEmpty:true @NotBlank:true ","description":"\n","tags":[],"title":"\nspringboot自动判定空值","uri":"/posts/post-301/"},{"categories":["默认分类"],"content":"一、安装 1、docker 安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 DOCKER_NAME=mysql MYSQL_ROOT_PASSWORD=78Jikbfz6zKYfPjC # 创建挂载目录 mkdir -p /data/$DOCKER_NAME mkdir -p /data/$DOCKER_NAME/conf mkdir -p /data/$DOCKER_NAME/data mkdir -p /data/$DOCKER_NAME/sql # 编写初始化sql vi /data/$DOCKER_NAME/sql/init.sql # 编写mysql配置文件 vi /data/$DOCKER_NAME/conf/my.cnf # 下载容器镜像 # docker search mysql docker pull mysql:5.7 # 运行容器 docker run --name $DOCKER_NAME \\ --restart=always \\ -p 3306:3306 \\ -v /data/$DOCKER_NAME/conf:/etc/mysql \\ -v /data/$DOCKER_NAME/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD \\ -d mysql:5.7 # 执行初始化脚本 mysql -uroot -p$MYSQL_ROOT_PASSWORD -h 127.0.0.1 -P 3306 \u003c /data/$DOCKER_NAME/sql/init.sql # 登陆验证 mysql -uroot -p$MYSQL_ROOT_PASSWORD -h 127.0.0.1 -P 33307 mysql\u003e show databases ; 2、编译安装 3、Yum安装 二、配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 # 客户端登录配置 [client] port = 3306 # 端口号 socket = /var/lib/mysql/mysql.sock # 套接字文件 # 客户端命令行配置 [mysql] no-auto-rehash # 默认不自动补全 auto-rehash自动补全 # 服务优化配置 [mysqld] skip-grant-tables # 跳过登录验证 user = mysql # 默认启动用户，一般不需要修改，可能出现启动不成功 port = 3306 # 端口号 socket = /var/lib/mysql/mysql.sock # 套接字文件 （套接字方式登陆比TCP/IP方式连接快） character-set-server = utf8mb4 # 设置数据库服务器默认编码 utf-8 basedir = /usr/local/mysql # 数据库安装目录--指定此参数可解决相对路径造成的问题 datadir = /var/lib/mysql #数据库目录，数据库目录切换时需要用到 pid-file = /var/run/mysqld/mysqld.pid #mysql进程文件，可指定自己的进程文件 external-locking = FALSE #外部锁定(非多服务器可不设置该选项，默认skip-external-locking) skip-external-locking #跳过外部锁定 （避免多进程环境下的external locking--锁机制） skip-name-resolve = 1 #跳过主机名解析，直接IP访问，可提升访问速度 log-error = /data/log/mysqld_error.log #错误日志文件 # 重要配置 max_connections = 5000 # 最大连接数 max_connect_errors = 6000 # 客户端请求异常中断次数 max_allowed_packet = 32M # 限制单条数据大小 sort_buffer_size = 8M # 每个连接独享内存数，如：500连接 * 8 = 4G 内存 join_buffer_size = 8M # 表关联缓存大小，每个连接独享 # 数据库引擎相关参数 default-storage-engine = InnoDB # 默认数据库引擎 # 性能分析 slow-query-log = 1 # 是否记录慢查询日志 long_query_time = 2 # 慢查询超时时间设置 slow-query-log-file=/var/log/mysql/query-slow.log #慢查询日志记录文件 # 二进制文件设置 log_bin = = /data/log/mysql/bin-log.log # 开启bin-log日志，指定存储路径 binlog_format = ROW # ROW(基于行的复制--安全，但是注意并发) STATEMENT(基于sql语句的复制)，MIXED(混合模式复制) binlog_cache_size = 4M # 二进制日志缓存，提高log-bin记录效率 log_bin_trust_function_creators = 1 #主从复制是需要注意，为了保证主从复制完全一致，需要开启此选项，主从默认阻止函数创建 max_binlog_size = 1G # 二进制日志文件大小默认1G 要求大于4096 小于1G expire_logs_days = 7 # 清除过期日志 # 主从复制相关 server-id = 2020 #主从复制必须，并且各服务器具有唯一性 log_slave_updates #配置从服务器的更新是否写入二进制日志，默认是不打开的 replicate-ignore-db = mysql #主从复制默认忽略的数据库，可用\",\"分隔或使用多条记录 # replicate-do-db=qrs,login #主从复制指定数据库,\",\"号隔开或使用多条记录 #数据库全量备份 [mysqldump] quick #强制mysqldump从服务器一次一行地检索表中的行 max_allowed_packet = 32M #可接收数据包大小 [isamchk] #在mysqld服务器不使用的情况下修复表或在崩溃状态下恢复表 key_buffer = 1024M sort_buff_size =1024M read_buffer = 16M write_buffer = 16M [myisamchk] #在mysqld服务器不使用的情况下修复表或在崩溃状态下恢复表 key_buffer = 1024M sort_buff_size = 1024M read_buffer = 16M write_buffer = 16M [mysqld_safe] #safe方式启动数据库，相比于mysqld,会在服务启动后继续监控服务状态，死机时重启 open-files-limit = 8192 三、sql语句 四、备份 1、mysqldump 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 #!/bin/bash # 建造AR-mysql server_host= server_port= server_user= server_passwd= back_date=`date \"+%Y-%m-%d\"` back_time=`date \"+%H:%M:%S\"` back_path=/data/backup/$back_date/mysql # 切换到备份目录 mkdir -p $back_path cd $back_path # db列表(过滤不备份库) db_list=`mysql -h $server_host \\ -P $server_port \\ -u$server_user \\ -p$server_passwd \\ -e \"show databases;\" \\ | grep -Ev \"Database|information_schema|mysql|test|performance_schema|sys\" ` # 遍历备份 for db in $db_list;do sql_name=${db}_${back_time}.sql mysqldump -h $server_host \\ -P $server_port \\ -u$server_user \\ -p$server_passwd \\ --databases $db \u003e $sql_name done # 删除过期文件 find /data/backup/ -mindepth 2 -type d -mtime +3 -exec rm -rf {} \\; 1 2 3 4 5 6 7 8 9 10 --all-databases \\ # 备份所有服务器 --compact \\ # 压缩模式 --comments \\ # 添加注释信息 --complete-insert \\ # 输出完成的插入语句 --lock-tables \\ # 备份前，锁定所有数据库表 --no-create-db | --no-create-info \\ # 禁止生成创建数据库语句 --force \\ # 当出现错误时仍然继续备份操作 --default-character-set \\ # 指定默认字符集 --add-locks --no-data \\ # 不到处 ","description":"\n","tags":[],"title":"\nMysql配置详解","uri":"/posts/post-302/"},{"categories":["默认分类"],"content":"一、安装 docker 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 docker pull minio/minio:latest DOCKER_NAME=minio MINIO_ACCESS_KEY=admin MINIO_SECRET_KEY=admin123 mkdir -p /data/$DOCKER_NAME/data mkdir -p /data/$DOCKER_NAME/conf docker run --name $DOCKER_NAME \\ -p 9000:9000 \\ -d \\ -e \"MINIO_ACCESS_KEY=$MINIO_ACCESS_KEY\" \\ -e \"MINIO_SECRET_KEY=$MINIO_SECRET_KEY\" \\ -v /data/$DOCKER_NAME/data:/data \\ -v /data/$DOCKER_NAME/conf:/root/.minio \\ minio/minio server /data # 客户端 docker pull minio/mc docker run -it --entrypoint=/bin/sh minio/mc mc config host add myminio http://192.168.0.1:9000 $MINIO_ACCESS_KEY $MINIO_SECRET_KEY # 配置指定桶开放下载 mc policy set public myminio/backup 源码 …\n二、mc客户端使用 bucket桶策略 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 cat \u003e getonly.json \u003c\u003c EOF { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": [\t// 可以做出的行动（权限） \"s3:ListAllMyBuckets\", // 查看所有的“桶”列表 \"s3:ListBucket\", // 查看桶内的对象列表 \"s3:GetBucketLocation\", \"s3:GetObject\", // 下载对象 \"s3:PutObject\", // 上传对象 \"s3:DeleteObject\" // 删除对象\t], \"Resource\": [ \"arn:aws:s3:::my-bucketname/*\" // （应用到的资源，*表示所有，也可以用路径来控制范围。arn:aws:s3是命名空间） ], \"Sid\": \"\" } ] } EOF 1 2 # 添加该策略 mc admin policy add myminio getonly getonly.json 管理用户 1 2 3 4 5 6 7 8 9 10 11 # 创建用户 mc admin user add myminio newuser password # 授权策略 mc admin policy set myminio getonly user=newuser # 禁用用户 mc admin user disable myminio newuser # 列出所有用户 mc admin user list myminio 管理组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 创建组 mc admin group add myminio newgroup newuser # 授权策略 mc admin policy set myminio getonly group=newgroup # # 禁用组 mc admin group disable myminio newgroup # 列出所有组 三、使用问题 1、分享链接无法访问 nginx代理配置 1 2 3 4 5 6 7 8 9 10 11 12 13 server { listen 80; server_name minio.maruifu.cn; location / { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Host $http_host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:9000; } } 配置bucket访问权限 minio默认bucket无读取和写入权限\n1、点击三个点按钮\n2、编辑策略\n3、添加权限\n三、API 1、golang 文档地址：https://docs.minio.io/docs/golang-client-quickstart-guide.html\n连接minio服务器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main import ( \"log\" \"github.com/minio/minio-go/v7\" \"github.com/minio/minio-go/v7/pkg/credentials\" ) func main() { endpoint := \"minio.dongzi.online\" accessKeyID := \"dongdonghe\" // ID secretAccessKey := \"19981014\" // Secret useSSL := false // ssl配置 // Initialize minio client object. minioClient, err := minio.New(endpoint, \u0026minio.Options{ Creds: credentials.NewStaticV4(accessKeyID, secretAccessKey, \"\"), Secure: useSSL, }) if err != nil { log.Fatalln(err) } log.Printf(\"%#v\\n\", minioClient) // minioClient is now setup } 创建bucket\n1 2 3 4 5 6 7 8 9 func createBucket(mc *minio.Client, bucketName string) (err error) { err = mc.MakeBucket(context.Background(), bucketName, minio.MakeBucketOptions{Region: \"us-east-1\", ObjectLocking: false}) // Region : 存储桶（us-east-1：默认） if err != nil { fmt.Println(err) return } fmt.Println(\"Successfully created mybucket.\") return } 列出所有bucket\n1 2 3 4 5 6 7 8 9 10 11 func listBucket(mc *minio.Client) (err error) { buckets, err := mc.ListBuckets(context.Background()) if err != nil { fmt.Println(err) return } for _, bucket := range buckets { fmt.Printf(\"bucket名称：%s，创建时间：%s\\n\", bucket.Name, bucket.CreationDate) } return } 检查bucket是否存在\n1 2 3 4 5 6 7 8 9 10 11 12 13 func bucketExits(mc *minio.Client, bucketName string) (err error) { found, err := mc.BucketExists(context.Background(), bucketName) if err != nil { fmt.Println(err) return } if found { fmt.Println(\"Bucket found\") } else { fmt.Println(\"Bucket not found\") } return } 删除bucket\n1 2 3 4 5 6 7 8 func deleteBucket(mc *minio.Client, bucketName string) (err error) { err = mc.RemoveBucket(context.Background(), bucketName) if err != nil { fmt.Println(err) return } return } 获取bucket文件对象列表\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func listObjs(mc *minio.Client, bucketName string) (err error) { ctx, cancel := context.WithCancel(context.Background()) defer cancel() objectCh := mc.ListObjects(ctx, bucketName, minio.ListObjectsOptions{ Prefix: \"制图\", // 前缀条件 Recursive: true, // 循环 }) for object := range objectCh { if object.Err != nil { fmt.Println(object.Err) return } fmt.Printf(\"文件名：%s，大小：%verb\", object.Key, object.Size) } return } 上传文件\n1 2 3 4 5 6 7 8 9 10 11 12 func uploadObject(mc *minio.Client, bucketName, objectName string, filePath string, contentType string) { n, err := mc.FPutObject(context.Background(), bucketName, // bucket objectName, // 上传文件名称 filePath, // 上传文件地址 minio.PutObjectOptions{ContentType: contentType}) // 上传文件类型 if err != nil { log.Fatalln(err) } log.Printf(\"Successfully uploaded %s of size %d byte \\n\", objectName, n.Size) } ","description":"\n","tags":[],"title":"\nminio安装使用","uri":"/posts/post-303/"},{"categories":["架构设计"],"content":"微服务\n网关简介 大家都都知道在微服务架构中，一个系统会被拆分为很多个微服务。那么作为客户端要如何去调用这么 多的微服务呢?如果没有网关的存在，我们只能在客户端记录每个微服务的地址，然后分别去调用。\n这样的架构，会存在着诸多的问题:\n客户端多次请求不同的微服务，增加客户端代码或配置编写的复杂性\n认证复杂，每个服务都需要独立认证。\n存在跨域请求，在一定场景下处理相对复杂。\n上面的这些问题可以借助API网关来解决。 所谓的API网关，就是指系统的统一入口，它封装了应用程序的内部结构，为客户端提供统一服务，一些与业务本身功能无关的公共逻辑可以在这里实现，诸如认证、鉴权、监控、路由转发等等。 添加上API网关之后，系统的架构图变成了如下所示:\n我们也可以观察下，我们现在的整体架构图:\n在业界比较流行的网关，有下面这些:\nNgnix+lua:使用nginx的反向代理和负载均衡可实现对api服务器的负载均衡及高可用，lua是一 种脚本语言,可以来编写一些简单的逻辑, nginx支持lua脚本\nKong:基于Nginx+Lua开发，性能高，稳定，有多个可用的插件(限流、鉴权等等)可以开箱即用。 问题:只支持Http协议;二次开发，自由扩展困难;提供管理API，缺乏更易用的管控、配置 方式。\nZuul :Netflflix开源的网关，功能丰富，使用JAVA开发，易于二次开发 问题:缺乏管控，无法动 态配置;依赖组件较多;处理Http请求依赖的是Web容器，性能不如Nginx\nSpring Cloud Gateway:Spring公司为了替换Zuul而开发的网关服务，将在下面具体介绍。\n**注意:**SpringCloud alibaba技术栈中并没有提供自己的网关，我们可以采用Spring Cloud Gateway来做网关\nGateway简介 Spring Cloud Gateway是Spring公司基于Spring 5.0，Spring Boot 2.0 和 Project Reactor 等技术开发 的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。它的目标是替代Netflflix Zuul，其不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如:安全，监 控和限流。\n优点:\n性能强劲:是第一代网关Zuul的1.6倍\n功能强大:内置了很多实用的功能，例如转发、监控、限流等\n设计优雅，容易扩展\n缺点:\n其实现依赖Netty与WebFlux，不是传统的Servlet编程模型，学习成本高\n不能将其部署在Tomcat、Jetty等Servlet容器里，只能打成jar包执行\n需要Spring Boot 2.0及以上的版本，才支持\nGateway快速入门 要求: 通过浏览器访问api网关,然后通过网关将请求转发到商品微服务\n基础版 第1步:创建一个 api-gateway 的模块,导入相关依赖\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cparent\u003e \u003cartifactId\u003espringcloud-alibaba\u003c/artifactId\u003e \u003cgroupId\u003ecn.maruifu\u003c/groupId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/parent\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cartifactId\u003eapi-gateway\u003c/artifactId\u003e \u003cdependencies\u003e \u003c!--gateway网关--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-gateway\u003c/artifactId\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e 第2步: 创建主类\npackage cn.maruifu; @SpringBootApplication public class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); } } 第3步: 添加配置文件\nserver: port: 7000 spring: application: name: api-gateway cloud: gateway: routes: # 路由数组[路由 就是指定当请求满足什么条件的时候转到哪个微服务] - id: product_route # 当前路由的标识, 要求唯一 uri: http://localhost:8081 # 请求要转发到的地址 order: 1 # 路由的优先级,数字越小级别越高 predicates: # 断言(就是路由转发要满足的条件) # 匹配路径转发 - Path=/product-serv/** # 当请求路径满足Path指定的规则时,才进行路由转发 filters: # 过滤器,请求在传递过程中可以通过过滤器对其进行一定的修改 - StripPrefix=1 # 转发之前去掉1层路径 第4步: 启动项目, 并通过网关去访问微服务\n增强版 第1步:加入nacos依赖\n\u003c!--nacos客户端--\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-nacos-discovery\u003c/artifactId\u003e \u003c/dependency\u003e 第2步:在主类上添加注解\n@SpringBootApplication @EnableDiscoveryClient public class ApiGatewayApplication { public static void main(String[] args) { SpringApplication.run(ApiGatewayApplication.class, args); } } 第3步:修改配置文件\nserver: port: 7000 spring: application: name: api-gateway cloud: nacos: discovery: server-addr: 127.0.0.1:8848 gateway: discovery: locator: enabled: true routes: # 路由数组[路由 就是指定当请求满足什么条件的时候转到哪个微服务] - id: product_route # 当前路由的标识, 要求唯一 uri: http://localhost:8081 # 请求要转发到的地址 order: 1 # 路由的优先级,数字越小级别越高 predicates: # 断言(就是路由转发要满足的条件) # 匹配路径转发 - Path=/product-serv/** # 当请求路径满足Path指定的规则时,才进行路由转发 filters: # 过滤器,请求在传递过程中可以通过过滤器对其进行一定的修改 - StripPrefix=1 # 转发之前去掉1层路径 第4步:测试\n简写版 第1步: 去掉关于路由的配置\nserver: port: 7000 spring: application: name: api-gateway cloud: nacos: discovery: server-addr: 127.0.0.1:8848 gateway: discovery: locator: enabled: true # 让gateway可以发现nacos中的微服务 第2步: 启动项目，并通过网关去访问微服\n这时候，就发现只要按照网关地址微服务接口的格式去访问，就可以得到成功响应。\nGateway核心架构 基本概念 路由(Route) 是 gateway 中最基本的组件之一，表示一个具体的路由信息载体。主要定义了下面的几个信息:\nid，路由标识符，区别于其他 Route。 uri，路由指向的目的地 uri，即客户端请求最终被转发到的微服务。 order，用于多个 Route 之间的排序，数值越小排序越靠前，匹配优先级越高。 predicate，断言的作用是进行条件判断，只有断言都返回真，才会真正的执行路由。 fifilter，过滤器用于修改请求和响应信息。 执行流程 执行流程大体如下:\nGateway Client向Gateway Server发送请求 请求首先会被HttpWebHandlerAdapter进行提取组装成网关上下文 然后网关的上下文会传递到DispatcherHandler，它负责将请求分发给RoutePredicateHandlerMapping RoutePredicateHandlerMapping负责路由查找，并根据路由断言判断路由是否可用 如果过断言成功，由FilteringWebHandler创建过滤器链并调用 请求会一次经过PreFilter–微服务-PostFilter的方法，最终返回响应 断言 Predicate(断言, 谓词) 用于进行条件判断，只有断言都返回真，才会真正的执行路由。\n断言就是说: 在 什么条件下 才能进行路由转发\n内置路由断言工厂 SpringCloud Gateway包括许多内置的断言工厂，所有这些断言都与HTTP请求的不同属性匹配。具体如下:\n基于Datetime类型的断言工厂\n此类型的断言根据时间做判断，主要有三个:\nAfterRoutePredicateFactory: 接收一个日期参数，判断请求日期是否晚于指定日期 BeforeRoutePredicateFactory: 接收一个日期参数，判断请求日期是否早于指定日期 BetweenRoutePredicateFactory: 接收两个日期参数，判断请求日期是否在指定时间段内 -After=2019-12-31T23:59:59.789+08:00[Asia/Shanghai]\n基于远程地址的断言工厂\nRemoteAddrRoutePredicateFactory:接收一个IP地址段，判断请求主机地址是否在地址段中\n-RemoteAddr=192.168.1.1/24\n基于Cookie的断言工厂 CookieRoutePredicateFactory:接收两个参数，cookie 名字和一个正则表达式。 判断请求cookie是否具有给定名称且值与正则表达式匹配。 -Cookie=chocolate, ch.\n基于Header的断言工厂\nHeaderRoutePredicateFactory:接收两个参数，标题名称和正则表达式。 判断请求Header是否具有给定名称且值与正则表达式匹配。 -Header=X-Request-Id, \\d+\n基于Host的断言工厂 HostRoutePredicateFactory:接收一个参数，主机名模式。判断请求的Host是否满足匹配规则。 -Host=**.testhost.org\n基于Method请求方法的断言工厂 MethodRoutePredicateFactory:接收一个参数，判断请求类型是否跟指定的类型匹配。 -Method=GET\n基于Path请求路径的断言工厂 PathRoutePredicateFactory:接收一个参数，判断请求的URI部分是否满足路径规则。 -Path=/foo/{segment}\n基于Query请求参数的断言工厂 QueryRoutePredicateFactory :接收两个参数，请求param和正则表达式， 判断请求参数是否具有给定名称且值与正则表达式匹配。 -Query=baz, ba.\n基于路由权重的断言工厂 WeightRoutePredicateFactory:接收一个[组名,权重], 然后对于同一个组内的路由按照权重转发 routes: -id: weight_route1 uri: host1 predicates: -Path=/product/** -Weight=group3, 1 -id: weight_route2 uri: host2 predicates: -Path=/product/** -Weight= group3, 9\n内置路由断言工厂的使用\n接下来我们验证几个内置断言的使用:\nserver: port: 7000 spring: application: name: api-gateway cloud: nacos: discovery: server-addr: 127.0.0.1:8848 gateway: discovery: locator: enabled: true routes: # 路由数组[路由 就是指定当请求满足什么条件的时候转到哪个微服务] - id: product_route # 当前路由的标识, 要求唯一 uri: lb://service-product # 请求要转发到的地址 predicates: # 断言(就是路由转发要满足的条件) # 匹配路径转发 - Path=/product-serv/** # 当请求路径满足Path指定的规则时,才进行路由转发 - Before=2022-02-18T00:00:00.000+08:00 #限制请求时间在2022-02-18之前 \\- Method=POST #限制请求方式为POST filters: # 过滤器,请求在传递过程中可以通过过滤器对其进行一定的修改 - StripPrefix=1 # 转发之前去掉1层路径 自定义路由断言工厂 我们来设定一个场景: 假设我们的应用仅仅让age在(min,max)之间的人来访问。\n第1步:在配置文件中,添加一个Age的断言配置\nspring: application: name: api-gateway cloud: nacos: discovery: server-addr: 127.0.0.1:8848 gateway: discovery: locator: enabled: true routes: - id: product-route uri: lb://service-product predicates: - Path=/product-serv/** - Age=18,60 # 限制年龄只有在18到60岁之间的人能访问 filters: - StripPrefix=1 第2步:自定义一个断言工厂, 实现断言方法\npackage cn.maruifu.predicates; import lombok.Data; import lombok.NoArgsConstructor; import org.apache.commons.lang3.StringUtils; import org.springframework.cloud.gateway.handler.predicate.AbstractRoutePredicateFactory; import org.springframework.stereotype.Component; import org.springframework.web.server.ServerWebExchange; import java.util.Arrays; import java.util.List; import java.util.function.Predicate; //自定义路由断言工厂 //泛型 用于接收一个配置类,配置类用于接收中配置文件中的配置 @Component public class AgeRoutePredicateFactory extends AbstractRoutePredicateFactory\u003cAgeRoutePredicateFactory.Config\u003e { public AgeRoutePredicateFactory(){ super(AgeRoutePredicateFactory.Config.class); } //用于从配置文件中获取参数值赋值到配置类中的属性上 @Override public List\u003cString\u003e shortcutFieldOrder(){ //这里的顺序要跟配置文件中的参数顺序一致 return Arrays.asList(\"minAge\",\"maxAge\"); } //断言 @Override public Predicate\u003cServerWebExchange\u003e apply( AgeRoutePredicateFactory.Config config){ return new Predicate\u003cServerWebExchange\u003e(){ @Override public boolean test(ServerWebExchange serverWebExchange){ //从serverWebExchange获取传入的参数 String ageStr=serverWebExchange.getRequest().getQueryParams().getFirst(\"age\"); if(StringUtils.isNotEmpty(ageStr)){ int age=Integer.parseInt(ageStr); return age\u003econfig.getMinAge()\u0026\u0026age\u003cconfig.getMaxAge(); } return true; } }; } @Data @NoArgsConstructor public static class Config { private int minAge; private int maxAge; } } 第4步:启动测试\n测试发现当age在(20,60)可以访问,其它范围不能访问 http://localhost:7000/product-serv/product/1?age=30 http://localhost:7000/product-serv/product/1?age=10 过滤器 三个知识点\n作用: 过滤器就是在请求的传递过程中,对请求和响应做一些手脚\n生命周期: Pre Post\n分类: 局部过滤器(作用在某一个路由上) 全局过滤器(作用全部路由上)\n在Gateway中, Filter的生命周期只有两个:“pre” 和 “post”。\nPRE: 这种过滤器在请求被路由之前调用。我们可利用这种过滤器实现身份验证、在集群中选择 请求的微服务、记录调试信息等。\nPOST:这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。\nGateway 的Filter从作用范围可分为两种: GatewayFilter与GlobalFilter。\nGatewayFilter:应用到单个路由或者一个分组的路由上。\nGlobalFilter:应用到所有的路由上。\n局部过滤器 局部过滤器是针对单个路由的过滤器。\n内置局部过滤器 在SpringCloud Gateway中内置了很多不同类型的网关路由过滤器。具体如下:\n| 过滤器工厂 | 作用 | 参数 | | :——–: | :–: | :–: | | AddRequestHeader | 为原始请求添加Header | Header的名称及值 | | AddRequestParameter | 为原始请求添加请求参数 | 参数名称及值 | | AddResponseHeader | 为原始响应添加Header | Header的名称及值 | | DedupeResponseHeader | 剔除响应头中重复的值 | 需要去重的Header名 称及去重策略 | | Hystrix | 为路由引入Hystrix的断路器保护 | HystrixCommand的名称 | | FallbackHeaders | 为fallbackUri的请求头中添加具体的异常信息 | Header名称 | | FallbackHeaders | 为请求添加一个 preserveHostHeader=true的属 性，路由过滤器会检查该属性以 决定是否要发送原始的Host | 无 | | RequestRateLimiter | 用于对请求限流，限流算法为令牌桶 | keyResolver、 rateLimiter、 statusCode、 denyEmptyKey、 emptyKeyStatus | | RedirectTo | 将原始请求重定向到指定的URL | http状态码及重定向 的 url | | RemoveHopByHopHeadersFilter | 为原始请求删除IETF组织规定的 一系列Header | 默认就会启用，可以 通 过配置指定仅删除 哪些 Header | | RewriteResponseHeader | 为原始请求删除某个Header | Header的名称 | | RemoveRequestHeader | 为原始请求删除某个Header | Header的名称 | | RewritePath | 重写原始的请求路径 | 原始路径正则表达式 以 及重写后路径的正 则表达式 | | RewriteResponseHeader | 重写原始响应中的某个Header | Header名称，值的正 则表达式，重写后的 值 | | SaveSession | 在转发请求之前，强制执行WebSession::save操作 | 无 | | secureHeaders | 为原始响应添加一系列起安全作用的响应头 | 无，支持修改这些安全 | | SetPath | 修改原始的请求路径 | 修改后的路径 | | SetResponseHeader | 修改原始响应中某个Header的 Header名称，修改后值 | Header名称，修改后值的值 | | SetStatus | 修改原始响应体的内容 | HTTP 状态码，可以是数字，也可以是字符串 | | StripPrefix | 用于截断原始请求的路径 | 使用数字表示要截断的路径的数量 | | Retry | 针对不同的响应进行重试 | retries、statuses、methods、series | | RequestSize | 设置允许接收最大请求包的大 小。如果请求包大小超过设置的 值，则返回 413 Payload Too Large | 请求包大小，单位为字节，默认值为5M | | ModifyRequestBody | 在转发请求之前修改原始请求体内容 | 修改后的请求体内容 | | ModifyResponseBody | 修改原始响应的内容 | 修改后的响应体内容 |\n内置局部过滤器的使用\nserver: port: 7000 spring: application: name: api-gateway cloud: nacos: discovery: server-addr: 127.0.0.1:8848 gateway: discovery: locator: enabled: true routes: # 路由数组[路由 就是指定当请求满足什么条件的时候转到哪个微服务] - id: product_route # 当前路由的标识, 要求唯一 uri: lb://service-product # 请求要转发到的地址 predicates: # 断言(就是路由转发要满足的条件) # 匹配路径转发 - Path=/product-serv/** # 当请求路径满足Path指定的规则时,才进行路由转发 filters: # 过滤器,请求在传递过程中可以通过过滤器对其进行一定的修改 - StripPrefix=1 # 转发之前去掉1层路径 - SetStatus=2000 # 修改返回状态 自定义局部过滤 第1步:在配置文件中,添加一个Log的过滤器配置\nserver: port: 7000 spring: application: name: api-gateway cloud: nacos: discovery: server-addr: 127.0.0.1:8848 gateway: discovery: locator: enabled: true # 让gateway可以发现nacos中的微服务 routes: - id: consumer uri: lb://consumer # lb指的是从nacos中按照名称获取微服务,并遵循负载均 衡策略 predicates: - Path=/consumer-serv/** filters: - StripPrefix=1 - Log=true,false # 控制日志是否开启 第2步:自定义一个过滤器工厂,实现方法\npackage cn.maruifu.predicates; import lombok.Data; import lombok.NoArgsConstructor; import org.springframework.cloud.gateway.filter.GatewayFilter; import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.cloud.gateway.filter.factory.AbstractGatewayFilterFactory; import org.springframework.stereotype.Component; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; import java.util.Arrays; import java.util.List; //自定义局部过滤器 @Component public class LogGatewayFilterFactory extends AbstractGatewayFilterFactory\u003cLogGatewayFilterFactory.Config\u003e { //构造函数 public LogGatewayFilterFactory() { super(LogGatewayFilterFactory.Config.class); } //读取配置文件中的参数 赋值到 配置类中 @Override public List\u003cString\u003e shortcutFieldOrder() { return Arrays.asList(\"consoleLog\", \"cacheLog\"); } //过滤器逻辑 @Override public GatewayFilter apply(LogGatewayFilterFactory.Config config) { return new GatewayFilter() { @Override public Mono\u003cVoid\u003e filter(ServerWebExchange exchange, GatewayFilterChain chain) { if (config.isCacheLog()) { System.out.println(\"cacheLog已经开启了....\"); } if (config.isConsoleLog()) { System.out.println(\"consoleLog已经开启了....\"); } return chain.filter(exchange); } }; } //配置类 接收配置参数 @Data @NoArgsConstructor public static class Config { private boolean consoleLog; private boolean cacheLog; } } 第3步:启动测试\n全局过滤器 全局过滤器作用于所有路由, 无需配置。通过全局过滤器可以实现对权限的统一校验，安全性验证等功 能。\n内置全局过滤器 SpringCloud Gateway内部也是通过一系列的内置全局过滤器对整个路由转发进行处理如下:\n自定义全局过滤器 内置的过滤器已经可以完成大部分的功能，但是对于企业开发的一些业务功能处理，还是需要我们自己编写过滤器来实现的，那么我们一起通过代码的形式自定义一个过滤器，去完成统一的权限校验。\n开发中的鉴权逻辑:\n当客户端第一次请求服务时，服务端对用户进行信息认证(登录)\n认证通过，将用户信息进行加密形成token，返回给客户端，作为登录凭证\n以后每次请求，客户端都携带认证的token\n服务端对token进行解密，判断是否有效。\n如上图，对于验证用户是否已经登录鉴权的过程可以在网关统一检验。\n检验的标准就是请求中是否携带token凭证以及token的正确性。\n下面的我们自定义一个GlobalFilter，去校验所有请求的请求参数中是否包含“token”，如何不包含请求 参数“token”则不转发路由，否则执行正常的逻辑。\npackage cn.maruifu.filter; import org.apache.commons.lang3.StringUtils; import org.springframework.cloud.gateway.filter.GatewayFilterChain; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.core.Ordered; import org.springframework.http.HttpStatus; import org.springframework.stereotype.Component; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; //自定义全局过滤器需要实现GlobalFilter和Ordered接口 @Component public class AuthGlobalFilter implements GlobalFilter, Ordered { //完成判断逻辑 @Override public Mono\u003cVoid\u003e filter(ServerWebExchange exchange, GatewayFilterChain chain) { String token = exchange.getRequest().getQueryParams().getFirst(\"token\"); if (StringUtils.isBlank(token)) { System.out.println(\"鉴权失败\"); exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED); return exchange.getResponse().setComplete(); } //调用chain.filter继续向下游执行 return chain.filter(exchange); } //顺序,数值越小,优先级越高 @Override @Override public int getOrder() { return 0; } } 网关限流 网关是所有请求的公共入口，所以可以在网关进行限流，而且限流的方式也很多，我们本次采用前面学 过的Sentinel组件来实现网关的限流。Sentinel支持对SpringCloud Gateway、Zuul等主流网关进行限流。\n从1.6.0版本开始，Sentinel提供了SpringCloud Gateway的适配模块，可以提供两种资源维度的限流:\nroute维度:即在Spring配置文件中配置的路由条目，资源名为对应的routeId\n自定义API维度:用户可以利用Sentinel提供的API来自定义一些API分组\n第一步：导入依赖\n\u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.csp\u003c/groupId\u003e \u003cartifactId\u003esentinel-spring-cloud-gateway-adapter\u003c/artifactId\u003e \u003c/dependency\u003e 第一步：编写配置类\n基于Sentinel 的Gateway限流是通过其提供的Filter来完成的，使用时只需注入对应的 SentinelGatewayFilter实例以及 SentinelGatewayBlockExceptionHandler 实例即可。\npackage cn.maruifu.config; import com.alibaba.csp.sentinel.adapter.gateway.common.rule.GatewayFlowRule; import com.alibaba.csp.sentinel.adapter.gateway.common.rule.GatewayRuleManager; import com.alibaba.csp.sentinel.adapter.gateway.sc.SentinelGatewayFilter; import com.alibaba.csp.sentinel.adapter.gateway.sc.callback.BlockRequestHandler; import com.alibaba.csp.sentinel.adapter.gateway.sc.callback.GatewayCallbackManager; import com.alibaba.csp.sentinel.adapter.gateway.sc.exception.SentinelGatewayBlockExceptionHandler; import org.springframework.beans.factory.ObjectProvider; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.Ordered; import org.springframework.core.annotation.Order; import org.springframework.http.HttpStatus; import org.springframework.http.MediaType; import org.springframework.http.codec.ServerCodecConfigurer; import org.springframework.web.reactive.function.BodyInserters; import org.springframework.web.reactive.function.server.ServerResponse; import org.springframework.web.reactive.result.view.ViewResolver; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; import javax.annotation.PostConstruct; import java.util.*; @Configuration public class GatewayConfiguration { private final List\u003cViewResolver\u003e viewResolvers; private final ServerCodecConfigurer serverCodecConfigurer; public GatewayConfiguration(ObjectProvider\u003cList\u003cViewResolver\u003e\u003e viewResolversProvider, ServerCodecConfigurer serverCodecConfigurer) { this.viewResolvers = viewResolversProvider.getIfAvailable(Collections::emptyList); this.serverCodecConfigurer = serverCodecConfigurer; } // 初始化一个限流的过滤器 @Bean @Order(Ordered.HIGHEST_PRECEDENCE) public GlobalFilter sentinelGatewayFilter() { return new SentinelGatewayFilter(); } // 配置初始化的限流参数 @PostConstruct public void initGatewayRules() { Set\u003cGatewayFlowRule\u003e rules = new HashSet\u003c\u003e(); rules.add(new GatewayFlowRule(\"product_route\") //资源名称,对应路由id .setCount(1) // 限流阈值 .setIntervalSec(1) // 统计时间窗口，单位是秒，默认是 1 秒 ); GatewayRuleManager.loadRules(rules); } // 配置限流的异常处理器 @Bean @Order(Ordered.HIGHEST_PRECEDENCE) public SentinelGatewayBlockExceptionHandler sentinelGatewayBlockExceptionHandler() { return new SentinelGatewayBlockExceptionHandler(viewResolvers, serverCodecConfigurer); } // 自定义限流异常页面 @PostConstruct public void initBlockHandlers() { BlockRequestHandler blockRequestHandler = new BlockRequestHandler() { @Override public Mono\u003cServerResponse\u003e handleRequest(ServerWebExchange serverWebExchange, Throwable throwable) { Map map = new HashMap\u003c\u003e(); map.put(\"code\", 0); map.put(\"message\", \"接口被限流了\"); return ServerResponse.status(HttpStatus.OK).contentType(MediaType.APPLICATION_JSON_UTF8).body(BodyInserters.fromObject(map)); } }; GatewayCallbackManager.setBlockHandler(blockRequestHandler); } } 第三步：测试 在一秒钟内多次访问http://localhost:7000/product-serv/product/1?token=1就可以看到限流启作用了。\n第四步：自定义API分组\n自定义API分组是一种更细粒度的限流规则定义\npackage cn.maruifu.config; import com.alibaba.csp.sentinel.adapter.gateway.common.SentinelGatewayConstants; import com.alibaba.csp.sentinel.adapter.gateway.common.api.ApiDefinition; import com.alibaba.csp.sentinel.adapter.gateway.common.api.ApiPathPredicateItem; import com.alibaba.csp.sentinel.adapter.gateway.common.api.ApiPredicateItem; import com.alibaba.csp.sentinel.adapter.gateway.common.api.GatewayApiDefinitionManager; import com.alibaba.csp.sentinel.adapter.gateway.common.rule.GatewayFlowRule; import com.alibaba.csp.sentinel.adapter.gateway.common.rule.GatewayRuleManager; import com.alibaba.csp.sentinel.adapter.gateway.sc.SentinelGatewayFilter; import com.alibaba.csp.sentinel.adapter.gateway.sc.callback.BlockRequestHandler; import com.alibaba.csp.sentinel.adapter.gateway.sc.callback.GatewayCallbackManager; import com.alibaba.csp.sentinel.adapter.gateway.sc.exception.SentinelGatewayBlockExceptionHandler; import org.springframework.beans.factory.ObjectProvider; import org.springframework.cloud.gateway.filter.GlobalFilter; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.Ordered; import org.springframework.core.annotation.Order; import org.springframework.http.HttpStatus; import org.springframework.http.MediaType; import org.springframework.http.codec.ServerCodecConfigurer; import org.springframework.web.reactive.function.BodyInserters; import org.springframework.web.reactive.function.server.ServerResponse; import org.springframework.web.reactive.result.view.ViewResolver; import org.springframework.web.server.ServerWebExchange; import reactor.core.publisher.Mono; import javax.annotation.PostConstruct; import java.util.*; // 自定义API分组 限流 @Configuration public class GatewayConfiguration { private final List\u003cViewResolver\u003e viewResolvers; private final ServerCodecConfigurer serverCodecConfigurer; public GatewayConfiguration(ObjectProvider\u003cList\u003cViewResolver\u003e\u003e viewResolversProvider, ServerCodecConfigurer serverCodecConfigurer) { this.viewResolvers = viewResolversProvider.getIfAvailable(Collections::emptyList); this.serverCodecConfigurer = serverCodecConfigurer; } // 初始化一个限流的过滤器 @Bean @Order(Ordered.HIGHEST_PRECEDENCE) public GlobalFilter sentinelGatewayFilter() { return new SentinelGatewayFilter(); } /** * 配置初始化的限流参数 */ @PostConstruct public void initGatewayRules(){ Set\u003cGatewayFlowRule\u003e rules=new HashSet\u003c\u003e(); rules.add(new GatewayFlowRule(\"product_api1\").setCount(1).setIntervalSec(1)); rules.add(new GatewayFlowRule(\"product_api2\").setCount(1).setIntervalSec(1)); GatewayRuleManager.loadRules(rules); } // 配置限流的异常处理器 @Bean @Order(Ordered.HIGHEST_PRECEDENCE) public SentinelGatewayBlockExceptionHandler sentinelGatewayBlockExceptionHandler() { return new SentinelGatewayBlockExceptionHandler(viewResolvers, serverCodecConfigurer); } // 自定义限流异常页面 @PostConstruct public void initBlockHandlers() { BlockRequestHandler blockRequestHandler = new BlockRequestHandler() { @Override public Mono\u003cServerResponse\u003e handleRequest(ServerWebExchange serverWebExchange, Throwable throwable) { Map map = new HashMap\u003c\u003e(); map.put(\"code\", 0); map.put(\"message\", \"接口被限流了\"); return ServerResponse.status(HttpStatus.OK).contentType(MediaType.APPLICATION_JSON_UTF8).body(BodyInserters.fromObject(map)); } }; GatewayCallbackManager.setBlockHandler(blockRequestHandler); } //自定义API分组 @PostConstruct private void initCustomizedApis() { Set\u003cApiDefinition\u003e definitions = new HashSet\u003c\u003e(); ApiDefinition api1 = new ApiDefinition(\"product_api1\") .setPredicateItems(new HashSet\u003cApiPredicateItem\u003e() {{ // 以/product-serv/product/api1 开头的请求 add(new ApiPathPredicateItem() .setPattern(\"/product- serv/product/api1/**\") .setMatchStrategy(SentinelGatewayConstants.URL_MATCH_STRATEGY_PREFIX) ); }}); ApiDefinition api2 = new ApiDefinition(\"product_api2\") .setPredicateItems(new HashSet\u003cApiPredicateItem\u003e() {{ // 以/product-serv/product/api2/demo1 完成的url路径匹配 add(new ApiPathPredicateItem().setPattern(\"/product-serv/product/api2/demo1\")); }}); definitions.add(api1); definitions.add(api2); GatewayApiDefinitionManager.loadApiDefinitions(definitions); } } ","description":"\n","tags":[],"title":"\nGateway–服务网关","uri":"/posts/post-304/"},{"categories":["架构设计"],"content":"微服务\n高并发带来的问题 在微服务架构中，我们将业务拆分成一个个的服务，服务与服务之间可以相互调用，但是由于网络原因 或者自身的原因，服务并不能保证服务的100%可用，如果单个服务出现问题，调用这个服务就会出现 网络延迟，此时若有大量的网络涌入，会形成任务堆积，最终导致服务瘫痪。\n接下来，我们来模拟一个高并发的场景\n编写java代码 @RestController @Slf4j public class OrderController2 { @Autowired private OrderService orderService; @Autowired private ProductService productService; @RequestMapping(\"/order/prod/{pid}\") public Order order(@PathVariable(\"pid\") Integer pid) { log.info(\"接收到{}号商品的下单请求,接下来调用商品微服务查询此商品信息\", pid);//调用商品微服 务,查询商品信息 Product product = productService.findByPid(pid); log.info(\"查询到{}号商品的信息,内容是:{}\", pid, JSON.toJSONString(product)); //模拟一次网络延时 try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } //下单(创建订单) Order order = new Order(); order.setUid(1); order.setUsername(\"测试用户\"); order.setPid(pid); order.setPname(product.getPname()); order.setPprice(product.getPprice()); order.setNumber(1); //为了不产生太多垃圾数据,暂时不做订单保存 //orderService.createOrder(order); log.info(\"创建订单成功,订单信息为{}\", JSON.toJSONString(order)); return order; } @RequestMapping(\"/order/message\") public String message() { return \"高并发下的问题测试\"; } } 修改配置文件中tomcat的并发数 server: #端口 port: 8091 #tomcat配置 tomcat: #tomcat的最大并发值修改为10,默认是200 max-threads: 10 #tomcat的最大并发值修改为10,默认是200 接下来使用压测工具,对请求进行压力测试 下载地址https://jmeter.apache.org/\n第一步:修改配置，并启动软件\n进入bin目录,修改jmeter.properties文件中的语言支持为language=zh_CN，然后点击jmeter.bat 启动 软件。\n第二步:添加线程组\n第三步:配置线程并发数\n第四步:添加Http取样\n第五步:配置取样，并启动测试\n访问message方法观察效果 结论: 此时会发现, 由于order方法囤积了大量请求, 导致message方法的访问出现了问题，这就是服务雪崩的 雏形。\n服务雪崩效应 在分布式系统中,由于网络原因或自身的原因,服务一般无法保证 100% 可用。如果一个服务出现了问 题，调用这个服务就会出现线程阻塞的情况，此时若有大量的请求涌入，就会出现多条线程阻塞等待， 进而导致服务瘫痪。\n由于服务与服务之间的依赖性，故障会传播，会对整个微服务系统造成灾难性的严重后果，这就是服务 故障的 雪崩效应 。\n雪崩发生的原因多种多样，有不合理的容量设计，或者是高并发下某一个方法响应变慢，亦或是某台机 器的资源耗尽。我们无法完全杜绝雪崩源头的发生，只有做好足够的容错，保证在一个服务发生问题， 不会影响到其它服务的正常运行。也就是\"雪落而不雪崩\"。\n常见容错方案 要防止雪崩的扩散，我们就要做好服务的容错，容错说白了就是保护自己不被猪队友拖垮的一些措施,\n下面介绍常见的服务容错思路和组件。\n常见的容错思路\n常见的容错思路有隔离、超时、限流、熔断、降级这几种，下面分别介绍一下。\n隔离 它是指将系统按照一定的原则划分为若干个服务模块，各个模块之间相对独立，无强依赖。当有故障发 生时，能将问题和影响隔离在某个模块内部，而不扩散风险，不波及其它模块，不影响整体的系统服 务。常见的隔离方式有:线程池隔离和信号量隔离.\n超时 在上游服务调用下游服务的时候，设置一个最大响应时间，如果超过这个时间，下游未作出反应，就断 开请求，释放掉线程。\n限流 限流就是限制系统的输入和输出流量已达到保护系统的目的。为了保证系统的稳固运行,一旦达到的需要 限制的阈值,就需要限制流量并采取少量措施以完成限制流量的目的。\n熔断 在互联网系统中，当下游服务因访问压力过大而响应变慢或失败，上游服务为了保护系统整体的可 用性，可以暂时切断对下游服务的调用。这种牺牲局部，保全整体的措施就叫做熔断。\n服务熔断一般有三种状态:\n熔断关闭状态(Closed) 服务没有故障时，熔断器所处的状态，对调用方的调用不做任何限制\n熔断开启状态(Open) 后续对该服务接口的调用不再经过网络，直接执行本地的fallback方法\n半熔断状态(Half-Open) 尝试恢复服务调用，允许有限的流量调用该服务，并监控调用成功率。如果成功率达到预期，则说明服务已恢复，进入熔断关闭状态;如果成功率仍旧很低，则重新进入熔断关闭状态。\n降级 降级其实就是为服务提供一个托底方案，一旦服务无法正常调用，就使用托底方案。\n常见的容错组件\nHystrix\nHystrix是由Netflflix开源的一个延迟和容错库，用于隔离访问远程系统、服务或者第三方库，防止级联 失败，从而提升系统的可用性与容错性。\nResilience4J Resilicence4J一款非常轻量、简单，并且文档非常清晰、丰富的熔断工具，这也是Hystrix官方推荐的替 代产品。不仅如此，Resilicence4j还原生支持Spring Boot 1.x/2.x，而且监控也支持和prometheus等 多款主流产品进行整合。\nSentinel Sentinel 是阿里巴巴开源的一款断路器实现，本身在阿里内部已经被大规模采用，非常稳定。\n下面是三个组件在各方面的对比:\nSentinel Hystrix resilience4j 隔离策略 信号量隔离(并发线程数限流) 线程池隔离/信号量隔离 信号量隔离 熔断降级策略 基于响应时间、异常比率、异常数 基于异常比率 基于异常比率、响应 实时统计实现 滑动窗口(LeapArray) 滑动窗口(基 于 RxJava) Ring Bit Buffer 动态规则配置 支持多种数据源 支持多种数据 有限支持 扩展性 多个扩展点 插件的形式 接口的形式 基于注解的支 持 支持 支持 支持 限流 基于 QPS，支持基于调用关系的限流 有限的支持 Rate Limiter 流量整形 支持预热模式、匀速器模式、预热排队模式 不支持 简单的 Rate Limiter模式 系统自适应保护 支持 不支持 不支持 控制台 提供开箱即用的控制台，可配置规则、查看秒级监控、机器发现等 简单的监控查看 不提供控制台，可对接其它监控系统 Sentinel入门 什么是Sentine Sentinel (分布式系统的流量防卫兵) 是阿里开源的一套用于服务容错的综合性解决方案。它以流量 为切入点, 从流量控制、熔断降级、系统负载保护等多个维度来保护服务的稳定性。\nSentinel 具有以下特征\n丰富的应用场景:Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景, 例如秒杀(即 突发流量控制在系统容量可以承受的范围)、消息削峰填谷、集群流量控制、实时熔断下游不可用 应用等。\n完备的实时监控:Sentinel 提供了实时的监控功能。通过控制台可以看到接入应用的单台机器秒 级数据, 甚至 500 台以下规模的集群的汇总运行情况。\n广泛的开源生态:Sentinel 提供开箱即用的与其它开源框架/库的整合模块, 例如与 SpringCloud、 Dubbo、gRPC 的整合。只需要引入相应的依赖并进行简单的配置即可快速地接入Sentinel。\n完善的SPI扩展点:Sentinel 提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快 速地定制逻辑。例如定制规则管理、适配动态数据源等。\nSentinel分为两个部分:\n核心库(Java 客户端)不依赖任何框架/库,能够运行于所有 Java 运行时环境，同时对 Dubbo/Spring Cloud 等框架也有较好的支持。 控制台(Dashboard)基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等 应用容器。 微服务集成Sentinel 为微服务集成Sentinel非常简单, 只需要加入Sentinel的依赖即可\n1 在pom.xml中加入下面依赖\n\u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-sentinel\u003c/artifactId\u003e \u003c/dependency\u003e 2 编写一个Controller测试使用\npackage cn.maruifu.controller; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; // @RestController @Slf4j public class OrderTestController { @RequestMapping(\"/order/message1\") public String message1() { return \"message1\"; } @RequestMapping(\"/order/message2\") public String message2() { return \"message2\"; } } 安装Sentinel控制台 Sentinel 提供一个轻量级的控制台, 它提供机器发现、单机资源实时监控以及规则管理等功能。\n下载jar包,解压到文件夹 https://github.com/alibaba/Sentinel/releases 2 .启动控制台\n# 直接使用jar命令启动项目(控制台本身是一个SpringBoot项目) java -Dserver.port=8080 -Dcsp.sentinel.dashboard.server=localhost:8080 -Dproject.name=sentinel-dashboard -jar sentinel-dashboard-1.8.3.jar 修改 shop-order ,在里面加入有关控制台的配置 spring: cloud: sentinel: transport: port: 9999 #跟控制台交流的端口,随意指定一个未使用的端口即可 dashboard: localhost:8080 # 指定控制台服务的地址 通过浏览器访问localhost:8080 进入控制台 ( 默认用户名密码是 sentinel/sentinel ) 控制台的使用原理Sentinel的控制台其实就是一个SpringBoot编写的程序。我们需要将我们的微服务程序注册到控制台上, 即在微服务中指定控制台的地址, 并且还要开启一个跟控制台传递数据的端口, 控制台也可以通过此端口 调用微服务中的监控程序获取微服务的各种信息。\n实现一个接口的限流 通过控制台为message1添加一个流控规则\n通过控制台快速频繁访问, 观察效果\nSentinel的概念和功能 基本概念 资源 资源就是Sentinel要保护的东西\n资源是 Sentinel 的关键概念。它可以是 Java 应用程序中的任何内容，可以是一个服务，也可以是一个 方法，甚至可以是一段代码。\n我们入门案例中的message1方法就可以认为是一个资源\n规则 规则就是用来定义如何进行保护资源的\n作用在资源之上, 定义以什么样的方式保护资源，主要包括流量控制规则、熔断降级规则以及系统保护 规则。\n我们入门案例中就是为message1资源设置了一种流控规则, 限制了进入message1的流量\n重要功能 Sentinel的主要功能就是容错，主要体现为下面这三个:\n流量控制 流量控制在网络传输中是一个常用的概念，它用于调整网络包的数据。任意时间到来的请求往往是随机 不可控的，而系统的处理能力是有限的。我们需要根据系统的处理能力对流量进行控制。Sentinel 作为 一个调配器，可以根据需要把随机的请求调整成合适的形状。\n熔断降级 当检测到调用链路中某个资源出现不稳定的表现，例如请求响应时间长或异常比例升高的时候，则对这 个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联故障\nSentinel 对这个问题采取了两种手段:\n通过并发线程数进行限制 Sentinel 通过限制资源并发线程的数量，来减少不稳定资源对其它资源的影响。当某个资源出现不稳定 的情况下，例如响应时间变长，对资源的直接影响就是会造成线程数的逐步堆积。当线程数在特定资源 上堆积到一定的数量之后，对该资源的新请求就会被拒绝。堆积的线程完成任务后才开始继续接收请 求。\n通过响应时间对资源进行降级 除了对并发线程数进行控制以外，Sentinel 还可以通过响应时间来快速降级不稳定的资源。当依赖的资 源出现响应时间过长后，所有对该资源的访问都会被直接拒绝，直到过了指定的时间窗口之后才重新恢复。\nSentinel和 Hystrix的区别\n两者的原则是一致的, 都是当一个资源出现问题时, 让其快速失败, 不要波及到其它服务 但是在限制的手段上, 确采取了完全不一样的方法:\nHystrix 采用的是线程池隔离的方式, 优点是做到了资源之间的隔离, 缺点是增加了线程切换 的成本。\nSentinel 采用的是通过并发线程的数量和响应时间来对资源做限制。\n系统负载保护 Sentinel 同时提供系统维度的自适应保护能力。当系统负载较高的时候，如果还持续让请求进入 可能会导致系统崩溃，无法响应。在集群环境下，会把本应这台机器承载的流量转发到其它的机器 上去。如果这个时候其它的机器也处在一个边缘状态的时候，Sentinel 提供了对应的保护机制， 让系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围之内处理最多的请求 总之一句话:我们需要做的事情，就是在Sentinel的资源上配置各种各样的规则，来实现各种容错的功能。\nSentinel规则 流量控制，其原理是监控应用流量的QPS(每秒查询率) 或并发线程数等指标，当达到指定的阈值时对流 量进行控制，以避免被瞬时的流量高峰冲垮，从而保障应用的高可用性。\n第1步: 点击簇点链路，我们就可以看到访问过的接口地址，然后点击对应的流控按钮，进入流控规则配 置页面。新增流控规则界面如下\n流控规则 资源名:唯一名称，默认是请求路径，可自定义\n针对来源:指定对哪个微服务进行限流，默认指default，意思是不区分来源，全部限制\n阈值类型单机阈值:\nQPS(每秒请求数量): 当调用该接口的QPS达到阈值的时候，进行限流\n线程数:当调用该接口的线程数达到阈值的时候，进行限流\n是否集群:暂不需要集群 接下来我们以QPS为例来研究限流规则的配置。\n简单配置 我们先做一个简单配置，设置阈值类型为QPS，单机阈值为3。即每秒请求量大于3的时候开始限流。接下来，在流控规则页面就可以看到这个配置。\n配置流控模式 sentinel共有三种流控模式，分别是:\n直接(默认):接口达到限流条件时，开启限流\n关联:当关联的资源达到限流条件时，开启限流 [适合做应用让步]\n链路:当从某个接口过来的资源达到限流条件时，开启限流\n下面呢分别演示三种模式:\n直接流控模式\n直接流控模式是最简单的模式，当指定的接口达到限流条件时开启限流。上面案例使用的就是直接流控 模式。\n关联流控模式\n关联流控模式指的是，当指定接口关联的接口达到限流条件时，开启对指定接口开启限流。第1步:配 置限流规则,将流控模式设置为关联，关联资源设置为的 /order/message2。\n通过Jmeter软件向/order/message2连续发送请求，注意QPS一定要大于3\n访问/order/message1,会发现已经被限流\n链路流控模式\n链路流控模式指的是，当从某个接口过来的资源达到限流条件时，开启限流。它的功能有点类似于针对 来源配置项，区别在于:针对来源是针对上级微服务，而链路流控是针对上级接口，也就是说它的粒度 更细。\n1.编写一个service，在里面添加一个方法message\npackage cn.maruifu.service.impl; import com.alibaba.csp.sentinel.annotation.SentinelResource; import org.springframework.stereotype.Service; @Service public class OrderTestServiceImpl { @SentinelResource(\"message\") public void message() { System.out.println(\"message\"); } } 第2步: 在Controller中声明两个方法，分别调用service中的方法message\npackage cn.maruifu.controller; import cn.maruifu.service.impl.OrderTestServiceImpl; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; // @RestController @Slf4j public class OrderTestController { /* @RequestMapping(\"/order/message1\") public String message1() { return \"message1\"; } @RequestMapping(\"/order/message2\") public String message2() { return \"message2\"; }*/ @Autowired private OrderTestServiceImpl orderTestServiceImpl; @RequestMapping(\"/order/message1\") public String message1() { orderTestServiceImpl.message(); return \"message1\"; } @RequestMapping(\"/order/message2\") public String message2() { orderTestServiceImpl.message(); return \"message2\"; } } 第3步: 禁止收敛URL的入口 context\n1.6.3 版本开始，Sentinel Web fifilter默认收敛所有URL的入口context，因此链路限流不生效。 1.7.0 版本开始(对应SCA的2.1.1.RELEASE)，官方在CommonFilter 引入了WEB_CONTEXT_UNIFY 参数， 用于控制是否收敛context。将其配置为 false 即可根据不同的URL进行链路限流。\nSCA 2.1.1.RELEASE之后的版本,可以通过配置spring.cloud.sentinel.web-context-unify=false即 可关闭收敛我们当前使用的版本是SpringCloud Alibaba 2.1.0.RELEASE，无法实现链路限流。\n目前官方还未发布SCA 2.1.2.RELEASE，所以我们只能使用2.1.1.RELEASE，需要写代码的形式实 现\n(1) 暂时将SpringCloud Alibaba的版本调整为2.1.1.RELEASE\n\u003cspring-cloud-alibaba.version\u003e2.1.1.RELEASE\u003c/spring-cloud-alibaba.version\u003e (2) 配置文件中关闭sentinel的CommonFilter实例化\nspring: cloud: sentinel: filter: enabled: false (3) 添加一个配置类，自己构建CommonFilter实例\npackage cn.maruifu.config; import com.alibaba.csp.sentinel.adapter.servlet.CommonFilter; import org.springframework.boot.web.servlet.FilterRegistrationBean; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class FilterContextConfig { @Bean public FilterRegistrationBean sentinelFilterRegistration() { FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new CommonFilter()); registration.addUrlPatterns(\"/*\"); // 入口资源关闭聚合 registration.addInitParameter(CommonFilter.WEB_CONTEXT_UNIFY, \"false\"); registration.setName(\"sentinelFilter\"); registration.setOrder(1); return registration; } } (4) : 控制台配置限流规则\n(5) :分别通过 /order/message1 和 /order/message2 访问, 发现2没问题, 1的被限流了\n配置流控效果 快速失败(默认): 直接失败，抛出异常，不做任何额外的处理，是最简单的效果\nWarm Up:它从开始阈值到最大QPS阈值会有一个缓冲阶段，一开始的阈值是最大QPS阈值的 1/3，然后慢慢增长，直到最大阈值，适用于将突然增大的流量转换为缓步增长的场景。\n排队等待:让请求以均匀的速度通过，单机阈值为每秒通过数量，其余的排队等待; 它还会让设 置一个超时时间，当请求超过超时间时间还未处理，则会被丢弃\n降级规则 降级规则就是设置当满足什么条件的时候，对服务进行降级。Sentinel提供了三个衡量条件:\n平均响应时间 :当资源的平均响应时间超过阈值(以 ms 为单位)之后，资源进入准降级状态。 如果接下来 1s 内持续进入 5 个请求，它们的 RT都持续超过这个阈值，那么在接下的时间窗口 (以 s 为单位)之内，就会对这个方法进行服务降级。 注意 Sentinel 默认统计的 RT 上限是 4900 ms，超出此阈值的都会算作 4900 ms，若需要变更此 上限可以通过启动配置项 -Dcsp.sentinel.statistic.max.rt=xxx 来配置。\n异常比例:当资源的每秒异常总数占通过量的比值超过阈值之后，资源进入降级状态，即在接下的 时间窗口(以 s 为单位)之内，对这个方法的调用都会自动地返回。异常比率的阈值范围是 [0.0,1.0]。 第1步: 首先模拟一个异常\nint i=0; @RequestMapping(\"/order/message2\") public String message2(){ i++; //异常比例为0.333 if(i%3==0){ throw new RuntimeException(); } return\"message2\"; } 第2步: 设置异常比例为0.25\n异常数 :当资源近 1 分钟的异常数目超过阈值之后会进行服务降级。注意由于统计时间窗口是分 钟级别的，若时间窗口小于 60s，则结束熔断状态后仍可能再进入熔断状态。 问题:流控规则和降级规则返回的异常页面是一样的，我们怎么来区分到底是什么原因导致的 呢?\n热点规则 热点参数流控规则是一种更细粒度的流控规则, 它允许将规则具体到参数上。 热点规则简单使用\n第1步: 编写代码\n@RequestMapping(\"/order/message3\") @SentinelResource(\"message3\") //注意这里必须使用这个注解标识,热点规则不生效 public String message3(String name, Integer age) { return name + age; } 第2步: 配置热点规则 第3步: 分别用两个参数访问,会发现只对第一个参数限流了\n热点规则增强使用\n参数例外项允许对一个参数的具体值进行流控\n编辑刚才定义的规则,增加参数例外项\n授权规则 很多时候，我们需要根据调用来源来判断该次请求是否允许放行，这时候可以使用 Sentinel 的来源访问控制的功能。来源访问控制根据资源的请求来源(origin)限制资源是否通过:\n若配置白名单，则只有请求来源位于白名单内时才可通过;\n若配置黑名单，则请求来源位于黑名单时不通过，其余的请求通过。\n上面的资源名和授权类型不难理解，但是流控应用怎么填写呢?\n其实这个位置要填写的是来源标识，Sentinel提供了 RequestOriginParser 接口来处理来源。\n只要Sentinel保护的接口资源被访问，Sentinel就会调用 RequestOriginParser 的实现类去解析访问来源。\n第1步: 自定义来源处理规则\n@Component public class RequestOriginParserDefinition implements RequestOriginParser{ @Override public String parseOrigin(HttpServletRequest request) { String serviceName = request.getParameter(\"serviceName\"); return serviceName; } } 第2步: 授权规则配置\n这个配置的意思是只有serviceName=pc不能访问(黑名单)\n第3步: 访问 http://localhost:8091/order/message1?serviceName=pc观察结果\n系统规则 系统保护规则是从应用级别的入口流量进行控制，从单台机器的总体 Load、RT、入口 QPS 、CPU使用 率和线程数五个维度监控应用数据，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。系统 保护规则是应用整体维度的，而不是资源维度的，并且仅对入口流量 (进入应用的流量) 生效。\nLoad(仅对 Linux/Unix-like 机器生效):当系统 load1 超过阈值，且系统当前的并发线程数超过 系统容量时才会触发系统保护。系统容量由系统的 maxQps * minRt 计算得出。设定参考值一般 是 CPU cores * 2.5。\nRT:当单台机器上所有入口流量的平均 RT 达到阈值即触发系统保护，单位是毫秒。\n线程数:当单台机器上所有入口流量的并发线程数达到阈值即触发系统保护。\n入口 QPS:当单台机器上所有入口流量的 QPS 达到阈值即触发系统保护。\nCPU使用率:当单台机器上所有入口流量的 CPU使用率达到阈值即触发系统保护\n扩展:自定义异常返回\n//异常处理页面 @Component public class ExceptionHandlerPage implements UrlBlockHandler { //用于定义资源，并提供可选的异常处理和 fallback 配置项。其主要参数如下: @SentinelResource /** * BlockException 异常接口,包含Sentinel的五个异常 * FlowException 限流异常 * DegradeException 降级异常 * ParamFlowException 参数限流异常 * AuthorityException 授权异常 * SystemBlockException 系统负载异常 * */ @Override public void blocked(HttpServletRequest request, HttpServletResponse response, BlockException e) throws IOException { response.setContentType(\"application/json;charset=utf-8\"); ResponseData data = null; if (e instanceof FlowException) { data = new ResponseData(-1, \"接口被限流了...\"); } else if (e instanceof DegradeException) { data = new ResponseData(-2, \"接口被降级了...\"); } response.getWriter().write(JSON.toJSONString(data)); } } @Data //全参构造 @AllArgsConstructor //无参构造 @NoArgsConstructor class ResponseData { private int code; private String message; } } @SentinelResource的使用 在定义了资源点之后，我们可以通过Dashboard来设置限流和降级策略来对资源点进行保护。同时还能通过@SentinelResource来指定出现异常时的处理策略。\n@SentinelResource 用于定义资源，并提供可选的异常处理和 fallback 配置项。其主要参数如下:\n属性 作用 value 资源名称 entryType entry类型，标记流量的方向，取值IN/OUT，默认是OUT blockHandler 处理BlockException的函数名称,函数要求:1. 必须是 public2. 返回类型 参数与原方法一致3. 默认需和原方法在同一个类中。若希望使用其他类 的函数，可配置blockHandlerClass ，并指定blockHandlerClass里面的 方法。 blockHandlerClass 存放blockHandler的类,对应的处理函数必须static修饰。 fallback 用于在抛出异常的时候提供fallback处理逻辑。fallback函数可以针对所 有类型的异常(除了exceptionsToIgnore 里面排除掉的异常类型)进行 处理。函数要求:1. 返回类型与原方法一致2. 参数类型需要和原方法相 匹配3. 默认需和原方法在同一个类中。若希望使用其他类的函数，可配 置fallbackClass ，并指定fallbackClass里面的方法。 fallbackClass 存放fallback的类。对应的处理函数必须static修饰 defaultFallback 用于通用的 fallback 逻辑。默认fallback函数可以针对所有类型的异常进 行处理。若同时配置了 fallback 和 defaultFallback，以fallback为准。函 数要求:1. 返回类型与原方法一致2. 方法参数列表为空，或者有一个 Throwable 类型的参数。3. 默认需要和原方法在同一个类中。若希望使 用其他类的函数，可配置fallbackClass ，并指定 fallbackClass 里面的方 法。 exceptionsToIgnore 指定排除掉哪些异常。排除的异常不会计入异常统计，也不会进入 fallback逻辑，而是原样抛出 exceptionsToTrace 需要trace的异常 定义限流和降级后的处理方法\n方式一:直接将限流和降级方法定义在方法中\n@Service @Slf4j public class OrderServiceImpl3 { int i = 0; @SentinelResource(value = \"message\", /*指定发生BlockException时进入的方法*/ blockHandler = \"blockHandler\", /* 指定发生Throwable时进入的方法) */ fallback = \"fallback\" public String message(){ i++; if(i % 3 == 0){ throw new RuntimeException(); } return\"message\"; } //BlockException时进入的方法 public String blockHandler(BlockException ex){ log.error(\"{}\", ex); return\"接口被限流或者降级了...\"; } //Throwable时进入的方法 public String fallback(Throwable throwable) { log.error(\"{}\", throwable); return \"接口发生异常了...\"; } } 方式二: 将限流和降级方法外置到单独的类中\n@Service @Slf4j public class OrderServiceImpl3 { int i = 0; @SentinelResource( value = \"message\", blockHandlerClass = OrderServiceImpl3BlockHandlerClass.class, blockHandler = \"blockHandler\", fallbackClass = OrderServiceImpl3FallbackClass.class, fallback = \"fallback\" ) public String message() { i++; if (i % 3 == 0) { throw new RuntimeException(); } return \"message4\"; } } @Slf4j public class OrderServiceImpl3BlockHandlerClass { //注意这里必须使用static修饰方法 public static String blockHandler(BlockException ex) { 1 编写处理类 log.error(\"{}\", ex); return \"接口被限流或者降级了...\"; } } @Slf4j public class OrderServiceImpl3FallbackClass { //注意这里必须使用static修饰方法 public static String fallback(Throwable throwable) { log.error(\"{}\", throwable); return \"接口发生异常了...\"; } } Sentinel规则持久化 通过前面的讲解，我们已经知道，可以通过Dashboard来为每个Sentinel客户端设置各种各样的规则，\n但是这里有一个问题，就是这些规则默认是存放在内存中，极不稳定，所以需要将其持久化。 本地文件数据源会定时轮询文件的变更，读取规则。这样我们既可以在应用本地直接修改文件来更新规则，也可以通过 Sentinel 控制台推送规则。以本地文件数据源为例，推送过程如下图所示:\n首先 Sentinel 控制台通过 API 将规则推送至客户端并更新到内存中，接着注册的写数据源会将新的规则 保存到本地的文件中。\n编写处理类\npackage cn.maruifu.config; import com.alibaba.csp.sentinel.command.handler.ModifyParamFlowRulesCommandHandler; import com.alibaba.csp.sentinel.datasource.*; import com.alibaba.csp.sentinel.init.InitFunc; import com.alibaba.csp.sentinel.slots.block.authority.AuthorityRule; import com.alibaba.csp.sentinel.slots.block.authority.AuthorityRuleManager; import com.alibaba.csp.sentinel.slots.block.degrade.DegradeRule; import com.alibaba.csp.sentinel.slots.block.degrade.DegradeRuleManager; import com.alibaba.csp.sentinel.slots.block.flow.FlowRule; import com.alibaba.csp.sentinel.slots.block.flow.FlowRuleManager; import com.alibaba.csp.sentinel.slots.block.flow.param.ParamFlowRule; import com.alibaba.csp.sentinel.slots.block.flow.param.ParamFlowRuleManager; import com.alibaba.csp.sentinel.slots.system.SystemRule; import com.alibaba.csp.sentinel.slots.system.SystemRuleManager; import com.alibaba.csp.sentinel.transport.util.WritableDataSourceRegistry; import com.alibaba.fastjson.JSON; import com.alibaba.fastjson.TypeReference; import org.springframework.beans.factory.annotation.Value; import java.io.File; import java.io.IOException; import java.util.List; //规则持久化 public class FilePersistence implements InitFunc { @Value(\"spring.application:name\") private String appcationName; @Override public void init() throws Exception { String ruleDir = System.getProperty(\"user.home\") + \"/sentinel-rules/\" + appcationName; String flowRulePath = ruleDir + \"/flow-rule.json\"; String degradeRulePath = ruleDir + \"/degrade-rule.json\"; String systemRulePath = ruleDir + \"/system-rule.json\"; String authorityRulePath = ruleDir + \"/authority-rule.json\"; String paramFlowRulePath = ruleDir + \"/param-flow-rule.json\"; this.mkdirIfNotExits(ruleDir); this.createFileIfNotExits(flowRulePath); this.createFileIfNotExits(degradeRulePath); this.createFileIfNotExits(systemRulePath); this.createFileIfNotExits(authorityRulePath); this.createFileIfNotExits(paramFlowRulePath); // 流控规则 ReadableDataSource\u003cString, List\u003cFlowRule\u003e\u003e flowRuleRDS = new FileRefreshableDataSource\u003c\u003e (flowRulePath, flowRuleListParser ); FlowRuleManager.register2Property(flowRuleRDS.getProperty()); WritableDataSource\u003cList\u003cFlowRule\u003e\u003e flowRuleWDS = new FileWritableDataSource\u003c\u003e(flowRulePath, this::encodeJson); WritableDataSourceRegistry.registerFlowDataSource(flowRuleWDS); // 降级规则 ReadableDataSource\u003cString, List\u003cDegradeRule\u003e\u003e degradeRuleRDS = new FileRefreshableDataSource\u003c\u003e(degradeRulePath, degradeRuleListParser); DegradeRuleManager.register2Property(degradeRuleRDS.getProperty()); WritableDataSource\u003cList\u003cDegradeRule\u003e\u003e degradeRuleWDS = new FileWritableDataSource\u003c\u003e(degradeRulePath, this::encodeJson); WritableDataSourceRegistry.registerDegradeDataSource(degradeRuleWDS); // 系统规则 ReadableDataSource\u003cString, List\u003cSystemRule\u003e\u003e systemRuleRDS = new FileRefreshableDataSource\u003c\u003e(systemRulePath, systemRuleListParser); SystemRuleManager.register2Property(systemRuleRDS.getProperty()); WritableDataSource\u003cList\u003cSystemRule\u003e\u003e systemRuleWDS = new FileWritableDataSource\u003c\u003e(systemRulePath, this::encodeJson); WritableDataSourceRegistry.registerSystemDataSource(systemRuleWDS); // 授权规则 ReadableDataSource\u003cString, List\u003cAuthorityRule\u003e\u003e authorityRuleRDS = new FileRefreshableDataSource\u003c\u003e(authorityRulePath, authorityRuleListParser); AuthorityRuleManager.register2Property(authorityRuleRDS.getProperty()); WritableDataSource\u003cList\u003cAuthorityRule\u003e\u003e authorityRuleWDS = new FileWritableDataSource\u003c\u003e(authorityRulePath, this::encodeJson); WritableDataSourceRegistry.registerAuthorityDataSource(authorityRuleWDS); // 热点参数规则 ReadableDataSource\u003cString, List\u003cParamFlowRule\u003e\u003e paramFlowRuleRDS = new FileRefreshableDataSource\u003c\u003e( paramFlowRulePath,paramFlowRuleListParser); ParamFlowRuleManager.register2Property(paramFlowRuleRDS.getProperty()); WritableDataSource\u003cList\u003cParamFlowRule\u003e\u003e paramFlowRuleWDS = new FileWritableDataSource\u003c\u003e( paramFlowRulePath, this::encodeJson ); ModifyParamFlowRulesCommandHandler.setWritableDataSource(paramFlowRuleWDS); } private Converter\u003cString, List\u003cFlowRule\u003e\u003e flowRuleListParser = source -\u003e JSON.parseObject( source, new TypeReference\u003cList\u003cFlowRule\u003e\u003e() { }); private Converter\u003cString, List\u003cDegradeRule\u003e\u003e degradeRuleListParser = source -\u003e JSON.parseObject( source, new TypeReference\u003cList\u003cDegradeRule\u003e\u003e() { }); private Converter\u003cString, List\u003cSystemRule\u003e\u003e systemRuleListParser = source -\u003e JSON.parseObject(source, new TypeReference\u003cList\u003cSystemRule\u003e\u003e() {}); private Converter\u003cString, List\u003cAuthorityRule\u003e\u003e authorityRuleListParser = source -\u003e JSON.parseObject(source,new TypeReference\u003cList\u003cAuthorityRule\u003e\u003e() {} ); private Converter\u003cString, List\u003cParamFlowRule\u003e\u003e paramFlowRuleListParser = source -\u003e JSON.parseObject(source,new TypeReference\u003cList\u003cParamFlowRule\u003e\u003e() { } ); private void mkdirIfNotExits(String filePath) throws IOException { File file = new File(filePath); if (!file.exists()) { file.mkdirs(); } } private void createFileIfNotExits(String filePath) throws IOException { File file = new File(filePath); if (!file.exists()) { file.createNewFile(); } } private \u003cT\u003e String encodeJson(T t) { return JSON.toJSONString(t); } } 添加配置 在resources下创建配置目录 META-INF/services ,然后添加文件com.alibaba.csp.sentinel.init.InitFunc\n在文件中添加配置类的全路径\ncn.maruifu.config.FilePersistence Feign整合Sentinel 第1步: 引入sentinel的依赖\n\u003c!--sentinel客户端--\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-sentinel\u003c/artifactId\u003e \u003c/dependency\u003e 第2步: 在配置文件中开启Feign对Sentinel的支持\nfeign: sentinel: enabled: true 第3步: 创建容错类\n//容错类要求必须实现被容错的接口,并为每个方法实现容错方案 package cn.maruifu.service.api; import cn.maruifu.vo.Product; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Component; //容错类要求必须实现被容错的接口,并为每个方法实现容错方案 @Component @Slf4j public class ProductApiServiceFallBack implements ProductApiService { @Override public Product findByPid(Integer pid) { Product product = new Product(); product.setPid(-1); return product; } } 第4步: 为被容器的接口指定容错类\npackage cn.maruifu.service.api; import cn.maruifu.vo.Product; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; //value用于指定调用nacos下哪个微服务 //fallback用于指定容错类 @FeignClient(value = \"service-product\", fallback = ProductApiServiceFallBack.class) //声明调用的提供者的name public interface ProductApiService { //指定调用提供者的哪个方法 //@FeignClient+@GetMapping 就是一个完整的请求路径 http://service- product/product/{pid} @GetMapping(value = \"/product/{pid}\") Product findByPid(@PathVariable(\"pid\") Integer pid); } 第5步: 修改controller\npackage cn.maruifu.controller; import cn.maruifu.service.OrderService; import cn.maruifu.service.api.ProductApiService; import cn.maruifu.vo.Order; import cn.maruifu.vo.Product; import com.alibaba.fastjson.JSON; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cloud.client.ServiceInstance; import org.springframework.cloud.client.discovery.DiscoveryClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import java.util.List; import java.util.Random; @RestController @Slf4j public class OrderController { @Autowired private RestTemplate restTemplate; @Autowired private OrderService orderService; @Autowired private DiscoveryClient discoveryClient; @Autowired private ProductApiService productApiService; //准备买1件商品 @GetMapping(\"/order/prod/{pid}\") public Order order(@PathVariable(\"pid\") Integer pid) { log.info(\"\u003e\u003e客户下单，这时候要调用商品微服务查询商品信息\"); // 方法一 通过IP调用 //通过restTemplate调用商品微服务 //Product product = restTemplate.getForObject(\"http://localhost:8081/product/\" + pid, Product.class); // 方法二 从nacos中获取服务地址 //ServiceInstance serviceInstance = discoveryClient.getInstances(\"service-product\").get(0); //String url = serviceInstance.getHost() + \":\" +serviceInstance.getPort(); //log.info(\"\u003e\u003e从nacos中获取到的微服务地址为:\" + url); //Product product = restTemplate.getForObject(\"http://\" + url + \"/product/\" + pid, Product.class); // 方法三 从nacos中获取服务地址 自定义规则实现随机挑选服务 //List\u003cServiceInstance\u003e instances = discoveryClient.getInstances(\"service-product\"); //int index = new Random().nextInt(instances.size()); //ServiceInstance serviceInstance = instances.get(index); //String url = serviceInstance.getHost() + \":\" + serviceInstance.getPort(); //log.info(\"\u003e\u003e从nacos中获取到的微服务地址为:\" + url); //Product product = restTemplate.getForObject(\"http://\" + url + \"/product/\" + pid, Product.class); // 方法四 基于Ribbon实现负载均衡 //直接使用微服务名字， 从nacos中获取服务地址 //String url = \"service-product\"; //Product product = restTemplate.getForObject( \"http://\" + url + \"/product/\" + pid, Product.class); // 方法五 通过fegin调用商品微服务 // 调用商品微服务,查询商品信息 log.info(\"接收到{}号商品的下单请求,接下来调用商品微服务查询此商品信息\", pid); Product product = productApiService.findByPid(pid); if (product.getPid() == -1) { Order order = new Order(); order.setPname(\"下单失败\"); return order; } log.info(\"查询到{}号商品的信息,内容是:{}\", pid, JSON.toJSONString(product)); //模拟一次网络延时 try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } //下单(创建订单) Order order = new Order(); order.setUid(1); order.setUsername(\"测试用户\"); order.setPid(product.getPid()); order.setPname(product.getPname()); order.setPprice(product.getPprice()); order.setNumber(1); //为了不产生太多垃圾数据,暂时不做订单保存 //orderService.save(order); log.info(\"创建订单成功,订单信息为{}\", JSON.toJSONString(order)); return order; } @RequestMapping(\"/order/message\") public String message() { return \"高并发下的问题测试\"; } } 第6步: 停止所有 shop-product 服务,重启 shop-order 服务,访问请求,观察容错效果\n扩展: 如果想在容错类中拿到具体的错误,可以使用下面的方式\npackage cn.maruifu.service.api; import cn.maruifu.vo.Product; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; //value用于指定调用nacos下哪个微服务 //fallback用于指定容错类 //@FeignClient(value = \"service-product\", fallback = ProductApiServiceFallBack.class) @FeignClient( value = \"service-product\", fallbackFactory = ProductApiServiceFallBackFactory.class) //声明调用的提供者的name public interface ProductApiService { //指定调用提供者的哪个方法 //@FeignClient+@GetMapping 就是一个完整的请求路径 http://service- product/product/{pid} @GetMapping(value = \"/product/{pid}\") Product findByPid(@PathVariable(\"pid\") Integer pid); } package cn.maruifu.service.api; import cn.maruifu.vo.Product; import feign.hystrix.FallbackFactory; import org.springframework.stereotype.Component; @Component public class ProductApiServiceFallBackFactory implements FallbackFactory\u003cProductApiService\u003e { @Override public ProductApiService create(Throwable throwable) { return new ProductApiService() { @Override public Product findByPid(Integer pid) { throwable.printStackTrace(); Product product = new Product(); product.setPid(-1); return product; } }; } } 注意: fallback和fallbackFactory只能使用其中一种方式\n","description":"\n","tags":[],"title":"\nSentinel–服务容错","uri":"/posts/post-305/"},{"categories":["架构设计"],"content":"微服务\n服务治理介绍 先来思考一个问题？\n通过上一章的操作，我们已经可以实现微服务之间的调用。但是我们把服务提供者的网络地址(ip，端 口)等硬编码到了代码中，这种做法存在许多问题:\n一旦服务提供者地址变化，就需要手工修改代码 一旦是多个服务提供者，无法实现负载均衡功能 一旦服务变得越来越多，人工维护调用关系困难\n那么应该怎么解决呢， 这时候就需要通过注册中心动态的实现服务治理。\n什么是服务治理 服务治理是微服务架构中最核心最基本的模块。用于实现各个微服务的自动化注册与发现。\n**服务注册:**在服务治理框架中，都会构建一个注册中心，每个服务单元向注册中心登记自己提供服 务的详细信息。并在注册中心形成一张服务的清单，服务注册中心需要以心跳的方式去监测清单中 的服务是否可用，如果不可用，需要在服务清单中剔除不可用的服务。\n**服务发现:**服务调用方向服务注册中心咨询服务，并获取所有服务的实例清单，实现对具体服务实例的访问。\n通过上面的调用图会发现，除了微服务，还有一个组件是服务注册中心，它是微服务架构非常重要的一 个组件，在微服务架构里主要起到了协调者的一个作用。注册中心一般包含如下几个功能:\n服务发现: 服务注册:保存服务提供者和服务调用者的信息\n服务订阅:服务调用者订阅服务提供者的信息，注册中心向订阅者推送提供者的信息\n服务配置:\n配置订阅:服务提供者和服务调用者订阅微服务相关的配置 配置下发:主动将配置推送给服务提供者和服务调用者 服务健康检测 检测服务提供者的健康情况，如果发现异常，执行服务剔除\n常见的注册中心 Zookeeper zookeeper是一个分布式服务框架，是Apache Hadoop 的一个子项目，它主要是用来解决分布式 应用中经常遇到的一些数据管理问题，如:统一命名服务、状态同步服务、集群管理、分布式应用 配置项的管理等。\nEureka Eureka是Springcloud Netflix中的重要组件，主要作用就是做服务注册和发现。但是现在已经闭 源\nConsul Consul是基于GO语言开发的开源工具，主要面向分布式，服务化的系统提供服务注册、服务发现 和配置管理的功能。Consul的功能都很实用，其中包括:服务注册/发现、健康检查、Key/Value 存储、多数据中心和分布式一致性保证等特性。Consul本身只是一个二进制的可执行文件，所以 安装和部署都非常简单，只需要从官网下载后，在执行对应的启动脚本即可。\nNacos Nacos是一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。他是SpringCloud Alibaba 组件之一，负责服务注册发现和服务配置，可以这样认为 nacos=eureka+config。\nnacos简介 Nacos 致力于帮助您发现、配置和管理微服务。Nacos 提供了一组简单易用的特性集，帮助您快速实现\n动态服务发现、服务配置、服务元数据及流量管理。 从上面的介绍就可以看出，nacos的作用就是一个注册中心，用来管理注册上来的各个微服务。\nnacos实战入门 接下来，我们就在现有的环境中加入nacos，并将我们的两个微服务注册上去。\n搭建nacos环境 安装nacos 从 Github 上下载源码方式\n1 2 3 4 5 6 7 git clone https://github.com/alibaba/nacos.git cd nacos/ mvn -Prelease-nacos -Dmaven.test.skip=true clean install -U ls -al distribution/target/ // change the $version to your actual path cd distribution/target/nacos-server-$version/nacos/bin 下载编译后压缩包方式\n您可以从 最新稳定版本 下载 nacos-server-$version.zip 包。\n1 2 unzip nacos-server-$version.zip 或者 tar -xvf nacos-server-$version.tar.gz cd nacos/bin 启动nacos Linux/Unix/Mac启动命令(standalone代表着单机模式运行，非集群模式):\nsh startup.sh -m standalone 如果您使用的是ubuntu系统，或者运行脚本报错提示[[符号找不到，可尝试如下运行：\nbash startup.sh -m standalone Windows启动命令(standalone代表着单机模式运行，非集群模式):\ncmd startup.cmd -m standalone 启动失败看一下自己是不是64位 1.8+JDK\n访问nacos 打开浏览器输入http://localhost:8848/nacos，即可访问服务， 默认密码是nacos/nacos\n将商品微服务注册到nacos 接下来开始修改 shop-product 模块的代码， 将其注册到nacos服务上\n在pom.xml中添加nacos的依赖\n\u003c!--nacos客户端--\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-nacos-discovery\u003c/artifactId\u003e \u003c/dependency\u003e 在主类上添加**@EnableDiscoveryClient**注解\n@SpringBootApplication @EnableDiscoveryClient public class ProductApplication 在application.yml中添加nacos服务的地址\nspring: cloud: nacos: discovery: server-addr: 127.0.0.1:8848 启动服务， 观察nacos的控制面板中是否有注册上来的商品微服务\n将订单微服务注册到nacos 接下来开始修改 shop_order 模块的代码， 将其注册到nacos服务上\n在pom.xml中添加nacos的依赖\n\u003c!--nacos客户端--\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-alibaba-nacos-discovery\u003c/artifactId\u003e \u003c/dependency\u003e 在主类上添加**@EnableDiscoveryClient**注解\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient public class OrderApplication 在application.yml中添加nacos服务的地址\nspring: cloud: nacos: discovery: server-addr: 127.0.0.1:8848 修改OrderController， 实现微服务调用\npackage cn.maruifu.controller; import cn.maruifu.service.OrderService; import cn.maruifu.vo.Order; import cn.maruifu.vo.Product; import com.alibaba.fastjson.JSON; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cloud.client.ServiceInstance; import org.springframework.cloud.client.discovery.DiscoveryClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; @RestController @Slf4j public class OrderController { @Autowired private RestTemplate restTemplate; @Autowired private OrderService orderService; @Autowired private DiscoveryClient discoveryClient; //准备买1件商品 @GetMapping(\"/order/prod/{pid}\") public Order order(@PathVariable(\"pid\") Integer pid) { log.info(\"\u003e\u003e客户下单，这时候要调用商品微服务查询商品信息\"); // 之前调用 //通过restTemplate调用商品微服务 //Product product = restTemplate.getForObject(\"http://localhost:8081/product/\" + pid, Product.class); //从nacos中获取服务地址 ServiceInstance serviceInstance = discoveryClient.getInstances(\"service-product\").get(0); String url = serviceInstance.getHost() + \":\" +serviceInstance.getPort(); log.info(\"\u003e\u003e从nacos中获取到的微服务地址为:\" + url); Product product = restTemplate.getForObject(\"http://\" + url + \"/product/\" + pid, Product.class); log.info(\"\u003e\u003e商品信息,查询结果:\"+\tJSON.toJSONString(product)); Order order = new Order(); order.setUid(1); order.setUsername(\"测试用户\"); order.setPid(product.getPid()); order.setPname(product.getPname()); order.setPprice(product.getPprice()); order.setNumber(1); orderService.save(order); return order; } } DiscoveryClient是专门负责服务注册和发现的，我们可以通过它获取到注册到注册中心的所有服务\n启动服务， 观察nacos的控制面板中是否有注册上来的订单微服务，然后通过访问消费者服务验证调 用是否成功\n实现服务调用的负载均衡 什么是负载均衡 通俗的讲， 负载均衡就是将负载(工作任务，访问请求)进行分摊到多个操作单元(服务器,组件)上 进行执行。\n根据负载均衡发生位置的不同,一般分为服务端负载均衡和客户端负载均衡。 服务端负载均衡指的是发生在服务提供者一方,比如常见的nginx负载均衡\n而客户端负载均衡指的是发生在服务请求的一方，也就是在发送请求之前已经选好了由哪个实例处理请求。\n我们在微服务调用关系中一般会选择客户端负载均衡，也就是在服务调用的一方来决定服务由哪个提供 者执行。\n自定义实现负载均衡 1通过idea再启动一个 shop-product 微服务，点击Copy Configurations 设置其端口为8082\n2通过nacos查看微服务的启动情况\n3修改 shop-order 的代码，实现负载均衡\npackage cn.maruifu.controller; import cn.maruifu.service.OrderService; import cn.maruifu.vo.Order; import cn.maruifu.vo.Product; import com.alibaba.fastjson.JSON; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cloud.client.ServiceInstance; import org.springframework.cloud.client.discovery.DiscoveryClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import java.util.List; import java.util.Random; @RestController @Slf4j public class OrderController { @Autowired private RestTemplate restTemplate; @Autowired private OrderService orderService; @Autowired private DiscoveryClient discoveryClient; //准备买1件商品 @GetMapping(\"/order/prod/{pid}\") public Order order(@PathVariable(\"pid\") Integer pid) { log.info(\"\u003e\u003e客户下单，这时候要调用商品微服务查询商品信息\"); // 之前调用 //通过restTemplate调用商品微服务 //Product product = restTemplate.getForObject(\"http://localhost:8081/product/\" + pid, Product.class); //从nacos中获取服务地址 //ServiceInstance serviceInstance = discoveryClient.getInstances(\"service-product\").get(0); //String url = serviceInstance.getHost() + \":\" +serviceInstance.getPort(); //log.info(\"\u003e\u003e从nacos中获取到的微服务地址为:\" + url); //Product product = restTemplate.getForObject(\"http://\" + url + \"/product/\" + pid, Product.class); //从nacos中获取服务地址 自定义规则实现随机挑选服务 List\u003cServiceInstance\u003e instances = discoveryClient.getInstances(\"service-product\"); int index = new Random().nextInt(instances.size()); ServiceInstance serviceInstance = instances.get(index); String url = serviceInstance.getHost() + \":\" + serviceInstance.getPort(); log.info(\"\u003e\u003e从nacos中获取到的微服务地址为:\" + url); Product product = restTemplate.getForObject(\"http://\" + url + \"/product/\" + pid, Product.class); log.info(\"\u003e\u003e商品信息,查询结果:\"+\tJSON.toJSONString(product)); Order order = new Order(); order.setUid(1); order.setUsername(\"测试用户\"); order.setPid(product.getPid()); order.setPname(product.getPname()); order.setPprice(product.getPprice()); order.setNumber(1); orderService.save(order); return order; } } 4启动两个服务提供者和一个服务消费者，多访问几次消费者测试效果\n基于Ribbon实现负载均衡 Ribbon 是 Spring Cloud 的一个组件， 它可以让我们使用一个注解就能轻松的搞定负载均衡\n第1步:在RestTemplate 的生成方法上添加@LoadBalanced注解\n@Bean @LoadBalanced public RestTemplate restTemplate() { return new RestTemplate(); } 第2步:修改服务调用的方法\npackage cn.maruifu.controller; import cn.maruifu.service.OrderService; import cn.maruifu.vo.Order; import cn.maruifu.vo.Product; import com.alibaba.fastjson.JSON; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cloud.client.ServiceInstance; import org.springframework.cloud.client.discovery.DiscoveryClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import java.util.List; import java.util.Random; @RestController @Slf4j public class OrderController { @Autowired private RestTemplate restTemplate; @Autowired private OrderService orderService; @Autowired private DiscoveryClient discoveryClient; //准备买1件商品 @GetMapping(\"/order/prod/{pid}\") public Order order(@PathVariable(\"pid\") Integer pid) { log.info(\"\u003e\u003e客户下单，这时候要调用商品微服务查询商品信息\"); // 之前调用 //通过restTemplate调用商品微服务 //Product product = restTemplate.getForObject(\"http://localhost:8081/product/\" + pid, Product.class); //从nacos中获取服务地址 //ServiceInstance serviceInstance = discoveryClient.getInstances(\"service-product\").get(0); //String url = serviceInstance.getHost() + \":\" +serviceInstance.getPort(); //log.info(\"\u003e\u003e从nacos中获取到的微服务地址为:\" + url); //Product product = restTemplate.getForObject(\"http://\" + url + \"/product/\" + pid, Product.class); //从nacos中获取服务地址 自定义规则实现随机挑选服务 //List\u003cServiceInstance\u003e instances = discoveryClient.getInstances(\"service-product\"); //int index = new Random().nextInt(instances.size()); //ServiceInstance serviceInstance = instances.get(index); //String url = serviceInstance.getHost() + \":\" + serviceInstance.getPort(); //log.info(\"\u003e\u003e从nacos中获取到的微服务地址为:\" + url); //Product product = restTemplate.getForObject(\"http://\" + url + \"/product/\" + pid, Product.class); // 基于Ribbon实现负载均衡 //直接使用微服务名字， 从nacos中获取服务地址 String url = \"service-product\"; Product product = restTemplate.getForObject( \"http://\" + url + \"/product/\" + pid, Product.class); log.info(\"\u003e\u003e商品信息,查询结果:\"+\tJSON.toJSONString(product)); Order order = new Order(); order.setUid(1); order.setUsername(\"测试用户\"); order.setPid(product.getPid()); order.setPname(product.getPname()); order.setPprice(product.getPprice()); order.setNumber(1); orderService.save(order); return order; } } Ribbon支持的负载均衡策略\nRibbon内置了多种负载均衡策略,内部负载均衡的顶级接口为com.netflix.loadbalancer.IRule ,\n具体的负载策略如下图所示:\n我们可以通过修改配置来调整Ribbon的负载均衡策略，具体代码如下\nservice-product: # 调用的提供者的名称 ribbon: NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule 基于Feign实现服务调用 什么是Feign Feign是Spring Cloud提供的一个声明式的伪Http客户端， 它使得调用远程服务就像调用本地服务一样 简单， 只需要创建一个接口并添加一个注解即可。\nNacos很好的兼容了Feign， Feign默认集成了 Ribbon， 所以在Nacos下使用Fegin默认就实现了负载均 衡的效果。\nFeign的使用 加入Fegin的依赖 \u003c!--fegin组件--\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-openfeign\u003c/artifactId\u003e \u003c/dependency\u003e 在主类上添加Fegin的注解 @SpringBootApplication @EnableDiscoveryClient @EnableFeignClients //开启Fegin public class OrderApplication {} 创建一个service package cn.maruifu.api; import cn.maruifu.vo.Product; import org.springframework.cloud.openfeign.FeignClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; @FeignClient(\"service-product\") //声明调用的提供者的name public interface ProductApiService { //指定调用提供者的哪个方法 //@FeignClient+@GetMapping 就是一个完整的请求路径 http://service- product/product/{pid} @GetMapping(value = \"/product/{pid}\") Product findByPid(@PathVariable(\"pid\") Integer pid); } 修改controller代码 package cn.maruifu.controller; import cn.maruifu.api.ProductApiService; import cn.maruifu.service.OrderService; import cn.maruifu.vo.Order; import cn.maruifu.vo.Product; import com.alibaba.fastjson.JSON; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.cloud.client.ServiceInstance; import org.springframework.cloud.client.discovery.DiscoveryClient; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import java.util.List; import java.util.Random; @RestController @Slf4j public class OrderController { @Autowired private RestTemplate restTemplate; @Autowired private OrderService orderService; @Autowired private DiscoveryClient discoveryClient; @Autowired private ProductApiService productApiService; //准备买1件商品 @GetMapping(\"/order/prod/{pid}\") public Order order(@PathVariable(\"pid\") Integer pid) { log.info(\"\u003e\u003e客户下单，这时候要调用商品微服务查询商品信息\"); // 之前调用 //通过restTemplate调用商品微服务 //Product product = restTemplate.getForObject(\"http://localhost:8081/product/\" + pid, Product.class); //从nacos中获取服务地址 //ServiceInstance serviceInstance = discoveryClient.getInstances(\"service-product\").get(0); //String url = serviceInstance.getHost() + \":\" +serviceInstance.getPort(); //log.info(\"\u003e\u003e从nacos中获取到的微服务地址为:\" + url); //Product product = restTemplate.getForObject(\"http://\" + url + \"/product/\" + pid, Product.class); //从nacos中获取服务地址 自定义规则实现随机挑选服务 //List\u003cServiceInstance\u003e instances = discoveryClient.getInstances(\"service-product\"); //int index = new Random().nextInt(instances.size()); //ServiceInstance serviceInstance = instances.get(index); //String url = serviceInstance.getHost() + \":\" + serviceInstance.getPort(); //log.info(\"\u003e\u003e从nacos中获取到的微服务地址为:\" + url); //Product product = restTemplate.getForObject(\"http://\" + url + \"/product/\" + pid, Product.class); // 基于Ribbon实现负载均衡 //直接使用微服务名字， 从nacos中获取服务地址 // String url = \"service-product\"; // Product product = restTemplate.getForObject( \"http://\" + url + \"/product/\" + pid, Product.class); //通过fegin调用商品微服务 Product product = productApiService.findByPid(pid); log.info(\"\u003e\u003e商品信息,查询结果:\"+\tJSON.toJSONString(product)); Order order = new Order(); order.setUid(1); order.setUsername(\"测试用户\"); order.setPid(product.getPid()); order.setPname(product.getPname()); order.setPprice(product.getPprice()); order.setNumber(1); orderService.save(order); return order; } } 重启order微服务,查看效果 ","description":"\n","tags":[],"title":"\nNacos Discovery–服务治理","uri":"/posts/post-306/"},{"categories":["架构设计"],"content":"微服务\n我们本次是使用的电商项目中的商品、订单、用户为案例进行讲解.\n案例准备 技术选型 maven: 3.3.9\n数据库: MySQL 5.7\n持久层: SpingData Jpa\n其他: SpringCloud Alibaba 技术栈\n模块设计 springcloud-alibaba 父工程\nshop-common 公共模块【实体类】\nshop-user 用户微服务 【端口: 8071】\nshop-product 商品微服务 【端口: 8081】\nshop-order 订单微服务 【端口: 8091】\n微服务调用 在微服务架构中，最常见的场景就是微服务之间的相互调用。我们以电商系统中常见的用户下单为例来 演示微服务的调用:客户向订单微服务发起一个下单的请求，在进行保存订单之前需要调用商品微服务 查询商品的信息。\n我们一般把服务的主动调用方称为服务消费者，把服务的被调用方称为服务提供者。\n在这种场景下，订单微服务就是一个服务消费者， 商品微服务就是一个服务提供者。\n创建数据库 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 DROP DATABASE IF EXISTS `shop`; CREATE DATABASE `shop` DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci; SET NAMES utf8mb4; SET FOREIGN_KEY_CHECKS = 0; USE `shop`; CREATE TABLE `shop_order` ( `oid` int NOT NULL AUTO_INCREMENT COMMENT '主键', `username` varchar(255) DEFAULT NULL COMMENT '用户名', `uid` int DEFAULT NULL COMMENT '用户id', `pid` int DEFAULT NULL COMMENT '商品ID', `pname` varchar(255) DEFAULT NULL COMMENT '商品名称', `pprice` decimal(10,2) DEFAULT NULL COMMENT '商品价格', `number` int DEFAULT NULL COMMENT '数量', PRIMARY KEY (`oid`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci; CREATE TABLE `shop_product` ( `pid` int NOT NULL AUTO_INCREMENT COMMENT '主键', `pname` varchar(255) DEFAULT NULL COMMENT '商品名称', `pprice` decimal(10,2) DEFAULT NULL COMMENT '商品价格', `stock` int DEFAULT NULL COMMENT '库存', PRIMARY KEY (`pid`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci; CREATE TABLE `shop_user` ( `uid` int NOT NULL AUTO_INCREMENT COMMENT '主键', `username` varchar(255) DEFAULT NULL COMMENT '用户名', `password` varchar(255) DEFAULT NULL COMMENT '密码', `telephone` varchar(255) DEFAULT NULL COMMENT '手机号', PRIMARY KEY (`uid`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci; 创建父工程 创建一个maven工程，然后在pom.xml文件中添加下面内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-parent\u003c/artifactId\u003e \u003cversion\u003e2.1.3.RELEASE\u003c/version\u003e \u003c/parent\u003e \u003cgroupId\u003ecn.maruifu\u003c/groupId\u003e \u003cartifactId\u003espringcloud-alibaba\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003cpackaging\u003epom\u003c/packaging\u003e \u003cproperties\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003cproject.build.sourceEncoding\u003eUTF-8\u003c/project.build.sourceEncoding\u003e \u003cproject.reporting.outputEncoding\u003eUTF- 8\u003c/project.reporting.outputEncoding\u003e \u003cspring-cloud.version\u003eGreenwich.RELEASE\u003c/spring-cloud.version\u003e \u003cspring-cloud-alibaba.version\u003e2.1.0.RELEASE\u003c/spring-cloud-alibaba.version\u003e \u003c/properties\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003e${spring-cloud.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-alibaba-dependencies\u003c/artifactId\u003e \u003cversion\u003e${spring-cloud-alibaba.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e \u003c/project\u003e 版本对应：\n创建基础模块 创建 shop-common 模块:\n在pom.xml中添加依赖\n\u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cparent\u003e \u003cartifactId\u003espringcloud-alibaba\u003c/artifactId\u003e \u003cgroupId\u003ecn.maruifu\u003c/groupId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/parent\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cartifactId\u003eshop-common\u003c/artifactId\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-data-jpa\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.alibaba\u003c/groupId\u003e \u003cartifactId\u003efastjson\u003c/artifactId\u003e \u003cversion\u003e1.2.56\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003emysql\u003c/groupId\u003e \u003cartifactId\u003emysql-connector-java\u003c/artifactId\u003e \u003cversion\u003e5.1.6\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e 创建实体类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 //用户 import lombok.Data; import javax.persistence.Id; import javax.persistence.Entity; import javax.persistence.GeneratedValue; import javax.persistence.GenerationType; @Entity(name = \"shop_user\") @Data public class User { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer uid;//主键 private String username;//用户名 private String password;//密码 private String telephone;//手机号 } //商品 import lombok.Data; import javax.persistence.Id; import javax.persistence.Entity; import javax.persistence.GeneratedValue; import javax.persistence.GenerationType; @Entity(name = \"shop_product\") @Data public class Product { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer pid;//主键 private String pname;//商品名称 private Double pprice;//商品价格 private Integer stock;//库存 } //订单 package cn.maruifu.vo; import lombok.Data; import javax.persistence.Id; import javax.persistence.Entity; import javax.persistence.GeneratedValue; import javax.persistence.GenerationType; //订单 @Entity(name = \"shop_order\") @Data public class Order { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long oid;//订单id private Integer uid;//用户id private String username;//用户名 private Integer pid;//商品ID private String pname;//商品名称 private Double pprice;//商品价格 private Integer number;//数量 } 创建用户微服务 新建一个 shop-user 模块，然后进行下面操作\n创建pom.xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cparent\u003e \u003cartifactId\u003espringcloud-alibaba\u003c/artifactId\u003e \u003cgroupId\u003ecn.maruifu\u003c/groupId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/parent\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cartifactId\u003eshop-user\u003c/artifactId\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003ecn.maruifu\u003c/groupId\u003e \u003cartifactId\u003eshop-common\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e 编写主类 package cn.maruifu; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class UserApplication { public static void main(String[] args) { SpringApplication.run(UserApplication.class, args); } } 创建配置文件 server: port: 8071 spring: application: name: service-user datasource: url: jdbc:mysql://127.0.0.1:3306/spring-cloud?serverTimezone=UTC\u0026useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=true username: root password: Mrf12345 driver-class-name: com.mysql.cj.jdbc.Driver jpa: database-platform: org.hibernate.dialect.MySQL5InnoDBDialect show-sql: true hibernate: ddl-auto: update use-new-id-generator-mappings: false 创建商品微服务 创建pom.xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cparent\u003e \u003cartifactId\u003espringcloud-alibaba\u003c/artifactId\u003e \u003cgroupId\u003ecn.maruifu\u003c/groupId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/parent\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cartifactId\u003eshop-product\u003c/artifactId\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecn.maruifu\u003c/groupId\u003e \u003cartifactId\u003eshop-common\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e 编写主类 @SpringBootApplication public class ProductApplication { public static void main(String[] args) { SpringApplication.run(ProductApplication.class, args); } } 创建配置文件 server: port: 8081 spring: application: name: service-product datasource: url: jdbc:mysql://shop?serverTimezone=UTC\u0026useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=true username: root password: root driver-class-name: com.mysql.cj.jdbc.Driver jpa: database-platform: org.hibernate.dialect.MySQL5InnoDBDialect show-sql: true hibernate: ddl-auto: update use-new-id-generator-mappings: false 创建ProductDao接口 1 2 3 4 5 6 7 package cn.maruifu.dao; import cn.maruifu.vo.Product; import org.springframework.data.jpa.repository.JpaRepository; public interface ProductDao extends JpaRepository\u003cProduct,Integer\u003e { } 创建ProductService类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package cn.maruifu.service.impl; import cn.maruifu.dao.ProductDao; import cn.maruifu.service.ProductService; import cn.maruifu.vo.Product; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; @Service public class ProductServiceImpl implements ProductService { @Autowired private ProductDao productDao; @Override public Product findByPid(Integer pid) { return productDao.findById(pid).get(); } } 创建Controller 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package cn.maruifu.controller; import cn.maruifu.service.ProductService; import cn.maruifu.vo.Product; import com.alibaba.fastjson.JSON; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; @RestController @Slf4j public class ProductController { @Autowired private ProductService productService; @GetMapping(\"/product/{pid}\") public Product product(@PathVariable(\"pid\") Integer pid) { Product product = productService.findByPid(pid); log.info(\"查询到商品:\" + JSON.toJSONString(product)); return product; } } 启动工程 等到数据库表创建完毕之后，加入测试数据\n1 2 3 4 5 6 7 INSERT INTO shop_product VALUE(NULL,'小米','1000','5000'); INSERT INTO shop_product VALUE(NULL,'华为','2000','5000'); INSERT INTO shop_product VALUE(NULL,'苹果','3000','5000'); INSERT INTO shop_product VALUE(NULL,'OPPO','4000','5000'); 通过浏览器访问服务 创建订单微服务 创建pom.xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cparent\u003e \u003cartifactId\u003espringcloud-alibaba\u003c/artifactId\u003e \u003cgroupId\u003ecn.maruifu\u003c/groupId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/parent\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cartifactId\u003eshop-order\u003c/artifactId\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ecn.maruifu\u003c/groupId\u003e \u003cartifactId\u003eshop-common\u003c/artifactId\u003e \u003cversion\u003e1.0-SNAPSHOT\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/project\u003e 编写主类 package cn.maruifu; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); } } 创建配置文件 server: port: 8091 spring: application: name: service-order datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://shop?serverTimezone=UTC\u0026useUnicode=true\u0026characterEncoding=utf-8\u0026useSSL=true username: root password: root jpa: database-platform: org.hibernate.dialect.MySQL5InnoDBDialect show-sql: true hibernate: ddl-auto: update use-new-id-generator-mappings: false 创建OrderDao接口 1 2 3 4 5 6 7 8 package cn.maruifu.dao; import cn.maruifu.vo.Order; import org.springframework.data.jpa.repository.JpaRepository; public interface OrderDao extends JpaRepository\u003cOrder,Long\u003e { } 创建OrderService类 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package cn.maruifu.service.impl; import cn.maruifu.dao.OrderDao; import cn.maruifu.service.OrderService; import cn.maruifu.vo.Order; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; @Service public class OrderServiceImpl implements OrderService { @Autowired private OrderDao orderDao; @Override public void save(Order order) { orderDao.save(order); } } 创建RestTemplate 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package cn.maruifu; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.annotation.Bean; import org.springframework.web.client.RestTemplate; @SpringBootApplication public class OrderApplication { public static void main(String[] args) { SpringApplication.run(OrderApplication.class, args); } @Bean public RestTemplate getRestTemplate() { return new RestTemplate(); } } 创建Controller 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 package cn.maruifu.controller; import cn.maruifu.service.OrderService; import cn.maruifu.vo.Order; import cn.maruifu.vo.Product; import com.alibaba.fastjson.JSON; import lombok.extern.slf4j.Slf4j; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; @RestController @Slf4j public class OrderController { @Autowired private RestTemplate restTemplate; @Autowired private OrderService orderService; //准备买1件商品 @GetMapping(\"/order/prod/{pid}\") public Order order(@PathVariable(\"pid\") Integer pid) { log.info(\"\u003e\u003e客户下单，这时候要调用商品微服务查询商品信息\"); //通过restTemplate调用商品微服务 Product product = restTemplate.getForObject(\"http://localhost:8081/product/\" + pid, Product.class); log.info(\"\u003e\u003e商品信息,查询结果:\" + JSON.toJSONString(product)); Order order = new Order(); order.setUid(1); order.setUsername(\"测试用户\"); order.setPid(product.getPid()); order.setPname(product.getPname()); order.setPprice(product.getPprice()); order.setNumber(1); orderService.save(order); return order; } } 浏览器访问服务进行测试 源码地址\n","description":"\n","tags":[],"title":"\n微服务环境搭建","uri":"/posts/post-307/"},{"categories":["架构设计"],"content":"微服务\n系统架构演变 随着互联网的发展，网站应用的规模也在不断的扩大，进而导致系统架构也在不断的进行变化。从互联网早期到现在，系统架构大体经历了下面几个过程: 单体应用架构—\u003e垂直应用架构—\u003e分布式架构— \u003eSOA架构—\u003e微服务架构，当然还有悄然兴起的Service Mesh(服务网格化)。接下来我们就来了解一下 每种系统架构是什么样子的， 以及各有什么优缺点。\n单体应用架构 互联网早期，一般的网站应用流量较小，只需一个应用，将所有功能代码都部署在一起就可以，这样可以减少开发、部署和维护的成本。\n比如说一个电商系统，里面会包含很多用户管理，商品管理，订单管理，物流管理等等很多模块，我们会把它们做成一个web项目，然后部署到一台tomcat服务器上。\n优点\n项目架构简单，小型项目的话， 开发成本低\n项目部署在一个节点上， 维护方便\n缺点\n全部功能集成在一个工程中，对于大型项目来讲不易开发和维护\n项目模块之间紧密耦合，单点容错率低\n无法针对不同模块进行针对性优化和水平扩展\n垂直应用架构 随着访问量的逐渐增大，单一应用只能依靠增加节点来应对，但是这时候会发现并不是所有的模块都会有比较大的访问量。\n还是以上面的电商为例子， 用户访问量的增加可能影响的只是用户和订单模块， 但是对消息模块 的影响就比较小. 那么此时我们希望只多增加几个订单模块， 而不增加消息模块. 此时单体应用就做不 到了， 垂直应用就应运而生了。\n所谓的垂直应用架构，就是将原来的一个应用拆成互不相干的几个应用，以提升效率。比如我们可 以将上面电商的单体应用拆分成:\n电商系统(用户管理 商品管理 订单管理)\n后台系统(用户管理 订单管理 客户管理)\nCMS系统(广告管理 营销管理)\n这样拆分完毕之后，一旦用户访问量变大，只需要增加电商系统的节点就可以了，而无需增加后台 和CMS的节点。\n分布式架构 当垂直应用越来越多，重复的业务代码就会越来越多。这时候，我们就思考可不可以将重复的代码抽取 出来，做成统一的业务层作为独立的服务，然后由前端控制层调用不同的业务层服务呢?这就产生了新 的分布式系统架构。它将把工程拆分成表现层和服务层两个部分，服务层中包含业务逻辑。表现层只需 要处理和页面的交互，业务逻辑都是调用服务层的服务来实现。\n优点\n抽取公共的功能为服务层，提高代码复用性 缺点\n系统间耦合度变高，调用关系错综复杂，难以维护 SOA架构 在分布式架构下，当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个 调度中心对集群进行实时管理。此时，用于资源调度和治理中心(SOA Service OrientedArchitecture， 面向服务的架构)是关键。\n优点\n使用注册中心解决了服务间调用关系的自动调节 缺点\n服务间会有依赖关系，一旦某个环节出错会影响较大( 服务雪崩 )\n服务关心复杂，运维、测试部署困难\n微服务架构 微服务架构在某种程度上是面向服务的架构SOA继续发展的下一步，它更加强调服务的\"彻底拆分\"。\n优点\n服务原子化拆分，独立打包、部署和升级，保证每个微服务清晰的任务划分，利于扩展\n微服务之间采用Restful等轻量级http协议相互调用\n缺点:\n分布式系统开发的技术成本高(容错、分布式事务等) 微服务架构介绍 微服务架构， 简单的说就是将单体应用进一步拆分，拆分成更小的服务，每个服务都是一个可以独立运行的项目。\n微服务架构的常见问题 一旦采用微服务系统架构，就势必会遇到这样几个问题:\n这么多小服务，如何管理他们?(服务治理 注册中心[服务注册 发现 剔除])\n这么多小服务，他们之间如何通讯?(restful rpc )\n这么多小服务，客户端怎么访问他们?(网关)\n这么多小服务，一旦出现问题了，应该如何自处理?(容错)\n这么多小服务，一旦出现问题了，应该如何排错? (链路追踪)\n对于上面的问题，是任何一个微服务设计者都不能绕过去的，因此大部分的微服务产品都针对每一个问 题提供了相应的组件来解决它们。\n微服务架构的常见概念 服务治理 服务治理就是进行服务的自动化管理，其核心是服务的自动注册与发现。\n服务注册:服务实例将自身服务信息注册到注册中心。\n服务发现:服务实例通过注册中心，获取到注册到其中的服务实例的信息，通过这些信息去请求它们提 供的服务。\n服务剔除:服务注册中心将出问题的服务自动剔除到可用列表之外，使其不会被调用到。\n服务调用 在微服务架构中，通常存在多个服务之间的远程调用的需求。目前主流的远程调用技术有基于HTTP的RESTful接口以及基于TCP的RPC协议。\nREST(Representational State Transfer):这是一种HTTP调用的格式，更标准，更通用，无论哪 种语言都支持http协议\nRPC(Remote Promote Call):一种进程间通信方式。允许像调用本地服务一样调用远程服务。 RPC框架的主要目标就是让远程服务调用更简单、透明。RPC框架负责屏蔽底层的传输方式、序列 化方式和通信细节。开发人员在使用的时候只需要了解谁在什么位置提供了什么样的远程服务接口 即可，并不需要关心底层通信细节和调用过程。\n区别与联系\n比较项 RESTful RPC 通讯协议 HTTP 一般使用TCP 性能 略低 较高 灵活度 高 较高 应用 微服务架构 SOA架构 服务网关 随着微服务的不断增多，不同的微服务一般会有不同的网络地址，而外部客户端可能需要调用多个服务的接口才能完成一个业务需求，如果让客户端直接与各个微服务通信可能出现:\n客户端需要调用不同的url地址，增加难度\n在一定的场景下，存在跨域请求的问题\n每个微服务都需要进行单独的身份认证\n针对这些问题，API网关顺势而生。\nAPI网关直面意思是将所有API调用统一接入到API网关层，由网关层统一接入和输出。一个网关的基本 功能有:统一接入、安全防护、协议适配、流量管控、长短链接支持、容错能力。有了网关之后，各个 API服务提供团队可以专注于自己的的业务逻辑处理，而API网关更专注于安全、流量、路由等问题。\n服务容错 在微服务当中，一个请求经常会涉及到调用几个服务，如果其中某个服务不可用，没有做服务容错的 话，极有可能会造成一连串的服务不可用，这就是雪崩效应。我们没法预防雪崩效应的发生，只能尽可 能去做好容错。服务容错的三个核心思想是:\n不被外界环境影响 不被上游请求压垮 不被下游响应拖垮 链路追踪 随着微服务架构的流行，服务按照不同的维度进行拆分，一次请求往往需要涉及到多个服务。互联网应 用构建在不同的软件模块集上，这些软件模块，有可能是由不同的团队开发、可能使用不同的编程语言 来实现、有可能布在了几千台服务器，横跨多个不同的数据中心。因此，就需要对一次请求涉及的多个 服务链路进行日志记录，性能监控即链路追踪\n微服务架构的常见解决方案 ServiceComb Apache ServiceComb，前身是华为云的微服务引擎 CSE (Cloud Service Engine) 云服务，是全球首个 Apache微服务顶级项目。它提供了一站式的微服务开源解决方案，致力于帮助企业、用户和开发者将 企业应用轻松微服务化上云，并实现对微服务应用的高效运维管理。\nSpringCloud Spring Cloud是一系列框架的集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设 施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。\nSpring Cloud并没有重复制造轮子，它只是将目前各家公司开发的比较成熟、经得起实际考验的服务框 架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了 一套简单易懂、易部署和易维护的分布式系统开发工具包。\nSpringCloud Alibaba Spring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的 必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。\nSpringCloud Alibaba介绍 Spring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的 必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里微服 务解决方案，通过阿里中间件来迅速搭建分布式应用系统。\n主要功能 服务限流降级:默认支持 WebServlet、WebFlux， OpenFeign、RestTemplate、Spring CloudGateway， Zuul， Dubbo 和 RocketMQ 限流降级功能的接入，可以在运行时通过控制台 实时修改限流降级规则，还支持查看限流降级 Metrics 监控。\n服务注册与发现:适配 Spring Cloud 服务注册与发现标准，默认集成了 Ribbon 的支持。\n分布式配置管理:支持分布式系统中的外部化配置，配置更改时自动刷新。\n消息驱动能力:基于 Spring Cloud Stream 为微服务应用构建消息驱动能力。\n分布式事务:使用 @GlobalTransactional 注解， 高效并且对业务零侵入地解决分布式事务问题。\n阿里云对象存储:阿里云提供的海量、安全、低成本、高可靠的云存储服务。支持在任何应用、任 何时间、任何地点存储和访问任意类型的数据。\n分布式任务调度:提供秒级、精准、高可靠、高可用的定时(基于 Cron 表达式)任务调度服务。 同时提供分布式的任务执行模型，如网格任务。网格任务支持海量子任务均匀分配到所有 Worker(schedulerx-client)上执行。\n阿里云短信服务:覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建 客户触达通道。\n组件 Sentinel:把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳 定性。\nNacos:一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。\nRocketMQ:一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠 的消息发布与订阅服务。\nDubbo:Apache DubboTM 是一款高性能 Java RPC 框架。\nSeata:阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务解决方案。\nAlibaba Cloud ACM:一款在分布式架构环境中对应用配置进行集中管理和推送的应用配置中心 产品。\nAlibaba Cloud OSS: 阿里云对象存储服务(Object Storage Service，简称 OSS)，是阿里云提 供的海量、安全、低成本、高可靠的云存储服务。您可以在任何应用、任何时间、任何地点存储和 访问任意类型的数据。\nAlibaba Cloud SchedulerX: 阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精 准、高可靠、高可用的定时(基于 Cron 表达式)任务调度服务。\nAlibaba Cloud SMS: 覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速 搭建客户触达通道。\n","description":"\n","tags":[],"title":"\n微服务介绍","uri":"/posts/post-308/"},{"categories":["默认分类"],"content":"对于用 Markdown 来写博客的用户来说，图片的引用问题是个众所周知的难题。使用了这套组合后，妈妈再也不用担心我图片链接失效打不开了。\n工具下载安装： Typora ： https://www.typora.io/\nuPic ： 从 Github release 下载。如果访问 Github 下载困难的，可以从Gitee release下载。\nChevereto ：https://chevereto.com/ ，群晖安装可以参考我之前的文章 http://maruifu.cn/article/142\nTypora上传设置 插入图片时选择：上传图片\n勾选： 对本地位置的图片应用上述规则\n勾选： 对网络位置的图片应用上述规则\n上传服务选择 ：uPic\nTypora上传设置\nuPic上传设置 API Key: 在浏览器登录你的Chevereto后，打开仪表盘-\u003e设置-\u003eAPI。拷贝 API v1 Key\n获取API Key\nAPI 地址：[你的 Chevereto 地址]/api/1/upload。例如 https://demo.chevereto.com/api/1/upload\n请求方式: POST 使用 Base64: 勾选 文件字段名: source\n其他字段：\n增加Headers字段： Content-Type:multipart/form-data; charset=utf-8;\n增加Body字段：\nkey: 填写上面准备好的 [API Key]\naction: upload\nuPic其他字段设置\nURL 路径：上传完成后获取图片链接的路径。[\"image\", \"url\"]\nuPic上传设置\n自定义chevereto上传用户（可选） 获取root权限 admin@XiaoMageNAS:~$ sudo -i root@XiaoMageNAS:~# 查看运行的docker容器 root@XiaoMageNAS:~# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f3e5f503f36d bitwardenrs/server:1.18.0 \"/start.sh\" 4 days ago Up 12 hours (healthy) 0.0.0.0:32769-\u003e80/tcp, 0.0.0.0:32777-\u003e3012/tcp bitwardenrs 8f0cd2b10c84 gogs/gogs:latest \"/app/gogs/docker/st…\" 5 weeks ago Up 5 days 3000/tcp, 0.0.0.0:32768-\u003e22/tcp, 0.0.0.0:32770-\u003e3001/tcp gogs-gogs1 c986eeb9d23d portainer/portainer \"/portainer\" 6 weeks ago Up 5 days 0.0.0.0:9999-\u003e9000/tcp portainer 5bd176c39f27 nmtan/chevereto:latest \"docker-php-entrypoi…\" 6 months ago Up 12 hours 0.0.0.0:10000-\u003e80/tcp nmtan-chevereto1 进入chevereto容器 docker exec -it 5bd176c39f27 bash\n退出容器chevereto容器 exit\n复制容器中的文件到本地目录 docker cp 5bd176c39f27:/var/www/html/app/routes/route.api.php /volume1/docker/ 修改配置文件 vi /volume1/docker/route.api.php // 将此105行代码$uploaded_id = CHV\\Image::uploadToWebsite($source); 修改为下面代码 $uploaded_id = CHV\\Image::uploadToWebsite($source, 'xiaomage'); 这里的xiaomage是要传的用户名，可以设置-\u003e账户-\u003e用户名 查看\n复制到容器目录里面 docker cp /volume1/docker/route.api.php 5bd176c39f27:/var/www/html/app/routes/overrides/ ","description":"\n","tags":[],"title":"\nTypora + uPic +Chevereto 完美组合","uri":"/posts/post-309/"},{"categories":["默认分类"],"content":"Git是一个 “分布式版本管理工具”，简单的理解版本管理工具：大家在写东西的时候都用过 “回撤” 这个\n功能，但是回撤只能回撤几步，假如想要找回我三天之前的修改，光用 “回撤” 是找不回来的。而 “版本\n管理工具” 能记录每次的修改，只要提交到版本仓库，你就可以找到之前任何时刻的状态（文本状\n态）。\n下面的内容就是列举了常用的 Git 命令和一些小技巧，可以通过 “页面内查找” 的方式进行快速查询：\nCtrl/Command+f 。\n前言 一定要先测试命令的效果后，再用于工作环境中，以防造成不能弥补的后果！\n所有的命令都在 git version 2.7.4 (Apple Git-66) 下测试通过\n统一概念：\n工作区：改动（增删文件和内容）\n暂存区：输入命令： git add 改动的文件名 ，此次改动就放到了 ‘暂存区’\n本地仓库(简称：本地)：输入命令： git commit 此次修改的描述 ，此次改动就放到了 ’本地\n仓库’，每个 commit，我叫它为一个 ‘版本’。\n远程仓库(简称：远程)：输入命令： git push 远程仓库 ，此次改动就放到了 ‘远程仓\n库’（GitHub 等)\ncommit-id：输出命令： git log ，最上面那行 commit xxxxxx ，后面的字符串就是\ncommit-id\n展示帮助信息 git help -g The command output as below:\nThe common Git guides are: attributes Defining attributes per path cli Git command-line interface and conventions core-tutorial A Git core tutorial for developers cvs-migration Git for CVS users diffcore Tweaking diff output everyday A useful minimum set of commands for Everyday Git glossary A Git Glossary hooks Hooks used by Git ignore Specifies intentionally untracked files to ignore modules Defining submodule properties namespaces Git namespaces repository-layout Git Repository Layout revisions Specifying revisions and ranges for Git tutorial A tutorial introduction to Git tutorial-2 A tutorial introduction to Git: part two workflows An overview of recommended workflows with Git 'git help -a' and 'git help -g' list available subcommands and some concept guides. See 'git help \u003ccommand\u003e' or 'git help \u003cconcept\u003e' to read about a specific subcommand or concept. See 'git help git' for an overview of the system. 回到远程仓库的状态 抛弃本地所有的修改，回到远程仓库的状态。\ngit fetch --all \u0026\u0026 git reset --hard origin/master 重设第一个commit 也就是把所有的改动都重新放回工作区，并清空所有的 commit，这样就可以重新提交第一个 commit\n了\ngit update-ref -d HEAD 查看冲突文件列表 git diff --name-only --diff-filter=U 展示工作区和暂存区的不同 输出工作区和暂存区的 difffferent (不同)。\ngit diff 还可以展示本地仓库中任意两个 commit 之间的文件变动：\ngit diff \u003ccommit-id\u003e \u003ccommit-id\u003e 展示暂存区和最近版本的不同 输出暂存区和本地最近的版本 (commit) 的 difffferent (不同)。\ngit diff --cached 展示暂存区、工作区和最近版本的不同 输出工作区、暂存区 和本地最近的版本 (commit) 的 difffferent (不同)。\ngit diff HEAD 快速切换到上一个分支 git checkout - 删除已经合并到 master 的分支 git branch --merged master | grep -v '^\\*\\| master' | xargs -n 1 git branch -d 展示本地分支关联远程仓库的情况 git branch -vv 关联远程分支 关联之后， git branch -vv 就可以展示关联的远程分支名了，同时推送到远程仓库直接： git\npush ，不需要指定远程仓库了。\ngit branch -u origin/mybranch 或者在 push 时加上 -u 参数\ngit push origin/mybranch -u 列出所有远程分支 -r 参数相当于：remote\ngit branch -r 列出本地和远程分支 -a 参数相当于：all\ngit branch -a 查看远程分支和本地分支的对应关系 git remote show origin 远程删除了分支本地也想删除 git remote prune origin 创建并切换到本地分支 git checkout -b \u003cbranch-name\u003e 从远程分支中创建并切换到本地分支 git checkout -b \u003cbranch-name\u003e origin/\u003cbranch-name\u003e 删除本地分支 git branch -d \u003clocal-branchname\u003e 删除远程分支 git push origin --delete \u003cremote-branchname\u003e 或者\ngit push origin :\u003cremote-branchname\u003e 重命名本地分支 git branch -m \u003cnew-branch-name\u003e 查看标签 git tag 展示当前分支的最近的 tag\ngit describe --tags --abbrev=0 查看标签详细信息 git tag -ln 本地创建标签 git tag \u003cversion-number\u003e 默认 tag 是打在最近的一次 commit 上，如果需要指定 commit 打 tag：\n$ git tag -a \u003cversion-number\u003e -m \"v1.0 发布(描述)\" \u003ccommit-id\u003e 推送标签到远程仓库 首先要保证本地创建好了标签才可以推送标签到远程仓库：\ngit push origin \u003clocal-version-number\u003e 一次性推送所有标签，同步到远程仓库\ngit push origin --tags 删除本地标签 git tag -d \u003ctag-name\u003e 删除远程标签 git push origin --delete tag \u003ctagname\u003e 切回到某个标签 一般上线之前都会打 tag，就是为了防止上线后出现问题，方便快速回退到上一版本。下面的命令是回\n到某一标签下的状态：\ngit checkout -b branch_name tag_name 放弃工作区的修改 git checkout \u003cfile-name\u003e 放弃所有修改\ngit checkout . 恢复删除的文件 git rev-list -n 1 HEAD -- \u003cfile_path\u003e #得到 deleting_commit git checkout \u003cdeleting_commit\u003e^ -- \u003cfile_path\u003e #回到删除文件 deleting_commit 之前的 状态 以新增一个 commit 的方式还原某一个 commit 的修改 git revert \u003ccommit-id\u003e 回到某个 commit 的状态，并删除后面的 commit 和 revert 的区别：reset 命令会抹去某个 commit id 之后的所有 commit\ngit reset \u003ccommit-id\u003e #默认就是-mixed参数。 git reset --mixed HEAD^ #回退至上个版本，它将重置HEAD到另外一个commit,并且重置暂存区以便 和HEAD相匹配，但是也到此为止。工作区不会被更改。 git reset --soft HEAD~3 #回退至三个版本之前，只回退了commit的信息，暂存区和工作区与回退之 前保持一致。如果还要提交，直接commit即可 git reset --hard \u003ccommit-id\u003e #彻底回退到指定commit-id的状态，暂存区和工作区也会变为指定 commit-id版本的内容 修改上一个 commit 的描述 如果暂存区有改动，同时也会将暂存区的改动提交到上一个 commit\ngit commit --amend 查看 commit 历史 git log 查看某段代码是谁写的 blame 的意思为‘责怪’，你懂的。\ngit blame \u003cfile-name\u003e 显示本地更新过 HEAD 的 git 命令记录 每次更新了 HEAD 的 git 命令比如 commit、amend、cherry-pick、reset、revert 等都会被记录下来\n（不限分支），就像 shell 的 history 一样。\n这样你可以 reset 到任何一次更新了 HEAD 的操作之后，而不仅仅是回到当前分支下的某个 commit 之\n后的状态。\ngit reflog 修改作者名 git commit --amend --author='Author Name \u003cemail@address.com\u003e' 修改远程仓库的 url git remote set-url origin \u003cURL\u003e 增加远程仓库 git remote add origin \u003cremote-url\u003e 列出所有远程仓库 git remote 查看两个星期内的改动 git whatchanged --since='2 weeks ago' 把 A 分支的某一个 commit，放到 B 分支上 git checkout \u003cbranch-name\u003e \u0026\u0026 git cherry-pick \u003ccommit-id\u003e 给 git 命令起别名 简化命令\ngit config --global alias.\u003chandle\u003e \u003ccommand\u003e 比如：git status 改成 git st，这样可以简化命令 git config --global alias.st status 存储当前的修改，但不用提交 commit 参考廖雪峰老师的教程\ngit stash 保存当前状态，包括 untracked 的文件 untracked 文件：新建的文件\ngit stash -u 展示所有 stashes git stash list 回到某个 stash 的状态 git stash apply \u003cstash@{n}\u003e 回到最后一个 stash 的状态，并删除这个 stash git stash pop 删除所有的 stash git stash clear 从 stash 中拿出某个文件的修改 git checkout \u003cstash@{n}\u003e -- \u003cfile-path\u003e 展示所有 tracked 的文件 git ls-files -t 展示所有 untracked 的文件 git ls-files --others 展示所有忽略的文件 git ls-files --others -i --exclude-standard 强制删除 untracked 的文件 可以用来删除新建的文件。如果不指定文件文件名，则清空所有工作的 untracked 文件。 clean 命\n令，注意两点：\nclean 后，删除的文件无法找回\n不会影响 tracked 的文件的改动，只会删除 untracked 的文件\ngit clean \u003cfile-name\u003e -f 强制删除 untracked 的目录 可以用来删除新建的目录，注意:这个命令也可以用来删除 untracked 的文件。详情见上一条\ngit clean \u003cdirectory-name\u003e -df 展示简化的 commit 历史 git log --pretty=oneline --graph --decorate --all 把某一个分支到导出成一个文件 git bundle create \u003cfile\u003e \u003cbranch-name\u003e 从包中导入分支 新建一个分支，分支内容就是上面 git bundle create 命令导出的内容\ngit clone repo.bundle \u003crepo-dir\u003e -b \u003cbranch-name\u003e 执行 rebase 之前自动 stash git rebase --autostash 从远程仓库根据 ID，拉下某一状态，到本地分支详细展示一行中的修改 git fetch origin pull/\u003cid\u003e/head:\u003cbranch-name\u003e 详细展示一行中的修改 git diff --word-diff 清除 .gitignore 文件中记录的文件 git clean -X -f 展示所有 alias 和 confifigs 注意： confifig 分为：当前目录（local）和全局（golbal）的 confifig，默认为当前目录的 confifig\ngit config --local --list (当前目录) git config --global --list (全局) 展示忽略的文件 git status --ignored commit 历史中显示 Branch1 有的，但是 Branch2 没有 commit git log Branch1 ^Branch2 在 commit log 中显示 GPG 签名 git log --show-signature 删除全局设置 git config --global --unset \u003centry-name\u003e 新建并切换到新分支上，同时这个分支没有任何 commit 相当于保存修改，但是重写 commit 历史\ngit checkout --orphan \u003cbranch-name\u003e 展示任意分支某一文件的内容 git show \u003cbranch-name\u003e:\u003cfile-name\u003e clone 下来指定的单一分支 git clone -b \u003cbranch-name\u003e --single-branch https://github.com/user/repo.git clone 最新一次提交 只会 clone 最近一次提交，将减少 clone 时间\ngit clone --depth=1 https://github.com/user/repo.git 忽略某个文件的改动 关闭 track 指定文件的改动，也就是 Git 将不会在记录这个文件的改动\ngit update-index --assume-unchanged path/to/file 恢复 track 指定文件的改动\ngit update-index --no-assume-unchanged path/to/file 忽略文件的权限变化 不再将文件的权限变化视作改动\ngit config core.fileMode false 以最后提交的顺序列出所有 Git 分支 最新的放在最上面\ngit for-each-ref --sort=-committerdate --format='%(refname:short)' refs/heads/ 在 commit log 中查找相关内容 通过 grep 查找，given-text：所需要查找的字段\ngit log --all --grep='\u003cgiven-text\u003e' 把暂存区的指定 fifile 放到工作区中 不添加参数，默认是 -mixed\ngit reset \u003cfile-name\u003e 强制推送 git push -f \u003cremote-name\u003e \u003cbranch-name\u003e git 配置 http 和 socks 代理 git config --global https.proxy 'http://127.0.0.1:8001' # 适用于 privoxy 将 socks 协议转为 http 协议的 http 端口 git config --global http.proxy 'http://127.0.0.1:8001' git config --global socks.proxy \"127.0.0.1:1080\" git 配置 ssh 代理 $ cat ~/.ssh/config Host gitlab.com ProxyCommand nc -X 5 -x 127.0.0.1:1080 %h %p # 直接使用 shadowsocks 提供的socks5 代理端口 Host github.com ProxyCommand nc -X 5 -x 127.0.0.1:1080 %h %p 推送镜像 git push --mirror $URL 一图详解 优雅的提交Commit信息 使用Angular团队提交规范\n主要有以下组成\n标题行: 必填, 描述主要修改类型和内容\n主题内容: 描述为什么修改, 做了什么样的修改, 以及开发的思路等等\n页脚注释: 放 Breaking Changes 或 Closed Issues\n常用的修改项\ntype: commit 的类型\nfeat: 新特性\nfifix: 修改问题\nrefactor: 代码重构\ndocs: 文档修改\nstyle: 代码格式修改, 注意不是 css 修改\ntest: 测试用例修改\nchore: 其他修改, 比如构建流程, 依赖管理.\nscope: commit 影响的范围, 比如: route, component, utils, build…\nsubject: commit 的概述\nbody: commit 具体修改内容, 可以分为多行\nfooter: 一些备注, 通常是 BREAKING CHANGE 或修复的 bug 的链接.\n使用Commitizen 代替 git commit 可以使用cz-cli工具代替 git commit\n全局安装\nnpm install -g commitizen Commitizen适配器 如果需要在项目中使用commitizen生成符合AngularJS规范的提交说明，初始化cz-conventional-changelog适配器：\ncommitizen init cz-conventional-changelog --save --save-exact 如果当前已经有其他适配器被使用，则会报以下错误，此时可以加上--force选项进行再次初始化\nError: A previous adapter is already configured. Use --force to override 全局安装后使用 git cz 代替git commit 就可以了,如下：\n? Select the type of change that you're committing: (Use arrow keys) ❯ feat: A new feature fix: A bug fix docs: Documentation only changes style: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc) refactor: A code change that neither fixes a bug nor adds a feature perf: A code change that improves performance test: Adding missing tests or correcting existing tests ","description":"\n","tags":[],"title":"\nGit的奇技淫巧","uri":"/posts/post-310/"},{"categories":["默认分类"],"content":"文章转载自: http://www.ciphermagic.cn/java8-builder.html\n程序员经常会遇到灵魂拷问：你有对象吗？\n没有，但我可以 new 一个！\n1 2 3 4 5 6 7 8 9 10 public class GirlFriend { private String name; private int age; // 省略 getter \u0026 setter ... public static void main(String[] args) { GirlFriend myGirlFriend = new GirlFriend(); myGirlFriend.setName(\"小美\"); myGirlFriend.setAge(18); } } 没问题，老铁！但如果对象的属性太多，咋办？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 public class GirlFriend { private String name; private int age; private int bust; private int waist; private int hips; private List\u003cString\u003e hobby; private String birthday; private String address; private String mobile; private String email; private String hairColor; private Map\u003cString, String\u003e gift; // 等等等等 ... // 省略 getter \u0026 setter ... public static void main(String[] args) { GirlFriend myGirlFriend = new GirlFriend(); myGirlFriend.setName(\"小美\"); myGirlFriend.setAge(18); myGirlFriend.setBust(33); myGirlFriend.setWaist(23); myGirlFriend.setHips(33); myGirlFriend.setBirthday(\"2001-10-26\"); myGirlFriend.setAddress(\"上海浦东\"); myGirlFriend.setMobile(\"18688888888\"); myGirlFriend.setEmail(\"pretty-xiaomei@qq.com\"); myGirlFriend.setHairColor(\"浅棕色带点微卷\"); List\u003cString\u003e hobby = new ArrayList\u003c\u003e(); hobby.add(\"逛街\"); hobby.add(\"购物\"); hobby.add(\"买东西\"); myGirlFriend.setHobby(hobby); Map\u003cString, String\u003e gift = new HashMap\u003c\u003e(); gift.put(\"情人节礼物\", \"LBR 1912女王时代\"); gift.put(\"生日礼物\", \"迪奥烈焰蓝金\"); gift.put(\"纪念日礼物\", \"阿玛尼红管唇釉\"); myGirlFriend.setGift(gift); // 等等等等 ... } } 1 2 3 4 5 6 7 8 9 10 11 12 13 GirlFriend{name='小美' , age=18 , bust=33 , waist=23 , hips=33 , hobby=[逛街, 购物, 买东西] , birthday='2001-10-26' , address='上海浦东' , mobile='18688888888' , email='pretty-xiaomei@qq.com' , hairColor='浅棕色带点微卷' , gift={情人节礼物=LBR 1912女王时代, 生日礼物=迪奥烈焰蓝金, 纪念日礼物=阿玛尼红管唇釉} } GirlFriend 是很美，但写起来也太麻烦了吧。\n说说缺点：实例化和设置属性分开，不好维护；变量名重复写。\n莫慌，看法宝~\n这里不再介绍其他 Builder 实现方式，直接祭出最实用的通用Builder：\n适用于所有类，不需要改造原来类，不需要 lombok 插件支持。\n先看看使用姿势：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public class GirlFriend { // 省略属性 ... // 省略 getter \u0026 setter ... // 为了演示方便，加几个聚合方法 public void addHobby(String hobby) { this.hobby = Optional.ofNullable(this.hobby).orElse(new ArrayList\u003c\u003e()); this.hobby.add(hobby); } public void addGift(String day, String gift) { this.gift = Optional.ofNullable(this.gift).orElse(new HashMap\u003c\u003e()); this.gift.put(day, gift); } public void setVitalStatistics(int bust, int waist, int hips) { this.bust = bust; this.waist = waist; this.hips = hips; } public static void main(String[] args) { GirlFriend myGirlFriend = Builder.of(GirlFriend::new) .with(GirlFriend::setName, \"小美\") .with(GirlFriend::setAge, 18) .with(GirlFriend::setVitalStatistics, 33, 23, 33) .with(GirlFriend::setBirthday, \"2001-10-26\") .with(GirlFriend::setAddress, \"上海浦东\") .with(GirlFriend::setMobile, \"18688888888\") .with(GirlFriend::setEmail, \"pretty-xiaomei@qq.com\") .with(GirlFriend::setHairColor, \"浅棕色带点微卷\") .with(GirlFriend::addHobby, \"逛街\") .with(GirlFriend::addHobby, \"购物\") .with(GirlFriend::addHobby, \"买东西\") .with(GirlFriend::addGift, \"情人节礼物\", \"LBR 1912女王时代\") .with(GirlFriend::addGift, \"生日礼物\", \"迪奥烈焰蓝金\") .with(GirlFriend::addGift, \"纪念日礼物\", \"阿玛尼红管唇釉\") // 等等等等 ... .build(); } } 看到了吗！实例化和属性设置在同一条语句执行，链式操作，一路点点点，清爽！\nTalk is cheap, show me the code：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 /** * 通用的 Builder 模式构建器 * * @author: CipherCui * @since 2019/8/29 */ public class Builder\u003cT\u003e { private final Supplier\u003cT\u003e instantiator; private List\u003cConsumer\u003cT\u003e\u003e modifiers = new ArrayList\u003c\u003e(); public Builder(Supplier\u003cT\u003e instantiator) { this.instantiator = instantiator; } public static \u003cT\u003e Builder\u003cT\u003e of(Supplier\u003cT\u003e instantiator) { return new Builder\u003c\u003e(instantiator); } public \u003cP1\u003e Builder\u003cT\u003e with(Consumer1\u003cT, P1\u003e consumer, P1 p1) { Consumer\u003cT\u003e c = instance -\u003e consumer.accept(instance, p1); modifiers.add(c); return this; } public \u003cP1, P2\u003e Builder\u003cT\u003e with(Consumer2\u003cT, P1, P2\u003e consumer, P1 p1, P2 p2) { Consumer\u003cT\u003e c = instance -\u003e consumer.accept(instance, p1, p2); modifiers.add(c); return this; } public \u003cP1, P2, P3\u003e Builder\u003cT\u003e with(Consumer3\u003cT, P1, P2, P3\u003e consumer, P1 p1, P2 p2, P3 p3) { Consumer\u003cT\u003e c = instance -\u003e consumer.accept(instance, p1, p2, p3); modifiers.add(c); return this; } public T build() { T value = instantiator.get(); modifiers.forEach(modifier -\u003e modifier.accept(value)); modifiers.clear(); return value; } /** * 1 参数 Consumer */ @FunctionalInterface public interface Consumer1\u003cT, P1\u003e { void accept(T t, P1 p1); } /** * 2 参数 Consumer */ @FunctionalInterface public interface Consumer2\u003cT, P1, P2\u003e { void accept(T t, P1 p1, P2 p2); } /** * 3 参数 Consumer */ @FunctionalInterface public interface Consumer3\u003cT, P1, P2, P3\u003e { void accept(T t, P1 p1, P2 p2, P3 p3); } } 这个示例最多支持三个参数的设置属性方法，也完全够用了。如果要扩展也很容易，依葫芦画瓢，添加多个参数的Consumer。\n快用你的 Builder 建个对象吧~\nlambok的@Accessors(chain = true)也可以使用链式结构\n","description":"\n","tags":[],"title":"\n你还在new对象吗？Java8通用Builder了解一下？","uri":"/posts/post-311/"},{"categories":["默认分类"],"content":"设计模式\n需求 业务需求是，有一个代报考系统，里面的一个功能是根据报考类目的不同维护不同的代报考规则。\n代报考规则的实体：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public class ExamRuleEditReqDTO extends BaseDTO { // 无 则新增 有则 修改 private Integer id; //报考规则名称 @NotNull(message = \"报考规则名称不能为空!\") private String name; /** * 报考类目 typeCode * 消防工程师 HC_EXAM_TYPE_FIRE_ENGINEER * 成人高考 HC_EXAM_TYPE_ADULT_EXAM * ACI 心理 HC_EXAM_TYPE_ACI_PSYCHOLOGY * ACI 营养 HC_EXAM_TYPE_ACI_NUTRITION * 健康管理师 HC_EXAM_TYPE_HEALTH_MANAGER * 自定义类目 HC_EXAM_TYPE_CUSTOMIZE */ @NotNull(message = \"报考类目Code不能为空!\") private String typeCode; //是否免协报费 private String exemptionAssistFlag; // ... 省略 get / set ... } service接口\n1 2 3 4 5 6 7 8 9 public interface ExamService { //维护代报考规则 ResponseBaseDTO\u003cInteger\u003e editExamRule(ExamRuleEditReqDTO reqDTO); //查询代报考规则 ResponseBaseDTO\u003cExamRuleDetailQueryRespDTO\u003e queryExamRuleDetail(ExamRuleQueryReqDTO reqDTO); } 传统实现 根据报考类目写一堆的if else：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 @Service public class ExamServiceImpl implements ExamService { @Autowired private ExamRuleFireEngineerHandler examRuleFireEngineerHandler; @Autowired private ExamRuleAdultExamHandler examRuleAdultExamHandler; @Autowired private ExamRuleAciPsychologyHandler examRuleAciPsychologyHandler; @Autowired private ExamRuleAciNutritionHandler examRuleAciNutritionHandler; @Autowired private ExamRuleHealthManagerHandler examRuleHealthManagerHandler; @Autowired private ExamRuleCustomizeHandler examRuleCustomizeHandler; public ResponseBaseDTO\u003cInteger\u003e editExamRule(ExamRuleEditReqDTO reqDTO) { if (ExamConstants.HC_EXAM_TYPE_FIRE_ENGINEER.equals(reqDTO.getTypeCode())) { return examRuleFireEngineerHandler.editHandler(reqDTO); } else if (ExamConstants.HC_EXAM_TYPE_ADULT_EXAM.equals(reqDTO.getTypeCode())) { return examRuleAdultExamHandler.editHandler(reqDTO); } else if (ExamConstants.HC_EXAM_TYPE_ACI_PSYCHOLOGY.equals(reqDTO.getTypeCode())) { return examRuleAciPsychologyHandler.editHandler(reqDTO); } else if (ExamConstants.HC_EXAM_TYPE_ACI_NUTRITION.equals(reqDTO.getTypeCode())) { return examRuleAciNutritionHandler.editHandler(reqDTO); } else if (ExamConstants.HC_EXAM_TYPE_HEALTH_MANAGER.equals(reqDTO.getTypeCode())) { return examRuleHealthManagerHandler.editHandler(reqDTO); } return new ResponseBaseDTO\u003c\u003e(ResponseBaseDTO.FLAG_FAIL, \"代报考类目参数不正确！\"); } public ResponseBaseDTO\u003cExamRuleDetailQueryRespDTO\u003e queryExamRuleDetail(ExamRuleQueryReqDTO reqDTO) { if (ExamConstants.HC_EXAM_TYPE_FIRE_ENGINEER.equals(reqDTO.getTypeCode())) { return examRuleFireEngineerHandler.editHandler(reqDTO); } else if (ExamConstants.HC_EXAM_TYPE_ADULT_EXAM.equals(reqDTO.getTypeCode())) { return examRuleAdultExamHandler.editHandler(reqDTO); } else if (ExamConstants.HC_EXAM_TYPE_ACI_PSYCHOLOGY.equals(reqDTO.getTypeCode())) { return examRuleAciPsychologyHandler.editHandler(reqDTO); } else if (ExamConstants.HC_EXAM_TYPE_ACI_NUTRITION.equals(reqDTO.getTypeCode())) { return examRuleAciNutritionHandler.editHandler(reqDTO); } else if (ExamConstants.HC_EXAM_TYPE_HEALTH_MANAGER.equals(reqDTO.getTypeCode())) { return examRuleHealthManagerHandler.editHandler(reqDTO); } else if (ExamConstants.HC_EXAM_TYPE_CUSTOMIZE.equals(reqDTO.getTypeCode())) { return examRuleHealthManagerHandler.editHandler(reqDTO); } return new ResponseBaseDTO\u003c\u003e(ResponseBaseDTO.FLAG_FAIL, \"代报考类目参数不正确！\"); } } 策略模式实现 利用策略模式，只需要两行即可实现业务逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 @Service public class ExamServiceImpl implements ExamService { @Autowired private ExamRuleHandlerContext examRuleHandlerContext; @Override @Transactional public ResponseBaseDTO\u003cInteger\u003e editExamRule(ExamRuleEditReqDTO reqDTO ) { return this.examRuleHandlerContext.getHandlerInstance(reqDTO.getTypeCode()).editHandler(reqDTO ); } @Override public ResponseBaseDTO\u003cExamRuleDetailQueryRespDTO\u003e queryExamRuleDetail(ExamRuleQueryReqDTO reqDTO) { return this.examRuleHandlerContext.getHandlerInstance(reqDTO.getTypeCode()).queryHandler(reqDTO); } } 可以看到上面的方法中注入了ExamRuleHandlerContext，这是一个处理器上下文，用来保存不同的业务处理器，具体在下文会讲解。我们从中获取一个抽象的处理器AbstractExamRuleHandler，调用其方法实现业务逻辑。\n现在可以了解到，我们主要的业务逻辑是在处理器中实现的，因此有多少个代报考类目，就对应有多少个处理器。以后需求变化，增加了代报考类目，只需要添加相应的处理器就可以，上述ExamServiceImpl完全不需改动。\n业务处理器的写法 @Component @ExamRuleHandler(ExamConstants.HC_EXAM_TYPE_CUSTOMIZE) public class ExamRuleCustomizeHandler extends AbstractExamRuleHandler { @Override public ResponseBaseDTO\u003cInteger\u003e editHandler(ExamRuleEditReqDTO reqDTO){ //处理自定义类目的规则 return null; } } @Component @ExamRuleHandler(ExamConstants.HC_EXAM_TYPE_HEALTH_MANAGER) public class ExamRuleCustomizeHandler extends AbstractExamRuleHandler { @Override public ResponseBaseDTO\u003cInteger\u003e editHandler(ExamRuleEditReqDTO reqDTO){ //处理健康管理师类目的规则 return null; } } @Component @ExamRuleHandler(ExamConstants.HC_EXAM_TYPE_ACI_NUTRITION) public class ExamRuleCustomizeHandler extends AbstractExamRuleHandler { @Override public ResponseBaseDTO\u003cInteger\u003e editHandler(ExamRuleEditReqDTO reqDTO){ //处理ACI营养类目的规则 return null; } } @Component @ExamRuleHandler(ExamConstants.HC_EXAM_TYPE_ACI_PSYCHOLOGY) public class ExamRuleCustomizeHandler extends AbstractExamRuleHandler { @Override public ResponseBaseDTO\u003cInteger\u003e editHandler(ExamRuleEditReqDTO reqDTO){ //处理ACI心理类目的规则 return null; } } @Component @ExamRuleHandler(ExamConstants.HC_EXAM_TYPE_ADULT_EXAM) public class ExamRuleCustomizeHandler extends AbstractExamRuleHandler { @Override public ResponseBaseDTO\u003cInteger\u003e editHandler(ExamRuleEditReqDTO reqDTO){ //处理成人高考类目的规则 return null; } } @Component @ExamRuleHandler(ExamConstants.HC_EXAM_TYPE_FIRE_ENGINEER) public class ExamRuleCustomizeHandler extends AbstractExamRuleHandler { @Override public ResponseBaseDTO\u003cInteger\u003e editHandler(ExamRuleEditReqDTO reqDTO){ //处理消防工程师类目的规则 return null; } } 首先每个处理器都必须添加到spring容器中，因此需要加上@Component注解，其次需要加上一个自定义注解@ExamRuleHandler，用于标识该处理器对应哪个订单类型，最后就是继承AbstractExamRuleHandler，实现自己的业务逻辑。\n自定义注解 @HandlerType 1 2 3 4 5 6 7 8 9 10 import java.lang.annotation.*; @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited public @interface ExamRuleHandler { String value(); } 抽象处理器 AbstractHandler public abstract class AbstractExamRuleHandler { public abstract ResponseBaseDTO\u003cInteger\u003e editHandler(ExamRuleEditReqDTO reqDTO ); public abstract ResponseBaseDTO\u003cExamRuleDetailQueryRespDTO\u003e queryHandler(ExamRuleQueryReqDTO reqDTO ); } 自定义注解和抽象处理器都很简单，那么如何将处理器注册到spring容器中呢？ 具体思路是：\n扫描指定包中标有@ExamRuleHandler的类； 将注解中的类型值作为key，对应的类作为value，保存在Map中； 重写 实现ApplicationContextAware接口的ExamRuleHandlerContext类中setApplicationContext方法，当spring容器初始化的时候，会自动的将ApplicationContext注入进来 我们将核心的功能封装在ExamRuleHandlerContext类中，完成上面的功能。\n上下文处理器ExamRuleHandlerContext 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import org.springframework.beans.BeansException; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.ApplicationContext; import org.springframework.context.ApplicationContextAware; import org.springframework.stereotype.Service; import java.util.HashMap; import java.util.Map; @Service public class ExamRuleHandlerContext implements ApplicationContextAware { @Autowired ApplicationContext applicationContext; private static final Map\u003cString,Class\u003e handlerMap = new HashMap\u003c\u003e(10); public AbstractExamRuleHandler getHandlerInstance(String typeCode){ Class clazz = handlerMap.get(typeCode); return (AbstractExamRuleHandler) applicationContext.getBean(clazz); } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { Map\u003cString,Object\u003e beans = applicationContext.getBeansWithAnnotation(ExamRuleHandler.class); if (beans != null \u0026\u0026 beans.size() \u003e 0) { for (Object serviceBean : beans.values()) { String payType = serviceBean.getClass().getAnnotation(ExamRuleHandler.class).value(); handlerMap.put(payType, serviceBean.getClass()); } } } } #getHandlerInstance方法根据类型获取对应的class，然后根据class类型获取注册到spring`中的bean。\n最后请注意一点，ExamRuleHandlerContext 必须能被扫描到，或者通过@Bean的方式显式的注册，才能在项目启动时发挥作用。\n总结 利用策略模式可以简化繁杂的if else代码，方便维护，而利用自定义注解和自注册的方式，可以方便应对需求的变更。本文只是提供一个大致的思路，还有很多细节可以灵活变化，例如使用枚举类型、或者静态常量，作为代报考的类型，相信你能想到更多更好的方法。\n","description":"\n","tags":[],"title":"\n使用策略模式消除if else代码","uri":"/posts/post-312/"},{"categories":["默认分类"],"content":"Stream 的终止操作 终端操作会从流的流水线生成结果。其结果可以是任何不是流的 值，例如：List、Integer，甚至是 void 。\n查找与匹配\n方 法 描 述 1 allMatch(Predicate p) 检查是否匹配所有元素 2 anyMatch(Predicate p) 检查是否至少匹配一个元素 3 noneMatch(Predicate p) 检查是否没有匹配所有元素 4 findFirst() 返回第一个元素 5 findAny() 返回当前流中的任意元素 6 count() 返回流中元素总数 7 max(Comparator c) 返回流中最大值 8 min(Comparator c) 返回流中最小值 9 forEach(Consumer c) 内部迭代(使用 Collection 接口需要用户去做迭 代，称为外部迭代。相反，Stream API 使用内部 迭代——它帮你把迭代做了) @Test public void test1(){ boolean b1=employees.stream()//allMatch-检查是否匹配所有元素 .allMatch((e)-\u003ee.getStatus().equals(Status.BUSY)); System.out.println(b1);//false boolean b2=employees.stream()//anyMatch-检查是否至少匹配一个元素 .anyMatch((e)-\u003ee.getStatus().equals(Status.BUSY)); System.out.println(b2);//true boolean b3=employees.stream()//noneMatch-检查是否没有匹配所有元素 .noneMatch((e)-\u003ee.getStatus().equals(Status.BUSY)); System.out.println(b3);//false Optional\u003cEmployee\u003e op=employees.stream()//findFirst-返回第一个元素//Optional是Java8中避免空指针异常的容器类 .sorted((e1,e2)-\u003eDouble.compare(e1.getSalary(), e2.getSalary())) .findFirst(); System.out.println(op.get());//Employee [name=王五, age=26, salary=3333.33, Status=VOCATION] Optional\u003cEmployee\u003e op2=employees.parallelStream()//findAny-返回当前流中的任意元素 .filter((e)-\u003ee.getStatus().equals(Status.FREE)) .findAny(); System.out.println(op2.get());//Employee [name=赵六, age=36, salary=6666.66, Status=FREE] Long count=employees.stream()//count-返回流中元素的总个数 .count(); System.out.println(count);//5 Optional\u003cEmployee\u003e op3=employees.stream()//max-返回流中最大值 .max((e1,e2)-\u003eDouble.compare(e1.getSalary(), e2.getSalary())); System.out.println(op3.get());//Employee [name=张三, age=18, salary=9999.99, Status=FREE] Optional\u003cDouble\u003e op4=employees.stream()//min-返回流中最小值 .map(Employee::getSalary) .min(Double::compare); System.out.println(op4.get());//3333.33 } 归约\n方 法 描述 1 reduce(T iden, BinaryOperator b) 可以将流中元素反复结合起来，得到一个值。返回 T 2 reduce(BinaryOperator b) 可以将流中元素反复结合起来，得到一个值。返回 Optional 备注：map 和 reduce 的连接通常称为 map-reduce 模式，因 Google 用它 来进行网络搜索而出名\n/* * 归约 * reduce(T identity,BinaryOperator b) / reduce(BinaryOperator b)-可以将流中元素反复结合起来，得到一个值。 */ @Test public void test3(){ List\u003cInteger\u003e list=Arrays.asList(1,2,3,4,5,6,7,8,9,10); Integer sum=list.stream()//reduce(T identity,BinaryOperator b) .reduce(0, (x,y)-\u003ex+y);//0为起始值 System.out.println(sum); System.out.println(\"--------------------------\"); Optional\u003cDouble\u003e op=employees.stream()//reduce(BinaryOperator b)//没有起始值，map返回可能为空，所以返回Optional类型 .map(Employee::getSalary) .reduce(Double::sum); System.out.println(op.get()); } 收集\n方 法 描 述 1 collect(Collector c) 将流转换为其他形式。接收一个 Collector接口的 实现，用于给Stream中元素做汇总的方法 Collector 接口中方法的实现决定了如何对流执行收集操作(如收集到 List、Set、Map)。但是 Collectors 实用类提供了很多静态方法，可以方便地创建常见收集器实例，具体方法与实例如下表\n方法 返回类型 作用 toList List 把流中元素收集到List Listemps= list.stream().collect(Collectors.toList()); toSet Set 把流中元素收集到Set Setemps= list.stream().collect(Collectors.toSet()); toCollection Collection 把流中元素收集到创建的集合 Collectionemps=list.stream().collect(Collectors.toCollection(ArrayList::new)); counting Long 计算流中元素的个数 long count = list.stream().collect(Collectors.counting()); summingInt Integer 对流中元素的整数属性求和 inttotal=list.stream().collect(Collectors.summingInt(Employee::getSalary)); averagingInt Double 计算流中元素Integer属性的平均 值 doubleavg= list.stream().collect(Collectors.averagingInt(Employee::getSalary)); summarizingInt IntSummaryStatistics 收集流中Integer属性的统计值。如：平均值 IntSummaryStatisticsiss= list.stream().collect(Collectors.summarizingInt(Employee::getSalary)); joining String 连接流中每个字符串 String str= list.stream().map(Employee::getName).collect(Collectors.joining()); maxBy Optional 根据比较器选择最大值 Optionalmax= list.stream().collect(Collectors.maxBy(comparingInt(Employee::getSalary))); minBy Optional 根据比较器选择最小值 Optionalmin = list.stream().collect(Collectors.minBy(comparingInt(Employee::getSalary))); reducing 归约产生的类型 从一个作为累加器的初始值 开始，利用BinaryOperator与 流中元素逐个结合，从而归 约成单个值 inttotal=list.stream().collect(Collectors.reducing(0, Employee::getSalar, Integer inttotal=list.stream().collect(Collectors.reducing(0, Employee::getSalar, Integer::sum)); collectingAndThen 转换函数返回的类型 包裹另一个收集器，对其结 果转换函数 inthow= list.stream().collect(Collectors.collectingAndThen(Collectors.toList(), List::size)); groupingBy Map\u003ck, list 根据某属性值对流分组，属 性为K，结果为V Map\u003cemp.status, list partitioningBy Map\u003cboolean, list 根据true或false进行分区 Map\u003cboolean,list\u003evd= list.stream().collect(Collectors.partitioningBy(Employee::getManage)); /* * 收集 * collect-将流转换为其他形式，接收一个Collector接口的实现，用于给Stream中元素做汇总的方法。 */ @Test public void test4(){ List\u003cString\u003e list=employees.stream() .map(Employee::getName) .collect(Collectors.toList()); list.forEach(System.out::println); System.out.println(\"----------------------------\"); Set\u003cString\u003e set=employees.stream() .map(Employee::getName) .collect(Collectors.toSet()); set.forEach(System.out::println); System.out.println(\"----------------------------\"); HashSet\u003cString\u003e hs=employees.stream() .map(Employee::getName) .collect(Collectors.toCollection(HashSet::new)); hs.forEach(System.out::println); System.out.println(\"----------------------------\"); //总和 Long count=employees.stream() .collect(Collectors.counting()); System.out.println(count); //平均值 Double avg=employees.stream() .collect(Collectors.averagingDouble(Employee::getSalary)); System.out.println(avg); //总和 Double sum=employees.stream() .collect(Collectors.summingDouble(Employee::getSalary)); System.out.println(sum); //最大值 Optional\u003cEmployee\u003e max=employees.stream() .collect(Collectors.maxBy((e1,e2)-\u003eDouble.compare(e1.getSalary(), e2.getSalary()))); System.out.println(max.get()); //最小值 Optional\u003cDouble\u003e min=employees.stream() .map(Employee::getSalary) .collect(Collectors.minBy(Double::compare)); System.out.println(min.get()); System.out.println(\"----------------------------\"); //分组 Map\u003cStatus,List\u003cEmployee\u003e\u003e map=employees.stream() .collect(Collectors.groupingBy(Employee::getStatus)); System.out.println(map);//{FREE=[Employee [name=张三, age=18, salary=9999.99, Status=FREE], Employee [name=赵六, age=36, salary=6666.66, Status=FREE]], VOCATION=[Employee [name=王五, age=26, salary=3333.33, Status=VOCATION]], BUSY=[Employee [name=李四, age=58, salary=5555.55, Status=BUSY], Employee [name=田七, age=12, salary=8888.88, Status=BUSY]]} //多级分组 Map\u003cStatus,Map\u003cString,List\u003cEmployee\u003e\u003e\u003e map2=employees.stream() .collect( Collectors.groupingBy( Employee::getStatus,Collectors.groupingBy((e)-\u003e{ if(e.getAge()\u003c=35){ return \"青年\"; }else if(e.getAge()\u003c=50){ return \"中年\"; }else{ return \"老年\"; } }) ) ); System.out.println(map2);//{FREE={青年=[Employee [name=张三, age=18, salary=9999.99, Status=FREE]], 中年=[Employee [name=赵六, age=36, salary=6666.66, Status=FREE]]}, VOCATION={青年=[Employee [name=王五, age=26, salary=3333.33, Status=VOCATION]]}, BUSY={青年=[Employee [name=田七, age=12, salary=8888.88, Status=BUSY]], 老年=[Employee [name=李四, age=58, salary=5555.55, Status=BUSY]]}} //分区 Map\u003cBoolean,List\u003cEmployee\u003e\u003e map3=employees.stream() .collect(Collectors.partitioningBy((e)-\u003ee.getSalary()\u003e8000)); System.out.println(map3);//{false=[Employee [name=李四, age=58, salary=5555.55, Status=BUSY], Employee [name=王五, age=26, salary=3333.33, Status=VOCATION], Employee [name=赵六, age=36, salary=6666.66, Status=FREE]], true=[Employee [name=张三, age=18, salary=9999.99, Status=FREE], Employee [name=田七, age=12, salary=8888.88, Status=BUSY]]} System.out.println(\"--------------------------------\"); DoubleSummaryStatistics dss=employees.stream() .collect(Collectors.summarizingDouble(Employee::getSalary)); System.out.println(dss.getSum()); System.out.println(dss.getAverage()); System.out.println(dss.getMax()); System.out.println(\"--------------------------------\"); String strr=employees.stream() .map(Employee::getName) .collect(Collectors.joining(\",\")); System.out.println(strr);//张三李四王五赵六田七 } ","description":"\n","tags":[],"title":"\n强大的 Stream API(三)","uri":"/posts/post-313/"},{"categories":["默认分类"],"content":"Stream 的中间操作 多个中间操作可以连接起来形成一个流水线，除非流水 线上触发终止操作，否则中间操作不会执行任何的处理！而在终止操作时一次性全部处理，称为“惰性求值”。\n//创建一个集合 List\u003cEmployee\u003e employees=Arrays.asList( new Employee(\"张三\",18,9999.99), new Employee(\"李四\",58,5555.55), new Employee(\"王五\",26,3333.33), new Employee(\"赵六\",36,6666.66), new Employee(\"田七\",12,8888.88), new Employee(\"田七\",12,8888.88) ); 筛选与切片\n方 法 描 述 1 filter(Predicate p) 接收 Lambda ， 从流中排除某些元素。 2 distinct() 筛选，通过流所生成元素的 hashCode() 和 equals() 去 除重复元素。 3 limit(long maxSize) 截断流，使其元素不超过给定数量。 4 skip(long n) 跳过元素，返回一个扔掉了前 n 个元素的流。 若流中元素 不足 n 个，则返回一个空流。与 limit(n) 互补 /* 筛选与切片 * filter--接收Lambda，从流中排除某些元素。 * limit--截断流，使其元素不超过给定数量。 * skip(n)--跳过元素，返回一个扔掉了前n个元素的流。若流中元素不足n个，则返回一个空流。与limit(n) 互补 * distinct--筛选，通过流所生成元素的 hashCode() 和 equals() 去掉重复元素 */ //内部迭代：迭代操作由 Stream API 完成 @Test public void test1(){ //中间操作：不会执行任何操作 Stream\u003cEmployee\u003e stream=employees.stream() .filter((e) -\u003e e.getAge()\u003e35 ); //终止操作：一次性执行全部内容，即 惰性求值 stream.forEach(System.out::println); } //外部迭代 @Test public void test2(){ Iterator\u003cEmployee\u003e it=employees.iterator(); while(it.hasNext()){ System.out.println(it.next()); } } @Test public void test3(){//发现“短路”只输出了两次，说明只要找到 2 个 符合条件的就不再继续迭代 employees.stream() .filter((e)-\u003e{ System.out.println(\"短路！\"); return e.getSalary()\u003e5000; }) .limit(2) .forEach(System.out::println); } @Test public void test4(){ employees.stream() .filter((e)-\u003ee.getSalary()\u003e5000) .skip(2)//跳过前两个 .distinct()//去重，注意：需要Employee重写hashCode 和 equals 方法 .forEach(System.out::println); } 映射\n方 法 描 述 1 map(Function f) 接收一个函数作为参数，该函数会被应用到每个元 素上，并将其映射成一个新的元素。 2 mapToDouble(ToDoubleFunction f) 接收一个函数作为参数，该函数会被应用到每个元 素上，产生一个新的 DoubleStream。 3 mapToInt(ToIntFunction f) 接收一个函数作为参数，该函数会被应用到每个元 素上，产生一个新的 IntStream。 4 mapToLong(ToLongFunction f) 接收一个函数作为参数，该函数会被应用到每个元 素上，产生一个新的 LongStream。 5 flatMap(Function f) 接收一个函数作为参数，将流中的每个值都换成另 一个流，然后把所有流连接成一个流 /* * 映射 * map--接收Lambda，将元素转换成其他形式或提取信息。接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新元素。 * flatMap--接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流 */ @Test public void test5(){ List\u003cString\u003e list=Arrays.asList(\"aaa\",\"bbb\",\"ccc\",\"ddd\"); list.stream() .map((str)-\u003estr.toUpperCase()) .forEach(System.out::println); System.out.println(\"------------------------\"); employees.stream() .map(Employee::getName) .forEach(System.out::println); System.out.println(\"------------------------\"); Stream\u003cStream\u003cCharacter\u003e\u003e stream=list.stream() .map(TestStreamAPI2::filterChatacter); stream.forEach((sm)-\u003e{ sm.forEach(System.out::println); }); System.out.println(\"------------------------\"); Stream\u003cCharacter\u003e sm=list.stream() .flatMap(TestStreamAPI2::filterChatacter); sm.forEach(System.out::println); } public static Stream\u003cCharacter\u003e filterChatacter(String str){ List\u003cCharacter\u003e list=new ArrayList\u003c\u003e(); for (Character ch : str.toCharArray()) { list.add(ch); } return list.stream(); } @Test public void test6(){//map和flatMap的关系 类似于 add(Object)和addAll(Collection coll) List\u003cString\u003e list=Arrays.asList(\"aaa\",\"bbb\",\"ccc\",\"ddd\"); List list2=new ArrayList\u003c\u003e(); list2.add(11); list2.add(22); list2.addAll(list); System.out.println(list2); } 排序\n方 法 描 述 1 sorted() 产生一个新流，其中按自然顺序排序 2 sorted(Comparator comp) 产生一个新流，其中按比较器顺序排序 //中间操作 /* * 排序 * sorted()-自然排序（按照对象类实现Comparable接口的compareTo()方法 排序） * sorted(Comparator com)-定制排序（Comparator） */ @Test public void test7(){ List\u003cString\u003e list=Arrays.asList(\"ccc\",\"bbb\",\"aaa\"); list.stream() .sorted() .forEach(System.out::println); System.out.println(\"------------------------\"); employees.stream() .sorted((e1,e2)-\u003e{ if(e1.getAge().equals(e2.getAge())){ return e1.getName().compareTo(e2.getName()); }else{ return e1.getAge().compareTo(e2.getAge()); } }).forEach(System.out::println); ","description":"\n","tags":[],"title":"\n强大的 Stream API(二)","uri":"/posts/post-314/"},{"categories":["默认分类"],"content":"了解 Stream Java8中有两大最为重要的改变。第一个是 Lambda 表达式；另外一 个则是 Stream API(java.util.stream.*)。 Stream 是 Java8 中处理集合的关键抽象概念，它可以指定你希望对 集合进行的操作，可以执行非常复杂的查找、过滤和映射数据等操作。 使用Stream API 对集合数据进行操作，就类似于使用 SQL 执行的数 据库查询。也可以使用 Stream API 来并行执行操作。简而言之， Stream API 提供了一种高效且易于使用的处理数据的方式。\n什么是 Stream 流(Stream) 到底是什么呢？ 是数据渠道，用于操作数据源（集合、数组等）所生成的元素序列。 “集合讲的是数据，流讲的是计算！”\n注意：\n①Stream 自己不会存储元素。 ②Stream 不会改变源对象。相反，他们会返回一个持有结果的新Stream。 ③Stream 操作是延迟执行的。这意味着他们会等到需要结果的时候才执行。\nStream 的操作三个步骤 创建 Stream\n一个数据源（如：集合、数组），获取一个流\n中间操作 一个中间操作链，对数据源的数据进行处理\n终止操作(终端操作) 一个终止操作，执行中间操作链，并产生结果\n创建 Stream 1.1可以通过Collection 系列集合提供的stream()或parallelStream()方法\ndefault Stream\u003c E\u003e stream() : 返回一个顺序流 default Stream\u003c E\u003e parallelStream() : 返回一个并行流\n//可以通过Collection 系列集合提供的stream()或parallelStream() List\u003cString\u003e list = new ArrayList\u003c\u003e(); Stream\u003cString\u003e stream1 = list.stream(); Stream\u003cString\u003e stream2 = list.parallelStream(); 1.2通过 Arrays 中的静态方法stream()获取数组流\nstatic \u003c T\u003e Stream\u003c T\u003e stream(T[] array): 返回一个流\n重载形式，能够处理对应基本类型的数组：\npublic static IntStream stream(int[] array) public static LongStream stream(long[] array)\npublic static DoubleStream stream(double[] array)\n//通过 Arrays 中的静态方法stream()获取数组流 Employee[] emps=new Employee[10]; Stream\u003cEmployee\u003e stream3= Arrays.stream(emps); 1.3通过Stream 类中的静态方法of()，通过显示值创建一个流。\n它可以接收任意数量的参数。\npublic static\u003c T\u003e Stream\u003c T\u003e of(T… values) : 返回一个流\n//通过Stream 类中的静态方法of() Stream\u003cString\u003e stream4=Stream.of(\"aa\",\"bb\",\"cc\"); 1.4.创建无限流\n可以使用静态方法 Stream.iterate() 和Stream.generate(), 创建无限流。\n迭代\npublic static\u003c T\u003e Stream\u003c T\u003e iterate(final T seed, final UnaryOperator\u003c T\u003e f)\n生成\npublic static\u003c T\u003e Stream\u003c T\u003e generate(Supplier\u003c T\u003e s)\n//创建无限流 //迭代 Stream\u003cInteger\u003e stream5=Stream.iterate(0, (x) -\u003e x+2); stream4.limit(10).forEach(System.out::println); //生成 Stream.generate(() -\u003e Math.random()) .limit(5) .forEach(System.out::println); ","description":"\n","tags":[],"title":"\n强大的 Stream API(一）","uri":"/posts/post-315/"},{"categories":["默认分类","SpringBoot","java"],"content":"Pgroza 简介 Pgroza 是参考groza制作的物联网平台，面向个人，开源。 此项目仅仅用于学习，不建议用在商业用途。 之所以会有这个想法，主要是因为之前从事过物联网行业，虽然是做上层业务的，但是还是对这个生态比较感兴趣，然后在网上找了不少的资料过后，终于还是决定自己搭建一个。经过调研后发现几个问题：1.凑齐一个生态成本比较高；2.基于现成的云平台进行开发过后，总是要受各种条件限制；3.依赖现有平台和框架，最后开发的基本上都是各种业务层的东西了，对生态链还是不够深入理解。\n关于Pgroza的发展 其实我还没想好要怎么去研发Pgroza，现在的想法是现做一个面向单个家庭的。 所以应该是一个单机版的，为了以后拓展方便，开发时需要注意解耦的问题。 如果研发顺利，应该是可以做成分布式的；未来的人对数据隐私会比现在重视的很多，所以多家庭接入的问题暂时不会考虑了。最后就是如果要面向大众，最好是能一键化部署，就好像安装应用程序一样。\n对Pgroza的初期功能分析 涉及对象 一般情况，物联网平台涉及对象不外乎两个：用户和设备。\n对于设备： 设备需要接入，接入时需要提供协议，现在的物联网平台一般都是规定一定的接入协议的，设备一般都是需要去遵从这些既定协议的。当然，如果设备商比较牛掰，物联网平台也可以增加协议去适配厂商的。设备按照协议接入平台后，在某些事件（常见的就是温度变化、湿度变化以及光变化等等）触发后，向平台上报数据，平台根据协议解析后，存储下来，展示的接口就可以查询数据用于展示了。高级的功能可以根据不同设备的事件产生联动效果（比如：检测到光变暗了，就开灯）。同种设备安装在不同的地方可能有不同的应用，所以每个设备需要有自己的信息，最好是在接入的时候就关联上。\n对于用户：用户需要管理设备（如：设备接入平台，设备信息维护，联动问题以及设备状态管理等等），但是不是所有用户都需要去管理设备，大部分人都是使用设备的，经常去使用的应当是各个设备的联动。所以用户有两种提供设备的人，使用设备的人。提供设备的人一般不关心接入用户使用的系统，而是关心怎么把硬件接入系统。\n简单功能分析 协议问题 设备和系统间通信提供socket协议以及蓝牙协议，具体的加密协议设备厂商自定义；在提供设备时，需要提供一份通信协议的sdk以便传输数据时加解密。\n设备接入 使用socket接入的设备商需要给设备固定mac地址并标识出来，蓝牙方式接入的设备不做要求；接入时，socket设备提供接入接口以便平台扫描，蓝牙设备同样需要默认开启蓝牙\n用户 用户不需要手动去接入设备，由平台自动扫描接入；但是用户需要给设备命名(修改设备信息时，mac地址不可修改）、根据设备商提供的说明上传sdk并为设备指定sdk。\n平台 平台就比较复杂了，需要提供协议管理、设备管理以及用户管理。\n需求 设备管理 设备接入 设备接入可以选择socket接入或者蓝牙接入，设备启动后由平台自行扫描，如果设备同时提供两种方式，则优先选择socket模式接入。接入时自动记录设备的相关信息到数据库，其中设备的mac地址字段需要建立索引，接入类型需要标注为socket/蓝牙，接入后，需要提示管理员立刻去更新设备信息以及指定协议管理中上传的通信的sdk。\n设备online/offline 设备接入后，默认为上线状态，后续扫描设备时，如果发现设备未被扫描到，重试扫描后还未发现，将设备状态改为下线状态。对外提供此设备上下线消息\n设备状态检测 检测设备的实时状态，可在设备信息中设置是否需要被扫描，设置后的设备才会被定时检测\n协议管理 协议sdk上传指定厂商和版本号，自动保存一条协议记录。\n用户管理 用户在设备接入后，会收到根据接入通知。用户收到接入通知后，需要去修改设备信息，为其指定厂商以及协议sdk等信息。\n如果厂商还未添加，需要先添加厂商，然后上传协议sdk到指定厂商的指定设备下\n事件联动 设备可提供的事件需要封装在协议sdk中，这些事件，分协议：如果是socket协议通信的设备，只接受ip和port；如果是蓝牙，只接受mac地址\n","description":"\n","tags":["Pgroza","物联网平台","物联网"],"title":"\n物联网平台——Pgroza（一）","uri":"/posts/post-13/"},{"categories":["默认分类"],"content":"国内注册商,国内站长和企业喜欢的注册商 www.net.cn 国内新后缀注册商 west.cn 363.hk zzy.cn 国内二位后缀域名注册商 quyu.net 国际注册商 Porkbun.com Dynadot.com Godaddy.com Namecheap.com Name.com Namesilo.com Uniregistry.com AllDomains.hosting 各后缀域名抢注平台 .com .net .org .cn .cc: juming.com\n.info .mobi .asia .xxx .pro .red .black .bet .blue .ac .us ：Dynadot.com\n新后缀抢注平台 Hexonet.net zzy.cn west.cn 国别后缀抢注平台 .ac .ag .bz .gg .io .je .ly .me .mn .sc .sh .to .vc ： park.io\n.eu .be .ch .de .fr .it .li .nl .uk ： catchtiger.com\n.es .it ： nidoma.com\n.nu .se ： webb.se 、rymdweb.com\n.nz ： expireddomains.co.nz\n.id .ly .tw ： docky.ly\n.ru .su ： nic.ru\n.cx .gs .hk: 363.hk\n查询工具 whois 查询： who.is\n域名溢价查询： yijia.me\n最终核实域名是不是可以注册： domai.nr、whois.domaintools.com、注册局\n注册局官网以及联系方式查询：https://www.iana.org/domains/root/db/xxx.html 将 xxx 替换为某个后缀\n可注册域名扫描（米友作品）： name.tg\n域名过期时间删除时间查询： expireddomains.net\n域名后缀注册量查询: www.363.hk/web/registration\n新后缀目前市场占有率查询： namestat.org\n全球每天有哪些域名被注册了： dnpedia.com/tlds/daily.php\n国内有哪些后缀可以备案： 域名.信息\n国内平台域名成交价格查询： wanmi.cc\n国际域名成交价格查询： namebio.com\n域名在哪里注册最便宜： tld-list.com 、nazhumi.com\n域名被墙污染查询： zijian.aliyun.com/#/domainDetect\n域名建站历史查询： archive.org\n域名 DNS 修改历史查询： completedns.com\n域名优惠活动： Namebeta.com\n域名备案查询: micp.chinaz.com\n","description":"\n","tags":[],"title":"\n域名工具网站","uri":"/posts/post-316/"},{"categories":["默认分类"],"content":"“scroll from source”快捷方式 ？ 先按“Option + F1”，再按“Enter”或“1”键。 打开终端 Terminal 的快捷键 ？ Option + F12 打开 project 的快捷键 ？ Command + 1 进入调用接口的快捷键 ？ Command + B 进入调用接口的实现方法快捷键 ？ Command + Option + B 提取变量名 ？ Command + Option + V ","description":"\n","tags":[],"title":"\nmac下 IDEA 特殊的快捷键","uri":"/posts/post-317/"},{"categories":["默认分类"],"content":"mac\n首先先声明一下，我这个破解方法的版本是12.022(官网最新的是15的,不清楚能不能,没测试),分享一波 安装包下载\nNavicat Premium 是一套数据库开发工具，让你从单一应用程序中同时连接 MySQL、MariaDB、MongoDB、SQL Server、Oracle、PostgreSQL 和 SQLite 数据库。它与 Amazon RDS、Amazon Aurora、Amazon Redshift、Microsoft Azure、Oracle Cloud、MongoDB Atlas、阿里云、腾讯云和华为云等云数据库兼容。你可以快速轻松地创建、管理和维护数据库。\n废话不多说,上破解方法.\n第一步：保存秘钥 公钥：(存储为名为rpk的文件,备用)\n-----BEGIN PUBLIC KEY----- MIIBITANBgkqhkiG9w0BAQEFAAOCAQ4AMIIBCQKCAQB8vXG0ImYhLHvHhpi5FS3g d2QhxSQiU6dQ04F1OHB0yRRQ3NXF5py2NNDw962i4WP1zpUOHh94/mg/KA8KHNJX HtQVLXMRms+chomsQCwkDi2jbgUa4jRFN/6N3QejJ42jHasY3MJfALcnHCY3KDEF h0N89FV4yGLyDLr+TLqpRecg9pkPnOp++UTSsxz/e0ONlPYrra/DiaBjsleAESZS I69sPD9xZRt+EciXVQfybI/2SYeAdXMm1B7tHCcFlOxeUgqYV03VEqiC0jVMwRCd +03NU3wvEmLBvGOmNGudocWIF/y3VOqyW1byXFLeZxl7s+Y/SthxOYXzu3mF+2/p AgMBAAE= -----END PUBLIC KEY----- 私钥：\n-----BEGIN RSA PRIVATE KEY----- MIIEogIBAAKCAQB8vXG0ImYhLHvHhpi5FS3gd2QhxSQiU6dQ04F1OHB0yRRQ3NXF 5py2NNDw962i4WP1zpUOHh94/mg/KA8KHNJXHtQVLXMRms+chomsQCwkDi2jbgUa 4jRFN/6N3QejJ42jHasY3MJfALcnHCY3KDEFh0N89FV4yGLyDLr+TLqpRecg9pkP nOp++UTSsxz/e0ONlPYrra/DiaBjsleAESZSI69sPD9xZRt+EciXVQfybI/2SYeA dXMm1B7tHCcFlOxeUgqYV03VEqiC0jVMwRCd+03NU3wvEmLBvGOmNGudocWIF/y3 VOqyW1byXFLeZxl7s+Y/SthxOYXzu3mF+2/pAgMBAAECggEAK5qZbYt8wenn1uZg 6onRwJ5bfUaJjApL+YAFx/ETtm83z9ByVbx4WWT7CNC7fK1nINy20/mJrOTZkgIx x6otiNC4+DIsACJqol+RLoo8I9pk77Ucybn65ZteOz7hVZIU+8j6LzW0KDt6yowX e75r7G/NEpfibNc3Zz81+oDd2x+bHyGbzc9QcePIVuEzkof6jgpbWrQZU14itx9l VxEgj/fbMccvBx8brR/l9ClmDZd9Y6TWsF1rfJpF3+DPeqFkKCiD7PGz3bs4O/Zd ZrfV21ZNVusBW49G6bU63gQVKsOf1qGo3efbAW1HVxgTQ/lExVdcMvdenZm+ADKp L4/wUQKBgQDOfBjn3OC2IerUFu18EgCS7pSjTSibXw+TeX3D5zwszLC091G2rGlT 5DihBUhMfesNdpoZynrs4YB6Sz9C3wSGAB8AM/tNvPhtSVtbMHmrdT2DEEKCvLkO RNBnt+8aTu2hGRanw9aL1189gzwrmXK5ZuuURfgLrB9ihrvjo4VznQKBgQCapx13 dEA1MwapBiIa3k8hVBCoGPsEPWqM33RBdUqUsP33f9/PCx00j/akwmjgQNnBlAJo Y7LOqPCyiwOkEf40T4IlHdzYntWQQvHhfBwqSgdkTE9tKj43Ddr7JVFRL6yMSbW3 9qAp5UX/+VzOLGAlfzJ8CBnkXwGrnKPCVbnZvQKBgQCd+iof80jlcCu3GteVrjxM LkcAbb8cqG1FWpVTNe4/JFgqDHKzPVPUgG6nG2CGTWxxv4UFKHpGE/11E28SHYjb cOpHAH5LqsGy84X2za649JkcVmtclUFMXm/Ietxvl2WNdKF1t4rFMQFIEckOXnd8 y/Z/Wcz+OTFF82l7L5ehrQKBgFXl9m7v6e3ijpN5LZ5A1jDL0Yicf2fmePUP9DGb ZTZbbGR46SXFpY4ZXEQ9GyVbv9dOT1wN7DXvDeoNXpNVzxzdAIt/H7hN2I8NL+4v EjHG9n4WCJO4v9+yWWvfWWA/m5Y8JqusV1+N0iiQJ6T4btrE4JSVp1P6FSJtmWOK W/T9AoGAcMhPMCL+N+AvWcYt4Y4mhelvDG8e/Jj4U+lwS3g7YmuQuYx7h5tjrS33 w4o20g/3XudPMJHhA3z+d8b3GaVM3ZtcRM3+Rvk+zSOcGSwn3yDy4NYlv9bdUj/4 H+aU1Qu1ZYojFM1Gmbe4HeYDOzRsJ5BhNrrV12h27JWkiRJ4F/Q= -----END RSA PRIVATE KEY----- 第二步：安装navicat 点击安装包一步一步安装即可\n第三步：替换公钥 finder中，右键navicat ,显示包内容，打开目录 /Contents/Resources，编辑rpk文件，用第一步的公钥替换并保存。(如果该目录下面没有rpk文件,可以直接将第一步保存备用的rpk文件移动进去就行)\n第四步：断网 第五步：打开navicat 根据navicat输入以下序列号：\n中文版64位密钥序列号： NAVH-T4PX-WT8W-QBL5\n英文版64位密钥序列号： NAVG-UJ8Z-EVAP-JAUW\n如果注册码右边出现的 ✔️，那么恭喜你，可以继续往下进行了。如果右边是黑色的❌,那么请从第头再来一遍。\n第六步：手动激活 由于断了网，则会出现激活失败，选择点击手动激活\n第七步：复制请求码 第八步：获取请求码明文 登录这个网址 http://tool.chacuo.net/cryptrsaprikey\n在输入加密私钥位置 填上第一步的私钥\n在待加密解密的文本 填上请求码(第七步中复制的)，点击RSA私钥解密。\n请注意：如果没出现请求码明文可能是\n1：网络问题，请多试几次\n2：请检查第三部rpk文件是否替换成功！(如果没有出现很可能是这个原因,再确认一下)\n第九步：替换时间戳 将请求码明文中的 K和DI的值替换到下面对应的地方，\n{“K”:“NAVHT4PXWT8WQBL5”, “N”:“52pojie”, “O”:“52pojie.cn”, “DI”:“ODQ2Yjg2ZDBjMTEzMjhh”, “T”:1616939200}\n再登录 https://unixtime.51240.com/\n调整到现在的时间(不用那么精确,没关系)，并把Unix时间戳替换到上面的T后面\n第十步：获取激活码 将替换好的文本，放入在待加密解密的文本 中，点击RSA加密，得到加密后的文本\n第十一步：输入并点击激活 输入激活码并点击激活。\n本文转载于https://my.oschina.net/u/4271891/blog/4256494 ","description":"\n","tags":[],"title":"\nMAC Navicat Premium Mac 12 破解(亲测可用!!!）","uri":"/posts/post-318/"},{"categories":["默认分类"],"content":"Git 官网下载：http://git-scm.com/download/mac 安装过程和 Windows 没啥区别，都是下一步下一步。 IntelliJ IDEA 对 Git 的支持很好，也不需要额外配置什么，IntelliJ IDEA 的 Git 操作都很便捷强烈使用 IntelliJ IDEA 作为 Git 的 GUI 操作工具。 Homebrew 方式（推荐）：brew install git JDK 官网下载 JDK7：http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html 官网下载 JDK8：http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html jdk-8u231-macosx-x64.dmg 百度云（d8rj）：https://pan.baidu.com/s/1VFAi0gpMWikTgjTQokZEhQ Java 开发环境理论上一般都是这个优先安装的。 安装过程和 Windows 没啥区别，都是下一步下一步，只是比 Windows 简单，连安装路径都不需要改而已，所以这里不截图了。 我这边不管是 Windows、Mac、Linux，只要开发环境，JAVA_HOME 我都是 JDK8，同时还装有 JDK6、JDK7，在使用 IntelliJ IDEA 的时候，我可以同时使用三个版本的 JDK。 JDK 的环境变量是要添加的，我这边可以贴一下。 如果你是 bash，你需要编辑的是这个：vim ~/.bash_profile 修改后之后刷新配置文件我是：source ~/.bash_profile 1 2 3 4 5 6 7 8 9 # JDK 1.8 JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_112.jdk/Contents/Home JRE_HOME=$JAVA_HOME/jre PATH=$PATH:$JAVA_HOME/bin CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JAVA_HOME export JRE_HOME export PATH export CLASSPATH 卸载 JDK 1 2 3 4 5 sudo rm -rf /Library/Internet\\ Plug-Ins/JavaAppletPlugin.plugin sudo rm -rf /Library/PreferencePanes/JavaControlPanel.prefPane sudo rm -rf /Library/Java/JavaVirtualMachines/jdk1.8.0_112.jdk IntelliJ IDEA 官网下载：http://www.jetbrains.com/idea/ 最优秀的 IDE，没有之一，我所有的生产力硬件设备都是为了支持它而购买的，所以内存一定要够大。 下面的 Maven、Tomcat 都是依赖于 IntelliJ IDEA 运行的，所以本质上我只要搞定 IntelliJ IDEA，其他的 Java 开发环境 IntelliJ IDEA 都会帮我们解决。 关于 IntelliJ IDEA Mac 下安装/配置等相关，请看我写的这个系列，里面有详细说明：IntelliJ IDEA 简体中文专题教程 在 IntelliJ IDEA 有几个特别的地方我单独拿出来讲讲吧： 如果启动 Tomcat 的时候报：Permission denied，你则可以：打开终端，进入 Tomcat\\bin 目录，然后执行：chmod 777 *.sh 如果启动 Tomcat 之后，控制台乱码了，并且你确认你在 IntelliJ IDEA 的 Preferences 中设置的控制台字体是支持中文的，那你可以尝试下在 Tomcat VM 参数上加上：-Dfile.encoding=UTF-8 Git 的路径配置：Preferences -- Version Control -- Git -- Path to Git executable 的值是：/usr/local/git/bin/git 那你的 IntelliJ IDEA 终端路径可以改成 zsh 的，配置方法在 Preferences -- Tools -- Terminal -- Shell path 的值改为是：/bin/zsh IntelliJ IDEA 在 Mac 下的配置文件保存路径 下面内容中：XXXXXX，表示 IntelliJ IDEA 的版本号，IntelliJ IDEA 的配置目录是跟版本号有关系的。 /Users/你的用户名/Library/Application Support/IntelliJIdeaXXXXXX，用于保存安装的插件 /Users/你的用户名/Library/Caches/IntelliJIdeaXXXXXX，用于保存缓存、日志、以及本地的版本控制信息（local history 这个功能） /Users/你的用户名/Library/Preferences/IntelliJIdeaXXXXXX，用于保存你的个人配置、授权文件，等价于 Windows 下的 config 目录 IntelliJ IDEA 设置 JDK Maven 官网下载：http://maven.apache.org/download.cgi Maven 是绿色版的，任何系统都适用。 安装方式和 Windows、Linux 没啥本质区别，都是把 zip 文件夹解压，然后新增几个系统变量，修改 Maven 配置文件参数。 我是把 Maven 解压后，直接把 Windows 的 settings.xml 复制过来，修改下该文件本地仓库的路径，其他没啥可以改的了。 然后本地仓库的那些依赖包是直接从 Windows 下拷贝过来的，这个是任何系统下都兼容的，不需要额外处理。 最后再用 IntelliJ IDEA 对 Maven 的配置路径重新做了修改。 以上这些点都需要你对 Maven 和 IntelliJ IDEA 有了解，对于这两个东西我也在本文章都贴了相关的文章链接，我这里不多说了，学习总是需要花时间的。 Maven 的环境变量是要添加的，我这边可以贴一下： 1 2 3 4 MAVEN_HOME=/Users/youmeek/my_software/work_software/maven3.3.9 PATH=$PATH:$MAVEN_HOME/bin export MAVEN_HOME export PATH 验证：mvn -v MySQL 5.7 官网下载 MySQL：http://dev.mysql.com/downloads/mysql/ MySQL 5.7 版本：https://dev.mysql.com/downloads/mysql/5.7.html#downloads MySQL 官网提供的 Mac 系统的安装包，是下一步下一步安装类型的，没啥难度，大家自己试一下。 需要特别注意的是：安装结束后，会提示你它生成的一个随机密码，你要复制下，等下要用 有几个点需要注意的是： 如何修改 root 密码： 打开：系统偏好设置 -- 底部的 MySQL -- 点击：Stop MySQL Server，根据提示输入你的 Mac 用户密码。 连接：sudo /usr/local/mysql/bin/mysql -h 127.0.0.1 -u root -P 3306 -p，输入刚刚复制的密码 - 修改密码：set password = password('123456'); MySQL 配置文件设置 创建文件 vim /etc/my.cnf，参考内容如下 重启 MySQL 服务即可 这里给一个 demo 示例： [mysql] default-character-set = utf8mb4 [mysqld] symbolic-links=0 log-error=/var/log/mysql/error.log default-storage-engine = InnoDB collation-server = utf8mb4_unicode_520_ci init_connect = 'SET NAMES utf8mb4' character-set-server = utf8mb4 lower_case_table_names = 1 max_allowed_packet = 50M sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION 通过命令行操作 MySQL 启动MySQL服务 sudo /usr/local/MySQL/support-files/mysql.server start 停止MySQL服务 sudo /usr/local/mysql/support-files/mysql.server stop 重启MySQL服务 sudo /usr/local/mysql/support-files/mysql.server restart 如果你要卸载 sudo rm -rf /usr/local/mysql sudo rm -rf /Library/PreferencePanes/MySQL* sudo rm -rf /var/db/receipts/com.mysql.* nginx #当前目录 /Users/maruifu/work/ComponentServices #下载nginx-1.18.0 wget http://nginx.org/download/nginx-1.18.0.tar.gz # 解压 tar -zxvf nginx-1.18.0.tar.gz #创建目录 mkdir nginx #创建模块目录 mkdir nginx-src #进入模板目录 cd nginx-src #下载pcre并解压 wget https://ftp.pcre.org/pub/pcre/pcre-8.41.tar.gz #下载openssl并解压 wget https://www.openssl.org/source/openssl-1.1.0g.tar.gz #下载zlib并解压 wget http://prdownloads.sourceforge.net/libpng/zlib-1.2.11.tar.gz #进入源码目录 cd ../nginx-1.18.0 #配置nginx ./configure \\ --with-http_gzip_static_module \\ --with-pcre=../nginx-src/pcre-8.41/ \\ --with-http_ssl_module \\ --with-openssl=../nginx-src/openssl-1.1.0g \\ --with-zlib=../nginx-src/zlib-1.2.11 \\ --prefix=/Users/maruifu/work/ComponentServices/nginx/nginx \\ #编译并安装 make \u0026\u0026 make install brew install wget\n","description":"\n","tags":[],"title":"\nmacOS 下git+ Java + Maven + MySql + Nginx 开发环境","uri":"/posts/post-319/"},{"categories":["默认分类"],"content":"原因 其默认启动执行脚本变为了~/.zshrc，所以总会显示zsh：xxx not found\n解决方法 在终端中输入\necho ‘source ~/.bash_profile’ \u003e\u003e ~/.zshrc ","description":"\n","tags":[],"title":"\nMac终端配置好的环境变量在关闭终端后失效怎么办","uri":"/posts/post-320/"},{"categories":["默认分类"],"content":"MAC\nAwesome Mac  现在我们变得非常大，与最初的想法不同，如今我们需要收集各种类别非常好用的 Mac 应用程序、软件以及工具。\n开发者工具 编辑器 一种用于编辑纯文本文件的程序，建议使用免费开源的编辑器\nAtom - GitHub 推出的开源编辑器，Atom常用插件。 Android Studio - Android 的官方 IDE，基于 Intellij IDEA。 Brackets - Adobe 推出的 Brackets 免费/开源编辑器。 BBEdit - 强大的文件编辑器，用于编辑文件，文本文件及程序源代码。 Coda2 - 用于编写 Web 应用，长得漂亮的编辑器。 CotEditor - 轻量级的纯文本编辑器。 Chocolat - 轻量级本地编辑器。 Deco IDE - React Native IDE 支持控件拖拽界面实时变更。 Espresso - Web 编程利器，具备了快速且强大的编辑功能、专业检查与分类、即时预览编辑成果、发布与同步功能等。 Emacs - Emacs 是基于控制台的编辑器和高度可定制的。 Eclipse - 流行的开源 IDE，主要用于 Java，也为多种语言提供插件支持。 Sublime Text - 一个比较简洁大方带插件管理系统的流行编辑器，Sublime常用插件。 Haskell for Mac - Haskell 的现代开发环境。 HBuilder - HBuilder 是 DCloud（数字天堂）推出的一款支持 HTML5 的 Web 开发 IDE。 JetBrains Toolbox App - 管理已安装的JetBrains工具，下载新工具并打开最近的项目。 CLion - 强大的 C 和 C++ IDE。(学生免费) DataGrip - 用于数据库和SQL的跨平台IDE。 (学生免费), 查看此处了解更多。 Rider - 跨平台 C# IDE。 它是 Microsoft 的 Visual Studio 的替代方案. AppCode - 适用于 iOS / macOS 开发的智能 IDE PyCharm - 一款 Python 开发集成环境，有专业版和社区版。 IntelliJ IDEA - 一款 Java 开发集成环境。(学生免费) GoLand - JetBrains出品的Go开发IDE，智能，灵活 Webstorm - 是 JetBrains 公司旗下一款 JavaScript 开发工具。学生免费，点击这里 查看更多。 NodeJS - 集成 Node.js，你肯定需要它，很多功能需要它。 EditorConfig - 帮助开发者在不同的编辑器和 IDE 之间定义和维护一致的代码风格。 Material Theme UI - Google 为 React 开发的主题。 LightTable - 下一代代码编辑器。 开源地址 micro - 一个现代直观的基于终端的文本编辑器。 开源地址 NetBeans IDE - 免费、开源的 IDE，主要用于 Java 开发，可支持多种语言和框架。 ONI - 由 Neovim 提供的 IDE。 Qt - 跨平台 C++ 图形用户界面应用程序开发框架。 TextMate - 文本编辑器软件，与 BBedit 一起并称苹果机上的 emacs 和 vim。 开源地址 Tincta - 一个免费的文本编辑器。 开源地址](https://github.com/CodingFriends/Tincta) Visual Studio Code - 微软推出的免费/开源编辑器，TypeScript 支持杠杠的，VSCode常用插件。 开源地址 Vim - Vim 古老的终端中使用的编辑器，Vim常用插件。 开源地址 Vimr - Vim 客户端，升级 Vim 体验。 开源地址 Visual Studio Community for Mac - 免费，开源，功能齐全的 IDE。 Xamarin Studio - 免费的跨平台的 C# IDE。支持 IOS、Android 和 .net 开发。 开源地址 Xcode - 开发 iOS 和 MacOS 基本 IDE。 开发者实用工具 BetterRename - 一款强大的批量重命名工具，可以通过搜索功能改名。 Beyond Compare - 对比两个文件夹或者文件，并将差异以颜色标示。 CodeKit - 自动编译 Less、Sass、Stylus、CoffeeScript、Jade \u0026 Haml等文件。 Cacher - 基于云的团队代码片段管理器，具有Gist同步，VSCode/Atom/Sublime软件包和Mac/Windows/Linux/Web客户端。 Dash - 强大到你无法想象的 API 离线文档软件。 DiffMerge - 可视化的文件比较（也可进行目录比较）与合并工具。 EnvPane - 图形终端查看环境变量的应用工具。 开源地址 Fanvas - 把 swf 转为 HTML5 canvas 动画的系统。 开源地址 FinderGo Finder 中快速打开终端，定位到目录 开源地址 Gas Mask - 编辑 hosts 文件的工具，更简单方便。 开源地址 Go2Shell - 从 Finder 打开命令行。 Gemini - 智能的重复文件查找器。 Hosts.prefpane - 编辑 hosts 文件的工具。 开源地址 Hex Fiend - 快速而聪明的开源十六进制编辑器。 开源地址 iHosts - 唯一上架 Mac App Store 的 /etc/hosts 编辑神器。 Integrity - 轻松找到无效链接。 Koala - 预处理器语言图形编译工具，支持 Less、Sass、CoffeeScript、Compass framework 的即时编译。 开源地址 Kaleidoscope - 一款很强大的文本文件和图像比较工具，同时和 git、svn 等版本控制工具能够完美的结合。 Localname - 提供对本地开发服务器的访问权限。 MJML - 简化设计回应电子邮件的方式。 开源地址 PaintCode - 将设计转换成 Objective-C, Swift 或 C# 代码。 PushMate 可通过确保推送有效载荷正确来解决常见的推送通知问题。 PPRows - 计算你写了多少行代码。 开源地址 SwitchHosts - 一个管理、切换多个 hosts 方案的工具。 开源地址 SCM Breeze - 用于增强与git交互的shell脚本集(用于bash和zsh)。 开源地址 SnippetsLab - 管理和组织你的代码片段。 StarUML - 强大的软件建模软件。 SecureCRT - 一款支持 SSH、Telnet 等多种协议的终端仿真程序。 Swiftify - Xcode ＆ Finder 扩展 Objective-C 转 Swift 代码转换器 SYM - 一个图形化的崩溃日志解析工具。 开源地址 TeXstudio - 集成创建 LaTeX 文档的写作环境。 开源地址 uTools - 一款基于插件的程序员效率工具，包含非常多的实用插件，如图床、UUID、密码、翻译、JSON格式化等。 Vagrant Manager - 管理你本地服务。 开源地址 Vagrant - 用来构建虚拟开发环境的工具。 开源地址 WeFlow - 一个基于 tmt-workflow 前端工作流的开发工具。 开源地址 Woodpecker - 在Mac上查看、编辑iOS App的沙盒文件, UserDefaults, Keychain项 zeplin - 前端与设计协同工作专用工具。 正则编辑器 Patterns - 正则表达式编辑器。 Regex - 感觉是用过最漂亮的正则表达式测试工具。 Reggy - 正则表达式编辑器。 开源地址 RegExRX - 正则表达式的开发工具。 API开发和分析 Cocoa Rest Client - 比 Postman 看起来漂亮的客户端，测试 HTTP/REST endpoints。 开源地址 Insomnia - 最直观的跨平台 REST API 客户端。 开源地址 Postman - Postman 帮助我们快速测试 API。 Katalon Studio - 简单开放性测试前端开放工具， 网页， 手机应用等客户端。 可以使用在不同的浏览器 网络分析 Charles - 一个代理工具，允许你查看所有的 HTTP 和 HTTPS 流量。 James - 用于 https 和 http 进行查询映射请求。 开源地址 mitmproxy - 一款支持 HTTP(S) 的中间人代理工具，可在终端下运行，可用于抓包 开源地址 Paw - 先进的 HTTP 客户端。 Proxie - HTTP 调试客户端。 Proxyman - 适用于 macOS 的现代直观 HTTP 调试代理. Wireshark - 世界上最广泛使用的网络协议分析软件。 开源地址 命令行工具 A curated list of shell commands and tools specific to OS X.\nautojump - 告别又臭又长的路径名，一键直达任何目录。 开源地址 bash-it - 一个社区的 bash 的框架。** 开源 ** bat - 带有语法高亮和Git集成的 cat(1) 克隆。 开源地址 color-retro-term - 一款复古风格的终端，非常酷炫。 cool-retro-term - 怀旧的命令行终端。 开源地址 Cakebrew - Homebrew 的客户端软件。摆脱命令方便安装、查看、卸载软件。 开源地址 cmus - 命令行播放音乐应用。 开源地址 Dnote - 命令行上的笔记本，支持多设备同步和网络界面。 开源地址 Fish Shell - 智能且用户友好的命令行终端。 Glances - 在命令行中查看你系统运行状态的工具。 开源地址 httpie - HTTPie 是一个让你微笑的命令行 HTTP 客户端。 开源地址 hyper - 基于 Web 技术的终端，直接替代自带的 Terminal。 开源地址 HyperTerm - 一款基于 Node 开发的终端软件，逼格很高。 开源地址 iTerm2 - 免费的终端工具，直接替代自带的 Terminal，有非常多惊人的特性。 开源地址 itunes-remote - 通过终端控制您的 iTunes。 开源地址 job - 短命令并发、重复执行工具, 适用于压测. 开源地址 LNav - 日志文件阅读器. 开源地址 mycli - 为 MySQL 命令行客户端，提供语法高亮和提示功能的工具！ 开源地址 m-cli - 用于 macOS 的瑞士军刀。 开源地址 Mac-CLI - 自动化您的 OS X 系统的使用。 开源地址 mas - 一个简单的命令行界面的苹果应用商店。 开源地址 ndm - 查看本地NPM安装的包客户端软件。摆脱命令方便安装、查看、卸载软件。 开源地址 pgcli - 为Postgres提供一个支持自动补全和语法高亮的命令行工具。 开源地址 silver searcher (ag) - 类似于ack的代码搜索工具，专注于速度。 开源地址 Serial - 为工程师和系统管理员嵌入式硬件更容易。 spaceship - 一个简约，功能强大且极易定制的Zsh提示。 开源地址 Tabby (formerly Terminus) - 免费的终端工具，基于 Web 技术的终端，用 TypeScript 写成的跨平台终端工具。深受 hyper 启发。 开源地址 Termius - 免费的终端工具，可以与 windows 平台的 xshell 媲美。 thefuck - 一个纠正错误命令的工具，输入错误命令后，输入fuck就可以修正成正确的命令行命令，支持自定义的bash_profile命令[ 开源地址] tmux - 一个优秀的终端复用器类自由软件。 开源地址 tmuxinator - Tmux的配置管理工具。 开源地址 ttygif - 将终端录制转换为 GIF 动画。 开源地址 trash - 将文件和目录移动到废纸篓。 开源地址 Upterm - Upterm (之前是 Black Screen) 来自 21 世纪的强大终端。 Zsh - 一个专为交互式使用而设计的命令行 shell。 开源地址 版本控制 Git - 版本控制工具，官网提供数十种 GUI 客户端 for Mac。 开源地址 SVN - 版本控制工具。 GUI Cornerstone - Mac 上最佳的 SVN 管理工具。 Fork - 一个快速友好的 Git 客户端。 GitFinder - 一个快速和轻量级的 Git 客户端的 Mac 与 Finder 集成。 GitX - Pieter’s的衍生版本，维护增强生产力和团队开发变化。 开源地址 Gitbar - 开源，在你的菜单栏上显示 GitHub 贡献统计。 开源地址 GitHub Desktop - 使用 GitHub 的 GUI 应用。 GitUp - 一个简单功能强大的 Git 客户端。 开源地址 GitKraken - 最流行的图形用户界面的 git 管理工具。 Hub - 将 GitHub 接口和 Git 命令进行包装。 开源地址 OhMyStar 最好的组织 Github Star 的软件。 SourceTree - 强大的 Git 跨平台客户端。 SmartGit - 非商业用途免费，全平台支持，集成 Github 服务。 Sublime Merge - Git客户端，来自Sublime Text的制造商。 Tower2 - 最强大的 Git 客户端。 Versions - Mac 上最好的 SVN 管理工具。 版本控制系统 Coding.net - 代码托管，项目管理，WebIDE，演示部署，开启云端开发模式，让开发更简单。 GitLab - 一个用于仓库管理系统的开源项目。 GitHub GitHub 托管代码，项目管理，演示部署，瞧，您现在就在访问GitHub。 Gogs - 一款极易搭建的自助 Git 服务 Golang 版本。 开源地址 Gerrit Gerrit 是一个免费、开放源代码的代码审查软件，使用网页界面。 Gitblit Java 版本 Git 代码托管，项目管理。 开源地址 Gitea - Gogs 的 fork 版本。** 开源 ** phabricator phabricator 支持 Git、SVN、HG 基于 PHP + Mysql 的开放源代码软件开发平台。 数据库 Another Redis Desktop Manager - 一款稳定全新的Redis管理工具。** 开源 ** Bdash - SQL 客户端应用程序，支持 MySQL、 PostgreSQL (Redshift)、 BigQuery。** 开源 ** Base 2 - 一个用于管理 SQLite 数据库的软件。 Chrome MySQL Admin - 一个 Chrome 插件，是 MySQL 开发的跨平台、可视化数据库工具。 开源地址 Core Data Editor - 核心数据编辑器可让您轻松查看，编辑和分析应用程序的数据。 开源地址 DB Browser for SQLite - 一个跨平台的用于管理 SQLite 数据库的软件。 开源地址 DataGrip - JetBrains 公司旗下一款数据库管理工具。点击这里 学生免费。 DBeaver - 跨平台 SQL 客户端，支持大部分主流数据库 ElectroCRUD - MySQL 数据库 CRUD 应用程序。 开源地址 Sequel Pro - 一个 MySQL 数据库管理软件。 开源地址 JackDB - 直接的 SQL 访问你所有的数据，无论在哪里。 开源地址 medis - 漂亮的 Redis 管理软件。 开源地址 MongoDB - 一个基于分布式文件存储的数据库。 开源地址 MongoBooster - MongoDB 图形化管理软件，内嵌 MongoShell，ES6 语法，流畅查询及智能感知。 mongoDB.app - 在Mac 上最简单的使用 MongoDB。 开源地址 Mongo Management Studio - MongoDB 图形化客户端管理软件。 MDB Explorer - Mac 上查看编辑 Access 数据库的工具。 MySQL Workbench - MySQL 数据库官方管理软件。 Navicat Data Modeler - 一个数据库设计工具，它帮助创建高质素的概念、逻辑和物理数据模型。 Postico - 现代 PostgreSQL 客户端，漂亮功能多。 Postgres.app - Mac 上最简单的方法的使用 PostgreSQL 关系型数据库管理系统。 开源地址 PSequel - PostgreSQL 数据库 GUI 软件。 pgModeler - 是一个专为PostgreSQL设计的开源数据建模工具。 开源地址 RedisClient - 漂亮跨平台的Redis管理软件。 开源地址 RedisDesktopManager - Redis 跨平台的 GUI 管理工具。 开源地址 SQLPro Studio - 支持 SQL Server, Postgres, Oracle 以及 MySQL 等主流的数据库可视化管理工具. SQLight - 一个 SQLite 数据库管理器工具，非常好用。 TablePlus - 支持 PostgreSQL，MySQL，RedShift，MariaDB… 各种数据库的高颜值客户端。 开源地址 Tableau Public - 数据可视化工具。 Keylord - Redis，Bolt，LevelDB 和 Memcached 键值数据库的桌面GUI客户端。 redis-pro - 轻量，易用的 Redis 客户端管理工具，使用SwiftUI编写，很好的支持 Dark mode。 开源地址 设计和产品 设计工具 Acorn - 一个像 PS，全面的功能集的图像编辑器。 Affinity Designer - 矢量图像设计工具，可以是 Adobe Illustrator 的替代。 Affinity Photo - 光栅图像设计工具，可以替代 Adobe PS 图象处理软件。 Alchemy - 开源的绘图工具软件，用于素描、会话以及一种新的绘图方式。 开源地址 Art Text 3 - 生成各种特效字体。 Blender - 全功能可扩展的跨平台 3D 内容套件。 开源地址 Figma - 一款基于 Web 的实时协作的云设计软件。 FontForge - 字体编辑工具。 开源地址 GIMP - 图像编辑软件，号称 Linux 下的 PhotoShop，同时有 Mac 版本。 开源地址 Gravit Designer - 混合矢量/位图布局应用，比起 Sketch 还差一点。 inklet - 将 Mac 上的触摸板变成绘图板。 Inkscape - 一款开源矢量图形编辑软件，与 Illustrator、Freehand、CorelDraw、Xara X 等其他软件相似。 开源地址 Krita - 一个开源的位图形编辑软件，包含一个绘画程式和照片编辑器。 开源地址 Monodraw - macOS 平台上强大的 ASCII 设计流程编辑器。 MagicaVoxel - 轻量级的8位像素编辑和交互路径追踪渲染器。 MakeHuman - 功能强大且免费的3D人体建模器。 Nik Collection - 专业照片后期制作工具，Google 收购后免费 Pixelmator - 强大的图像编辑器，可能PS图像处理软件的选择。 Paintbrush - 位图图像编辑器。 开源地址 Pencil2D - 制作2D手绘动画的简单直观的工具。 开源地址 Principle - 使用它很容易设计动画和交互式用户界面。 Pixel Perfect - 比较 UI 模型和开发结果非常容易。 Sculptris - 所见所得的 3D 建模。 Sketch - 混合矢量/位图布局应用，特别适用于用户界面，Web 和移动设计。 Sketch Toolbox - 一个超级简单的 Sketch 插件管理器。 开源地址 Measure - 设计稿标注、测量工具。 开源地址 User Flows - 直接从画板生成流程图。 开源地址 Sketch Cache Cleaner - 清理 Sketch 历史文件，释放磁盘空间。 开源地址 SketchBook - 出众的绘图软件。 ScreenToLayers - 轻松导出桌面分层文件 PSD 文件。 开源地址 Sparkle - 可视化网页设计工具。 Tayasui Sketches - 专业的绘图软件。 Vectr - 免费图形编辑器。这是一个简单而强大的 Web 和桌面跨平台工具，把你的设计变成现实。 原型流程 Axure RP 8 - 画原型图工具，团队协作，方便好用。 ProtoPie - 高保真交互原型设计。 Adobe XD (Experience Design) - 用于网站和移动应用的设计和原型设计。 Balsamiq Mockups - 一个快速的网页设计原型工具，帮助你更快、更聪明的工作。 Origami Studio - 一种设计现代界面的新工具，由 Facebook 设计师构建和使用。 Flinto - 快速制作高保真的互交原型工具，支持 Sketch 导入。 Kite - 一个强大的动画制作工具制作 Mac 和 iOS 原型中的应用。 Justinmind - 功能更丰富团队协作方便。 MockFlow - 用于网页设计和可用性测试的在线原型设计套件。 pencil - 开源免费制作软件原型的工具 开源地址 Mockplus - 更快更简单的原型设计工具。 OmniGraffle - 可用来绘制图表、流程图、组织结构图、思维导图以及插图或原型。 XMind - 一款实用的思维导图软件。 Lighten - XMind 出品的一款实用的思维导图软件。 Loremify - 快速准确的设计，原型或生成标题，段落，列表和文章。 Scapple - 一款实用的思维导图软件。 Framer - 做交互原型的工具。 Marvel - 简单设计，原型设计和协作。 MindNode - 简洁的风格与人性化的操作，绘制思维脑图。 WriteMapper - 专为写作者而设的脑图工具。 SimpleMind - 超小体积的思维导图工具。 macSVG - 设计 HTML5 SVG 和动画. 开源地址 作图工具 Draw.io - 上百种图形，支持多种格式导出。 OmniGraffle - Omni 成员，native 应用。 ProcessOn - 流程图、思维导图、原型图… 中文友好，免费保存 5 个文件。 截图工具 GifCapture - 开源 macOS 截屏生成 Gif 工具。 开源地址 Gifox - 专业的高颜值 GIF 录制应用。 GIF Brewery - gives everyone the power to create stunning GIFs from video files. GIPHY Capture - 免费软件的捕捉和分享图片在桌面上。 Kap - 轻量 GIF 录屏小工具。 开源地址 KeyCastr - 录屏好帮手，实时显示按键操作的小工具。 开源地址 Licecap - 是一款屏幕录制工具输出 GIF，录制过程中可以随意改变录屏范围。 开源地址 Monosnap - 制作截图，录制视频共享文件。 Skitch - 截图附带强大的标注功能。 Shifty - 一个菜单栏应用程序，让您更多地控制夜班。 开源地址 ScreenShot PSD - 将屏幕捕获存为分层的 PSD，便于编辑。 Snipaste - 一个简单但强大的截图工具。 Snip - 高效的截图工具，支持滚动截屏，腾讯作品。 Teampaper Snap - 为设计师量身定做的屏幕截图兼注释工具。 截图(Jietu) - 截图附带强大的标注功能，腾讯作品。 Xnip - 免费好用的滚动截屏利器。 iShot - 完全免费、功能全面的截图工具，支持贴图、滚动截图、延时截图等。 其它工具 APNGb - 编辑 png 图片格式的软件。 开源地址 Assetizr - 图片编辑应用，轻松更改图片尺寸，压缩图片，重命名图片。 AppIconBuilder(图标构建) - App图标多平台一键导出。 Couleurs - 简单的屏幕取色应用程序。 Eagle App - 强大的图片、视频、音频、設計素材及文件管理软件。 Frank DeLoupe - 支持 Retina 的屏幕拾色器。 Image2icon - 将你的图片转换成图标。 ImageAlpha - 压缩 PNG 图片，去掉无效的透明。 开源地址 ImageOptim - 压缩图片，删除 EXIF 信息。 开源地址 iPic - 上传图片至七牛、阿里云等图床，支持 Markdown 链接。 IconKit - App图标自动生成器。 (https://itunes.apple.com/cn/app/iconkit-icon-resizer-for-app/id507135296?mt=12) Iconjar - 图标管理软件，带组织和搜索功能。 JPEGmini - 将图像尺寸降低高达 80％，而不会影响质量。 Preset Brewery - 将Lightroom预设转换为Adobe Camera Raw的工具。 PicGo - 支持常用 cdn 的图床工具。 开源地址 Resize Master - 更快速和容易批量调整图像和加水印。 RightFont - 字体管理工具。 svgus - SVG 图片管理器。 Solarized - 干净清爽的颜色主题，支持 iTerm、Intellij IDEA、Vim 等。 Sip - 收集，整理和分享你的颜色拾色器。 Spectrum - 一款可以轻松直观地创建漂亮配色方案的应用程序。 TinyPNG4Mac - 图片压缩专用开源工具。 开源地址 Tropy - 照片档案管理工具。 开源地址 uPic - macOS 原生应用，功能强大且简洁的图床客户端。 开源地址 马克鳗 - 高效的设计稿标注、测量工具。 虚拟机 Docker - 开源的应用容器引擎。 开源地址 DockStation - 管理 Docker 项目的程序。 开源地址 Parallels Desktop - 虽然好用但是收费机制，更新花钱、花钱、花钱。 Portainer - 基于网页管理 Docker 容器和 swarm 集群。 开源地址 Virtual Box - 免费、免费、免费，带 NTFS 读写，不用买 ParagonNTFS，省100块。 VMware Fusion - 强大的虚拟机，商业软件。 Veertu - Mac 上轻量级的虚拟机。通过一种高响应，沙箱且本地化的方式在你在 Mac 上运行虚拟机。 通信 推荐一些通信工具，沟通，团队协同。\nAdium - 呃，这个是老的集成多个平台的聊天客户端。 BearyChat - 互联网团队协作，沟通工具。 ChitChat - WhatsApp 非官方。 开源地址 Electronic WeChat - 调用微信接口，使用 Electron 开发的第三方漂亮开源微信应用。 开源地址 Franz - 一个使用 Electron开发的，可以同时登录 23 个平台的即时通讯软件。 Flume - 简约大气高逼格的Instagram，如果只是浏览点赞评论，免费版已经足够用。 Gitter - 关于 GitHub 的项目交流，支持 Markdown，对开发者极为友好。 Keybase - 一个安全的消息应用程序! 开源地址 Maipo脉搏 - 微博第三方 Mac 应用。 Messenger - Facebook 第三方聊天工具。 开源地址 QQ - QQ for Mac App。 Rambox - 消息和电子邮件应用程序，将常见的Web应用程序组合成一个程序。 开源地址 Skype - Skype 共享、跨平台的短信和电话。 Slack - 团队协作，沟通工具。 Telegram - 通讯新时代。 Textual - 最受欢迎的世界与我们相关的 KPI 应用 for OS X。 开源地址 Teambition - 团队协作。提供管理任务、安排日程、查找文件、即时讨论等团队所需要的一切协作功能。 WeChat - 微信 for Mac App。 WeeChat - 一个命令行聊天客户端。 Zoom - 视频会议 \u0026 屏幕共享，提供录制功能。 御飯 - 饭否第三方Mac应用。 简聊 - 企业级即时沟通工具，已经下线了，可以自己搭建一套系统玩儿。 开源地址 钉钉 - 企业级办公通讯免费平台。 零信 - 随时随地工作，跨平台。 今目标 - 一款面向中小企业的互联网工作平台。 日事清 - 工作计划软件，日志软件，项目管理，团队协作软件，个人日程管理，团队协作工具。日程安排，计划分配，笔记总结等。 RTX_腾讯通 - 企业内部可以使用的聊天软件，企业内部可以使用此通讯工具，这个软件有Mac版本也有win版本，Mac版本专为 Retina 显示优化过 Email Airmail - 快速的邮件客户端支持 Mac 和 iPhone。 Foxmail - 快速的邮件客户端。 网易邮箱大师 - 全平台的邮箱管理客户端，网易邮箱大师电脑版。 MailTags - 管理和组织邮件，日程和标签进行分类邮件。 Nylas Mail - 免费邮件客户端。 开源地址 N1 - 可以扩展的开源收费邮件客户端。 Newton(原Cloudmagic) - 界面非常简洁的一个邮件客户端。 Postbox - 这个貌似也非常强大哦，关键是简洁漂亮的收费邮件客户端。 Polymail - 简单，功能强大，长得好看的新晋邮件客户端。 Spark - 新推出的快速邮件客户端支持 Mac 和 iPhone。 ThunderBird - Mozilla 公司出品的强大的 Email 客户端程序。 Yomail - 新出的国内开发的比较好的邮件客户端。 文件共享 Cyberduck - 免费 FTP，SFTP，S3 和 WebDAV 客户端 \u0026 OpenStack Swift Client。 Flow - 支持简单的 FTP + SFTP 客户端。 Transmit - 一个 FTP 客户端，支持 FTP + SFTP + S3。 Yummy FTP - 专业快速，可靠的 FTP 客户端。 数据恢复 DiskWarrior - 恢复文件系统损坏时，磁盘工具进行选择。 Data Rescue - 多种情况下的全面和专业的数据恢复。 R-Studio for Mac - 可恢复分区被格式化、损坏或被删除的文件。 音频和视频 Audacity - 免费开源的编辑音频的软件。 开源地址 Ardour - 录制，编辑和混合多轨音频。 开源地址 Audio Hijack - 一个记录任何应用程序的音频，包括网络电话 Skype，网络流从 Safari，以及更多。 ArcTime - 跨平台字幕制作软件。 Adapter - 视频，音频和图像转换工具。 Aegisub - 免费、开源、跨平台的专业字幕编辑软件，可以快速打轴，制作特效字幕等，字幕组必备。 开源地址 Cog - 一个免费的开源音频播放器。 开源地址 Carol - 为 macOS 提供最小化和美丽的歌词应用程序。 开源地址 Elmedia Player - 支持 FLV, MP4, AVI, MOV, DAT, MKV, MP3, FLAC, M4V 等格式播放. Hydrogen - 专业鼓乐类工具，创建专业但简单而直观的鼓乐节目。 开源地址 HandBrake - 高性能的视频编码和转换工具，具有很好的图形用户界面。 开源地址 iFFmpeg - MacOS 上功能强大、易用的视频压制软件。 IINA - 基于MPV的，现代视频播放器，支持多点触摸控制。 开源地址 Kodi - 一款一流的免费开源媒体中心软件，可用于播放视频、音乐，查看图片，玩游戏等。 开源地址 LosslessCut - 跨平台工具，使用ffmpeg进行快速无损的视频和音频修剪。 开源地址 LyricsX - 一款功能完备的歌词工具。 开源地址 Metadatics - 音频元数据编辑器，支持大多数常见的音频文件。 Mixxx - 免费的DJ软件，给你一切你需要的表演组合，名副其实的替代 Traktor。 开源地址 MuseScore - 免费的作曲与乐谱软件。 开源地址 MPV - 一个免费、开源和跨平台的媒体播放器。 开源地址 Movie Catcher - 电影美剧搜索及在线观看离线下载软件，借助百度云实现离线下载以及在线播放功能。 开源地址 Natron - 开源的视频合成软件，功能与 Adobe After Effects 或者 Nuke 类似。 开源地址 Popcorn Time - 电影播放器，观看 torrent 电影。 Playback - 实验性质的视频播放器。 开源地址 Perian - 让 QuickTime 播放所有常见格式的免费插件。 开源地址 Radiant Player - Google Play音乐播放器。 开源地址 Soda Player - 一款能够直接播放种子、磁力链接、在线视频、自动获取字幕、链接和本地视频文件的播放器。 Sonora - 一个很小的音乐播放器。 开源地址 Stringed 2 - 音频编辑处理工具。 Shotcut - 免费开源视频编辑器。 开源地址 ScreenFlow - 屏幕和视频编辑软件。 Synfig Studio - 工业级、强大的 2D 矢量动画制作软件。 开源地址 SpotMenu - Spotify 和 iTunes 在状态菜单栏中显示。 开源地址 VOX Player - 免费全能音乐播放器，撸码之余听听歌是一种享受。 VLC - 开源的跨平台多媒体播放器及框架，可播放大多数多媒体文件。 开源地址 XLD - 解码/解码/转换/播放各种“无损”音频文件。 开源地址 云音乐播放器 ieaseMusic 基于网易云音乐 开源地址 QQ音乐 网易云音乐 虾米音乐 酷我音乐 酷狗音乐 音频录制与编辑 GarageBand 来自Apple的免费数字音频工作站（DAW)，提供简介低门槛的操作界面和完整的音乐录制、剪辑制作功能 Logic Pro X 来自Apple的专业数字音频工作站（DAW），提供完整专业的音乐制作功能、优秀的自带插件和音源，原生支持Apple Silicon实现高效运行 书签阅读写作 Agenda - 以日期为重点的笔记记录应用程序，用于规划和记录您的项目。 Bear Writer - 漂亮，灵活的写作应用程序，用于制作笔记和散文。 Boostnote - 为程序员量身定做的笔记应用。 开源地址 Chmox - 读 chm 文件的软件。 CHM Reader - 读 chm 文件的软件。 iChm - 读 chm 文件的软件。 开源地址 Joplin - 支持 markdown 的开源记事本和具有同步功能的待办事项列表管理器。 开源地址 Kindle App - 亚马逊 Kindle App 电子书阅读器。 Klib - 全新的 Kindle、iBooks 标注管理工具。 MarginNote - 一款优秀的 PDF 有标注软件，批注、抽认卡、思维导图、汇总视图等功能。 PDF Reader Pro - 可以查看，创建，签名，转换和压缩任何 PDF 文档。 PDF Expert - PDF 阅读、批注，编辑文本，添加照片，填写表单。 QOwnNotes - 是开源记事本，带有 markdown 支持和待办事项列表管理器。 开源地址 Spillo - 功能强大，美观、快速网络书签网页阅读。 Skim - PDF 阅读器和笔记本。 开源地址 texpad - Mac 下非常棒的 LaTeX 编辑器。 支持自动编译预览，自动补全等。 WonderPen - 专注于写作的应用，支持 markdown，很多贴心细节，支持长文写作，可导出多种格式。 Office KOffice - 集成化办公套件，包含文字处理器、电子 表格、幻灯片制作、项目管理等多种工具。 Keynote 讲演 构建炫目的演示文稿。 LibreOffice - 一款功能强大的免费开源办公软件，默认使用开放文档格式，并支持其他多种文档格式。 开源地址 Microsoft Office 微软Office办公套件 Numbers 表格 创建令人印象深刻的电子表格。 Pages 文稿 引人注目的文稿。 WPS - 是一套跨平台的办公室软件套件。 RSS Leaf - RSS 客户端程序。 NetNewsWire - 免费的 RSS 阅读器。 开源地址 ReadKit - 书签 RSS 管理客户端。 Reeder 4 - RSS 服务订阅。 Vienna - RSS/Atom 新闻阅读客户端。 开源地址 irreader - 多功能的 RSS 阅读器，支持订阅播客和任何网站。 Markdown A curated list of delightful Markdown stuff. Cmd Markdown - Cmd Markdown 编辑阅读器，支持实时同步预览，区分写作和阅读模式，支持在线存储，分享文稿网址。 EME - 最近刚出的一款 Markdown 编辑器，界面很像 Chrome 浏览器的界面，很简约。 iA Writer - Markdown 文本预览编辑，注重语法检查，专门为作家提供的编辑器。 LightPaper - 简单的 Markdown 文本编辑器。 Marp - Markdown 制作幻灯片编辑器。 开源地址 MWeb - 专业的 Markdown 写作、记笔记、静态博客生成软件。 MacDown - 一款开源的 Markdown 编辑器，深受Mou的影响。** 开源 ** Marked 2 - Markdown 文本预览编辑，为所有作家提供一套优雅而强大的工具。 TextNut - Markdown 编辑器，富文本之间自由切换。 Typora - 基于 Electron 的“读写一体” Markdown 编辑器。 Ulysses - 适用于 Mac，iPad 和 iPhone 的写作应用程序，支持 Markdown。 Yu Writer - 一款能找到写作乐趣的 Markdown 文本编辑器。 马克飞象 - Markdown 编辑器，提供 Web 端 和 App 端，多种配色，支持同步到 印象笔记。 Effie - 轻量级 Markdown 写作软件，支持大纲笔记和思维导图。 笔记 Evernote - 笔记本应用程序。\nInkdrop - Markdown 爱好者的笔记本应用程序。\nleanote - 支持 Markdown 的一款开源笔记软件，支持直接成为个人博客。 开源地址\nNotes - 简洁的笔记应用。 开源地址\nNotebook 漂亮的笔记本应用程序。\nNotion - 一个集大成的富文本笔记管理软件，支持丰富却又简单明了的的文字格式，甚至覆盖了TODO类软件的功能。数据在服务端存储，支持web访问，也提供了macOS/Windows/iOS/安卓等平台客户端。\nOneNote - 微软备注应用。\nQuiver - 程序猿的笔记本。\n有道云笔记 - 支持多目录，Markdown，iWork/Office 预览。\n为知笔记 - 支持 Markdown，搜集整理图片链接导入文档。\n阿里语雀 - 云笔记类知识管理、协作平台，基于Markdown写作，支持内嵌流程图、脑图、时序、代码渲染以及Sketch画板创作，个人知识分享等！相比有道云笔记、印象笔记同类产品，包含其全部的功能以外，支持知识分享以及更强大的创作、协作、编辑器，它来自阿里巴巴蚂蚁金服。\n制作电子书 Calibre - 丑陋的软件，但强大的软件电子书管理和转换。 开源地址 Sigil - 多平台 EPUB 编辑器。 开源地址 Scribus - 开源电子杂志制作软件。 开源地址 软件打包工具 AppJS - 使用 JS、HTML 和CSS 构建跨平台的桌面应用程序。 开源地址 AlloyDesktop - 同上，腾讯出品，给个差评。 开源地址 create-dmg - 快速创建一个压缩镜像文件。 开源地址 Electron - 前身是 AtomShell，使用 JS、HTML 和 CSS 构建跨平台的桌面应用程序。 开源地址 Electrino - 使用 JS、HTML 和 CSS 构建跨平台的桌面应用程序，构建出的应用体积比 Electron 小。 开源地址 Finicky - Web 应用程序转化为苹果的应用程序。 开源地址 HEX - 使用 JS、HTML 和 CSS 构建跨平台的桌面应用程序，有道出品。 开源地址 ionic - 一个用来开发混合手机应用的，开源的，免费的代码库。 开源地址 nw.js - 使用 HTML 和 JavaScript 来制作桌面应用。 开源地址 MacGap - 桌面 WebKit 打包 HTML、CSS、JS 应用。 开源地址 react-desktop - 为 macOS Sierra带来 React UI 组件。 开源地址 ReactXP - 微软官方出品，支持平台 Web，iOS，Android 和 Windows UWP 仍然是一项正在进行的工作。 开源地址 React Native macOS - 用 React Native 技术构建 OS X 下的桌面应用程序。 开源地址 React Native Desktop for Ubuntu - 用 React Native 技术构建 Ubuntu 下的桌面应用程序。 开源地址 下载工具 aria2 - 一款支持多种协议的轻量级命令行下载工具。 开源地址 Downie - 支持多达近 1200 个视频站点的视频下载工具。 Free Download Manager - 功能强大的下载加速器。 FOLX - 一个 Mac osx 系统风格界面的下载管理工具。 JDownloader - 下载工具，下载文件的一键式托管。 Motrix - Motrix 是一款全能的下载工具，支持下载 HTTP、FTP、BT、磁力链、百度网盘等资源。 开源地址 qBittorrent - 一个替代 μTorrent 的开源软件。 开源地址 Transmission - 免费的 BitTorrent 客户端 开源地址 You-Get - 网络富媒体命令行下载工具。 开源地址 网盘 推荐一些有Mac客户端的网盘。\n115 - 115 云客户端。 Dropbox - 非常好用的免费网络文件同步工具，提供在线存储服务。 NextCloud - 基于 ownCloud 完全开源免费开源，企业文件同步和共享。 Mega - 免费的云服务，提供 50GB 的免费存储空间。 Resilio Sync - P2P私有云盘，BitTorrent血统，支持安卓/iOS/Windows/macOS/Linux/FreeBSD/NAS等系统平台。注意：截止2021.7.20，macOS平台客户端存在休眠崩溃现象，除此之外可以正常使用。 Seafile - 是由国内团队开发的国际化的开源云存储软件项目。 Syncthing - Resilio Sync的开源竞争者，架构上更加开放自由，良好的用户文档，基于Go语言支持大量系统平台，甚至包括OpenWrt！此项目的界面翻译工作也支持开源共建。 开源地址 ownCloud - 私有云网盘。 百度云 - 百度云客户端。 腾讯微云 - 腾讯云客户端。 坚果云 - 坚果云客户端。 亿方云 - 硅谷团队打造，个人免费。 阿里云盘 - 阿里云盘。 输入法 Kawa - 给每个输入法定义一个快捷键. 开源地址 RIME - 中州韻輸入法引擎。 开源地址 Rocket - 使用冒号快捷键可以更快捷地输入表情符号。 Type2Phone - 把 Macbook 键盘变为 iPhone 的蓝牙键盘。 WBIM - 五笔输入法。 QQ输入法 - 腾讯出品的输入法。 搜狗输入法 - 搜狗输入法。 百度输入法 - 支持拼音五笔输入。 落格输入法 - 打破 Mac 双拼多年来的窘境。 iAvro - 孟加拉语输入法。 开源地址 清歌五笔输入法 - 为 iOS 和 Mac 专门打造的五笔输入法。 颜文字 - 颜文字输入。 哈利路亚英文输入法 - 智能英文输入法，具备自动补全，自动纠错功能。 浏览器 这里放Mac的浏览器应用\nBrave - 用 Brave 浏览更快更安全。 Chrome - Chrome 浏览器谷歌出品。 Firefox - 迎接 Firefox Quantum。快，只为更好。火狐浏览器。 Safari - Mac 预装自带浏览器。 Opera - Opera 浏览器。 QQ浏览器 - QQ 浏览器－腾讯出品。 Vivaldi - Opera 开发商出品新的浏览器。 Ōryōki - 小的 web 浏览器。这是一个试验性的项目，目前正在开发中 傲游云浏览器 - 傲游云浏览器。 360极速浏览器 - 更好用，不将就。 翻译工具 有道翻译 - 有道词典桌面版。 辞海词典 - 学单词、背单词、辞海词典。 eudic - 欧路词典词典。 Grammarly - 修正英语语法及用语 iText - 截图识别文字、翻译 iTranslate - 支持全世界超过 80 种语言发音和输出。 Ludwig - 语言搜索引擎，可帮助您用英语写得更好。 Translate Tab - 菜单栏翻译插件，封装了谷歌翻译，支持自动识别语言。 Bob - 简小好用的翻译工具，支持语言自动检测，截图翻译。 开源地址 Translatium - 在 100 多种语言之间翻译单词、短语和图像，并提供字典、音译和语音输出支持。 开源地址 安全工具 Antivirus One - 值得信赖的Mac安全保护工具：保护您的 Mac 免受病毒、恶意软件和广告软件的侵害。阻止潜在的 Web威胁并保护您的Mac免受漏洞影响。 BlockBlock - 恶意软件会自行安装，以确保它在重新引导时自动重新执行。 Dylib Hijack Scanner - Dylib 劫机扫描仪或 DHS，是一个简单的实用程序，将扫描您的计算机的应用程序是易受 dylib 劫持或被劫持。 Encrypto - 免费加密工具，用于加密文件和文件夹 GPG Suite - macOS平台的一站式GnuPG解决方案，提供命令行和GUI的加解密工具。开箱即用的gpg-agent密码缓存服务，还包括一个GUI的pinenry程序，支持与macOS原生钥匙串集成。 开源地址 KextViewer - 查看所有在 OS 内核中加载的模块。 KnockKnock - “谁在那？” 查看Mac上持久安装的内容。 LinkLiar - 可以帮助你哄骗 Wi-Fi 和以太网接口的 MAC 地址。 开源地址 LuLu - 免费的macOS防火墙，旨在阻止未经授权（传出）的网络流量。 开源地址 Murus - 强大、灵活且易于理解使用的防火墙，官方提供多种不同的APP以提供不同功能的组合。最基础的免费版本Murus Lite是纯粹基于传入端口的防火墙，跟基于应用程序的macOS原生防火墙形成有效互补。 OverSight - 监控 Mac 的麦克风和网络摄像头，当内部麦克风被激活，或者当进程访问摄像头时提醒用户。 RansomWhere? - 通用 Ransomware 检测。 TaskExplorer - 使用 TaskExplorer 探索在 Mac 上运行的所有任务（进程）。 What’s Your Sign? - 验证文件的加密签名可以推断其来源或可信度。 科学上网 假设你是个勤奋的同学，你总有一天会强烈需要它们，上帝保佑他们吧。\nAlgo - 在云中设置个人 IPSEC VPN。 开源地址 ClashX - 基于 clash 的一款支持规则过滤的科学上网工具。 开源地址 Lantern - 科学上网。 开源地址 ShadowsocksX - 一个快速的隧道代理，可以帮助你绕过防火墙。 开源地址 ShadowsocksX-NG - 一款 ShadowsocksX 客户端软件。 开源地址 Surge - 科学上网。 Shimo - 连接大量 VPN 的应用 Tunnelbear - 简单的私人 VPN。 Tunnelblick - OpenVPN 的免费软件。 tinc - VPN 软件. 开源地址 V2Ray - 原生支持 Socks、HTTP、Shadowsocks、VMess 等协议。 其它实用工具 12306ForMac - Mac 版 12306 订票/检票助手。 开源地址 1440 Minutes Left Today - 在菜单栏中，直接记录到一天结束还剩多少分钟。 AirServer - 将手机投影到电脑上。 Alfred - 效率神器。 Raycast - 类似Alfred功能，重要的是免费。 BitBar - 支持使用各种语言将信息展示到Mac OS的菜单栏。 开源地址 BetterZip - 压缩解压缩工具支持格式 ZIP、TAR、TGZ、TBZ、TXZ (new)、7-ZIP、RAR。 BetterTouchTool - 代替默认的系统操作方式（组合键、修饰键、手势等）。 CopyQ - 高级功能剪贴板管理工具。 开源地址 ControlPlane - 自定义 Mac 情景模式。某些场景让 Mac 自动静音或是自动打开 Mail 客户端等等。 开源地址 ClipMenu - 一个剪贴板操作的管理器。 开源地址 Clipy - 基于 ClipMenu 继续开发的强大的剪切板管理器。 开源地址 CheatSheet - CheatSheet 是一款 Mac 上的非常实用的快捷键快速提醒工具。 DaisyDisk - 磁盘空间使用扫描工具。 DNS Heaven - 可以令基于 glibc 的 macOS 应用直接使用原生栈来解析 DNS，主要适用于 VPN。 开源地址 eZip - 界面简洁，功能完善，支持主流的多种压缩格式。支持 Mojave 深色模式、QuickLook预览、拖拽解压。 f.lux - 自动调整您的电脑屏幕，以匹配亮度。 Lunar - 外接显示器亮度/对比度调节工具，从此告别物理按键。 开源地址 Hammerspoon - 功能强大的自动化工具，Lua 脚本驱动，支持窗口管理。 开源地址 HTTrack - 可以下载整个网站和离线浏览。 HapticKey - Touch Bar 触觉反馈。 开源地址 HWSensors - 自带FakeSMC的黑苹果硬件状态监控插件。 开源地址 Hungrymark - 非常有用的收藏夹应用，收藏文件，文件夹，网址，快速的通过状态栏菜单访问这些书签。 iStat pro - 免费的 Mac OS 电脑硬件信息检测软件。 Itsycal - 一款简洁实用的开源日历工具。 开源地址 Karabiner - 一个强大的和稳定的 OS X 的键盘定制。 开源地址 Keyboard Maestro - 根据键盘，菜单，位置，添加的设备等触发器自动执行日常操作。 Keytty - 让你通过键盘使用鼠标。 Keka - 一个免费的 macOS 文件解压缩程序。 Lungo - 防止Mac进入睡眠状态。 Memo - 给你的便笺加个密。 Manta - 灵活的发票桌面应用程序，漂亮和可定制模板。 开源地址 Mos - 让你的鼠标滚轮丝滑如触控板。 开源地址 Mac Cache Cleaner - 缓存清理工具 开源地址 Numi - 漂亮的计算器应用。 NoSleep - 合上盖子不休眠，可根据是否连接电源单独设置。 openEmu - 模拟器，可以玩魂斗罗之类，轻松回到小时候。 开源地址 OmniDiskSweeper - 磁盘空间使用扫描工具。 OmniPlan - 项目管理软件。 Paste - 智能剪贴板历史片段管理。 PasteBot - 强大的剪贴板管理器。 PDF Archiver - 一个用于标记和归档任务的好工具。 开源地址 Qbserve - 观察你如何度过你的时间。 RescueTime - 个人分析服务，向您展示如何花时间和提供工具来帮助您提高工作效率。 Snap - 一款可以给 Dock 上的程序添加快捷键的小工具。 Streaker - GitHub贡献和统计跟踪菜单栏应用程序。 开源地址 The Unarchiver - 解压许多不同种类的归档压缩文件。 开源地址 Timing - Mac 的自动时间和生产力跟踪。 Unarchive One - 快速解压单个多个不同种类的压缩文件/压缩文件到各类常见压缩格式。 Ukelele - Unicode 键盘布局编辑器。 WWDC - Mac OS 的非官方的 WWDC APP。 开源地址 xScope - 测量、检查和测试屏幕上的图形和布局的工具。搜索你的苹果和网络，快速打开应用程序。 360压缩 - 简单易用，免费无广告的压缩工具。 超级右键 - 一款finder右键菜单扩展，包括了大量便捷工具比如新建文件，直接打开终端等 剪贴板工具 ClipMenu - 一个剪贴板操作的管理器。 开源地址 CopyQ - 高级功能剪贴板管理工具。 开源地址 iPaste - 轻巧高效的剪贴板工具。 Paste - 智能剪贴板历史片段管理。 PasteBot - 强大的剪贴板管理器。 菜单栏工具 BeardedSpice - 允许您使用 Mac 键盘上的媒体键控制基于Web的媒体播放器（SoundCloud，YouTube 等）和一些本机应用程序。 开源地址 Bartender - 组织或隐藏Mac上的菜单栏图标。 BitBar - 支持使用各种语言将信息展示到 Mac OS 的菜单栏。 开源地址 iGlance - 状态栏的系统监视器。 开源地址 Itsycal - 一款简洁实用的开源日历工具。 开源地址 Vanilla - 隐藏系统菜单栏。 待办事项工具 2Do - 比较好的 TODO 应用程序。 Day-O 2 - 菜单日历更换内置日历。 Fantastical - 日历应用程序，你将管理好生活。 Focus - 一个漂亮的番茄工作法为基础的时间管理工具。 Microsoft To-Do - 任务管理工具微软出品。 Nozbe - 适用于个人和团队的强大GTD应用程序，支持每个Apple设备。 OmniFocus - 由 OmniGroups 制作的 Nice GTD 应用程序。 Taskade - 实时协作编辑器，协作简历任务管理器，大纲和笔记。 TaskPaper - 漂亮的纯文本任务列表。 Things - 令人愉快且易于使用的任务管理器。 Todoist - 跨平台的任务管理器与移动应用程序。 Wunderlist - 奇妙清单跨平台的任务管理器与移动应用程序。 滴答清单 - 轻便且强大的跨平台任务管理应用。 系统相关工具 Amphetamine - 覆盖您的节能设置并让您的Mac保持清醒状态。 AdBlock One - 适用于MacOS/iOS的免费广告拦截器 停止在Safari中看到烦人的广告。更快地打开网站。更安全地浏览网页。 AppCleaner - 一个小应用程序，让你彻底卸载不需要的应用程序。 AppTrap - 删除APP的同时移除文件。 开源地址 blueutil - 命令行蓝牙控制工具，可以配合SleepWatcher实现MacBook合盖瞬间关闭蓝牙，开盖自动打开蓝牙。这在使用蓝牙耳机时尤其有用。 开源地址 Cleaner One - 多合一磁盘清理管理器：清理您的 Mac 并优化其性能，立即运行快速扫描以验证什么占用了您的存储空间。 Cleaner for Xcode - Xcode 的清理工具，清理几十G应该不是问题。 开源地址 Coolant - 这是能让你知道什么应用程序造成你 CPU100% 让 Mac 电脑过热电池耗尽的菜单应用程序。 coconutBattery - 显示Mac中有关电池的实时信息。 DaisyDisk - 磁盘空间使用扫描工具。 FruitJuice - 会让你知道每天保持不插电的时间，以保持你的电池健康。 gfxCardStatus - 控制Mac独立显卡与集成显卡之间的切换。 HandShaker - Mac 电脑上也可以方便自如地管理您在 Android 手机中的内容。 HTML5 Player - Chrome 插件解决中国视频网站播放视频电脑发热的情况。 iStat Menus - 菜单栏上的高级 Mac 系统监视器。 iStats - iStats 是一个可以让你快速查看电脑 CPU 温度，磁盘转速和电池等信息的命令行工具。 开源地址 Juice - 让电池显示更有趣 开源地址 KeepingYouAwake - 替代咖啡因，更好地支持Mac中的暗模式。 开源地址 Monity - 帮助用户实时监控系统的一款非常漂亮的软件。 Mounty - NTFS 分区读写组件。 NitroShare - 跨平台网络文件传输应用程序。 开源地址 OnyX - 多功能实用工具来验证磁盘和文件，运行清洁和系统维护任务，配置隐藏选项等。 OmniDiskSweeper - 磁盘空间使用扫描工具。 Paragon NTFS - 在 Mac OS X 中完全读写、修改、访问 Windows NTFS 硬盘、U 盘等外接设备的文件。 Porting Kit - 在Mac中安装Windows®游戏。 SleepWatcher - 可以在MacBook合盖和开盖时执行自定义脚本，比如开关蓝牙等。可以通过homebrew安装。 开源地址 smcFanControl - 短小精悍的风扇转速温控软件，可以预设两档风扇最低转速，方便在不同工作负载间人工强制切换。因为只是限制风扇最低速度，所以系统原生温控调速不会完全失效。 开源地址 SSH Tunnel - 管理你的 SSH。 TG Pro - 温度监控，风扇控制和硬件诊断，帮助您保持 Mac的 凉爽和健康。 Tuxera NTFS - Mac 上的 NTFS 文件系统驱动。 腾讯柠檬清理 - 一款免费的Mac系统清理软件，替代原来的Mac电脑管家，腾讯出品。 窗口管理 Amethyst - 窗口管理器（自动保持窗口大小的窗口）。 开源地址 BetterSnapTool - 窗口管理工具，可通过快捷键或窗口拖动快速实现分屏。 Contexts- 提供比 Mac 原生 Dock 更强大功能尤其在你有多个屏幕的时候,它可以帮助你更快捷切换。 Divvy - 凭借其惊人的 Divvy Grid 系统，窗口管理处于最佳状态。 IntelliDock - 自动隐藏 Dock。 Moom - 多任务多窗口的软件。 Magnet - 一个窗口管理器，可以保持工作空间的组织。 rcmd - 使用 ⌘ Right Command 键根据名称切换应用程序。 ShiftIt - 窗口位置和大小管理软件。 开源地址 Slate - 窗口管理器，可用 JavaScript 写配置。 开源地址 SizeUp - 强大的，以键盘为中心的窗口管理。 Spectacle - 简单的移动和调整大小的窗口，和可定制的键盘快捷键。 开源地址 Total Spaces - 像 ubuntu 一样提供窗口管理，为工作区创建热键，使您可以轻松移动。 密码管理 1password - 跨平台帐号密码管理软件。 Authy - 双因素身份验证令牌管理器，可在您的设备上进行备份和同步。 Bitwarden - 适用于Mac OS，iOS和浏览器的开源密码管理工具。 开源地址 Buttercup - 跨平台密码管理器 开源地址 Dashlane - 基于云的密码管理器，拥有屡获殊荣的设计。 Enpass - 具有云集成的跨平台密码管理工具。 Keeweb - 与 KeePass 兼容的免费跨平台密码管理器。 开源地址 LastPass - 密码管理器和安全的数字笔记。 MacPass - 密码管理器。 开源地址 RememBear - 治愈系密码管理工具。 Finder fman - 先进的双窗口文件管理器，拥有很多特性。 ForkLift - 先进的双窗口文件管理器和文件传输客户端。 Hazel - 设计精美的自动文件管理软件。 MacAssistant - Google 助手 开源地址 Path Finder - 强大的 Finder 替代者，拥有很多特性。 Quicklook-Plugins - Finder 快速预览文件插件。 QSpace - 一款简洁高效的多视图文件管理器。 TotalFinder - 强大的 Finder 替代者，界面风格像 Chrome。 XtraFinder - 给 Finder 添加有用的新特性。 远程协助 RustDesk - 又一个远程桌面软件。 开源地址 AnyDesk 是一款远程控制跨多平台的程序。 Microsoft Remote Desktop - 微软官方的远程桌面连接工具(国区App store没有上架,下载地址)。 RealVNC 是一款免费的远程控制跨多平台的程序。 TeamViewer - 远程协助及在线协作和会议功能的软件，商业软件个人使用免费。 QuickLook插件 List of useful Quick Look plugins for developers.\n使用 Homebrew Cask 将通过命令安装即为简单。开发人员使用的Quick Look插件列表。如果手动安装，你可将下载的 .qlgenerator 文件移动到 ~/Library/QuickLook 运行 qlmanage -r\nQuicklookStephen - 可以让您查看没有文件扩展名的纯文本文件，如 README、INSTALL、Capfile、CHANGELOG…brew install --cask install qlstephen 第三方应用市场APP 这里讨论盗版问题或者提供黑名单？，拒绝盗版从我做起，欢迎大家监督。\n正版 这里只提供正版软件购买下载的应用商店。\nHomebrew Cask - 基于Homebrew扩展的，通过命令行安装 Mac GUI 软件的工具。 开源地址 Homebrew - 体验通过命令行安装 Mac 软件的工具(大部分是命令行工具)。 开源地址 MacUpdate Desktop - 管理/更新/下载 App，跟踪优惠信息。 MacPorts - 一个软件包管理工具，可用于简化 OS X 和 Darwin 操作系统内软件的安装。 开源地址 Setapp - MacPaw 推出的订阅制付费 App 平台服务。 应用商店黑名单 第三方应用市场APP黑名单，存在盗版软件传播和下载，拒绝盗版从我做起，欢迎大家监督它们。\n迅雷Thunder Store - 迅雷 Thunder for Mac 带应用市场。 Mac软件宝箱 - Macx 推出软件宝箱。 MacHunter - Mac 应用市场。 Mac软件下载网站 这里主要是推荐一些软件下载的网站，还有一些Mac OSX软件分享网站\n正版/介绍 App Shopper：http://appshopper.com/ MacUpdate：https://www.macupdate.com/ 少数派：http://sspai.com/tag/Mac Mac玩儿法：http://www.waerfa.com 腾讯柠檬精选：https://lemon.qq.com/lab/ 盗版软件下载网站黑名单 上面有大量的开源软件或者免费软件，拒绝盗版从我做起，下面被删除的网站提供大量破解软件下载，欢迎大家监督它们。\n玩转苹果：http://www.ifunmac.com AppKed：http://www.macbed.com appaddict：https://www.appaddict.org/ Mac精品软件：http://xclient.info/ MacWk：https://macwk.com/ MacPeers：https://www.macpeers.com Mac毒：https://www.macdo.cn Macx：https://www.macx.cn/ Mac软件下载站：http://www.pshezi.com MacPeers：http://www.macpeers.com Mac志：http://www.isofts.org Mac软件分享：http://www.waitsun.com MacSky苹果软件园：http://www.macsky.net/ Softasm：https://softasm.com/ Mac破解软件：https://www.macappstore.net/ 卡卡源：http://www.kkroot.com/ 苹果软件园：http://www.maczapp.com 马可菠萝：http://www.macbl.com/ 极致分享：https://alltoshare.com/ 麦克社：http://www.macshe.com/ 未来软件园：http://www.orsoon.com/ 腾牛网：http://www.qqtn.com/mac/r_17_1.html 未来软件园：http://www.orsoon.com/mac/ 威锋网：https://bbs.feng.com/forum.php?mod=forumdisplay\u0026fid=19\u0026page= MAC萌新网：https://www.macxin.com ","description":"\n","tags":[],"title":"\nAwesome Mac","uri":"/posts/post-321/"},{"categories":["IDE"],"content":"（Win + Linux）快捷键 说明 IntelliJ IDEA 的便捷操作性，快捷键的功劳占了一大半，对于各个快捷键组合请认真对待。IntelliJ IDEA 本身的设计思维是提倡键盘优先于鼠标的，所以各种快捷键组合层出不穷，对于快捷键设置也有各种支持，对于其他 IDE 的快捷键组合也有预设模板进行支持。\n关于各个快捷键的频率分类上可能每个人都有各自的看法，下面的整理也只是以我个人的使用习惯来划分的，而我应该是可以代表某一部分小众人员。但是我个人还是强烈建议你可以在我的基础上整理一份属于你的快捷键目录（删除掉多余的字眼，只保留快捷键内容），本篇文章也只是起到一个工具和引子的作用。\n对于下面各个快捷键的使介绍描述也许用我个人语言翻译起来不够准确或是不全面，且在不同的文件类型上按出来的效果也可能结果不太一样,所以 强烈建议 你自己把各个快捷键都亲自操作下体会下各个快捷键的实际用法。\n前提 IntelliJ IDEA 官方出的学习辅助插件：IDE Features Trainer：https://plugins.jetbrains.com/plugin/8554?pr=idea Ctrl 快捷键 介绍 Ctrl + F 在当前文件进行文本查找 （必备） Ctrl + R 在当前文件进行文本替换 （必备） Ctrl + Z 撤销 （必备） Ctrl + Y 删除光标所在行 或 删除选中的行 （必备） Ctrl + X 剪切光标所在行 或 剪切选择内容 Ctrl + C 复制光标所在行 或 复制选择内容 Ctrl + D 复制光标所在行 或 复制选择内容，并把复制内容插入光标位置下面 （必备） Ctrl + W 递进式选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展选中范围 （必备） Ctrl + E 显示最近打开的文件记录列表 （必备） Ctrl + N 根据输入的 类名 查找类文件 （必备） Ctrl + G 在当前文件跳转到指定行处 Ctrl + J 插入自定义动态代码模板 （必备） Ctrl + P 方法参数提示显示 （必备） Ctrl + Q 光标所在的变量 / 类名 / 方法名等上面（也可以在提示补充的时候按），显示文档内容 Ctrl + U 前往当前光标所在的方法的父类的方法 / 接口定义 （必备） Ctrl + B 进入光标所在的方法/变量的接口或是定义处，等效于 Ctrl + 左键单击 （必备） Ctrl + K 版本控制提交项目，需要此项目有加入到版本控制才可用 Ctrl + T 版本控制更新项目，需要此项目有加入到版本控制才可用 Ctrl + H 显示当前类的层次结构 Ctrl + O 选择可重写的方法 Ctrl + I 选择可继承的方法 Ctrl + + 展开代码 Ctrl + - 折叠代码 Ctrl + / 注释光标所在行代码，会根据当前不同文件类型使用不同的注释符号 （必备） Ctrl + [ 移动光标到当前所在代码的花括号开始位置 Ctrl + ] 移动光标到当前所在代码的花括号结束位置 Ctrl + F1 在光标所在的错误代码处显示错误信息 （必备） Ctrl + F3 调转到所选中的词的下一个引用位置 （必备） Ctrl + F4 关闭当前编辑文件 Ctrl + F8 在 Debug 模式下，设置光标当前行为断点，如果当前已经是断点则去掉断点 Ctrl + F9 执行 Make Project 操作 Ctrl + F11 选中文件 / 文件夹，使用助记符设定 / 取消书签 （必备） Ctrl + F12 弹出当前文件结构层，可以在弹出的层上直接输入，进行筛选 Ctrl + Tab 编辑窗口切换，如果在切换的过程又加按上delete，则是关闭对应选中的窗口 Ctrl + End 跳到文件尾 Ctrl + Home 跳到文件头 Ctrl + Space 基础代码补全，默认在 Windows 系统上被输入法占用，需要进行修改，建议修改为 Ctrl + 逗号 （必备） Ctrl + Delete 删除光标后面的单词或是中文句 （必备） Ctrl + BackSpace 删除光标前面的单词或是中文句 （必备） Ctrl + 1,2,3…9 定位到对应数值的书签位置 （必备） Ctrl + 左键单击 在打开的文件标题上，弹出该文件路径 （必备） Ctrl + 光标定位 按 Ctrl 不要松开，会显示光标所在的类信息摘要 Ctrl + 左方向键 光标跳转到当前单词 / 中文句的左侧开头位置 （必备） Ctrl + 右方向键 光标跳转到当前单词 / 中文句的右侧开头位置 （必备） Ctrl + 前方向键 等效于鼠标滚轮向前效果 （必备） Ctrl + 后方向键 等效于鼠标滚轮向后效果 （必备） Alt 快捷键 介绍 Alt + ` 显示版本控制常用操作菜单弹出层 （必备） Alt + Q 弹出一个提示，显示当前类的声明 / 上下文信息 Alt + F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择 （必备） Alt + F2 对于前面页面，显示各类浏览器打开目标选择弹出层 Alt + F3 选中文本，逐个往下查找相同文本，并高亮显示 Alt + F7 查找光标所在的方法 / 变量 / 类被调用的地方 Alt + F8 在 Debug 的状态下，选中对象，弹出可输入计算表达式调试框，查看该输入内容的调试结果 Alt + Home 定位 / 显示到当前文件的 Navigation Bar Alt + Enter IntelliJ IDEA 根据光标所在问题，提供快速修复选择，光标放在的位置不同提示的结果也不同 （必备） Alt + Insert 代码自动生成，如生成对象的 set / get 方法，构造函数，toString() 等 （必备） Alt + 左方向键 切换当前已打开的窗口中的子视图，比如Debug窗口中有Output、Debugger等子视图，用此快捷键就可以在子视图中切换 （必备） Alt + 右方向键 按切换当前已打开的窗口中的子视图，比如Debug窗口中有Output、Debugger等子视图，用此快捷键就可以在子视图中切换 （必备） Alt + 前方向键 当前光标跳转到当前文件的前一个方法名位置 （必备） Alt + 后方向键 当前光标跳转到当前文件的后一个方法名位置 （必备） Alt + 1,2,3…9 显示对应数值的选项卡，其中 1 是 Project 用得最多 （必备） Shift 快捷键 介绍 Shift + F1 如果有外部文档可以连接外部文档 Shift + F2 跳转到上一个高亮错误 或 警告位置 Shift + F3 在查找模式下，查找匹配上一个 Shift + F4 对当前打开的文件，使用新Windows窗口打开，旧窗口保留 Shift + F6 对文件 / 文件夹 重命名 Shift + F7 在 Debug 模式下，智能步入。断点所在行上有多个方法调用，会弹出进入哪个方法 Shift + F8 在 Debug 模式下，跳出，表现出来的效果跟 F9 一样 Shift + F9 等效于点击工具栏的 Debug 按钮 Shift + F10 等效于点击工具栏的 Run 按钮 Shift + F11 弹出书签显示层 （必备） Shift + Tab 取消缩进 （必备） Shift + ESC 隐藏当前 或 最后一个激活的工具窗口 Shift + End 选中光标到当前行尾位置 Shift + Home 选中光标到当前行头位置 Shift + Enter 开始新一行。光标所在行下空出一行，光标定位到新行位置 （必备） Shift + 左键单击 在打开的文件名上按此快捷键，可以关闭当前打开文件 （必备） Shift + 滚轮前后滚动 当前文件的横向滚动轴滚动 （必备） Ctrl + Alt 快捷键 介绍 Ctrl + Alt + L 格式化代码，可以对当前文件和整个包目录使用 （必备） Ctrl + Alt + O 优化导入的类，可以对当前文件和整个包目录使用 （必备） Ctrl + Alt + I 光标所在行 或 选中部分进行自动代码缩进，有点类似格式化 Ctrl + Alt + T 对选中的代码弹出环绕选项弹出层 （必备） Ctrl + Alt + J 弹出模板选择窗口，将选定的代码加入动态模板中 Ctrl + Alt + H 调用层次 Ctrl + Alt + B 在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口 Ctrl + Alt + C 重构-快速提取常量 Ctrl + Alt + F 重构-快速提取成员变量 Ctrl + Alt + V 重构-快速提取变量 Ctrl + Alt + Y 同步、刷新 Ctrl + Alt + S 打开 IntelliJ IDEA 系统设置 （必备） Ctrl + Alt + F7 显示使用的地方。寻找被该类或是变量被调用的地方，用弹出框的方式找出来 Ctrl + Alt + F11 切换全屏模式 Ctrl + Alt + Enter 光标所在行上空出一行，光标定位到新行 （必备） Ctrl + Alt + Home 弹出跟当前文件有关联的文件弹出层 Ctrl + Alt + Space 类名自动完成 Ctrl + Alt + 左方向键 退回到上一个操作的地方 （必备） Ctrl + Alt + 右方向键 前进到上一个操作的地方 （必备） Ctrl + Alt + 前方向键 在查找模式下，跳到上个查找的文件 Ctrl + Alt + 后方向键 在查找模式下，跳到下个查找的文件 Ctrl + Alt + 右括号（]） 在打开多个项目的情况下，切换下一个项目窗口 Ctrl + Alt + 左括号（[） 在打开多个项目的情况下，切换上一个项目窗口 Ctrl + Shift 快捷键 介绍 Ctrl + Shift + F 根据输入内容查找整个项目 或 指定目录内文件 （必备） Ctrl + Shift + R 根据输入内容替换对应内容，范围为整个项目 或 指定目录内文件 （必备） Ctrl + Shift + J 自动将下一行合并到当前行末尾 （必备） Ctrl + Shift + Z 取消撤销 （必备） Ctrl + Shift + W 递进式取消选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展取消选中范围 （必备） Ctrl + Shift + N 通过文件名定位 / 打开文件 / 目录，打开目录需要在输入的内容后面多加一个正斜杠 （必备） Ctrl + Shift + U 对选中的代码进行大 / 小写轮流转换 （必备） Ctrl + Shift + T 对当前类生成单元测试类，如果已经存在的单元测试类则可以进行选择 （必备） Ctrl + Shift + C 复制当前文件磁盘路径到剪贴板 （必备） Ctrl + Shift + V 弹出缓存的最近拷贝的内容管理器弹出层 Ctrl + Shift + E 显示最近修改的文件列表的弹出层 Ctrl + Shift + H 显示方法层次结构 Ctrl + Shift + B 跳转到类型声明处 （必备） Ctrl + Shift + I 快速查看光标所在的方法 或 类的定义 Ctrl + Shift + A 查找动作 / 设置 Ctrl + Shift + / 代码块注释 （必备） Ctrl + Shift + [ 选中从光标所在位置到它的顶部中括号位置 （必备） Ctrl + Shift + ] 选中从光标所在位置到它的底部中括号位置 （必备） Ctrl + Shift + + 展开所有代码 （必备） Ctrl + Shift + - 折叠所有代码 （必备） Ctrl + Shift + F7 高亮显示所有该选中文本，按Esc高亮消失 （必备） Ctrl + Shift + F8 在 Debug 模式下，指定断点进入条件 Ctrl + Shift + F9 编译选中的文件 / 包 / Module Ctrl + Shift + F12 编辑器最大化 （必备） Ctrl + Shift + Space 智能代码提示 Ctrl + Shift + Enter 自动结束代码，行末自动添加分号 （必备） Ctrl + Shift + Backspace 退回到上次修改的地方 （必备） Ctrl + Shift + 1,2,3…9 快速添加指定数值的书签 （必备） Ctrl + Shift + 左键单击 把光标放在某个类变量上，按此快捷键可以直接定位到该类中 （必备） Ctrl + Shift + 左方向键 在代码文件上，光标跳转到当前单词 / 中文句的左侧开头位置，同时选中该单词 / 中文句 （必备） Ctrl + Shift + 右方向键 在代码文件上，光标跳转到当前单词 / 中文句的右侧开头位置，同时选中该单词 / 中文句 （必备） Ctrl + Shift + 前方向键 光标放在方法名上，将方法移动到上一个方法前面，调整方法排序 （必备） Ctrl + Shift + 后方向键 光标放在方法名上，将方法移动到下一个方法前面，调整方法排序 （必备） Alt + Shift 快捷键 介绍 Alt + Shift + N 选择 / 添加 task （必备） Alt + Shift + F 显示添加到收藏夹弹出层 / 添加到收藏夹 Alt + Shift + C 查看最近操作项目的变化情况列表 Alt + Shift + I 查看项目当前文件 Alt + Shift + F7 在 Debug 模式下，下一步，进入当前方法体内，如果方法体还有方法，则会进入该内嵌的方法中，依此循环进入 Alt + Shift + F9 弹出 Debug 的可选择菜单 Alt + Shift + F10 弹出 Run 的可选择菜单 Alt + Shift + 左键双击 选择被双击的单词 / 中文句，按住不放，可以同时选择其他单词 / 中文句 （必备） Alt + Shift + 前方向键 移动光标所在行向上移动 （必备） Alt + Shift + 后方向键 移动光标所在行向下移动 （必备） Ctrl + Shift + Alt 快捷键 介绍 Ctrl + Shift + Alt + V 无格式黏贴 （必备） Ctrl + Shift + Alt + N 前往指定的变量 / 方法 Ctrl + Shift + Alt + S 打开当前项目设置 （必备） Ctrl + Shift + Alt + C 复制参考信息 其他 快捷键 介绍 F2 跳转到下一个高亮错误 或 警告位置 （必备） F3 在查找模式下，定位到下一个匹配处 F4 编辑源 （必备） F7 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该方法体还有方法，则不会进入该内嵌的方法中 F8 在 Debug 模式下，进入下一步，如果当前行断点是一个方法，则不进入当前方法体内 F9 在 Debug 模式下，恢复程序运行，但是如果该断点下面代码还有断点则停在下一个断点上 F11 添加书签 （必备） F12 回到前一个工具窗口 （必备） Tab 缩进 （必备） ESC 从工具窗口进入代码文件窗口 （必备） 连按两次Shift 弹出 Search Everywhere 弹出层 官网快捷键资料 Windows / Linux：https://www.jetbrains.com/idea/docs/IntelliJIDEA_ReferenceCard.pdf Mac OS X：https://www.jetbrains.com/idea/docs/IntelliJIDEA_ReferenceCard_Mac.pdf 第三方快捷键资料 来自 eta02913：http://xinyuwu.iteye.com/blog/1005454 Mac 快捷键 根据官方pdf翻译：https://www.jetbrains.com/idea/docs/IntelliJIDEA_ReferenceCard_Mac.pdf 在 IntelliJ IDEA 中有两个 Mac 版本的快捷键，一个叫做：Mac OS X，一个叫做：Mac OS X 10.5+ 目前都是用：Mac OS X 10.5+ 有两套的原因：https://intellij-support.jetbrains.com/hc/en-us/community/posts/206159109-Updated-Mac-OS-X-keymap-Feedback-needed 建议将 Mac 系统中与 IntelliJ IDEA 冲突的快捷键取消或更改，不建议改 IntelliJ IDEA 的默认快捷键。\nMac 键盘符号 图标 介绍 ⌘ Command ⇧ Shift ⇪ Caps Lock ⌥ Option = Alt ⌃ Control ↩ Enter ⌫ Delete ⌦ Fn + Delete ↑ 上箭头 ↓ 下箭头 ← 左箭头 → 右箭头 ⇞ Fn + ↑ = Page Up ⇟ Fn + ↓ = Page Down Home Fn + ← End Fn + → ⇥ Tab = 右制表符 ⇤ Shift + Tab = 左制表符 ⎋ Esc = Escape ⏏ 电源开关键 Editing（编辑） Control + Space 基本的代码补全（补全任何类、方法、变量） Control + Shift + Space 智能代码补全（过滤器方法列表和变量的预期类型） Command + Shift + Enter 自动结束代码，行末自动添加分号 Command + P 显示方法的参数信息 Control + J 显示当前位置的变量、方法的 Documentation 内容 Control + J 快速查看文档 Shift + F1 查看外部文档（在某些代码上会触发打开浏览器显示相关文档） Command + 鼠标放在代码上 显示代码简要信息 Command + F1 在错误或警告处显示具体描述信息 Command + N, Control + Enter, Control + N 生成代码（getter、setter、构造函数、hashCode/equals,toString） Control + O 覆盖方法（重写父类方法） Control + I 实现方法（实现接口中的方法） Command + Option + T 包围代码（使用if..else, try..catch, for, synchronized等包围选中的代码） Command + / 注释/取消注释与行注释 Command + Option + / 注释/取消注释与块注释 Option + 方向键上 连续选中代码块 Option + 方向键下 减少当前选中的代码块 Control + Shift + Q 显示上下文信息 Option + Enter 显示意向动作和快速修复代码 Command + Option + L 格式化代码 Control + Option + O 优化import Control + Option + I 自动缩进线 Tab / Shift + Tab 缩进代码 / 反缩进代码 Command + X 剪切当前行或选定的块到剪贴板 Command + C 复制当前行或选定的块到剪贴板 Command + V 从剪贴板粘贴 Command + Shift + V 从最近的缓冲区粘贴 Command + D 复制当前行或选定的块 Command + Delete 删除当前行或选定的块的行 Control + Shift + J 智能的将代码拼接成一行 Command + Enter 智能的拆分拼接的行 Shift + Enter 开始新的一行 Command + Shift + U 大小写切换 Command + Shift + ] / Command + Shift + [ 选择直到代码块结束/开始 Option + Fn + Delete 删除到单词的末尾 Option + Delete 删除到单词的开头 Command + 加号 / Command + 减号 展开 / 折叠代码块 Command + Shift + 加号 展开所以代码块 Command + Shift + 减号 折叠所有代码块 Command + W 关闭活动的编辑器选项卡 Search/Replace（查询/替换） Double Shift 查询任何东西 Command + F 文件内查找 Command + G 查找模式下，向下查找 Command + Shift + G 查找模式下，向上查找 Command + R 文件内替换 Command + Shift + F 全局查找（根据路径） Command + Shift + R 全局替换（根据路径） Command + Shift + S 查询结构（Ultimate Edition 版专用，需要在Keymap中设置） Command + Shift + M 替换结构（Ultimate Edition 版专用，需要在Keymap中设置） Usage Search（使用查询） Option + F7 / Command + F7 在文件中查找用法 / 在类中查找用法 Command + Shift + F7 在文件中突出显示的用法 Command + Option + F7 显示用法 Compile and Run（编译和运行） Command + F9 编译Project Command + Shift + F9 编译选择的文件、包或模块 Control + Option + R 弹出 Run 的可选择菜单 Control + Option + D 弹出 Debug 的可选择菜单 Control + R 运行 Control + D 调试 Control + Shift + R, Control + Shift + D 从编辑器运行上下文环境配置 Debugging（调试） F8 进入下一步，如果当前行断点是一个方法，则不进入当前方法体内 F7 进入下一步，如果当前行断点是一个方法，则进入当前方法体内，如果该方法体还有方法，则不会进入该内嵌的方法中 Shift + F7 智能步入，断点所在行上有多个方法调用，会弹出进入哪个方法 Shift + F8 跳出 Option + F9 运行到光标处，如果光标前有其他断点会进入到该断点 Option + F8 计算表达式（可以更改变量值使其生效） Command + Option + R 恢复程序运行，如果该断点下面代码还有断点则停在下一个断点上 Command + F8 切换断点（若光标当前行有断点则取消断点，没有则加上断点） Command + Shift + F8 查看断点信息 Navigation（导航） Command + O 查找类文件 Command + Shift + O 查找所有类型文件、打开文件、打开目录，打开目录需要在输入的内容前面或后面加一个反斜杠/ Command + Option + O 前往指定的变量 / 方法 Control + 方向键左 / Control + 方向键右 左右切换打开的编辑tab页 F12 返回到前一个工具窗口 Esc 从工具窗口进入代码文件窗口 Shift + Esc 隐藏当前或最后一个活动的窗口，且光标进入代码文件窗口 Command + Shift + F4 关闭活动run/messages/find/… tab Command + L 在当前文件跳转到某一行的指定处 Command + E 显示最近打开的 文件记录 列表 Command + Shift + E 显示最近打开的 文件代码位置记录 列表 Option + 方向键左 / Option + 方向键右 光标跳转到当前单词 / 中文句的左 / 右侧开头位置 Command + Option + 方向键左 / Command + Option + 方向键右 退回 / 前进到上一个操作的地方 Command + Shift + Delete 跳转到最后一个编辑的地方 Option + F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择(如在代码编辑窗口可以选择显示该文件的Finder) Command + B / Command + 鼠标点击 进入光标所在的方法/变量的接口或是定义处 Command + Option + B 跳转到实现处，在某个调用的方法名上使用会跳到具体的实现处，可以跳过接口 Option + Space, Command + Y 快速打开光标所在方法、类的定义 Control + Shift + B 跳转到类型声明处 Command + U 前往当前光标所在方法的父类的方法 / 接口定义 Control + 方向键下 / Control + 方向键上 当前光标跳转到当前文件的前一个/后一个方法名位置 Command + ] / Command + [ 移动光标到当前所在代码的花括号开始/结束位置 Command + F12 弹出当前文件结构层，可以在弹出的层上直接输入进行筛选（可用于搜索类中的方法） Control + H 显示当前类的层次结构 Command + Shift + H 显示方法层次结构 Control + Option + H 显示调用层次结构 F2 / Shift + F2 跳转到下一个/上一个突出错误或警告的位置 F4 / Command + 方向键下 编辑/查看代码源 Option + Home 显示到当前文件的导航条 F3选中文件/文件夹/代码行，添加/取消书签 Option + F3 选中文件/文件夹/代码行，使用助记符添加/取消书签 Control + 0...Control + 9 定位到对应数值的书签位置 Command + F3 显示所有书签 Refactoring（重构） F5 复制文件到指定目录 F6 移动文件到指定目录 Command + Delete 在文件上为安全删除文件，弹出确认框 Shift + F6 重命名文件 Command + F6 更改签名 Command + Option + N 一致性 Command + Option + M 将选中的代码提取为方法 Command + Option + V 提取变量 Command + Option + F 提取字段 Command + Option + C 提取常量 Command + Option + P 提取参数 VCS/Local History（版本控制/本地历史记录） Command + K 提交代码到版本控制器 Command + T 从版本控制器更新代码 Option + Shift + C 查看最近的变更记录 Control + C 快速弹出版本控制器操作面板 Live Templates（动态代码模板） Command + Option + J 弹出模板选择窗口，将选定的代码使用动态模板包住 Command + J 插入自定义动态代码模板 General（通用） Command + 1...Command + 9 打开相应编号的工具窗口 Command + S 保存所有 Command + Option + Y 同步、刷新 Control + Command + F 切换全屏模式 Command + Shift + F12 切换最大化编辑器 Option + Shift + F 添加到收藏夹 Option + Shift + I 检查当前文件与当前的配置文件 Control + ` 快速切换当前的scheme（切换主题、代码样式等） Command + , 打开IDEA系统设置 Command + ; 打开项目结构对话框 Shift + Command + A 查找动作（可设置相关选项） Control + Shift + Tab 编辑窗口标签和工具窗口之间切换（如果在切换的过程加按上delete，则是关闭对应选中的窗口） Other（一些官方文档上没有体现的快捷键） Command + Shift +8 竖编辑模式 从 Windows 过度到 Mac 必备快捷键对照表 Mac 键盘符号 图标 介绍 ⌘ Command ⇧ Shift ⇪ Caps Lock ⌥ Option = Alt ⌃ Control ↩ Enter ⌫ Delete ⌦ Fn + Delete ↑ 上箭头 ↓ 下箭头 ← 左箭头 → 右箭头 ⇞ Fn + ↑ = Page Up ⇟ Fn + ↓ = Page Down Home Fn + ← End Fn + → ⇥ Tab = 右制表符 ⇤ Shift + Tab = 左制表符 ⎋ Esc = Escape ⏏ 电源开关键 Alt Win 快捷键 Mac 快捷键 介绍 Alt + ` Control + V 显示版本控制常用操作菜单弹出层 Alt + F1 Option + F1 显示当前文件选择目标弹出层，弹出层中有很多目标可以进行选择 Alt + F7 Option + F7 查询所选对象/变量被引用 Alt + Enter Option + Enter IntelliJ IDEA 根据光标所在问题，提供快速修复选择，光标放在的位置不同提示的结果也不同 Alt + Insert Command + N 代码自动生成，如生成对象的 set / get 方法，构造函数，toString() 等 Alt + 左方向键 Control + 左方向键 切换当前已打开的窗口中的子视图，比如Debug窗口中有Output、Debugger等子视图，用此快捷键就可以在子视图中切换 Alt + 右方向键 Control + 右方向键 切换当前已打开的窗口中的子视图，比如Debug窗口中有Output、Debugger等子视图，用此快捷键就可以在子视图中切换 Alt + 前方向键 Control + 前方向键 当前光标跳转到当前文件的前一个方法名位置 Alt + 后方向键 Control + 后方向键 当前光标跳转到当前文件的后一个方法名位置 Alt + 1,2,3…9 Command + 1,2,3…9 显示对应数值的选项卡，其中 1 是 Project 用得最多 Ctrl Win 快捷键 Mac 快捷键 介绍 Ctrl + F Command + F 在当前文件进行文本查找 Ctrl + R Command + R 在当前文件进行文本替换 Ctrl + Z Command + Z 撤销 Ctrl + G Command + L 跳转到指定行数位置 Ctrl + Y Command + Delete 删除光标所在行 或 删除选中的行 Ctrl + D Command + D 复制光标所在行 或 复制选择内容，并把复制内容插入光标位置下面 Ctrl + W Option + 方向键上 递进式选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展选中范围 Ctrl + E Command + E 显示最近打开的文件记录列表 Ctrl + N Command + O 根据输入的 类名 查找类文件 Ctrl + J Command + J 插入自定义动态代码模板 Ctrl + P Command + P 方法参数提示显示 Ctrl + Q Control + J 当前位置变量、方法的 Documentation 内容显示 Ctrl + U Command + U 前往当前光标所在的方法的父类的方法 / 接口定义 Ctrl + B Command + B 进入光标所在的方法/变量的接口或是定义处，等效于 Ctrl + 左键单击 Ctrl + / Command + / 注释光标所在行代码，会根据当前不同文件类型使用不同的注释符号 Ctrl + F1 Command + F1 在光标所在的错误代码处显示错误信息 Ctrl + F11 Option + F3 选中文件 / 文件夹，使用助记符设定 / 取消书签 Ctrl + F12 Command + F12 弹出当前文件结构层，可以在弹出的层上直接输入，进行筛选 Ctrl + Space Control + Space 基础代码补全，默认在 Windows 系统上被输入法占用，需要进行修改，建议修改为 Ctrl + 逗号 Ctrl + Delete Option + Fn+ Delete 删除光标后面的单词或是中文句 Ctrl + BackSpace Option + Delete 删除光标前面的单词或是中文句 Ctrl + 1,2,3…9 Control + 1,2,3…9 定位到对应数值的书签位置 Ctrl + 加号 Command + 加号 展开代码 Ctrl + 减号 Command + 减号 折叠代码 Ctrl + 左键单击 Control + 左键单击 在打开的文件标题上，弹出该文件路径 Ctrl + 左方向键 Option + 左方向键 光标跳转到当前单词 / 中文句的左侧开头位置 Ctrl + 右方向键 Option + 右方向键 光标跳转到当前单词 / 中文句的右侧开头位置 Ctrl + 前方向键 预设中没有该快捷键 等效于鼠标滚轮向前效果 Ctrl + 后方向键 预设中没有该快捷键 等效于鼠标滚轮向后效果 Shift Win 快捷键 Mac 快捷键 介绍 Shift + F11 Command + F3 弹出书签显示层 Shift + Tab Shift + Tab 取消缩进 Shift + Enter Shift + Enter 开始新一行。光标所在行下空出一行，光标定位到新行位置 Shift + 左键单击 Shift + 左键单击 在打开的文件名上按此快捷键，可以关闭当前打开文件 Alt + Shift Win 快捷键 Mac 快捷键 介绍 Alt + Shift + N Option + Shift + N 选择 / 添加 task Alt + Shift + 左键双击 Option + Shift + 左键双击 选择被双击的单词 / 中文句，按住不放，可以同时选择其他单词 / 中文句 Alt + Shift + 前方向键 Option + Shift + 前方向键 移动光标所在行向上移动 Alt + Shift + 后方向键 Option + Shift + 后方向键 移动光标所在行向下移动 Ctrl + Alt Win 快捷键 Mac 快捷键 介绍 Ctrl + Alt + L Command + Option + L 格式化代码，可以对当前文件和整个包目录使用 Ctrl + Alt + O Control + Option + O 优化导入的类，可以对当前文件和整个包目录使用 Ctrl + Alt + T Command + Option + T 对选中的代码弹出环绕选项弹出层 Ctrl + Alt + S Command + 逗号 打开 IntelliJ IDEA 系统设置 Ctrl + Alt + Enter Command + Option + Enter 光标所在行上空出一行，光标定位到新行 Ctrl + Alt + 左方向键 Command + Option + 左方向键 退回到上一个操作的地方 Ctrl + Alt + 右方向键 Command + Option + 右方向键 前进到上一个操作的地方 Ctrl + Shift Win 快捷键 Mac 快捷键 介绍 Ctrl + Shift + F Command + Shift + F 根据输入内容查找整个项目 或 指定目录内文件 Ctrl + Shift + R Command + Shift + R 根据输入内容替换对应内容，范围为整个项目 或 指定目录内文件 Ctrl + Shift + J Control + Shift + J 自动将下一行合并到当前行末尾 Ctrl + Shift + Z Command + Shift + Z 取消撤销 Ctrl + Shift + W Option + 方向键下 递进式取消选择代码块。可选中光标所在的单词或段落，连续按会在原有选中的基础上再扩展取消选中范围 Ctrl + Shift + N Command + Shift + O 通过文件名定位 / 打开文件 / 目录，打开目录需要在输入的内容后面多加一个正斜杠 Ctrl + Shift + U Command + Shift + U 对选中的代码进行大 / 小写轮流转换 Ctrl + Shift + T Command + Shift + T 对当前类生成单元测试类，如果已经存在的单元测试类则可以进行选择 Ctrl + Shift + C Command + Shift + C 复制当前文件磁盘路径到剪贴板 Ctrl + Shift + B Control + Shift + B 跳转到类型声明处 Ctrl + Shift + / Command + Option + / 代码块注释 Ctrl + Shift + [ Command + Shift + [ 选中从光标所在位置到它的顶部中括号位置 Ctrl + Shift + ] Command + Shift + ] 选中从光标所在位置到它的底部中括号位置 Ctrl + Shift + 加号 Command + Shift + 加号 展开所有代码 Ctrl + Shift + 减号 Command + Shift + 减号 折叠所有代码 Ctrl + Shift + F7 Command + Shift + F7 高亮显示所有该选中文本，按Esc高亮消失 Ctrl + Shift + F12 Command + Shift + F12 编辑器最大化 Ctrl + Shift + Enter Command + Shift + Enter 自动结束代码，行末自动添加分号 Ctrl + Shift + Backspace Ctrl + Shift + Backspace 退回到上次修改的地方 Ctrl + Shift + 1,2,3…9 Control + Shift + 1,2,3…9 快速添加指定数值的书签 Ctrl + Shift + 左键单击 Command + Shift + 左键单击 把光标放在某个类变量上，按此快捷键可以直接定位到该类中 Ctrl + Shift + 左方向键 Option + Shift + 左方向键 在代码文件上，光标跳转到当前单词 / 中文句的左侧开头位置，同时选中该单词 / 中文句 Ctrl + Shift + 右方向键 Option + Shift + 右方向键 在代码文件上，光标跳转到当前单词 / 中文句的右侧开头位置，同时选中该单词 / 中文句 Ctrl + Shift + 前方向键 Command + Shift + 前方向键 光标放在方法名上，将方法移动到上一个方法前面，调整方法排序 Ctrl + Shift + 后方向键 Command + Shift + 后方向键 光标放在方法名上，将方法移动到下一个方法前面，调整方法排序 Ctrl + Shift + Alt Win 快捷键 Mac 快捷键 介绍 Ctrl + Shift + Alt + V Command + Shift + Option + V 无格式黏贴 Ctrl + Shift + Alt + S Command + ; 打开当前项目设置 Other Win 快捷键 Mac 快捷键 介绍 F2 F2 跳转到下一个高亮错误 或 警告位置 F4 F4 编辑源 F11 F3 添加书签 F12 F12 回到前一个工具窗口 Tab Tab 缩进 ESC ESC 从工具窗口进入代码文件窗口 最特殊的快捷键 Alt + Enter 介绍 说明 这是一个非常特殊的快捷键，有必要拿出来单独讲。 强烈注意：此快捷键跟光标所在位置有着很严重关联关系，光标放的位置不同，使用此快捷键出来的菜单选项完全不一样。 可以从几个思路：Java 类、JSP、HTML、JavaScript、CSS、SQL 等文件类型 下面演示的各个功能是基于：IntelliJ IDEA 2016.1.1，如果你使用早期版本，可能不一定有对应的功能。 智能辅助 在 接口类 中，如果光标当前所在的方法，已经在 接口实现类 中生成了，则此快捷键的效果是跳转。 在 接口类 中添加一个方法后，让该 接口实现类 也跟着生成 在 接口实现类 中添加一个方法后，让该 接口类 也跟着生成 对当前光标所在类，生成单元测试类 对当前光标所在类，创建子类，常用在对接口生成接口实现类 移除未使用的变量、对象等元素 对属性创建 set、get 方法 添加 doc，只能把光标放在方法名或是变量名等这类元素上才会有 把自己造的单词加入词库中，让拼写单词检查错误的波浪线效果消失。 自己造的词库在上图所示位置 快速移除当前类所继承的接口，并且同时清空已经写好的该接口所有的 Override 方法。 光标只能方式 接口实现类 上的 接口对象单词 上才可以实现。 修改光标当前元素的作用域 给调用的方法生成返回值 根据返回值自动强转 对光标所在的对象进行包导入 切换成静态导入 根据 Language Level 级别不同，JDK 特性不同，给不同意见。Language Level 的含义在其他章节有讲过。 给 Hibernate 的 Entity 对象分配数据源，从而产生一系列智能功能 ","description":"\n","tags":[],"title":"\nIDEA快捷键","uri":"/posts/post-322/"},{"categories":["默认分类"],"content":"简洁清爽的代码风格应该是大多数工程师所期待的。在工作中笔者常常因为起名字而纠结，夸张点可以说是编程5分钟，命名两小时！\n每个公司都有不同的标准，目的是为了保持统一，减少沟通成本，提升团队研发效能。所以本文中是笔者结合阿里巴巴开发规范，以及工作中的见闻针对Java领域相关命名进行整理和总结，仅供参考。\n一，Java中的命名规范 好的命名能体现出代码的特征，含义或者是用途，让阅读者可以根据名称的含义快速厘清程序的脉络。不同语言中采用的命名形式大相径庭，Java中常用到的命名形式共有三种，既首字母大写的UpperCamelCase，首字母小写的lowerCamelCase以及全部大写的并用下划线分割单词的UPPERCAMELUNSER_SCORE。通常约定，类一般采用大驼峰命名，方法和局部变量使用小驼峰命名，而大写下划线命名通常是常量和枚举中使用。\n类型(名) 约束 例 项目 全部小写多个单词用中划线分隔‘-’ spring-cloud 包 全部小写 com.alibaba.fastjson 类 单词首字母大写 Feature,FieldDeserializer 变量 首字母小写多个单词组成时，除首个单词其他单词首字母都要大写 password, userName 常量 全部大写，多个单词，用’_‘分隔 CACHEEXPIREDTIME 方法 同变量 read(), getById(Long id) 二，包命名 包名统一使用小写，点分隔符之间有且仅有一个自然语义的英文单词或者多个单词自然连接到一块（如 springframework，deepspace不需要使用任何分割）。包名统一使用单数形式，如果类命有复数含义，则可以使用复数形式。\n包名的构成可以分为以下几四部分【前缀】 【发起者名】【项目名】【模块名】。常见的前缀可以分为以下几种：\n前缀 例 含义 indi或onem indi.发起者名.项目名.模块名.…… 个体项目个人发起，但非自己独自完成可公开或私有项目，copyright主要属于发起者。 pers pers.个人名.项目名.模块名.…… 个人项目指个人发起，独自完成，可分享的项目copyright主要属于个人 priv priv.个人名.项目名.模块名.…… 私有项目，指个人发起，独自完成非公开的私人使用的项目，copyright属于个人。 team team.团队名.项目名.模块名.…… 团队项目，指由团队发起并由该团队开发的项目copyright属于该团队所有 顶级域名 com.公司名.项目名.模块名.…… 公司项目copyright由项目发起的公司所有 三，类命名 类名使用大驼峰命名形式，类命通常时名词或名词短语，接口名除了用名词和名词短语以外，还可以使用形容词或形容词短语，如Cloneable，Callable等，表示实现该接口的类有某种功能或能力。对于测试类则以它要测试的类开头，以Test结尾，如HashMapTest。\n对于一些特殊特有名词缩写也可以使用全大写命名，比如XMLHttpRequest，不过笔者认为缩写三个字母以内都大写，超过三个字母则按照要给单词算。这个没有标准如阿里巴巴中fastjson用JSONObject作为类命，而google则使用JsonObjectRequest命名，对于这种特殊的缩写，原则是统一就好。\n属性(类) 约束 例 抽象 Abstract 或Base 开头 BaseUserService 枚举 Enum 作为后缀 OSType 工具 Utils作为后缀 StringUtils 异常 Exception结尾 RuntimeException 接口实现 接口名+ Impl UserServiceImpl 领域模型相 /DO/DTO/VO/DAO 正例：UserDAO反例：UserDao 设计模式相关 Builder，Factory等 当使用到设计模式时要使用对应的设计模式作为后缀如ThreadFactory 处理特定功能 Handler，PredicateValidator 表示处理器，校验器，断言这些类工厂还有配套的方法名如handle，predicate，validate 测试 Test后缀 UserServiceTest表示用来测试UserService类的 MVC分层 Controller，ServiceServiceImpl，DAO后缀 UserManageControllerUserManageDAO 四，方法 方法命名采用小驼峰的形式，首字小写，往后的每个单词首字母都要大写。和类名不同的是，方法命名一般为动词或动词短语，与参数或参数名共同组成动宾短语，即动词 + 名词。一个好的函数名一般能通过名字直接获知该函数实现什么样的功能。\n4.1 返回真伪值的方法 位置 单词 意义 例 pre is 对象是否符合期待的状态 isValid pre can 对象能否执行所期待的动作 canRemove pre should 调用方执行某个命令或方法是好还是不好应不应该，或者说推荐还是不推荐 shouldMigrate pre has 对象是否持有所期待的数据和属性 hasObservers pre needs 调用方是否需要执行某个命令或方法 needsMigrate 4.2 用来检查的方法 单词 意义 例 ensure 检查是否为期待的状态 不是则抛出异常或返回error code ensureCapacity validate 检查是否为正确的状态 不是则抛出异常或返回error code validateInputs 4.3 按需求才执行的方法 位置 单词 意义 例 suf IfNeeded 需要的时候执行不需要则什么都不做 drawIfNeeded pre might 同上 mightCreate pre try 尝试执行失败时抛出异常或是返回errorcode tryCreate suf OrDefault 尝试执行失败时返回默认值 getOrDefault suf OrElse 尝试执行失败时返回实际参数中指定的值 getOrElse pre force 强制尝试执行error抛出异常或是返回值 forceCreate, forceStop 4.4 异步相关方法 位置 单词 意义 例 pre blocking 线程阻塞方法 blockingGetUser suf InBackground 执行在后台线程 doInBackground suf Async 异步方法 sendAsync suf Sync 同步方法 sendSync pre/alo schedule Job和Task放入队列 schedule, scheduleJob pre/alo post 同上 postJob pre/alo execute 执行异步或同步方法 execute,executeTask pre/alo start 同上 star,tstartJob pre/alo cancel 停止异步方法 cance,cancelJob pre/alo stop 同上 stop,stopJob 4.5 回调方法 位置 单词 意义 例 pre on 事件发生时执行 onCompleted pre before 事件发生前执行 beforeUpdate pre pre 同上 preUpdate pre will 同上 willUpdate pre after 事件发生后执行 afterUpdate pre post 同上 postUpdate pre did 同上 didUpdate pre should 确认事件是否可以执行 shouldUpdate 4.6 操作对象生命周期的方法 单词 意义 例 initialize 初始化或延迟初始化使用 initialize pause 暂停 onPause , pause stop 停止 onStop, stop abandon 销毁的替代 abandon destroy 同上 destroy dispose 同上 dispose 4.7 与集合操作相关的方法 单词 意义 例 contains 是包含指定对象相同的对象 contains add 添加 addJob append 添加 appendJob insert 插入到下标n insertJob put 添加与key对应的元素 putJob remove 移除元素 removeJob enqueue 添加到队列的最末位 enqueueJob dequeue 从队列中头部取出并移除 dequeueJob push 添加到栈头 pushJob pop 从栈头取出并移除 popJob peek 从栈头取出但不移除 peekJob find 寻找符合条件的某物 findById 4.8 与数据相关的方法 单词 意义 例 create 新创建 createAccount new 新创建 newAccount from 从既有的某物新建或是从其他的数据新建 fromConfig to 转换 toString update 更新既有某物 updateAccount load 读取 loadAccount fetch 远程读取 fetchAccount delete 删除 deleteAccount remove 删除 removeAccount save 保存 saveAccount store 保存 storeAccount commit 保存 commitChange apply 保存或应用 applyChange clear 清除或是恢复到初始状态 clearAll reset 清除或是恢复到初始状态 resetAll 4.9 成对出现的动词 单词 意义 get获取 set 设置 add 增加 remove 删除 create 创建 destory 移除 start 启动 stop 停止 open 打开 close 关闭 read 读取 write 写入 load 载入 save 保存 create 创建 destroy 销毁 begin 开始 end 结束 backup 备份 restore 恢复 import 导入 export 导出 split 分割 merge 合并 inject 注入 extract 提取 attach 附着 detach 脱离 bind 绑定 separate 分离 view 查看 browse 浏览 edit 编辑 modify 修改 select 选取 mark 标记 copy 复制 paste 粘贴 undo 撤销 redo 重做 insert 插入 delete 移除 add 加入 append 添加 clean 清理 clear 清除 index 索引 sort 排序 find 查找 search 搜索 increase 增加 decrease 减少 play 播放 pause 暂停 launch 启动 run 运行 compile 编译 execute 执行 debug 调试 trace 跟踪 observe 观察 listen 监听 build 构建 publish 发布 input 输入 output 输出 encode 编码 decode 解码 encrypt 加密 decrypt 解密 compress 压缩 decompress 解压缩 pack 打包 unpack 解包 parse 解析 emit 生成 connect 连接 disconnect 断开 send 发送 receive 接收 download 下载 upload 上传 refresh 刷新 synchronize 同步 update 更新 revert 复原 lock 锁定 unlock 解锁 check out 签出 check in 签入 submit 提交 commit 交付 push 推 pull 拉 expand 展开 collapse 折叠 begin 起始 end 结束 start 开始 finish 完成 enter 进入 exit 退出 abort 放弃 quit 离开 obsolete 废弃 depreciate 废旧 collect 收集 aggregate 聚集 五，变量\u0026常量命名 5.1 变量命名 变量是指在程序运行中可以改变其值的量，包括成员变量和局部变量。变量名由多单词组成时，第一个单词的首字母小写，其后单词的首字母大写，俗称骆驼式命名法（也称驼峰命名法），如 computedValues，index、变量命名时，尽量简短且能清楚的表达变量的作用，命名体现具体的业务含义即可。\n变量名不应以下划线或美元符号开头，尽管这在语法上是允许的。变量名应简短且富于描述。变量名的选用应该易于记忆，即，能够指出其用途。尽量避免单个字符的变量名，除非是一次性的临时变量。pojo中的布尔变量，都不要加is(数据库中的布尔字段全都要加 is_ 前缀)。\n5.2 常量命名 常量命名CONSTANT_CASE，一般采用全部大写（作为方法参数时除外），单词间用下划线分割。那么什么是常量呢？\n常量是在作用域内保持不变的值，一般使用final进行修饰。一般分为三种，全局常量（public static final修饰），类内常量（private static final 修饰）以及局部常量（方法内，或者参数中的常量），局部常量比较特殊，通常采用小驼峰命名即可。\n/** * 一个demo * * @author XiaoMage * @date 2020-07-07 00:25 **/ public class HelloWorld { //局部常量(正例) public static final long USER_MESSAGE_CACHE_EXPIRE_TIME = 3600; //局部常量(反例，命名不清晰） public static final long MESSAGE_CACHE_TIME = 3600; // 全局常量 private static final String ERROR_MESSAGE = \"error message\"; //成员变量 private int currentUserId; /** * 控制台打印 {@code message} 信息 * * @param message 消息体，局部常量 */ public void sayHello ( final String message ) { System.out.println(\"Hello world!\"); } } 常量一般都有自己的业务含义,不要害怕长度过长而进行省略或者缩写。如，用户消息缓存过期时间的表示，那种方式更佳清晰，交给你来评判。\n通用命名规则 1.尽量不要使用拼音；杜绝拼音和英文混用。对于一些通用的表示或者难以用英文描述的可以采用拼音，一旦采用拼音就坚决不能和英文混用。正例：BeiJing， HangZhou 反例：validateCanShu\n2.命名过程中尽量不要出现特殊的字符，常量除外。\n3.尽量不要和jdk或者框架中已存在的类重名，也不能使用java中的关键字命名。\n4.\u003e妙用介词，如for(可以用同音的4代替), to(可用同音的2代替), from, with，of等。如类名采用User4RedisDO，方法名getUserInfoFromRedis，convertJson2Map等。\n六，代码注解 6.1 注解的原则 好的命名增加代码阅读性，代码的命名往往有严格的限制。而注解不同，程序员往往可以自由发挥，单并不意味着可以为所欲为之胡作非为。优雅的注解通常要满足三要素。\n1.Nothing is strange 没有注解的代码对于阅读者非常不友好，哪怕代码写的在清除，阅读者至少从心理上会有抵触，更何况代码中往往有许多复杂的逻辑，所以一定要写注解，不仅要记录代码的逻辑，还有说清楚修改的逻辑。\n2.Less is more 从代码维护角度来讲，代码中的注解一定是精华中的精华。合理清晰的命名能让代码易于理解，对于逻辑简单且命名规范，能够清楚表达代码功能的代码不需要注解。滥用注解会增加额外的负担，更何况大部分都是废话。\n// 根据id获取信息【废话注解】 Advance with the time 注解应该随着代码的变动而改变，注解表达的信息要与代码中完全一致。通常情况下修改代码后一定要修改注解。 6.2 注解格式 注解大体上可以分为两种，一种是javadoc注解，另一种是简单注解。javadoc注解可以生成JavaAPI为外部用户提供有效的支持javadoc注解通常在使用IDEA，或者Eclipse等开发工具时都可以自动生成，也支持自定义的注解模板，仅需要对对应的字段进行解释。参与同一项目开发的同学，尽量设置成相同的注解模板。\na. 包注解 包注解在工作中往往比较特殊，通过包注解可以快速知悉当前包下代码是用来实现哪些功能，强烈建议工作中加上，尤其是对于一些比较复杂的包，包注解一般在包的根目录下，名称统一为package-info.java。\n/** * 落地也质量检测 * 1. 用来解决什么问题 * 对广告主投放的广告落地页进行性能检测，模拟不同的系统，如Android，IOS等; 模拟不同的网络：2G，3G，4G，wifi等 * 2. 如何实现 * 基于chrome浏览器，用chromedriver驱动浏览器，设置对应的网络，OS参数，获取到浏览器返回结果。 * 注意：网络环境配置信息{@link cn.mycookies.landingpagecheck.meta.NetWorkSpeedEnum}目前使用是常规速度，可以根据实际情况进行调整 * @author xiaomage * @time 2020/07/7 20:3 下午 */ package cn.maruifu.landingpagecheck; b. 类注接 javadoc注解中，每个类都必须有注解。\n/** * Copyright (C), 2019-2020, XiaoMage balabala... * 类的介绍：这是一个用来做什么事情的类，有哪些功能，用到的技术..... * @author 类创建者姓名 保持对齐 * @date 创建日期 保持对齐 * @version 版本号 保持对齐 */ c. 属性注解 在每个属性前面必须加上属性注释，通常有一下两种形式，至于怎么选择，你高兴就好，不过一个项目中要保持统一。\n/** 提示信息 */ private String userName; /** * 密码 */ private String password; d. 方法注释 在每个方法前面必须加上方法注释，对于方法中的每个参数，以及返回值都要有说明。\n/** * 方法的详细说明，能干嘛，怎么实现的，注意事项... * @param xxx 参数1的使用说明， 能否为null * @return 返回结果的说明， 不同情况下会返回怎样的结果 * @throws 异常类型 注明从此类方法中抛出异常的说明 */ e. 构造方法注释 在每个构造方法前面必须加上注释，注释模板如下：\n/** * 构造方法的详细说明 * @param xxx 参数1的使用说明， 能否为null * @throws 异常类型 注明从此类方法中抛出异常的说明 */ 而简单注解往往是需要工程师字节定义，在使用注解时应该注意一下几点：\n枚举类的各个属性值都要使用注解，枚举可以理解为是常量，通常不会发生改变，通常会被在多个地方引用，对枚举的修改和添加属性通常会带来很大的影响。\n保持排版整洁，不要使用行尾注释；双斜杠和星号之后要用1个空格分隔。\nint id = 1 ; // 反例：不要使用行尾注释 //反例：换行符与注释之间没有缩进 int age = 18 ; // 正例：姓名 String name ; /** * 1. 多行注释 * * 2. 对于不同的逻辑说明，可以用空行分隔 */ 总结 无论是命名和注解，他们的目的都是为了让代码和工程师进行对话，增强代码的可读性，可维护性。优秀的代码往往能够见名知意，注解往往是对命名的补充和完善。命名太难了！\n参考文献：《码出高效》 https://www.cnblogs.com/wangcp-2014/p/10215620.html https://qiita.com/KeithYokoma/items/2193cf79ba76563e3db6 https://google.github.io/styleguide/javaguide.html#s2.1-file-name\n","description":"\n","tags":[],"title":"\n编码5分钟，命名2小时？Java开发都需要参考的一份命名规范！","uri":"/posts/post-323/"},{"categories":["语言"],"content":"\n","description":"\n","tags":[],"title":"\n各种乱码原因及示例","uri":"/posts/post-324/"},{"categories":["语言"],"content":" public static void main(String[] args) throws Exception{ Class clazz = Class.forName(\"com.mantis.hc.sale.dto.response.ExamAssistCustomerQueryRespDTO\"); Class clazz1 = ExamAssistCustomerQueryRespDTO.class; ExamAssistCustomerQueryRespDTO examAssistCustomerQueryRespDTO = new ExamAssistCustomerQueryRespDTO(); examAssistCustomerQueryRespDTO.setAccount(\"qweqweqweqweqw\"); String attachmenturl = (String) clazz.getMethod(\"getAccount\").invoke(examAssistCustomerQueryRespDTO);//执行方法 String attachmenturl1 = (String) clazz1.getMethod(\"getAccount\").invoke(examAssistCustomerQueryRespDTO);//执行方法 System.out.println(attachmenturl); System.out.println(attachmenturl1); } ","description":"\n","tags":[],"title":"\nJava 通过反射动态执行方法","uri":"/posts/post-325/"},{"categories":["默认分类"],"content":" import java.net.HttpURLConnection; import java.net.URL; import java.util.ArrayList; import java.util.Arrays; import java.util.List; public class TextFile { // 验证表单 public static void main(String[] args) throws Exception{ // select group_concat(CONCAT('\"',download_url,'\"')) from course_unit_live_ware where company_id = 6131 ' List\u003cString\u003e list = Arrays.asList(\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/702e126d6d714be0979ae27aaa59893b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/98edd35b7e8a493cbeeda2bf4abeb8d8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/92e2360fc7514bd191b1c248de8fda5d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/85faf19d86084a938571907db4f83c4a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/40dbca378bb943f7b3e37d5b5eac96d2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/801813d720bd4c78a2dd625b67c06d47.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/17edf013973e4165bfc7dde51df5bd35.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7f0d8f3582c0404b8ae2b1f5dc412634.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/432b9e8c14554b97b0e768d0c537e1ec.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9b631ac34bd6481bbad76972aa4fc451.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e14972af0bc544d6ac0b7e9afdc6eacb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/556f9f7f7fad46adbc503d04b828e8d7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/97bf085bedbd4580a4ab11ee3f647bab.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/daaf99588ea74c4096bc5a7a67a863d1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/40d2f50034ee48ebb12be2041c7993b1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f1a4c1d1e6dd49f6916b12fa567f7e90.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/465aa654f340470eab8c2b42e5910f9c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8ee3a5f6498c41f09b395eb6a0a196f9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/da32ffe3f65e452d837a3a3f725dc616.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5d26ba917eed4cd993f9277f00136f74.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/305205f4ca904947a12ce6c70f63b2a8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2318f7bebcdf4753a7691f7698fd7276.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7e5dc3b31ee8410198f17c76be171191.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1523b5a96b07454199aa49f754455d9f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/acffe314668c406588c1a4a561623bf1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e530da73cd9b44e696b4c28bee7120ab.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/de71dd25a42c4fe5a8440657e3cb7bcb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3c8b5a8afd9c4e7196d1b72ab2f9d1a0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9c3127b283d8421889d29b634063e575.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/702913e86512412ca059ec0ce1c8dd23.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4399c6b54449437eacc28ed16dae37e9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a82bb1c6e8ba4f7dbfafa52fad6f20f6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b80cfe4d7795401d9a7329cbd2f1c632.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f5db2f998cc2420ab8dd49797c446075.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/bc5f5e7339b54ddab1e4fe14ff093a8c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/236aa74e879c43ba9ec8ce9ab5362aa7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9b5181135c514aa6817054c80e8951b5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/814faa0ed3a049e28d283ce46c42e534.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/04a34d0d6e8a45909c1a69bc2c53879a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5035619fd8d046efb801f814eb4d3558.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/655af2f33be44ca6a65d44bd105ae096.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/93c12587782743329023ed1755f1017d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1d419488dbc347dcbf2fa7ad8d907490.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4665ae7009294581be2d8c440cf6ec85.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/76094bdd6e394d6690b33061cb368b08.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/dde28a8ad6654df0a41ef060bff1b054.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c4e9fa0593e74f41bc69d5482ebf0ed7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a52b5a15d57f4489869221d9e61882d8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cb65b44b33c84c3eadbb788d265b717a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/bd9b7a76d4904e6a9e668c046918aac5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/990a50760fd7423c92f1d22053370790.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/bc1bdda8c4a24a39bff8d9e84405de27.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/65959afab74d4c40a4272f5b2bd23462.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/df38fb50715d4fd488bfcb4ae9e5bee0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7c1694b04396468fa4175607af1a7e88.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0f2dc86a8be44e8a9a90b4f3a2eca107.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c929491d7c0d46b8bb259bc298047976.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3ad9793493394a04a92584bdb1202277.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/41cbf947e9e547b68e1580c4271203b2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0a848a84fd0d4723abb53db288be1dbe.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/26bc66ade8004f0783ec89e5191f1970.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b4e4a530640841749221098c7f556ace.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6678c4d1cd2c4e1eabf5e2a5b8a0b9fd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/578021ed9ad34f3888f5a30199fb51e3.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f32e6b9987ea470896b851e4176767c6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9890795f2c4749499cc57ba7f0bae515.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a68c04cef9754d12aa238c14e2a66181.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6bea411318a14c5eadcbde42a2b7211d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/904b398d0696462781ae651b1cc6b582.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a59a2f023a63419f99609fd1dae74e9d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6771117fa0a3429da9f23e221f7a5908.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a45d79bcd66f412387a835f060ae2040.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4d2989eaf73c4364a6f199c9c424b505.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/362d50b7f5bc43669c007146b3de965c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/97c2992ab3d540549f2af5412c9fefb2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/470e3bc8f4e54078807152d1c052d9a0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a37e58c2c46e4e5295d7afc13263c271.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b7c1354fcea44ddfa6dcc3c25f87e7bc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d31d2de60ffe49a8b52f2b2f701ad4ce.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/03b42aaad4b94ae5a7ed30ecaa7ee135.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/fc2c45344443421eb2e5b8fbd8a870ef.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/24fd13b3cd8b4f85996d9737a7a4b38f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4a9f9e3e7da24dcd859b59f134f7e56f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/47c26ed24c79495ebb1550c35702d706.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f9b9028f7b6d45568fdc1b67b159d43f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/209713f818f745a98037960f26398514.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6376fc4b1c6e4e4d96f6a639d8da90df.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/31842ec0a13843828b8f689eb839c3c9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c717c3778c8b4a269a5e1b8722a70b03.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3abc12043a074558b0838cf9d2142d54.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cd63c7b95e68435487b55cef8ad60401.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4cff460653c941c09f561075a6ea094c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/046289ebeb66464f8ee4c9513f2655c1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/321ef6ee5f8646959b1462bc9c95b7e1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/38a19f3313864b4c967946ccc8577a8a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8f7a4de2e83e46cfb213b867b22a4042.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cc3373db56284de6975e092b7f228cf6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9944faf6b227420d87f2941f6feae97e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/db36d8b49c224dd798eff66adf10b2a7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b2af642a1d6941a7ba81f12db2607fd1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/725521c38fe543c5af09d84979aca35e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6cd3da393aeb460689de4411a950ff74.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a15a5be305e14fb3bd7203d499ecc567.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8049502208b14c7b93225127c8159baa.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/afdea3fb6be44d9d90c825b6c75ef3be.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5b73b211dc154ca4847fb11a69b6f6c6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/08fafe56896440249bd7d690fc843974.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ad855a6e9dcf49cda150aedac627d3dd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f45f3e1f3c5041699dd8bce6f966243b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/647944e827d04721be28e714154ae901.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6c2f659c6e334417801eb1daafaf135b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2fa519d6f0f64905b01be3e779f29880.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/df0f1e9799f6477c823f7494b7a1aa04.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f4dcf7599b9c4620adf872716c217640.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1ceb49d70da94f5daff406dc37127e19.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ccdb98eb3bf8426e8bde3e223afd3026.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2dae8777056e42f6b22ca9e4b2eac3e4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cfee387fbe9d407e9cb3ce5ed638adcc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ebd27fa837404af194c61d1eac959fd3.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1c5180b459eb4ec4857f9981e109abfb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/87b206cbf0e24b18a8540d5738fa842b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3173fedd9d7b4372a11b543814c09423.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b3169327123f441896feaa226773a9a1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/48ebbfe856404df8b989ed4300ffa865.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/47238eef8b974789931b1fc35aa48efa.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e1bf5fcde3474dc3bb0244b923447fc3.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/43cfeaa763134734ad8330c812276d64.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c618ca9b9b2444b1a1ed00a2e0cf89c9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4fc82e4e91584f82ab6663ce96dd0fa9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d5945638b9694eb9a04bfc284fe4a1ed.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1f4bb2208c0a42e3af0cb1a6182ead1a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ec150daf5d27463ebe6f5e7910109f95.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/85eea4197af44654bbbaeb8bedb6bf42.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f9f2d72878dc425aa2ab7c77889cae2b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/70bf652c2f51496d92f21e337baf1f6b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c74cac5bbc7e45d1815dd3c83296f86d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2abd872158f143ca8ec56d22ef62b54f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a7ad7cbaeab345f7801f1c0c8abc453a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/36b1942b04c1475b927ca4d835f11f4b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7c74d4e6e1224365828bd1f611fd513c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/fbe780219f17485a82748950f2ab6ee2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5364ae000d214a088dccf3a9326bea22.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6bfe48dc82204132b68072b3d34fbf29.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8d921d267afe49e0a6697bda05380359.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/63fcef2ff33c45c69395e340a65aa161.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c1c2e9d1c7ed44dbb94623df56862a6b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/33f4db0be5ca472eb38004b1600c055e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6eccb93d0f52447288b7342cda2c3bbe.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f54f3da8813e4ac7bf8ba9174f795d62.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/17a7775f5b6d4f799546305f53ee52ed.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0fc95b9fcc3f4576a0940e9e7efb8ed7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e6ee9403d91b443f9aa9ec807b098264.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/61ae2f85bc1a4355ab5b3fb69afce8b6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/da9119fba59042978ed8e8ed7b145e29.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/10e7ecf7086e4a14a9c380ac0cb1e6f5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/21a8fb0ac5a84a56893b41cf3607bbe1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e4880563e9854638b9af4326364eb96b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e4ab8910528e4dfd9fee0cd8b6fb6a82.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0bd1a001efda45e98d972be536e66c96.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6de2663b03994821a41ff7decb59454e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d422ddcd633a49fc8fff8e16140d40d0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/bfdc6fcbf2c342178c0bf1f2aaeeb9cd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/aece5d987a44450d84935ef39b9a7191.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f595c285caa74c53b8e9eabad024a484.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/93fd02eab7b74b5997597d1d24646e16.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/631cf8b3ddf548d0b5c4b2a5bbc74cc0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3fc94ebc5df14350b7ff624349c6b58c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/dbfeca63b4874a1383c5f716721452ee.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3773871bb4944bafb7c3c327c0e60072.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b40760e210c74524ba4396a34036f7db.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b62b8ac8a8194fa2a028b9cb8e28b215.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/42a938b887674c109f374ce0bfc96853.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/afaa6ce55bc94d2185b15359a4d789db.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1d99d5db80a14e9ba120552026631a53.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c01239c39d27420c8418600266a33ed1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/aaea4eb937ec4c388c30bf7708d4be3c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/96f3575572634efabc19946280e4c84f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1b9570d0ecde48039da3898a4a7c3a40.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c081166b33a74fdf9cea16f1ef924f1f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/30716f87fa7144558e834698e9cdaf7c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/725948959892497db16e1fe34d675bb5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9dfea505e88d4057a6a498b20e9b2e93.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4d0ec18bd84e46eab629ad108011310a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/15ceab0dc07441ca90ee5c7c7ffd271f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2757b1d23f00407d92faf5c1aef9550c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e340cd08ae894895bcdb47f81851dcd5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/34863b8f7eb147c29262121efb6b6283.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6590bfde51464c3bacf3fb610f3d1acc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4937d28e80684764ae4034af55175256.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/57121fe2bbb54aee9b23eb53b9570bb2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/42db3aa3402749e48de56bf6145bc183.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/da6357ffaef64c04939bebadbdb6905d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8f240821533f40ceb6799e9db3ce6ca5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b4bde65129ea4d9e9342cb1b40faa140.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0ab03bb06d344403820611b3352002d1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/27209d0481724b84a7bdd278492caaa7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6f6f8e02fd93495eb90249294ded1951.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4f56c72b47684a5b90a4b72ba6ebc1a4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/08999852765e4989831a03aeaaee12be.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cc06d4f0c95d496aa51370ceb8353445.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3391b05f8a604846ab2e06a123fe47dd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1f1228d839964a709d3460bcb34ca70f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/848ed3759ead42739ae28c912548796e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/41acaa8ecff148a2a7b0a3bd18c5b1c9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/76bfa468be4549e8be8a759168f2e551.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/235d15a8dd674987bd6d6c1dcc6463e5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/af68a15ac82444489b066133aea9364e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/34ef5c8f49a9495a9ac7916d9ae66400.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ba51a40fd01e4225879d1d6b5ba4041b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6d345e4cf7194e35ab4a875948cff8e7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/08aa9c027dd24cfd926f644371f7a616.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b6a261a26c40497e881156086adf43c1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/befc62e1d6f843cf8f8380d03fe70314.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/aa584d5f9fbd497897dd92c730c6409c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/527b5bde112d40b79d78ee75e443886d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1678b30c91a9447982ddf57f25ae3706.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a688199c1dba467baf1e24e782abb448.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1bd090b0c574493e98e2775fbebec87b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/077494bdfb1d45ac82eac5bbd56131f8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c8bd0dc922b348768e0b5d70c8693286.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c330b7911d4644108cdc2c742fc7eef7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e6c69443c89c4964b8e21d58ee793f52.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/37946a398bc14a7086a2fa5579cabead.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f05fb7dec291461bbd7369593471b42d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/67126a414fde458484e0bdbc8e2abd0e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/71a1353575e649b0981005d2daccd3ac.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/528f74c1592f4a7ea484a99e38b876e0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2ed90dd3fd9c452eadea1f9460409238.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7317277cf2d140a0932b89b38c9f35ef.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/833818abbcc1468489e40003c7ed8e73.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1741ebce7c304d9b8ed246862baa17f8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/490e84fbd87b49f9912923f8aac257aa.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/01e981fa150840c7b61e8167d048638a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7ec16fbf5f37434ab5d5bda3580ac718.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9791c64c476c40b38b9a6a120cd791d0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6934345b5fbd416aa906e9b357272e43.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/77da91f473ce45b0b513dbee9a6d6e37.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b4217239b1d14ca19b936f7a20cc382f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/843311bb924d452cbf9f8b92c9d7725b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/21032a09cf8247c28c7e43f47e1a9268.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/20d60c5b1224401c8f5059bd8bfbc6c9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/470edcb52e5448438ddf0eefebf16b81.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/913bcbe1446e4de69d025edf4ba4fae8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8fb29a70afdc45abb36f0a327fe4c9a5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1c57a9c3222a474d842eddeb3d160b1b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ab5e101b6c374675b48f18c39ce305b1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4405ae77db234aa8a18ab44dc5b9420c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c8c0f2b3179c4dd783a07a718164608b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e3c10a963fd1420e9dd22eec425030cc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2bb7d0149b244408b23f83a58566eca0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/043b4d41c5774f9e8f7f6659fa3244c1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8df88e5baf5247819c386976bf5b9727.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e45bf3b8935a4e029a7474c93a6d00fd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8050a0e3b59245ebafd6057249a3e62a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5acef8968dc046a08aa298537ad7b710.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e5ba00b5514e46fea6055f9be573bfd8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a2f8423e90774fb4a2d28b2176d3f28a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a1d5c4bd622b43f98eaa67d3cb611b71.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3d8695a44c4146e69b3747cbe19d49df.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a5fd9b02e39941f4b300983af4e68bdf.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c40e1fe177a749ecba2ad5e22e49239a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/005f698dc07f4d56a11bebf89b165e3e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/318c66e0eb254e9cac985ca6d865f73a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/74a067d33d2d472d87f21f640de207ba.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/18c2e65ec53943ee80f6e8c96f16f0a7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/960ba5cb20a3433d8dd63de3c485b9b5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b2c053dd926547229906d4edfb8fb720.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9841251ab3d34075b91a05d3a088a317.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5bf7ed7ebdce48e8a2e466ec24787572.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/32519bdde8604d99bc90f13dffbc82e9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9039ae579dc4414d947a05cf3607bcbf.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b7547a934d1447d7bdf67da0fbeefc6d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ac381ef03a4a4f9d84966104d6572fe9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5ba6cf6c64404e539d667165b1f86f92.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/dcd341f7107f477c9ec36ed5350b6225.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4d4f80fa9b8c4843852fd45331ab13f8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1bae7f7c2612430d94a6c9e4ef15706d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/86b7befae3494bb1b5ced5a7f142eb0e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6621475986b74e7cad92f321a999735b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f679ae3072b74e1faf18b992d242327d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/88bfea43c8d3446398ce818ccff9d0c1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ef4bd9ea4cec42b080dfb9643ff64dff.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/91a2b48a8e354f19ba633fb32f2e7bf0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5abc237429764d75b3b6cfe8f12748e4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/dd0abc5c76af4b4990fdd61c38588535.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8a7800eab12a4528a3b3f0f891e5ce14.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0ae97e79fac245539150f005aa9a726f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e159f7e8e3b54dd8aba4d72b060038fe.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0df42666f8c44204b9a9d776e36bad5d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/675cc8a5010341b5b7c41e25d29264fa.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cd7ceab0bdad40cf95a08407e640598c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/93c0ffe1b54c485ca988b9149fb43555.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5535fd57f9124916ae416ca4f070f624.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/809ad13d1825429681d986545412751f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4a3049b53bb54ff1901bd731d73b27ce.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7773657805f64ea6aff300abe8d65adb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/69a0868b745a413197317f7da61e73fd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/51184f8eac134959b2c834ee5f4838df.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/dca8fd9556934aec83a100490bd584d3.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3404fe69b30741faa5f2d879ed9931d9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9ec19754dc9c4e4a8f673dc7eb8d9f30.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/80d409ecaa18477ba3b77c784150a15c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b66faffcf3ec4079b27d062af4d1b827.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/271b2d9136d649c3a27e3d5838164245.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/835681274cef420fa866ce061bbaef6a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c355ef4d0d374d47b4ae8b0b54279a73.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d5a79245d0ad46eab58e13caf68aee6e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/68bf0b8e1e63413882f400b8aba7f371.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ff7be25eaad644809b8c424b61345659.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4af0c0e261f94824a5d21d5ffe0e4140.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7450551a79b945feb3edd1513cb4dcc9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3b39885d742d47f9b1cbfdb5747847ab.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6d103eb27a374af0b89dbbc7b85c6c04.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/41fe90c6eb9846f2a703daa03d0b39f2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5c8cebd47e7349b092f637ba4d243de9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1e823be594554aaa8e8a9e29187800cb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c128564a30244421a864172b4037e02d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/54152d039b624d09a48a49c301c04ba4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/fc1077fef7bb4487ad8495233799b75d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8037bb2361524540bfc80b7b1a52276c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c8683a69ea0c47deb1035cb6d9a82442.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/36610fad06e145e0bd600f4f58f6d776.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e1f1acfbdcbf4baab58be731ddbf1bae.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/baaf0a94ecb44b35826faa1274d7dfd3.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6c156fc92c994ba78643d92162d592c4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/25b77ad1a9ce44a6a45dc0901adecd2b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/61c28437be044ae19d04e4374da36ce6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f89ca1336791468e9719f34edb5a366e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4b5cbb39c62342b9be7de598b28ede1a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/94d171c653ba4406844f519ab2a79c04.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c2dc675bd7df4138980f58a3b9003d56.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1f894f7a36054a09bd737f1d6cb76d5e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/84315dfcd47a48e0aecf75d55969ed4c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ba0da0e4af2847c58b45841b8d767c15.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/465af1b101974c78be14bb2748ffa931.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a61557f321a54014bd88eec9182cbbd4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/452dfd2e2097482fa38f7c251bc8426c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2cdf8fad5b6849cf93c6be12feb608d1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/76e2aff88d8049cfbaa41033dd649180.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/94fcc06b07b6442d9cfddbf747b877cd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3fd02073bf4b40ff9fecc9e22c1b662f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8f1d9a045f5443228fda61daaa812d90.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e7eb58a8bffb491d934a0fcd4a1bdd01.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/39302efc21f845858e163a1fad20ba2e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/67e9a09a6b874142a285de89bcd20cd7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/48df374868af406f85999c0b95650b5a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/07d22952a0644172934cc09169e32f8e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6437680da9d14b63aca12b24a90cfc18.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/22d5226d6237431fad102b1d8ad9f316.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3426d9c1902f46f8b75f36a42aaa802d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4a6f991b50b1478d8954e712e8dde063.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d52b479f4bfa452e911b4fa38a6ad658.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/faa73b0ca47741e3af687c41c75b86db.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/06c63d206da44ea1bbdbb0deac93d4ca.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/38182eaa59344cb48a5ddcfaa1f67ea5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ef5b07a1dfbd44aaa775a748c08969b9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/dc08ac73c55c4c9485db43f7dcc1569e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/39980c42a810408e9a970605e2059571.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/fec7e04c7cf446ada460123ccb9e7367.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2ab35e1b80fa43e0a4abd3a025dd7c85.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/399fcb0f191c4b0c995caedaf891d4f9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e582e025724d4419b7e7d7941bc452cc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ac4b2ed43b5e4e918acc14142114a135.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/702c6f30ef58469f83854e6ad4af5ff9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/64bbaa7c130d4a839ba1d3240a8a9871.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/40111f24acf54a9d96b579a9fee24656.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c991e18a42ee4c339e471d12235d3055.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/dc1b93d8b7174056a40dcf8733c13115.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/365d1845638c43a29c103a6c48697413.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b58e6009d29e40838dbb98d9517a6bee.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/10e73afe008d47c187f950dafef3a2ad.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4eaa24f9d2eb423d8dd1a572c9fdb163.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/29f3f05b26ea4fe7bba8b15d768b6789.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/737e5927298b43f3a1b8e73e5f51f18a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/dd91cbc9dc3a4baa908e50e342b8fadd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b4b193f594b143109f668938ad1a5921.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0a922debac164a24b42fcbad5bcb1470.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/315a7b4196fb4c3bb23aa1e9cdc2ae49.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/10738e4317f84511bf0bbdba80661a1b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/27b628ffcd92486f976e6ac93004d013.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c5e83ba8dd954d78a3782d049d88d8ea.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b8653a382df6463485b1c9a40fe6b7c3.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e37df4c32aae4c2f8fd759738ae446d7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8507d4a9e42d44f0803843b2cff337b0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0a6c0e05c52141fab7c699d677c57e76.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5081249a9e9d490d8bd89ece0c93e863.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/256982e65571426b99f2b0c5ccce0eeb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e27a3eb5ff9f45ff86a2a10d510786c5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b6e9a10bbbf64a64991a2238e6b4fbfb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0bb429d682594de2a1a41749e3ff681e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/639dc2a052b94c0ba7ebddfb7382b8c8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/880cf90703384e9aaa7219255752404e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e8aa8168597045478c011a3518d6db2a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/25691ae70e404347a7e1cdd584588e3f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c14921b56748487dbed6a58ed0e90ef4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6948db0b281d428f928970a71325bb79.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7e174f67f3964d5489904b54c47d8c5f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/adecacbdc1b94be1a09d427bb2d84aa6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/242aa5854a88436399797cd0cf3a7b63.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7066ee27d10c478a83465149c2b93bc9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/52f92d8fb43e4709b25a173ebb733b43.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/695cafeeda00461fb26264c61851e5ca.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f29de63d253d4f8a8ea4610229249d90.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d724c9a9cb144b338a4e00bdd1de36eb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/bdd30545d55346caac250e583b0f6ecc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4460f3955f8e460fb9a6f89bdd24d228.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/aa9d88d10ebc48f0a2430bef4ff9ca3d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/94733e01686a42a09874194c8de1f6c1.doc\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/01f6358036914b3c98d7b71e03b94865.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1165423b4f954fcb9172ef46cc7ee5af.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/bbd2d5ed36d74d60a0c796cbc0138222.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a042a5b737c14fa4b8de2f7cfccb2bf3.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/39475ec4e67d4720a3b8434c804b37d1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f1ba9e8c7c5e4e9a8e86ea5dcb68af9a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/12335895f10142ed96d68df9def2ef0f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9a97ca2834c142398aca6a4e529d3024.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/690fa63aa5bd49bf9b906c88d2130e7e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/29834c0ba9244c27b2c812996d6bfa3d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/35cb2a44efb646b7a60fdfa914e9340d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/69b94786ab494f4497493c495555d0d6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/07610732e53e46d5a487820df5aadc7e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/75992ee72fdf4a51a720327d0b43cb4c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9f78fa4b2b2f4b09a2107b9ed4ddc845.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/639c16a2256d4e65a0832ab0ad69f1bb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/63b4e06a1c9d440a810a6cbcf69c1ebf.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9382bc9d9dbd4f8d9ddc00f09cc33e94.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c974f8138d9043b1aa5a29a9de458bd1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/20aac7d589d5400f836445c5d01635b6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2475e3e624464e949d5e54581b8b3a64.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/281d26289a594462be27067a75b9587b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b1abad5622bb4aeda077af8569c59fcf.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/24c17c61410d48cbb1d7f4bbbfbc5e41.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/43185804b24348b69ba9756a5b6f2095.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4bb82f3b1290491ba77e07dfb56525ca.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/54aa7a2b41b74faab26d56057afd94bd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/26206df317d9403293961fde99ea1f50.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/699bb2718f2946d79db97a0e5f241d3d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/61856787250841cd86c7e73a833d11bb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8624612a73b64f86af8e177612f4f81b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/15c754b1b3ad41b38cab68813473fb89.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0106c381b45948078cda7cac307fee93.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/941235c245cd44449c631aa1cd3d81f1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/70bbcbe2523b4e978a2567faa75b648d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/880e1e6510404a99b29561b19177a7ba.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/64f5c482b4034a7bb0c4e87384c66eb3.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1605b2ee1c8b4ee281846b043932e75c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/69a1a7dbca9a4f91b869d8b57c4cc4b3.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/39c45d5303b04c4db800b480339f3a09.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/475e0124595349b19af8f64a46f7557e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4088bc64f6864537a35be6f854948c96.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5f74511f687b41c3ba211603c64ec5db.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6b565a31b5f844e7a9f6bba9b339d407.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/79ab381a5b6c4223b2247816a1af8441.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f1ae7424e3ac48bfbe964163ad8472be.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cb0cf0d16bf64294805f27f616393e64.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2a65ab7e0dbc4691bb5598aed02552db.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/85f5b890e6e444c58f1f723a2c87c1db.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/dcc8e5cbc8ec47be9c6c89cbe7e12f18.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/dd62f7f09aba4a108fe212e3cc80da56.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/76cdb65d0e2c48c4a3053c4be340c7c1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3f3f55d0e54c43348b2e3ea688d5cd23.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4d65d7231a714732add3338bf3a9df3f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e41ed80c4faf4a0ea0e52f5083b2dfdf.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/06daadfeec294879a69b48d4a89d1484.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c757d3a2a7784ae99fea1755de5bf931.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/eb049b187f3a4e3aaa71b0ee5d612013.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8a91f0a71b2b4558b0a7b44717a7cd6a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2051d71c93e54c6382219e8585ae3d95.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ff21ec7d97524610a2297e8a1f35191e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ec7b2dd0e81442e8a64170491f36c01a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/479cf06db942442084b4452f43b881a4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/54d57b776fb042bb888785ea7dea04f5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/384114536f444d36b75b982ad0514793.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/83babf03b072451ebfd8d6c76c5d4acc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/50eb40fa315b4efba105b29a7db942d9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e1aa997b62aa40f891f5df742e9b1c19.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2254b52c5b7a419ab43154064c7567ac.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/fbeb0ed3670f49ac8bb3612fe7920a53.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0253ad7ba0e64dd68bc93f18b9a111fb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/14035d86b9f04a25923483340ef9c7c7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/259ee6c20ada4e2bb240f236aaceb028.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f00daa845df54fbda63c3d9dcc14f3f2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cd62a9d13bf2403ab4f15c44ac118c10.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/311f237f51034fc09be401ffdb0e762a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0a4363a2f2384aaf9bdfe5e04efc5211.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4840f309ab54431ba07ddd83fe8e4837.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/dec5fbb602924cb8bcb2077998837e86.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a4add5b42c724d16b7201358a47618c4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/fc914ffc8b86459ba41d55416b70da52.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0edba343989748faa634e6591820122f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7b43e235030445f1a8a6c4538651b925.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b6121616c1cf4db883e37c6743eda8ed.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f7e1423c7f2f4ac890b93a0ce0bb8c76.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/36841b58dcc4409a92bfd674204aca98.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5e9290456aad43fab7fec56673f52986.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ed5fcc9f7d624632b1ea1fd4a84190fa.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cae35cb1988a426982f49fba4b5693fb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/66b6aabcc0054bf880a7a6abb5f422bf.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5e4521b5e9964c198da52a60cd27968b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/356256cabddb47328c827b40cf15fccb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/505d53a0a7e14715a8f6a3596e043f81.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b4fd9455b6114c7b87812af5b0e4dbea.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1de3068763644c889b8321c934854321.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5b3398baeeea42a6b3dc77714a321b7e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3195051803f2416ba1e1ba9623793e28.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9114de7a00b84aa2876719ce7c74ca15.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f739dd3eae314b6bb006e19c5bd08ca9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9895276dfd5549dfbc86f6b5226a5b29.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/37c19959b2004aab9ff7ca0dd1eb41aa.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4606fd3f47744de0b2ee5459af258d70.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/20af17838a934a309f426410c94e6ecd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/600694989cff49b6ae4cbc52babc9204.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/aa458af36d5640eaa688fd1b2bb9d23a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/76eeba2d39ff456094fadeb5cea6a41c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/af336f4017774435a8c0da0425aaffa6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b763fbb391954f8bbdb3513172164705.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/63a0e2478a8f4ad78a62d1ecae523aef.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/37446a890b0e406aa61b35570fce3af4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7d88da9b44834e0aa6b4202d7113e71f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/06538f80713f41bea3da56cf3592f6d0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/990454cfb68f4562b233859677874f23.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3d1cf8e22dd4415cb76321411be24cb1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b74c8725be3945aa913cabce4dd3e893.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/78aa8571c6c4454bb133b326d85e59b2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/549f872c2d774ab39431e45e8c956b5a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ac348de5ef5e4c2c9faf0ef3f7cd2d59.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/eb47cd31a082476198dd79ea63f19fd0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/54f7efccb09543378ff42916c69cc6e0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d8261608eb6d48a297a553f95e0a068a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/dc7c57d585974c8981d9c354067172e5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/27f7228f93a04ad093ef09b47f05983b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9179d42dba5147eca8d56e89dfa9c47b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/41b0b01ead8d4485b60cac6a83fae576.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e37ba80e8b74441faed74aa64765dbde.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7f3abd3b46b34e139db898fb498ad932.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d48b6c6ca1ae4d3b90c44aabdad0213d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/bb40eff6b4be459cb4f89b8d8d4900d6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1dc10bc2eedd44e7935e9166c546eca5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0cfba0733f26470bbb6dd29f4914e6fb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8f9144830f6e408184ad5dde47a195cc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0326a04e8a5a40a5bea1c0e154240eee.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9eaa1fb57991486cb6d23dd548913609.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f8864d59754842dbb6430e87cd72ec39.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8b12f2a30d5d41bfacbacd3f853a848c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/feee3e17ed7542a5802ac11f532ff30f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0c001c7bd98748939a4828f92ebf9d38.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/23add793da424d89a78723812f6365e2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a94f2b52a33a46c3850dc1f2cf17091c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d7b82540121640b6b010b844e77ea082.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a14b9b81abba4e11b5fa321b21f1de72.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/735164e00f6b48209ef9c1e3bb4a13a3.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b03727deb7734c06a900af9f65d523db.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/58b94440213f46d5aedb23fb26084a14.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9a2b6784298f468e9a7ea99e2e14c161.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/07a2cf8280ea44af88151d810ecfe3f9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7bae0bbef57049f98ce1b14fca74f21c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/bd432883f2fa462fb7995b1245e9497b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7bf8986fff294635993d6470864ef1b1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c9b6c906c54943e0aca4895caec17f84.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/304c8142299e4378bd4e48e97be073db.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/be3743874e1a47e28801cd958e646eee.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/820257c331f74f99b24e8f5e656e7c95.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/63a9a865af8949c68dcd66fba4faa74a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9c872fad247c4eb98c6bdd8baa08bd21.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/283eb3512fba4ab5aad8994f51e35d1a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5abb915301464266b15505104059fac6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/24338d55f42048d7ba6143e63d52567e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/057d6c1d4f894e43aaa922337c8430a6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/107eb161bf3143149262f8a749c523dd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2dd79ff2253a4949956d80f01b2c7f16.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4674397835254833ad4b49cffe9effcf.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/bd8fd2d5d605442c8c00831125b940b2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/70ca506a2e5a4b038a71962b5271a545.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/22dac913eca84fda941d1be59f0da2d2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/10a8d09569d9416cb2769a91eed84dd7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/13371166f716446397b7a9c87d2f6967.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/15134a1796c2462d9c7dc7990076518f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a8173d4310364db185d18acd6ca90334.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cda58ff945b84fc49a9f8bab5d6df735.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/32aa020836b74294aa3babdbd94ca3e7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e7bb3e1489804e919bec895fa536e917.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/dc6ed0daeb55493eae264bff8a528f73.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3d796adc5bf041508071d6971f455e8d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3a7a779832c84067aa77008aa1586eb0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d46a1515f5144a14841b5739d5aa3e65.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cfac671942b542848de27ac5c1ecb74e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5e09eed09ec9418ab28fc12707e884fd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/eae95b56e044417b87ef302ba49be417.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/45b6062fadce4a559d74a7d1253d3f37.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d13251e9fa604af3ac1b8524560f0e64.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/fbdb35f58b1244dd914e056281d4faa0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c05def6005194ddeac5f990abf060d2a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/36bd8072b2e448f8ab8f0f4151c13053.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d5ff6f23647e4dc1b83da9f107ffe62e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/920bed2a57d34502bf70824ed0722044.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/571e4b798d3b47e6929355e40f9906ac.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/bdf5d8793e9e4e759bd126de7e470edf.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5fd5b6d04cec401d9368d080291d9e6a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/87e2ce05eae3480a80f08917ba6ac8ff.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7742cd7658a64932bed4a8acbc6e8192.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/bd90ea804f1e4c93af25ef6a6aa1b51e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c500f325ecd5453e8b5c3b9313141e79.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/aaedef0271c1416794505cb2c848e6ee.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2c942118749e431cb69f4d26d9d4fde2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/079fdeb7033443909e1b28c745bbf4b8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3130df2c0f4a4ee78e99e64a98cd26e2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2515f16092574509aa3b176efee1e4d9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/56c3bce3be9e48bc969b6d58d8b3f3e4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2c75eedf4d7f4f3ea939d16d3fa3cd2b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/858568f80f464b168114cfe67efe2554.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/edab6b9f241b4eb4805fa624cca3f192.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/629052c0b74e43c2bd3a725c03a673ae.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/13038f7d09644e82a6c0723f437c4271.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9b11d206f9354a9995803c4fa63f6209.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/692e7af2337147908f78a08ed432d59c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/37429066dd0e48348cc18a91e890adac.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2285bb94210347c6852d9107b5ab9bb2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/335cc3324a0b4f9dae452ce363d492bc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3366aea5474441d29bcb438ddba49c96.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f60835a0f5ff48b5a59d193aa8e61feb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6e7a5ab971e24524b1c7c775364fc1ae.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0a8b37266c4c40e3b8b46e0c3b34e3da.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c9be465289a3409cbafea60054445fa2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b2ef58f439aa4b37a56073ddefc5d681.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/05b0827ed49a4d6f95f7caf7580bf0d5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d3e73298f3fc4156a3e1f280c661ecba.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/aabac1fc63b54add8c5f8c31d146d842.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4945f90e8fb44e6d8ba5f98e4679ced4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/96f469825c6e4387863e97a981dd5273.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e5d37aa3e195453991a327baa2b04a57.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/35020081e1934cfab7ae6ef67764b23a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a626a231b00d4b1fbdc17e89a86ef9cc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8b955ee5f2b541f7969c7d43ce4c64ea.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a902604a6f3b42a285519ec748fc3a5b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0a8c3d8a6dae49049fc0230db78b25ec.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/117e5181cc174eb682018757716825a7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e1a8fc1327974f1fa05ad7022ac91403.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/27852ee41cfd46cebcf1cf8085747417.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e8489771edd948bd8a7b4d02ef7cb69c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/13bbf541ee1b4a479dcf9fbe233bc017.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/fa2906f9993e4a57b0e90c8d08bd0406.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/59a88cab0165406e87f3156c187e6bfa.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ee351c7819f64f979958c018bdac7a9c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/49394eed32214f1b980824c1ca3a593f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d3fa29f9bc5d430ea93c78d4db5e0edc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f927918fec7a4bf3a7d8a16c096b172e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1a0cb1aafcf942999e8f2002e92f958c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4530f8fb674144ecb2d1ab3024c5ffec.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7f359532f70e491a924509d798b4da4c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0e78d18df108462ba4a0c8dfefd1209b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/461140e7bebe4e8fa6765bc86fcaa1cd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/60bd2450a77b4c9ab2187d4ba52e72c4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6dc800c624dd422bb81e19f6266a21ac.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1b1865c3847548e190b58462d560619c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e62f925e59924fddb27fc23636ccbda1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b8aa913b7c6c47c8849888218f5d576d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d8b62c632b0a41afacc6943e3cca5bde.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/bfa6a139b7094ee8bd274511e09e05fd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e85976ab54634200a28d2adf4221cb5f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8167aa5dcdd34eb8a3a10eaa5c1105f6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ff00300087fd458daa63506a2ae8ac37.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/33e27399b0384889b36046ed4c22dae9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6f5f8e55a74c459fb2c65adee6437ace.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f740e3118df643b19a352f1cfc935f2f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/435fa7feeed5426fb3e46b6f4f4554d4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3ef5000a5f2548bfb57a7369c4654b5f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5aeca04a914d4ee4b71f33309bcc9f51.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/37236b2da92e45e5b3b385513c713e92.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9de8c7a4fcda4978a8c1874cfa8921cf.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a51dba11e2a846ff8a7c338d486503c3.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a237ba479be14312b3a8898edc9db00b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8ef281f1d6c8449a8aa6f2c81201d147.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1519398495ab4cefbe72b2cf36fb19cd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/af2f5275f7b94a09bc9882ec443da6d1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/13a025e18f434d4ca024792467c554ea.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5ae2273218a8480ebcfb9072c09bf807.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d4eaa0aeedf14c69987abff14330ad72.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/36506d01b46f43e88a14b3cfcb96c566.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/07d27c209a2d4e30ba825da86542396d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/662d27a8539746e2b1ea67abfbf09b3a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6525e23e55804b67af3b4f60fc7ea81c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/37fadf4e614b40b0912d886bc682a60e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/df6ff75bdfe0487aa37bf8f5d9c59764.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c9a0990e9caf4f5d9e4d360d775f03a7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7a8c5db5fbca42c490358775555b6388.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4facb691a84442ad8b6be808ca4b448d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b1175d66b17743e394d83e6412748c1a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/070397a346d9446490e2bac57c5c068d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4fbbe9fa076443e9b975dcbe6c090557.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1289852e40e2415593f36af6cc8b05aa.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6a9fa50ac07a4b9d94d41764b036e4f8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ef90c0962e9c49ef805d8d599fa540e6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ccf059c72c134ddc8c23663138d7a3a9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/536c89aa818c4feab0f7ed32adadc341.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ae0f0d458b0341f1901cb4ad2adfb80b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3df4033c3304469c91745835a3dac4e9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f20de8ef3083430d9067428e2ed87d1d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/931146de220a435c82a7197145d58092.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2c6d5e74ea814c16989a2e18bbab4b54.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c80b9cfcd19d4e68b0bc03731f9cc13a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8790f918abed49a68e8ff142c4a9a0af.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/94045274af8f4de6bedd1ec4371fda05.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/45bc9ef7f6db4e42a882bb767ba3ff2f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/544a413fd30143b78406b455a09d3a7c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c1f09d88b4a04635b9316db0b94a79e7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/05a9cbb665a74a819586762e75075870.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1b74678751f84376987b1859f5d9dbdd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/883e730dadd342d39a309752c3bc726e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9576a938f88d4fd7a1b3e15521ea5587.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6732d23a135d4af893e8e8cc2d412c50.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/18d29c5ac9f04867b9cbce46326c9e09.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/54bceb01bd44481da4b93cd30a6ebb7a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4adcb1d44c124a8aa9c8c5c00ac4435a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3291468fd1504381bcc4ac92712116d6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/aade7610493543029c0eef1e258b1697.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a9fa6696cd8d4174a3d5c6f8496a7b20.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/12995a0294aa43fdbc8a7bd0feda057a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/039260ffce824540989733588a7e81f0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7003bbe41b204cf391e0c57ebf8664ad.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6ec020ebc0ea4565985b72204725d116.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/23575e24210946bfa0578932b6f97f68.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5c2a48a20e2f42b787195e8fe346aaff.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/96c64be2bf344ea187dae7946e14fab0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cc5da67280a04e3fb12d0767cd1771f4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a56d5aa085d34948a0db1da328bec461.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/983c29cddabe4039a1da7ed5efaabe5f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/87b42bbec6dc451181d8237040cb2810.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/062cd8727b8c4eec8ddb8051125aef80.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c89858881366458a93c5bd9af56e2665.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/df6bf2f4efaf4b518dc98e8d8a2c6110.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e2d91a0039d54f6a901993b343817439.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ed8276a303db470ab8ae47bf4d75b574.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/122c95e6d4f14b118edc354d6ead555d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cf304c612d4a4fd2882049274fc78fa2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a17d7f9f18454e97bdd209b88af89170.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7a8043d5b2e84de3a76a7d6ab712182e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d445348f5ddc47b49f5c9c5d544790d7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8e563adc3e264e95b644791f262d1b18.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0a3eecff2fe24b19b4ad5a46dffde7c7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/65097cd4be164d6288e8faf5b3e2e897.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/956ef527ce4642c0beb6b13744ac423b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/12669ac230f541beba49c48e365b6bf8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8dc0dcb937f8466a9b8992a69dd7193d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/147df231efaa49779f3f92718770ce2a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/35638b6b2fe54b1dad00610a8ad2e58d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a6da05d31eac4e2b83980b80bda7fe98.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e83aebe8f57f4d3f9c94255813538ee7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8a2f029386504a328c5f1b297fa86b29.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/24c33165484e4258bdc30a5589fd3d63.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/228a294b1a494f45beee13334c468690.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5b38d843d12849308e78c978c4ff2041.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/423bca5120584bc2b1a2b3b77e501fd4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/82ad59eabb66414aa22cf094c4707b60.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/818fcffc2d094c5eadc462aa7854b85e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/23696fea53b6416398e3d4be84f4b421.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7e8fdf98f66c450bb9f94a815b68cab7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3538ab2d1a1a474492c201bd88e5af73.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f06d93e927974001847b3954c3d4591a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5687f174a4d249ecb8b97fb12e23dc0b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/810318d34fa54b54ab18290860f20453.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c0f716c005714cd3b8eb8f624aa19b04.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/fe6d62ea179c4450bd95d70bbd88c1e3.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/891f0e193f54419d917018514773c48f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4bf1d93753a84839a1dd5d275234ad1b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b4accc01383948999d9556bd4faeb424.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cda07200dd374cbc807152da30028b87.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b581f7632b544944804de798fb28dccd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/23a60544905341de857f479677081f90.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/41c31de75dc64a918d98d190ecb4fbeb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ebdc5e8c22aa463ba55b41376e2d2d2c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/35ddc6946aa54f3d80a40429e46777fc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0ecd5502eb6745d8bd84ee7b07e6df6c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6ee184e890e045b28f40948b1002077d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/40b763ee98b8415495c61293881039f3.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4b0d6f924ee5429dac75e48805f4ae09.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e2ff3c6b2006431d8ff44594d10293f5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4d87cb6736384034a3d395425f894522.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c2d6b51c61754210abce67fed59fb81a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/fdf57bd6f1684c9695c7eb1d39e258e1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/730226cf95ee49938f6f0c3dbad26567.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/320c81a4789046419be19ffeea75c193.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c6fc13a6b1dc471f93ebf76af096a221.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c6c55742da8848cbad9e87409471ae9d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f8c63bf5036e4de7b74a4c80f2bc6d0d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4c171d78d3f444bf959ca42df20ed3ff.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/caa6dc04c5254364bfca0f9e291a17fb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5d4c54b74f684ae195d1d6395ea2e65b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/fc13fa6956b944ed9801aa1e9c7eff81.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b9d6467b7986442badd0a1fc6ac0ded1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e944f9aeb7684998a4cb03f24a91439b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a7a0eff189a74b0bab27c3ffc9a44ed2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3af4e1bcd5bb49009387e4b5973bd9fa.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/eef34c237dd249e08453242325de71ec.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/448ed208c3d64518aca4242e4deb4b02.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7a108325c0c7447b8f15c7d8c9807147.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1859511a416f4c4c9f45c2c77c5f3e99.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/eedc9ed3b4cf415c8c90d24063732c0a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2a53cfc1c28d4170a15bb2e9ef215a17.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cb8943056e65468a88f61bb3744de760.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/19e747ebb7df4c5e900991206190a213.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4131e5ff2fe048ccbfdb679b4a42c633.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5987283628644cfb99643bedcad8ac7e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/974472946f6c436ba4e854c8237685c1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d844b85af945427f81b2feb87ba08601.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ad1659e54ea541009dfdc6dfd5c67c55.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e8f7073b38f144e4b8584899ecfc0fd4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/91b00945e4734b6587cdb239845cc16c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0f4be2547a56495da846018c433c3e56.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0c5365790b204efeb506f3376f48c5ee.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e0dd717ef7c946f990e2502909f160e7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e31e54aca68b43fc988b00c7606fd018.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/975cf4ad833b496a8309f0b502b9aaf7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3e136fb1a6fe4b76a30928cae1b67f49.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a52bc35b661a42d8b7ead77e86cdd6ee.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/aacb80a631c8406493e1b03472951cf2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f04f9f703bc144dc90d4bf66ca004447.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5f8f1f5a22d644a289c794bdd08eab2f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2c286ca7ca254bbf9d58bc317918ac25.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cf4e39a64c164596985c6c239a75fff3.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5c93a13c4acb41e0998376a9b6f0663f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2249f05ddbe04017908a592762e5fc15.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5d708cf7a2de4a25b44bf8b0c06e1bdf.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/482a1dfea17e4bfaa24fb7760d24d223.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5073e173b7544397bd337acf5e8c5df4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9da5c2eb474947f08aeb2bc70c1c2ccc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8b5abb55f0b94750a4bc0e31004d0a58.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/83893175c3de4775b41faf86c89bfb98.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b2f32d5d17c9408c92e0a2b3f3c9437a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b3c4f3da52aa4129ad8c9c35faa88967.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/92dc37227ba54d87aca655a6013ffd29.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5b62cf4ea5fc4ea6bc3ca2849b8f3e02.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8fe9e83d22c84101bccc94b6bfbcabd1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/525e56c26cf44800b3cf778a6df89953.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1c7af95c11a74383875799b5a1ab1727.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c9429933983a4eb5b8be741cce6bee67.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8fa00904b3004383ab7d39814c65414e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/bed3659e5b794552b75f1eefad54717c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/099f3e9202ab4d43925de4e9844a688d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/91740153537e4f449efc19d6f4b72d8b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1d8b3b92c1044f0bbbdbc21a01b07578.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a6a5f78a7dfb40a2a9df9fd8ebc8bfa4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e663e5e622404909af34a3b9d39e11e2.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ebfa3f5437244adfaeffff58ada0d91c.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b6c9262787cf4255b1a550e61801410c.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f7fb2d44a43e40188f661b1b189dae7e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1c4a0afc6dda477ea727e1cf3346438e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/897a92bb5b1e4f5b8854b3c6c8e5824e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/61b4a79602084aaf8b5ae1aacc2f1313.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/544cdc9fa5d74a598c1362871b03423a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/34afa6c768774f65ab43badf2d01b9a6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1747d73c032944c082e0e1c94962f901.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b2cbd3319626430f962e0092f4fe0bcf.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e25b220778f14d3da702e81843e1c050.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cc354504e38b41d0bfa36ea0e44f7eff.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/86a0c95797f046e291aedab2be7e276d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/81f59fbc1b6e4b5f936228b815e4301b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/707ecf9bca2b4307a049cf9eab205f3c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/43cbd5a6338c42adb8dd68b0ba176523.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/74c47f29e43d4c348c0e89f604390c82.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f9fd200eb14a45de9c1e3895a3b2b1fc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0eb1860417f54082b8e0d94924156300.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ac6e20e87d254244b7ca8324235fae34.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/77438d49de1442b0b1526adf531c4b86.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/051a31f9227e4e4a8dfa5814ab9d66cd.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/96352e3b4b1d41838909a38a61b20d68.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/12a3184358c34749ab7252129ef47127.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7824100d93864a3ab7c4461da3c8588f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e7009adfca9a449e8a009d81274e955a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e45a7bcb6ba54050abe0006db51fcace.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ab39eec912ac42d080f60ecc5bd9b362.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/be2f98ec11754c49a928dab321138cd0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/16d085fdfe0b4286be6bb695c283d66f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0b818a8ab7dc4ba3be36be850a5e5e56.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/29beb7703224426aa848edc6ffdd29bf.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/01cc2e074e51412883560a44524a82d0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2ff7801330974f8eaff40ce9a3a3a39d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/edf1bea331184eed8fca3d50877550a6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a8f4844572c846c799e7dabfccec02c4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/00acc764f445481ead55a108e020c8d1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c139ea9b1a5c43258ed3c160adb5893d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5bafaa683ce44da8905c767d01dce427.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/bc1111c58dec4ea6abcec4e4f57bf249.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4c21b27daca34e74b083f93f0c06bb1f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8e189e398a9c4f28b1ed78d8ac8b239d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/836a8c1968c94bc7a9b6075ca9f434be.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c7ae6aa04023486bb9c0cc811423a455.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6cc13a5f949a412aa04069a70fa2a39c.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/88e7d78f342c44a890fe63399f8b9be9.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/185ae5949fb040bb85ae2e0400266e16.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e2df39fab91f465f89c38fae1a038981.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/965ef42ec4584d59b9771da7382e4492.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d4e4bf33bbf642a8b2f4ca4303c3ae58.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/53ef2102baaa46adb038399344c7ae38.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/73a2475fa7ec430ab08f38ee60958485.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/fc314b91504e4ecaa03e6b80e65c60f9.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3875776e43ee48b19183101e6d2cd766.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b04ebd7f492e4de88fe4a098db965fe8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/160f72aa0aaa471794c200ee116199a4.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f1ab558b16ce4cae8cb1263eee660e0c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/be7f10e9cc1f45fab9c645c75e98a463.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2dc440ab56cf4bbca13c80c1b06b8a2b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0daa3ac061e94d328ccb7bfefda793f1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/155ef5e2933647a89a285c3c5339f6a8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a959a2639f1a47edbeb958e8ccd13cc7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/10f3bf6ee50443fcabb3afbb92e967a1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/db4a23a7012049dca648e6ff11bbbf74.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0976c6bd5bfc41e0b2713a38b111ca1c.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6bedaecce55748a4a0317dae4369e8e7.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5fb090fc208f448d9d68fa04d732fa5b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/be24fcf3174b431198c23aa79fa73617.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0e802cd485304d79b06d88a337d1e8c0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d1b982bd2a2a4fa084bda389e4ea66d5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9084de0e125f4d3fa32854e8c745da79.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/07f0177ba93146eaa91b56c343d47a50.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/acb9c1cb1f2d4cceae2680d57e985da1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/23e657edc6bb4a8b905b2ae87238a803.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d3a04b0ebf4c46f9b7a7b6a30629a157.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2310819165e24634b2163bfb722e010f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5ae83c2474924ad5974d32020b517052.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d9eabc59786c455cafcb9ecb533b0bd1.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/49b15dde1ba547dbb223512bfb60de6a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e046baf0ab5d4f67a05ee921e3a8374e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/091d948bb8a44cfba0d3796af557728c.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4d2fda738de949359813e9a387e268c8.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d90c3fbeda054e8ebd44737c2b461f7a.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/58f2dffffe344b6ebd33efd0d357e27d.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4b31275c6f3c4be08b4ff56f18b38ba9.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/944120092e424000aa108809926eda8d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7b52a5801f7f433baa8c913670494043.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e8da12602cdd4261ae468876b37dca94.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cf6ee5dd65e54e629c5530ed9be1b46c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e69f52516d36404ab35db92ba01b317a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d865d2f6242545269ff13e6632613574.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c2dfd56cca7a46ea8d68d03ecfdad4c5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6a4151c1547b4715b4408e939467da76.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/860bbac35fe542269dd42f8f6ba56e90.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/22202a7f934b4ae6976a7a9d91c530e2.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ee54112ce11340c0ab482cff7edf3481.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/851106c2eb3a4fe0b9cd76a68190b30b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/0bafdda7700c4ad799a246288aebd519.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d105e884448441c8a83b5b004c7ce687.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ad1c284a002f4e93b9a42158b08899c8.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/620cb65478464bf88d2f6dbf87af0c9f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4b86927b5fc340b5ad893c888e75cb37.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/41f02b43d71e47b19cff611a1940a0ee.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e15c4e2427ad41be88d34098cda08bdd.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/021b3caed5144edf8e14967a0a52c4bf.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/410ac602230546c7b5adf9fdee35524c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6ff00ab61b764570937091962b2f541e.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f36f1f252a9446a7a0c3658073e51012.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/71264a49a375487587969f4ee0d55f71.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c196ab875e9546bfaecc956f8bbca30d.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8164c436fef041398c68883768503145.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1c015a6fe71141f3abb65a84235fba35.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f8eae073d97a48fe98ce1863ae68891d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/740eccfb9602455eb88ac3bd98937665.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4947d116dc5d4e69afc671da78b729c5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a46beec0fad2478b9cea27c4968739bd.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/06460fe37b9d4f9382d358a39f4cbfe0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f5a0d6d739c240bf95ca0eb916964efd.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b06bc79e8ff94d3ca89631e6049c8963.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a15b4199f1e547cd9c90d3050181697f.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b0fdedb3af744d49a9e6cad69a7ee678.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d60b52b9a10f42aa8dfd3a63ebd757d5.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b5a1c36aa7af49cf91f833c2350448dc.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5afdecc84b2f42c2ac821824f92d6bd0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7a98ff4aa8c546f98c376a6dcb78b1de.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/cd19ff647d874112824bc000483de57d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/f94765e2de25411aa329c9ebe6a88f03.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/72582f60cd084f5587fe8b5bb20c6970.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/df41fa9e7cf3426f93c7f51d098c5bbb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/235d18cf79314deab4e7bb6608f75e0d.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7364700758544d609c7df9c58ca9e150.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/eaab4a7d977d46be86283442b5bbc3be.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/25e098a1c56a42b08f61772144d0b9b6.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8882696ec9664182b866e86167863f89.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d5892861a89b4bbb845979de34898a81.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e89df1755bea473385e246b0caf23df7.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/3f55b68af07c42eeb784336c2de9dd9a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/7493aaaea8044a90aca3d249d18aa4fb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/26542229439441288d6cad7608ca858b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8466e8511464449b823dbf9477b3b68f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/c6c10bff087c46889515910e18990269.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/fe86f9afc68c4cf987043abbaaa44ed3.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/d0bbd132700a47948c595724ed1aaeb6.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/83c423f028104bfdb11cc3f4cdcc9042.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/948d85dfb1804f1caba506200b938b46.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6f748f7b6d3f48228185deaa9985b720.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8fae6ab9491a4326a2c45b72b8fb49c0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/551a27a4b6204aa1b65957c8dad59c86.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/5594e65926084e608d866fa862991f2e.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b191294a266f4ebda67ac3a8c1f2f4bb.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/e064a0ca38e7472798472eaeb7792e59.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/6907452aebc74550865b40db79fc6186.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/882add6a5827409c9a746389936c91b7.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/b2a0e86237f64d3d8cd490aac1a76503.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/8556f94eb2954a4782a80b991dc686be.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/57a7e088ecd04317b1b1dfcc0a7f7b1b.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/4693094f90c9442ba672b6121993b15a.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/ddd958cee9824831930574be9129bd2f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/62b5018442e740dfa43a86ce600090b5.ppt\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/2c5f4637b5144c8bb7cd18c9e296efde.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/a5ecb1603e5d47709b953be1e1b0ca6c.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9244a9ca65bd4e38909e3b24e69ee3e0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/316619b9f05443acb5578a9a4a9ce81f.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/86d2b0326d604aca9c6caa8644aad4d0.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/1ed4cf50181a48be8997720ba6962c43.pdf\",\"https://files.bjmantis.net/sijiao/static/COURSEWAREURL/9571af3714064898865c2d76d015cf1b.pdf\"); List\u003cString\u003e strs = new ArrayList\u003c\u003e(); for (int i = 0; i \u003c list.size(); i++) { printSchedule( (i + 1)*100/list.size()); if(!\"N\".equals(getFlile(list.get(i)))){ strs.add(getFlile(list.get(i))); } } System.out.println(\"\\n\"+\"不能下载地址列表:\"+strs.toString()); } public static String getFlile(String filepath)throws Exception{ URL pathUrl = new URL(filepath); HttpURLConnection urlcon = (HttpURLConnection) pathUrl.openConnection(); if(urlcon.getResponseCode()\u003e=400){ return filepath; } return \"N\"; } private static int TOTLE_LENGTH = 100; public static void printSchedule(int percent){ for (int i = 0; i \u003c TOTLE_LENGTH + 10; i++) { System.out.print(\"\\b\"); } int now = TOTLE_LENGTH * percent / 100; for (int i = 0; i \u003c now; i++) { System.out.print(\"\u003e\"); } for (int i = 0; i \u003c TOTLE_LENGTH - now; i++) { System.out.print(\" \"); } System.out.print(\" \" + percent + \"%\"); } } ","description":"\n","tags":[],"title":"\nJava 检测无效下载地址（进度版）","uri":"/posts/post-326/"},{"categories":["默认分类"],"content":"public void downloadVideoById(HttpServletRequest request, HttpServletResponse response) throws Exception { logger.info(\"下载请求start\u003e\u003e\"); String fileName = request.getParameter(\"fileName\");//文件名 String filePath = request.getParameter(\"filePath\");//文件名 try { if (StringUtil.isEmpty(fileName) || StringUtil.isEmpty(filePath)) { response.setStatus(HttpServletResponse.SC_UNAUTHORIZED); response.setCharacterEncoding(\"UTF-8\"); response.setContentType(\"application/json;charset=UTF-8\"); response.getWriter().print(\"参数错误，请联系管理员!\"); response.flushBuffer(); return; } URL pathUrl = new URL(filePath); HttpURLConnection urlcon = (HttpURLConnection) pathUrl.openConnection(); if(urlcon.getResponseCode()\u003e=400){ response.setStatus(HttpServletResponse.SC_UNAUTHORIZED); response.setCharacterEncoding(\"UTF-8\"); response.setContentType(\"application/json;charset=UTF-8\"); response.getWriter().print(\"文件不存在，请联系管理员!\"); response.flushBuffer(); return; } //获取输入流对象（用于读文件） 网络流 InputStream inputStream = new URL(filePath).openStream(); //本地流文件 // FileInputStream fis = new FileInputStream(new File(filePath)); //动态设置响应类型，根据前台传递文件类型设置响应类型 response.setContentType(\"application/\" + fileName.substring(fileName.lastIndexOf(\".\")+1)); //设置响应头,attachment表示以附件的形式下载，inline表示在线打开 response.setHeader(\"content-disposition\", \"attachment;fileName=\" + URLEncoder.encode(fileName, \"UTF-8\"));//下载时浏览器显示的名称 //获取输出流对象（用于写文件） ServletOutputStream os = response.getOutputStream(); //下载文件,使用spring框架中的FileCopyUtils工具 FileCopyUtils.copy(inputStream, os); } catch (Exception e) { logger.error(\"下载失败 start \u003e\u003e\",e); response.setStatus(HttpServletResponse.SC_UNAUTHORIZED); response.setCharacterEncoding(\"UTF-8\"); response.setContentType(\"application/json;charset=UTF-8\"); response.getWriter().print(\"下载失败，请联系管理员!\"); response.flushBuffer(); } } ","description":"\n","tags":[],"title":"\nJava 通过网络流转发文件到浏览器","uri":"/posts/post-327/"},{"categories":["语言"],"content":" public static void main(String[] args) throws Exception { String oldPath = \"/Users/admin/test/jmeter/123.log\"; String newPath = \"/Users/admin/test/jmeter/123/qweqweqweq.log\"; //创建指定的路径 File directory = new File(newPath); //获取文件夹 路径 String courseFile = directory.getParent(); File file = new File(courseFile );// if(!file.exists()){//如果文件夹不存在 file.mkdir();//创建文件夹 } File oldFile = new File(oldPath ); File newFile = new File(newPath ); //重命名 System.out.println(oldFile.renameTo(newFile)); } ","description":"\n","tags":[],"title":"\nJava 修改文件名","uri":"/posts/post-328/"},{"categories":["NAS"],"content":"Docker chevereto 准备的环境 mysql 数据库 （我目前是使用的是MariaDB 10,安装数据库不多做叙述，可以看我之前的教程）\n我用的是 Navicat ，新建数据库 填写 chevereto 如图：\nDocker chevereto的下载 在群晖docker里面的注册表里面搜索 Chevereto ，我用的nmtan/chevereto下载，如果有让你选择标签的话默认就好，等待容器镜像下载完成。如图: Docker chevereto的存储卷 在群晖的docker目录里面建立子目录Chevereto，后面安装容器会挂载此目录作为图床的文件存储目录,注意文件名的大小写 Docker chevereto的配置 容器镜像下载完成后，点击下载的镜像文件名的小箭头，查看该容器该如何进行配置，docker其实大部分都有配置介绍，多看看自己也会配置 双击该镜像进行安装，容器名称随意填写，内存限制根据实际需要填写，点击高级设置，启用自动重新启动打钩，卷设置里面点击添加文件夹，选择你刚刚在docker目录下创建的 chevereto目录，后面装载路径填写【/var/www/html/images】，不能有空格，请注意，然后在到端口设置，本地端口设置为10000，容器端口不需要修改，后面进行docker的环境配置，\n点击启用后，可以使用http:群晖地址:10000 进行访问，设置 相关的信息\n有时候会提示群晖 没有 对 images 文件夹的写入权限 ，后面对/volume1/docker/chevereto 赋予权限即可！\n也可以从ssh 里面直接赋予所有权限\nchmod +r 777 chevereto Docker chevereto修改上传大小 http://域名:10000/dashboard/settings/image-upload\n获取root权限 admin@XiaoMageNAS:~$ sudo -i root@XiaoMageNAS:~# 查看运行的docker容器 root@XiaoMageNAS:~# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 327c9776e0d3 nmtan/chevereto:latest \"docker-php-entrypoi…\" 17 hours ago Up 5 hours 0.0.0.0:10000-\u003e80/tcp Chevereto 7a30c3437280 oldiy/music-player-docker:latest \"docker-php-entrypoi…\" 13 days ago Up 13 days 0.0.0.0:32769-\u003e264/tcp, 0.0.0.0:32768-\u003e9000/tcp oldiy-music-player-docker1 1c8b79caaee6 luodaoyi/kms-server:1112 \"/bin/sh -c 'vlmcsdm…\" 8 weeks ago Exited (255) 7 weeks ago luodaoyi-kms-server1 root@XiaoMageNAS:~# 复制到群晖本地目录 root@XiaoMageNAS:~# docker cp 327c9776e0d3:/var/www/html/.htaccess /volume1/docker/ root@XiaoMageNAS:~# 修改配置文件 vi /volume1/docker/.htaccess # Disable server signature ServerSignature Off # Disable directory listing (-indexes), Multiviews (-MultiViews) and enable Follow system links (+FollowSymLinks) Options -Indexes Options -MultiViews \u003cIfModule mod_rewrite.c\u003e RewriteEngine On # If you have problems with the rewrite rules remove the \"#\" from the following RewriteBase line # You will also have to change the path to reflect the path to your Chevereto installation # If you are using alias is most likely that you will need this. #RewriteBase / # 404 images # If you want to have your own fancy \"image not found\" image remove the \"#\" from RewriteCond and RewriteRule lines # Make sure to apply the correct paths to reflect your current installation RewriteCond %{REQUEST_FILENAME} !-f RewriteRule images/.+\\.(gif|jpe?g|png|bmp) - [NC,L,R=404] #RewriteRule images/.+\\.(gif|jpe?g|png|bmp) content/images/system/default/404.gif [NC,L] RewriteCond %{REQUEST_FILENAME} !-f RewriteCond %{REQUEST_FILENAME} !-d RewriteCond %{REQUEST_URI} !\\.(css|js|html|htm|rtf|rtx|svg|svgz|txt|xsd|xsl|xml|asf|asx|wax|wmv|wmx|avi|bmp|class|divx|doc|docx|exe|gif|gz|gzip|ico|jpe?g|jpe|mdb|mid|midi|mov|qt|mp3|m4a|mp4|m4v|mpeg|mpg|mpe|mpp|odb|odc|odf|odg|odp|ods|odt|ogg|pdf|png|pot|pps|ppt|pptx|ra|ram|swf|tar|tif|tiff|wav|wma|wri|xla|xls|xlsx|xlt|xlw|zip)$ [NC] RewriteRule . index.php [L] #修改上传文件大小增加以下 配置 最大支持 32M 根据自己情况配置 php_value post_max_size 64M php_value upload_max_filesize 32M \u003c/IfModule\u003e 复制到容器目录里面 docker cp /volume1/docker/.htaccess 327c9776e0d3:/var/www/html/ 然后进入到docker容器管理里面重新启动即可解除2m上传限制\n","description":"\n","tags":[],"title":"\n群晖Docker安装chevereto图床","uri":"/posts/post-329/"},{"categories":["NAS"],"content":"前言 Windows系统中能够通过KMS进行激活的一般称为VL版,即VOLUME授权版。我们可以自行搭建KMS激活服务器，实现每180天一次的自动激活，使得系统一直保持激活状态。这次就跟大家分享一下如何利用群晖NAS的Docker容器套件搭建KMS服务器，并演示如何利用我们自己的KMS服务器激活Windows操作系统与Microsoft Office。\n操作步骤 先到套件中心安装Docker套件\n安装好以后打开Docker在注册表这里搜索：KMS，选择第一个，点击【下载】\n选择一个版本，我这里就选择:1112\n稍等片刻下载完成，完成后再到【映像】选择到我们刚才下载的点击【启动】\n开始创建容器，这里点击【高级设置】\n在【网络】这里勾选【使用与Docker Host相同的网络】\n最后确认一下即可点击【应用】，应用后自动启动容器。\n这样我们的KMS服务器就算搭建好了，KMS服务器默认端口号为：1688，IP的话就是我们NAS的IP。想要外网也可以用的话就可以使用内网穿透或者端口映射。下面以Windows10专业工作站版为例演示一下如何使用KMS激活系统。\n这里首先我们先判断一下我们的Windows是什么版本，管理员身份运行命令提示符，输入：wmic os get caption 看到我这里是Windows 10 专业工作站版\n打开：https://technet.microsoft.com/en-us/library/jj612867.aspx 找到对应系统版本的KEY，例如Windows10 专业工作站版的KEY为：NRG8B-VKK3Q-CXVCJ-9G2XF-6Q84J\n依旧管理员身份打开命令提示符，键入如下命令（对应您自己的情况修改以下命令内容。nas.maruifu.cn为您的NAS的IP地址，NRG8B-VKK3Q-CXVCJ-9G2XF-6Q84J为操作系统对应的KEY）：\n1 2 3 4 5 slmgr /skms nas.zeruns.tech slmgr /ipk NRG8B-VKK3Q-CXVCJ-9G2XF-6Q84J slmgr /ato 查看一下系统的激活状态\n这样我们就完成了利用自建的KMS服务器激活我们的操作系统，接下来就是激活Microsoft Office，这里我以Microsoft Office 2019 VOL 专业版为例演示操作。\n首先先确认下我们的Office是否为VOL版，方法如下（请您根据自身情况更改以下命令）：\n管理员身份运行命令提示符，输入 cd C:\\Program Files\\Microsoft Office\\Office16 切换目录 （这里请根据您自己的Office版本更改相应路径），再输入cscript ospp.vbs /dstatus 。可以看到这里有VL字样即为VOL版\n然后开始激活，输入如下命令：\n1 2 3 4 5 cd C:\\Program Files\\Microsoft Office\\Office16 cscript ospp.vbs /sethst:nas.zeruns.tech cscript ospp.vbs /act 最后看到Product activation successful字样即为激活成功。\n查看一下Microsoft Office的激活状态\n","description":"\n","tags":[],"title":"\n群晖NAS利用Docker容器搭建KMS激活服务器实现激活windows系统和office","uri":"/posts/post-330/"},{"categories":["默认分类"],"content":"pull镜像wordpress下来，但是出现如下错误：\n# docker pull wordpress:latest Error response from daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaitin headers) 查看日志，发现出现如下错误：\n#tailf /var/log/messages Aug 19 16:46:29 docker02 dockerd: time=\"2019-08-19T16:46:29.157861585+08:00\" level=warning msg=\"Error getting v2 registry: Get https://registry.docker-cn.com/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\" Aug 19 16:46:29 docker02 dockerd: time=\"2019-08-19T16:46:29.157965774+08:00\" level=info msg=\"Attempting next endpoint for pull after error: Get https://registry.docker-cn.com/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\" Aug 19 16:46:44 docker02 dockerd: time=\"2019-08-19T16:46:44.158651847+08:00\" level=warning msg=\"Error getting v2 registry: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\" Aug 19 16:46:44 docker02 dockerd: time=\"2019-08-19T16:46:44.158907684+08:00\" level=info msg=\"Attempting next endpoint for pull after error: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\" Aug 19 16:46:44 docker02 dockerd: time=\"2019-08-19T16:46:44.159189201+08:00\" level=error msg=\"Handler for POST /v1.40/images/create returned error: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\" 发现是因为docker加速器超时导致pull不下来 查看加速器：/etc/docker/daemon.json\n# cat /etc/docker/daemon.json { \"registry-mirrors\": [\"https://registry.docker-cn.com\"], \"insecure-registries\": [\"10.0.0.12:5000\"] } 导致此问题产生，主要是因为国家把docker国外镜像hub封掉了，导致镜像pull不下来，为此，改用国内的镜像\n# cat /etc/docker/daemon.json { \"registry-mirrors\": [\"https://docker.mirrors.ustc.edu.cn/\",\"https://hub-mirror.c.163.com\",\"https://registry.docker-cn.com\"], \"insecure-registries\": [\"10.0.0.12:5000\"] } #systemctl restart docker # docker pull wordpress:latest latest: Pulling from library/wordpress 1ab2bdfe9778: Pulling fs layer 1448c64389e0: Pulling fs layer 4b8a4e62b444: Pulling fs layer 9eb9d1e8e241: Pulling fs layer d20b2d19292c: Pull complete 023060ea5930: Pull complete a7fa99bc84ac: Pull complete 138ec8da18f2: Pull complete cd4dae5ac262: Pull complete c90eff48869a: Pull complete 1bc49f4d3a43: Pull complete e3bb2b10f58d: Pull complete fd7b454ec570: Pull complete 6096f23889f4: Pull complete 81072ed817d5: Pull complete ecce7df16ad3: Pull complete f4475635015e: Pull complete bad34b7324ad: Pull complete 890f49d5ad8a: Pull complete 7e4ee285d305: Pull complete Digest: sha256:6566a68d0c613304aa11255d98aba6e29c5fa8cd8497064639343956a4c7d2b1 Status: Downloaded newer image for wordpress:latest docker.io/library/wordpress:latest 可以正常Pull下来了。\n","description":"\n","tags":[],"title":"\nDocker镜像pull不下来最终解决方法","uri":"/posts/post-331/"},{"categories":["默认分类"],"content":"群晖安装 MariaDB10 后，默认仅支持本机连接，也就是说，你的局域网电脑是连接不上的，如果需要局域网连接，需要做处理。\n环境：群晖6.2、MariaDB10\n处理方法：\n1、使用 ssh 登录到群晖\n2、进入 MariaDB 默认安装目录\ncd /volume1/@appstore/MariaDB10/usr/local/mariadb10/bin 3、使用 root 登录 MariaDB，然后进行修改\nadmin@XiaoMageNAS:~$ sudo -i root@XiaoMageNAS:~# cd /volume1/@appstore root@XiaoMageNAS:/volume1/@appstore# ls AudioStation DownloadStation MailPlus-Server NoteStation PHP7.0 TextEditor WebStation CloudStation ffmpeg MariaDB10 PDFViewer PHP7.2 transmission CloudSync Git Node.js_v12 Perl PythonModule VideoStation Docker MailClient Node.js_v8 PhotoStation SynologyApplicationService WebDAVServer root@XiaoMageNAS:/volume1/@appstore# cd /volume1/@appstore/MariaDB10/usr/local/mariadb10/bin root@XiaoMageNAS:/volume1/@appstore/MariaDB10/usr/local/mariadb10/bin# root@XiaoMageNAS:/volume1/@appstore/MariaDB10/usr/local/mariadb10/bin# ./mysql -u root -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 14 Server version: 10.3.21-MariaDB Source distribution Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]\u003e use mysql Database changed MariaDB [mysql]\u003e update user set host = '%' where user = 'root'; ERROR 1062 (23000): Duplicate entry '%-root' for key 'PRIMARY' MariaDB [mysql]\u003e select host,user from user; +-----------+------+ | host | user | +-----------+------+ | % | root | | 127.0.0.1 | root | | ::1 | root | +-----------+------+ 3 rows in set (0.000 sec) MariaDB [mysql]\u003e FLUSH PRIVILEGES; Query OK, 0 rows affected (0.001 sec) MariaDB [mysql]\u003e 其中 host 为 % 表示不限制IP，你也可以设置具体的IP地址，或者网段 192.168.1.% 这样。 另外，上面出现的 ERROR 1062 (23000): Duplicate entry ‘%-root’ for key ‘PRIMARY’ 不予理会，其意思是 host 为主键，不能设置重复的值。所以我们后来的查询中，host 还是3个不同的值。刚刚执行的 update 语句只成功修改了数据库中一条数据。\n4、不需要重启服务，即可连接登录。\n","description":"\n","tags":[],"title":"\n群晖 MariaDB10 开启远程登录","uri":"/posts/post-332/"},{"categories":["默认分类"],"content":"5月22日披露的政府工作报告显示，中国将发行1万亿元（人民币，下同）抗疫特别国债。\n作为特殊时期的特殊举措，1万亿元特别国债即将发行的消息迅速登上了微博热搜。\n小伙伴们都很关心：特别国债是什么？为什么要发行？怎么发行？老百姓能买吗？是否值得买今天就来和大家说道说道。\n01 关于特别国债 这次的特别国债顾名思义：抗疫，就是为了应对新冠肺炎疫情影响，由中央财政统一发行的特殊国债。\n发行的原因也很简单：由于疫情影响，财政收入下降，但支出变多，所以需要发行特别国债，弥补资金缺口。\n这也是我们国家时隔13年之后，又一次发行特别国债。\n02 怎么发行？ 虽然目前只是提出了发行的计划，具体的发行方式还没有正式的说明。\n但我们可以从历史中两次发行特别国债中找找规律。\n历史上我国在1998年和2007年发行过2次特别国债。\n第一次是在1998年，中国发行了2700亿元的特别国债，面向中国工商银行、中国农业银行、中国银行和中国建设银行定向发行。\n第二次是在2007年，中国发行了1.55万亿元的特别国债采用的是定向发行和公开发行相结合，其中0.2万亿元向社会公众发行。\n从之前经验来看，特别国债主要面向各大银行等金融机构进行定向发行，可能会有 少部分针对个人投资者的公开发行，但是额度不会太高，大概率需要去 各大商业银行柜台或者线上系统进行抢购。\n但是据我预计：这次大概率是要面向公众开放的。\n毕竟这是抗疫特别国债，全国老百姓参与了抗疫的过程，购买抗疫特别国债也是一种爱国主义的表达方式。\n如果感兴趣，可以留意下一步发行的具体安排，以及各大银行的官方消息。大概率是能抢购的。\n03 利率是多少？ 根据历史情况看：1998年发行的特别国债利率为7.2%，介于当年的3年期储蓄国债利率（7.11%）和5年期储蓄国债利率之间（7.86%）。\n2007年发行的特别国债利率，利率在4.2%-4.5%之间，当年五年期储蓄国债利率也在4.5%左右。\n可以看出，特别国债利率与储蓄国债利率其实差别不大，基本上 特别国债的利率在三年期-五年期国债的利率中间。\n当前的储蓄国债有三年期和五年期，三年期的利率为4%，五年期的利率为4.27%，此次发行的一万亿特别国债是10年期的，年化利率大概率会在4%-4.2%的水平。\n04 值得购买吗？ 一般情况下，值不值得买，就考虑风险、收益率和流动性。\n从风险来看，国债是由中央政府发行，信用级别最高，没有什么风险；\n就目前国债在二级市场的表现来看，流动性也是很不错的。\n从收益来看，国债收益率看起来不是那么高，甚至还不如5年期的国债，但是胜在能锁死利率。\n之前我说过利率未来大概率是下行状态，现在能十年锁死4%左右的收益率，还是相当不错的一次理财机会了。\n而且此次特别国债还免征利息所得税，外加上历史意义。在我看来还是有较大的吸引力的。\n但是还是要提醒大家一句：特别国债不好买！是需要抢购的！！如果没买到也不用着急。\n据悉，6月10日将正式开发售今年的第一批储蓄国债，国债买的机会很多，收益、安全性也都差不多。\n多看看银行官网（主要是五大行）的消息，买国债还是有希望的。只要是银行官网释放消息，一般各行的网上银行和柜台都是能购买国债的\n","description":"\n","tags":[],"title":"\n1万亿元特别国债","uri":"/posts/post-333/"},{"categories":["默认分类"],"content":"python3 python3 菜鸟教程\n这是python3的开发入门基础教程。\npython入门建议主要根据菜鸟教程进行。\nxlwings xlwings知乎\nxlwings of github\nxlwings 官网\nxlwings知乎 介绍xlwings； xlwings of github slwings 源码； xlwings 官网 xlwings 官方网站\n上面三个主要用于使用python操作excel时的重要查询路径。\n","description":"\n","tags":["python","python3"],"title":"\npython3入门","uri":"/posts/post-12/"},{"categories":["NAS"],"content":"一 ，申请公网IP(动态IP) 在北方联通公网IP多一些,在南方电信公网IP多一些\n北漂的我自己用的 正好是北京联通宽带,当初在咸鱼办理的七百多办理下来五百多.\n申请公网IP 一开始跟客服说客服说办理专网才有公网IP,申请失败!(客服可能理解错了,要的不是固定的公网IP,有钱当然随意了)\n后又拨打客服沟通说要弄摄像头弄nas,帮转一下技术客服,然后给技术上说,然后四五分钟后重启就好了,\n验证公网IP 登录光猫后台查看IP\n输入地址 www.ipip.net 查看IP\n发现两个IP一致说明公网IP 开通好了,记住那个VLAN ID 3961,我的是北京的是3961 ,地域不一样这个也不一样后面会用到\n二 , 光猫桥接 光猫集成了很多功能，身兼数职，除了最基本的光电转换功能外，还集成了路由功能、DHCP服务、NAT、IPTV、WIFI功能等。而光猫的硬件只能满足家庭网络的基本需求，如果将光猫作为家庭网络的中心节点，由于光猫的性能问题，现在基本都是智能家具,笔记本,PC电脑,床头灯手机,天猫精灵,小爱同学,摄像机,智能插座,IPAD等等光设备就十几个,我打游戏时 经常460,作为一级宽带运营商不应该出现的问题,一开始购买联通宽带也是这个原因,不像是鹏博士,长城宽带那样二三级运营商\n二三级运营商的运营模式大概是这样的 比如从1级运营商那里买1000兆宽带,然后往外卖 ,卖的时候宣称是100兆宽带,应该卖给10个人就够了,让每个人最大能达到100兆,假如每个人都用 最大能到1000兆,这时候没问题,但是他不会只卖给10个人,他会卖给100个人,如果这个时候里面只有同时10个人上网,那没有问题,每个人都能达到100兆,假如100个人同时上网,平均分配,每个人才会10M,因为总的1000M不变.这也就是为啥晚上的时候 你家的网络会慢的原因了!(当然没我说的这么简单,他可能会根据地域,算法 去优化这种网络带宽的分配策略)\n首先登陆自己的光猫后台 查看自己的光猫的连接宽带的账号密码 账号会显示,密码不知道的 可以按f12 打开检查\n点击弹出框的左上角的鼠标箭头,选中密码,然后把\n\u003cinput type=\"password\" 修改为 \u003cinput type=\"text\" 这样密码就显示出来了 记住这个账号\n进入管理员模式 用电脑直接通过网线连接光猫,不要经过路由器\n我的联通光猫 是 ZXHN F477V2\n192.168.1.1/hidden_version_switch.gch ，选 default version，密码 CUAdmin\n机器自动重启之后就可以进 192.168.1.1/cu.html 了， 选管理员账户，密码 CUAdmin\n进去之后新建 internet bridge，vlan 选项记得选 改 tag，然后在 vlan_id 里填 3961(有的不是3961, 上面说过不知道的看上面)\n保存设置之后 重启就可以了\n另外，如果有问题要恢复初始状态，重新回到 hidden_version_switch.gch 里选 beijing 配置 然后在配置页面里输入宽带账号就可以了\n不知道的咋弄的联系客服让维修师傅帮你修改一下也可以!\n路由器拨号 用电脑连接路由器路由器连接光猫\n路由器选择宽带拨号PPPoE\n输入前面查看的账号密码,这个时候查看路由器WAN口的IP地址,和之前通过 www.ipip.net 查看的IP地址是否一致,一致就说明可以了!\n路由器端口转发 找到转发设置\n可以端口转发,也可以DMZ主机,两个区别的是一个是指定端口转发,一个是所有接口转发.我这里因为后面部署好多应用,数据库啥的,我这里选择的是用的DMZ主机\nDMZ主机地址填写自己的NAS的内网IP地址就可以了\n这个时候直接访问自己的外网地址就可以了!\n","description":"\n","tags":[],"title":"\nNAS 篇二：外网访问NAS上面的应用","uri":"/posts/post-334/"},{"categories":["NAS"],"content":"购买理由 处于以下考虑我有了人生中的第一台NAS\n我之前购买了一台小米家庭云盘,之前是备份照片,离线下载,智能摄像机录像存储用的 ,后来感觉 也只能干这些,下载东西需要安装客户端,不能直接对外分享,不支持PC操作,尤其是MAC(公司给配了一台MAC),关键是有两个T的监控级内置硬盘,,和购买内存差不多少了,因为当时是众筹还很便宜, 在一个技术交流群里面有个人要购买,正好卖给他了.用了一年多便宜一百块钱. 我的阿里云服务器太慢了,换了mac笔记本后,之前我一直用的FoxMail邮箱里面的笔记,发现MAC客户端不支持,之前的笔记只能一点点复制出来,索性搭建了一个开源的笔记,发现有个为知笔记(多端支持同步支持makedown语法正式我想要的) 推荐挺好的,搭建好了,太卡了 页面打开半天,当然和我服务器有关系. 过去两年内各大硬盘的关停和限速. 可以作为家里的小型服务器使用。 自己心里种草了，自己也是个爱折腾的人，我的人生两大定律 “一切向钱看”,“活着就要折腾”,这是促成这个得主要原因 设备采购 网上搜了一下 主要是推荐了三个品牌 群晖,威联通,铁威马各有各的特点总结三句话\n可玩性推荐群晖\n安全性推荐威联通\n性价比推荐铁威马\n我开始选择了铁威马,购买后发现声音有点大,北京租房的我只能在一个屋里面,虽然我睡眠质量比较好,毕竟还有对象在,体验两天,自费退回去了.后来选择了群辉,比铁威马多了近一千块\n系统安装 搞定连上电源、网线，点击开机键。然后打开路由器地址查看终端管理,打开局域网地址，按照提示下一步下一步，设置好内容就可以了，十分钟左右就结束。安装完毕进入系统界面.\n软件安装 我们买NAS的最主要需求：\n1.文件云存储、云备份\n2.照片云管理\n3.影音文件云管理\n4.云笔记\n5.远程下载\n6.其他高阶应用\n","description":"\n","tags":[],"title":"\nNAS 篇一：记录下自己的第一台NAS系","uri":"/posts/post-335/"},{"categories":["默认分类"],"content":"Docker的三大核心概念：镜像、容器、仓库\n镜像：类似虚拟机的镜像、用俗话说就是安装文件。\n容器：类似一个轻量级的沙箱，容器是从镜像创建应用运行实例，\n可以将其启动、开始、停止、删除、而这些容器都是相互隔离、互不可见的。\n仓库：类似代码仓库，是Docker集中存放镜像文件的场所。\n简单介绍一下在CentOS上安装Docker。 前置条件：\n64-bit 系统 kernel 3.10+ 1.检查内核版本，返回的值大于3.10即可。 $ uname -r 2.使用 sudo 或 root 权限的用户登入终端。 3.确保yum是最新的 $ yum update 4.添加 yum 仓库 tee /etc/yum.repos.d/docker.repo \u003c\u003c-'EOF' [dockerrepo] name=Docker Repository baseurl=https://yum.dockerproject.org/repo/main/centos/$releasever/ enabled=1 gpgcheck=1 gpgkey=https://yum.dockerproject.org/gpg EOF 5.安装 Docker [root@maruifu ~]# yum install -y docker-engine 安装成功后，使用docker version命令查看是否安装成功，安装成功后——如下\n[root@maruifu ~]# docker version Client: Version: 17.05.0-ce API version: 1.29 Go version: go1.7.5 Git commit: 89658be Built: Thu May 4 22:06:25 2017 OS/Arch: linux/amd64 Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? 6.启动docker $systemctl start docker.service 7.验证安装是否成功(有client和service两部分表示docker安装启动都成功了) 使用docker version命令查看\n[root@maruifu ~]# docker version Client: Version: 17.05.0-ce API version: 1.29 Go version: go1.7.5 Git commit: 89658be Built: Thu May 4 22:06:25 2017 OS/Arch: linux/amd64 Server: Version: 17.05.0-ce API version: 1.29 (minimum version 1.12) Go version: go1.7.5 Git commit: 89658be Built: Thu May 4 22:06:25 2017 OS/Arch: linux/amd64 Experimental: false 8.设置开机自启动 $ sudo systemctl enable docker 到此为止docker就完全安装好了。\n","description":"\n","tags":[],"title":"\nlinux上安装Docker(非常简单的安装方法)","uri":"/posts/post-336/"},{"categories":["默认分类"],"content":"Redis 的应用场景 现在不论大厂还是小平台，在面试的时候，都会面试redis。我们知道，redis很火,但是平时我们好像没有怎么（真正的）用到redis。\n通常情况下，我们用redis做了什么？ 缓存 缓存 缓存 缓存 缓存 …… 实际上redis可以做什么？ 缓存 排行榜 Session共享 分布式锁 延时队列/消息队列（支付） 发布，订阅消息 限流 …… 让我们动手试试吧 既然redis有这么多用处，哪我们为什么不试试呢？下面就通过以下几篇文章，我们来真正的了解下redis。\n","description":"\n","tags":["redis"],"title":"\nredis应用-前序","uri":"/posts/post-10/"},{"categories":["默认分类","Spring Cloud"],"content":"写在前面 通过前面SpringCloud入门篇（一）- 简介，我们基本上了解到本系列文章我们需要涉及的各种组件了，今天就让我们认识下Eureka。由于前面我们已经废话太多，这里我们就直接开始。\n创建Eureka服务 Eureka作为服务中心，我们这里要使用的也是其服务发现这一重要特性。需要注意的是，由于其本身也是服务，所以正常情况下，它是可以发现自身的。\n我们首先创建一个基础项目CloudBlogProject 之后我们修改一下pom.xml，以便后续维护：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cgroupId\u003ecn.com.pfinfo\u003c/groupId\u003e \u003cartifactId\u003ecloud.blog\u003c/artifactId\u003e \u003cversion\u003e0.0.1\u003c/version\u003e \u003cpackaging\u003epom\u003c/packaging\u003e \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-parent\u003c/artifactId\u003e \u003cversion\u003e2.0.3.RELEASE\u003c/version\u003e \u003crelativePath /\u003e \u003c!-- lookup parent from repository --\u003e \u003c/parent\u003e \u003cname\u003eBaseCloud\u003c/name\u003e \u003cproperties\u003e \u003cproject.build.sourceEncoding\u003eUTF-8\u003c/project.build.sourceEncoding\u003e \u003cproject.reporting.outputEncoding\u003eUTF-8\u003c/project.reporting.outputEncoding\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003cspring-cloud.version\u003eFinchley.RELEASE\u003c/spring-cloud.version\u003e \u003c/properties\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003e${spring-cloud.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-maven-plugin\u003c/artifactId\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e \u003c/project\u003e 然后，创建一个Maven Module： 同样，也是修改pom.xml，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003c!-- 其他省略 --\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-server\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cproject\u003e 在EurekaService中，我们创建一个启动类EurekaServerApplication.java：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package cn.com.pfinfo.eurekaserver; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer; @EnableEurekaServer @SpringBootApplication public class EurekaServerApplication { public static void main(String[] args) { SpringApplication.run(EurekaServerApplication.class, args); } } 修改配置文件application.properties：\n1 2 3 4 5 6 7 8 9 10 11 spring.application.name=eureka-server #服务注册中心端口号 server.port=8080 #服务注册中心实例的主机名 eureka.instance.hostname=127.0.0.1 #是否向服务注册中心注册自己 eureka.client.register-with-eureka=false #是否检索服务 eureka.client.fetch-registry=false #服务注册中心的配置内容，指定服务注册中心的位置 eureka.client.serviceUrl.defaultZone=http://${eureka.instance.hostname}:${server.port}/eureka/ 我们启动一下，打开127.0.0.1:8080 集群版本（伪） 除了我们自己学习的时候会这么搭建单机Eureka，企业基本不会这样选择，人家玩的都是集群。那我们怎么搭建集群Eureka呢？ 为了减少大家的学习成本（不论是知识上还是硬件上的），这里就在单机上实现伪集群。 我们只用在EurekaServer中创建2个配置文件application-eureka-secondary.properties、application-eureka-tertiary.properties 它们与application.properties区别只有下面这些不一样：\n# application的配置 server.port=8080 eureka.instance.hostname=eureka-primary eureka.client.serviceUrl.defaultZone=http://eureka-secondary:8078/eureka/,http://eureka-tertiary:8079/eureka/ # eureka-secondary的配置 server.port=8078 eureka.instance.hostname=eureka-secondary eureka.client.serviceUrl.defaultZone=http://eureka-primary:8080/eureka/,http://eureka-tertiary:8079/eureka/ # eureka-tertiary的配置 server.port=8079 eureka.instance.hostname=eureka-tertiary eureka.client.serviceUrl.defaultZone=http://eureka-primary:8080/eureka/,http://eureka-secondary:8078/eureka/ 然后，我们修改hosts，添加如下配置\n127.0.0.1 eureka-primary 127.0.0.1 eureka-secondary 127.0.0.1 eureka-tertiary 我们依次创建启动配置，为了方便，我们分别命名为：\neureka-service(primary) - EurekaServerApplication eureka-service(secondary) - EurekaServerApplication eureka-service(tertiary) - EurekaServerApplication 修改对应配置的VM arguments，添加对应配置：\n#eureka-secondary -Dspring.profiles.active=eureka-secondary #eureka-tertiary -Dspring.profiles.active=eureka-tertiary 注意：primary使用的application，所以不用添加）。\n以eureka-secondary为例，配置如下： 然后分别启动：primary、secondary、tertiary。 再次点开127.0.0.1:8080或者eureka-primary:8080我们就能看见如下界面 后话 当然，如果你最后打开发现有一行红字，不同担心，网上有很多解决办法，你可以自行百度。\n","description":"\n","tags":["SpringCloud"],"title":"\nSpringCloud入门篇（二） - Eureka","uri":"/posts/post-9/"},{"categories":["默认分类","java","SpringBoot","Spring Cloud"],"content":" 写在前面 **本系列文章，假定读者会使用Spring Boot完成项目开发。**如果读者对这方面只是上有欠缺，建议先补足相应知识。\n本文不涉及SpringCloud的相关组件，主要是为例让读者了解SpringCloud以及为什么要选择这个技术\nSpringCloud怎么出现的 这个问题是需要站在企业的角度去思考的。说这个问题之前，我们先要明白几个问题：\n互联网架构是如何演变的 演变过程中，不同级别企业是如何转型的 单机、分布式和集群的区别是什么？ 如果你对上面这些问题有个大概的理解了（度娘一下），下面我说的你可能就更能理解了。 其实对企业来说，一切系统的开发，就是花更小的代价来完成更快速的响应，当然这里的“更小的代价”是一个相对的描述。\n以前单机的时候，比较多的企业由于种种原因（资源有限，人力不足，为了快速开发一个产品，或上线一个网站），单机往往是一个不错的选择，此时会将应用程序、文件服务、数据库服务等资源集中在一台 Server 上。这样部署方便，就像tomcat部署war包。\n后来，带宽越来越大，服务开发的时候可展示的资源（图片、短视频）也越来越多，相对的，脚手架也是百花齐放，与之带来的是对各种文件资源的依赖增多，以前一个网页加载完毕也就∏kb/十几kb/j几十kb，连接数也就那么些；现在动辄几百kb/几Mb，连接数还越来越多，用户越来越庞大。这些都是需要各种开销的，有兴趣的可以去搜一下“打开一个网页背后都发生了什么”。企业为了更快的处理好这个问题，就开始增加机器（分流），但是紧接着问题出现了，如何能保证这些机器间的隔离性以及业务的一致性（如对数据库的脏读、幻读、重复读等问题），所以某些大公司开始了专治各种不服，这就开启了集群时代。\n再到后来，3G到4G时代，网络基本上不再作为互联网发展的限制，越来越多的用户开始习惯于使用互联网产品（比如知名的BAT），这些企业为了应对某些业务（如：双11）高峰时期，大量囤积了机器，自主研发了一系列技术，但是平时闲下来的时候，机器就空闲了，所以，企业需要降低成本，就有了公有云。公有云的出现，让小企业小公司也可以通过租用这些机器，完成自己系统云化，这就是云时代。\n在这期间，单纯的集群下，特定时期出现的高峰访问某个业务，对机器压力都是很大的，机器高负荷运转，其他业务也会受影响（资源补足），所以企业开始拆分系统业务，一个业务分拆多个子业务，部署在不同的服务器上。 这就是分布式，Spring Cloud就是在这期间出现的，其本质实际上是整合了Spring旗下的很多组件。\n所以，总的来说： 单机、分布式和集群是企业在不同时代下应对用户需求的各种部署方案。\n可能有很多人之前对分布式和集群有点混淆。简单来说：\n分布式：一个业务分拆多个子业务，部署在不同的服务器上 集群：同一个业务，分别部署在不同的服务器上\n所以分布式的每一个节点，完成的是不同的业务，一个节点挂了，那么这个业务功能就无法访问了，甚至可能会影响到其他业务。而集群是一个比较有组织的架构，正因为有组织性，一个服务节点挂了，其他服务节点可以顶上来，从而保证了服务的健壮性。\n所以说，集群可以理解为：你中有我，我中有你，手拉手肩并肩，一起保证服务的健壮性。\nSpringCloud的组件 基本上在多家公司做过大型一点的商业项目，都会知道，分布式集群化方案，每家企业都有自己的特色，基本上都是基于nginx+docker，有条件的就是k8s+nginx+docker+jenkin或者nginx+dobbo+docker。 其实本质都是： 分流、自动化部署、自动调度。健壮性较好的，系统能够自愈，不需要重启服务。\n详细点说就是： 服务治理、负载均衡、分布式配置中心、服务保护（熔断器、降级）、网关路由、监控。 这些之前主要是K8S+nginx在做。 现在Spring也开发出一套自己的（由于SpringCloud的版本命名特殊，所以，先说明，后续版本默认是基于Finchley.RELEASE来表述），整合了一下，叫SpringCloud:\nSpring Cloud Eureka: 服务治理、服务注册（Eureka Client）、服务发现（Eureka Server） Spring Cloud Ribbon: 负载均衡 Spring Cloud Consul： 配置中心 Spring Cloud Zuul: 网关路由 Spring Cloud Feign: 服务调用 Spring Cloud Hystrix： 服务保护（熔断器、降级） Spring Boot Admin： 监控 当然，上面这些组件有的只是对应功能的一种实现方案，肯定还有其他的实现方案，具体的就需要大家自行探索了。\n","description":"\n","tags":["SpringCloud"],"title":"\nSpringCloud入门篇（一）- 简介","uri":"/posts/post-8/"},{"categories":["数据库"],"content":"[mysql]replace的用法（替换某字段部分内容） [mysql]replace的用法\n1.replace into replace into table (id,name) values(‘1’,‘aa’),(‘2’,‘bb’) 此语句的作用是向表table中插入两条记录。如果主键id为1或2不存在就相当于 insert into table (id,name) values(‘1’,‘aa’),(‘2’,‘bb’) 如果存在相同的值则不会插入数据\n2.replace(object,search,replace) 把object中出现search的全部替换为replace select replace(‘www.163.com’,‘w’,‘Ww’)—\u003eWwWwWw.163.com 例：把表table中的name字段中的aa替换为bb update table set name=replace(name,‘aa’,‘bb’)\n3.UPDATE更新一个字段中的的部分内容\n现在有一条记录的字段是“abcdefg\",现在我只想将该字段中的c改为C，update语句应该怎么写\nupdate 表名 set 字段1 = replace(字段1,‘c’,‘C’)\n","description":"\n","tags":[],"title":"\nmysql 替换字段部分内容","uri":"/posts/post-339/"},{"categories":["数据库"],"content":"全局搜索字段所在位置\nSELECT COLUMN_NAME,TABLE_SCHEMA,TABLE_NAME FROM information_schema.COLUMNS WHERE COLUMN_NAME='字段名字' +---------------+--------------+---------------+ | COLUMN_NAME | TABLE_SCHEMA | TABLE_NAME | +---------------+--------------+---------------+ | contacts_name | dxxxf_v3 | fledts | | contacts_name | dxxxf_v3 | losdftions | | contacts_name | dxxxf_v3 | orgafsizatsdons | | contacts_name | pxxnf | afdts | | contacts_name | sxxmens | lafions | | contacts_name | pxxmedfs | sgdszations | +---------------+--------------+---------------+ ———————————————— ","description":"\n","tags":[],"title":"\nmsyql全局搜索字段所在位置","uri":"/posts/post-340/"},{"categories":["默认分类","建站"],"content":"前言 很早就有过想法，自行建站，都希望自己写一个程序，删删改改中，技术变化，Spring 出了SpringBoot，前端从AngularJS到React，VUE。自己的程序也从SS2H+html+js变成了SpringBoot+shiro+html+layui。改动过程中，发现代码是越改越少，终于还是放弃了。在开源中国看看火热的开源项目，慢慢的，发现一些轻量级的项目，本着不浪费的原则，开始了我的建站之路。\n服务器 首先我们需要购买云服务器。由于我们是实实在在的要搭建一个网站出来，涉及到的东西还比较多（公网ip，域名购买和备案等等），最好是选择大体量的云服务商（比如：阿里云、腾讯云）。我使用的是腾讯云（别问我为什么，当年搞活动的时候买的，一直用到现在），下面也将以腾讯云为例。其他云服务商如何我没调研过，不清楚，具体的信息需要读者自行search。如果读者想自己搭建服务器也可以，但是后续的域名解析以及公网ip就需要自行解决。\n购买云服务器 如果不急于一时，可以找云服务商做活动的时候入手一台云服务器。\n不要点开网站，看见半截就开跑，多看看 可以多点点，多看看，有心就能找到低价货。\n详细的购买初期设置都可以在快速配置 Linux 云服务器解决\n强烈建议使用linux\n服务器初始配置 关于linux常用端口可以查看这篇文章：Linux下常用服务的端口号超详细整理 看了上边这篇文章，我们应该知道，购买好服务器之后，我们需要关闭很多端口，防止别有用心之人来攻击服务器。我们只需要对外开放80，443（网页请求）以及22端口（远程连接），其余端口需要关闭。我们登录腾讯云后访问云服务器管理，然后再左侧找到安全组，并在安全组设置策略如下： 其余的我们就不需要改动了。尤其是那几个内网的，关闭后，很可能腾讯云就没法监控你服务器了（我没试过去修改），换句话说就是，你可能无法在网页上看见下面这些消息了： 最后 基本上到这里我们云服务器算是初步搞定，你的ip是在实例查看： 为了服务器安全，请不要随意暴露ip\n","description":"\n","tags":["linux","建站","腾讯云"],"title":"\n建站（一）-云服务器","uri":"/posts/post-5/"},{"categories":["默认分类"],"content":"Linux\nLinux 服务器上如何通过 Shell 脚本一键部署 SpringBoot 应用\nspringboot 是默认集成Tomcat容器的，将项目打包成jar包库、使用Java直接启动jar包（非spring boot也可以）\n首先需要在服务器端安装jdk、maven、git 点我看maven安装教程 点我看git安装教程\n想要SpringBoot项目使用maven打包成jar包需先在项目中的pom添加build插件,代码如下 \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cartifactId\u003emaven-dependency-plugin\u003c/artifactId\u003e \u003cconfiguration\u003e \u003coutputDirectory\u003e${project.build.directory}/libs\u003c/outputDirectory\u003e \u003cexcludeTransitive\u003efalse\u003c/excludeTransitive\u003e \u003cstripVersion\u003efalse\u003c/stripVersion\u003e \u003cincludeScope\u003ecompile\u003c/includeScope\u003e \u003c!--\u003cincludeScope\u003eruntime\u003c/includeScope\u003e--\u003e \u003c/configuration\u003e \u003cexecutions\u003e \u003cexecution\u003e \u003cid\u003ecopy-dependencies\u003c/id\u003e \u003cphase\u003epackage\u003c/phase\u003e \u003cgoals\u003e \u003cgoal\u003ecopy-dependencies\u003c/goal\u003e \u003c/goals\u003e \u003cconfiguration\u003e \u003c!-- \u003coutputDirectory\u003elibs\u003c/outputDirectory\u003e --\u003e \u003cexcludeTransitive\u003efalse\u003c/excludeTransitive\u003e \u003cstripVersion\u003etrue\u003c/stripVersion\u003e \u003c/configuration\u003e \u003c/execution\u003e \u003c/executions\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e 此插件是指将项目所依赖的jar，打包的时候打包到libs目录下，一遍到时候编写shell脚本读取依赖的jar\n接下来就可以编写shell脚本了（get源码的方式有很多种，直接上传上去也行。本文将使用Git在服务器端直接拉取源码，编译打包，启动） 主要修改 proc ,SOURCE_HOME,APP_LOG,PROFILES_ACTIVE 文件就好!\n#打包完后的jar名称，替换成你自己项目的名称，该名称可以在maven项目的pom中配置 proc=\"wechat\" #项目源码的目录地址（初始可能需要自己从Git拉下来） SOURCE_HOME=\"/usr/local/publicwx/publicWechat\" #日志地址 APP_LOG=\"$SOURCE_HOME/target/catalina.base_IS_UNDEFINED/logs/log_info.log\" #环境配置 用户配置开发(dev)，测试(test)，生产(prod)的配置文件，避免频繁改动 PROFILES_ACTIVE=\"spring.profiles.active=dev\" #JVM启动参数，关于JVM调优这里不介绍，感兴趣的可以自行百度 JVM调优 JAVA_OPTS=\"-server -Xms512M -Xmx512M -Xss256k -Xmn256m -XX:SurvivorRatio=4 -XX:+AggressiveOpts -XX:+UseBiasedLocking -XX:MetaspaceSize=128M -XX:MaxMetaspaceSize=256M -XX:CMSInitiatingOccupancyFraction=90 -XX:+CMSParallelRemarkEnabled -XX:+UseCMSCompactAtFullCollection -XX:+DisableExplicitGC -XX:MaxTenuringThreshold=0 -XX:CMSFullGCsBeforeCompaction=100 -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:LargePageSizeInBytes=128m -XX:+UseFastAccessorMethods -XX:+UseCMSInitiatingOccupancyOnly -Djava.awt.headless=true\" psid=0 #检查进程是否存在 checkpid() { javaps=$(pgrep -f \"$proc\") if [ -n \"$javaps\" ]; then psid=$javaps else psid=0 fi } #编写启动方法 start() { checkpid if [ $psid -ne 0 ]; then echo \"================================\" echo \"warn: $proc already started! (pid=$psid)\" echo \"================================\" else echo \"Starting $proc ...\" #到项目源码目录 cd $SOURCE_HOME #输出，准备获取最新代码 echo -n \"git pull source ,please wait .....\" #获取最新代码，此列只在目录所在分支pull #若想部署指定分支代码，可以在脚本调用参数中添加一个变量，用git checkout ${targer_branch} git pull #输出，最新代码已拉取完毕，准备打包 echo -n \"mvn package source ,please wait .....\" #maven打包命令，此处特别注意是 —U ,是指引用快照版本的jar（引用自己的项目）每次都更新最新的。 mvn clean package -Dmaven.test.skip=true #打包成功后默认是在启动项目的target目录下。 cd target #输出，准备启动 echo -n $\"Starting $proc:\" #循环加载所需的jar，此处和2的pom配置有关 for name in *.jar do APP_CLASS=\"$name\" done #启动脚本，--spring.profiles.active= 用于设置环境所使用的配置文件 JAVA_CMD=\"java \"$JAVA_OPTS\" -jar \"$APP_CLASS\" --\"$PROFILES_ACTIVE\" \u0026\" #后台运行 $JAVA_CMD \u0026 sleep 1 checkpid if [ $psid -ne 0 ]; then echo \"======================================\" echo \"$proc Start Success! (pid=$psid)[OK]\" echo \"======================================\" else echo \"[Failed]\" fi fi } #查看日志 showlog() { tail -f $APP_LOG } #停用项目 stop() { checkpid if [ $psid -ne 0 ]; then echo -n \"Stopping $proc ...(pid=$psid) \" kill -9 $psid if [ $? -eq 0 ]; then echo \"[OK]\" else echo \"[Failed]\" fi checkpid if [ $psid -ne 0 ]; then stop fi else echo \"================================\" echo \"warn: $proc is not running\" echo \"================================\" fi } #项目状态 status() { checkpid if [ $psid -ne 0 ]; then echo \"$proc is running! (pid=$psid)\" else echo \"$proc is not running\" fi } #设置脚本参数，启动的时候可以采用./脚本名称.sh start/stop/restart/log/status等参数 case \"$1\" in start) start ;; stop) stop ;; log) showlog ;; status) status ;; restart) stop start ;; esac ","description":"\n","tags":[],"title":"\nLinux 服务器上如何通过 Shell 脚本一键部署 SpringBoot 应用","uri":"/posts/post-341/"},{"categories":["数据库"],"content":"查看linux系统版本 [root@maruifu ~]# cat /etc/redhat-release 查看操作系统版本 CentOS Linux release 7.6.1810 (Core) [root@maruifu ~]# uname -r 查看系统内核版本 3.10.0-957.21.3.el7.x86_64 下载 下载地址 : https://dev.mysql.com/downloads/mysql/\ncentos7 选择 Red Hat Enterprise Linux / Oracle Linux\n版本就自己根据自己系统下载就好了\n可以选择 RPM Bundle 使用wget 下载 mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar\n[root@nfs_client ~]# wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar 也可以细化下载，下载须要的mysql组件，有4个：分别是 server、client、common、libs\n卸载旧版本的MySql （没有的话，则跳过此步骤） 1、查看旧版本MySql rpm -qa | grep mysql 将会列出旧版本MySql的组件列表，如：\n[root@maruifu ~]# rpm -qa | grep mysql mysql-community-libs-5.7.28-1.el7.x86_64 mysql-community-server-5.7.28-1.el7.x86_64 mysql-community-common-5.7.28-1.el7.x86_64 mysql-community-client-5.7.28-1.el7.x86_64 2、逐个删除掉旧的组件 使用命令rpm -e –nodeps {-file-name}进行移除操作，移除的时候可能会有依赖，要注意一定的顺序。\nrpm -e --nodeps mysql-community-libs-5.7.28-1.el7.x86_64 安装 解压 [root@maruifu tools]# pwd /usr/local/tools [root@maruifu tools]# tar xvf mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar\n卸载 centos7自带的mariadb-lib\n[root@maruifu tools]# rpm -qa|grep mariadb mariadb-libs-5.5.56-2.el7.x86_64 [root@maruifu tools]# rpm -e mariadb-libs-5.5.56-2.el7.x86_64 –nodeps 安装 这里我们只安装mysql-server服务，只需要安装如下4个软件包即可，\n使用命令rpm -ivh {-file-name}进行安装操作。\n**注：ivh中， i-install安装；v-verbose进度条；h-hash哈希校验**\n按照依赖关系依次安装rpm包 依赖关系依次为common→libs→client→server\n1 2 3 4 1. rpm -ivh mysql-community-common-5.7.28-1.el7.x86_64.rpm 2. rpm -ivh mysql-community-libs-5.7.28-1.el7.x86_64.rpm 3. rpm -ivh mysql-community-client-5.7.28-1.el7.x86_64.rpm 4. rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm 特殊情况1 在阿里云ECS云服务器上安装mysql5.7，当安装 mysql-community-server-5.7.28-1.el7.x86_64.rpm 时报错，报错如下\n[root@maruifu ~]# rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm warning: mysql-community-server-5.7.28-1.el7.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 5072e1f5: NOKEY error: Failed dependencies: libaio.so.1()(64bit) is needed by mysql-community-server-5.7.28-1.el7.x86_64 libaio.so.1(LIBAIO_0.1)(64bit) is needed by mysql-community-server-5.7.28-1.el7.x86_64 libaio.so.1(LIBAIO_0.4)(64bit) is needed by mysql-community-server-5.7.28-1.el7.x86_64 解决法案就是：安装libaio\n[root@maruifu ~]# yum -y install libaio 安装libaio后，再重新安装一次mysql-community-server-5.7.28-1.el7.x86_64.rpm，此时就能正常安装了\n特殊情况2 比如解决了“特殊情况1”，但在启动mysql的时候，启动不起来，或启动后，去查找临时密码，使用命令没反应。查看日志mysqld.log(可在/etc/my.cnf中查找到mysqld.log的配置位置)，报如下错误，此时怎么解决？\n[ERROR] Fatal error: Can’t open and lock privilege tables: Table ‘mysql.user’ doesn’t exist\n1\u003e先通过rpm -e –nodeps xxx 卸载掉server，卸载后删除datadir目录，\n2\u003e卸载后查看 /etc/my.cnf 中，datadir的配置情况，将datedir目录删除，\n3\u003e最后通过命令rpm -ivh xxx 重新安装server,此时就能正常使用mysql了\n命令代码如下：\n[root@maruifu ~]# rpm -e --nodeps mysql-community-server-5.7.22-1.el7.x86_64 [root@maruifu ~]# cat /etc/my.cnf datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock [root@maruifu ~]# cd /var/lib [root@maruifu lib]# rm -rf mysql [root@maruifu ~]# rpm -ivh mysql-community-server-5.7.22-1.el7.x86_64.rpm [root@maruifu ~]# systemctl start mysqld.service [root@maruifu ~]# ps -ef|grep mysql mysql 21001 1 0 Nov22 ? 00:00:00 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid root 22218 20782 0 00:21 pts/1 00:00:00 grep --color=auto mysql root 24317 31119 0 Nov21 pts/0 00:00:00 mysql -u root -p 登录并创建MySql密码 启动MySql 安装完后，使用命令 service mysqld start 或 systemctl start mysqld.service 启动MySQL服务。（如果mysql服务无法启动，就重启一下系统）\nsystemctl start mysqld.service 启动mysql systemctl status mysqld.service 查看mysql状态 systemctl stop mysqld.service 关闭mysql 查看mysql进程 ps -ef|grep mysql 查看3306端口 netstat -anop|grep 3306 登陆mysql修改root密码 由于MySQL5.7.4之前的版本中默认是没有密码的，登录后直接回车就可以进入数据库，进而进行设置密码等操作。其后版本对密码等安全相关操作进行了一些改变，在安装过程中，会在安装日志中生成一个临时密码。\n怎么找到这个临时密码呢？\ngrep 'temporary password' /var/log/mysqld.log [root@maruifu ~]# grep 'temporary password' /var/log/mysqld.log 2019-11-21T08:07:27.278434Z 1 [Note] A temporary password is generated for root@localhost: rj3pj;g3XWIh rj3pj;g3XWIh即为登录密码。使用这个随机密码登录进去，然后修改密码，使用命令：\nmysql -uroot -p 执行下面的命令修改MySql root密码\nset password for root@localhost=password('12345678'); 在5.6后,mysql内置密码增强机制,低强度密码会报错:\nERROR 1819 (HY000): Your password does not satisfy the current policy requirements 更改策略，设置 validate_password_policy=0;\nmysql\u003e set global validate_password_length=1; Query OK, 0 rows affected (0.00 sec) 修改密码\n1. mysql\u003e set password for root@localhost=password('TianTianIT12345'); 2. Query OK, 0 rows affected, 1 warning (0.00 sec) 此时，虽然防火墙我时关着的，但root用户只能用于本机访问，不能用于远程访问，否则会报以下错误。因此，接下来要做的是授予root用户远程访问权限。\n查看当前授予过的权限：\nuse mysql; select user,host from user; mysql\u003e use mysql; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql\u003e select user,host from user; +---------------+-----------+ | user | host | +---------------+-----------+ | root | % | | mysql.session | localhost | | mysql.sys | localhost | | root | localhost | +---------------+-----------+ 4 rows in set (0.00 sec) mysql\u003e show grants; +---------------------------------------------------------------------+ | Grants for root@localhost | +---------------------------------------------------------------------+ | GRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' WITH GRANT OPTION | | GRANT PROXY ON ''@'' TO 'root'@'localhost' WITH GRANT OPTION | +---------------------------------------------------------------------+ 2 rows in set (0.00 sec) 授予root用户远程访问权限：\nmysql\u003e grant all privileges on *.* to root@'%' identified by 'TianTianIT12345'; Query OK, 0 rows affected, 1 warning (0.05 sec) 刷新权限，使设置生效， OK。\nmysql\u003e flush privileges; Query OK, 0 rows affected (0.36 sec) ","description":"\n","tags":[],"title":"\ncentos7 安装 mysql 详解","uri":"/posts/post-342/"},{"categories":["默认分类"],"content":"nginx\nlinux 中nginx 的安装 ##序言\nNginx是lgor Sysoev为俄罗斯访问量第二的rambler.ru站点设计开发的。从2004年发布至今，凭借开源的力量，已经接近成熟与完善。\nNginx功能丰富，可作为HTTP服务器，也可作为反向代理服务器，邮件服务器。支持FastCGI、SSL、Virtual Host、URL Rewrite、Gzip等功能。并且支持很多第三方的模块扩展。\nNginx的稳定性、功能集、示例配置文件和低系统资源的消耗让他后来居上，在全球活跃的网站中有12.18%的使用比率，大约为2220万个网站。\n牛逼吹的差不多啦，如果你还不过瘾，你可以百度百科或者一些书上找到这样的夸耀，比比皆是。\nNginx常用功能 1、Http代理，反向代理：作为web服务器最常用的功能之一，尤其是反向代理。 Nginx在做反向代理时，提供性能稳定，并且能够提供配置灵活的转发功能。Nginx可以根据不同的正则匹配，采取不同的转发策略，比如图片文件结尾的走文件服务器，动态页面走web服务器，只要你正则写的没问题，又有相对应的服务器解决方案，你就可以随心所欲的玩。并且Nginx对返回结果进行错误页跳转，异常判断等。如果被分发的服务器存在异常，他可以将请求重新转发给另外一台服务器，然后自动去除异常服务器。\n2、负载均衡 Nginx提供的负载均衡策略有2种：内置策略和扩展策略。内置策略为轮询，加权轮询，Ip hash。扩展策略，就天马行空，只有你想不到的没有他做不到的啦，你可以参照所有的负载均衡算法，给他一一找出来做下实现。上3个图，理解这三种负载均衡算法的实现 3、web缓存 Nginx可以对不同的文件做不同的缓存处理，配置灵活，并且支持FastCGI_Cache，主要用于对FastCGI的动态程序进行缓存。配合着第三方的ngx_cache_purge，对制定的URL缓存内容可以的进行增删管理。\n4、Nginx相关地址 源码：https://trac.nginx.org/nginx/browser\n官网：http://www.nginx.org/\nNginx安装 安装依赖库 安装gcc模块， 安装Nginx前，必须先确保安装了gcc环境。那么何为gcc?它是 Linux 下默认的 C/C++ 编译器，大部分 Linux 发行版中都是默认安装的。命令行输入gcc -v，如果显示命令未找到或command not found，则代表没有安装gcc，需要安装上。\nyum install gcc-c++ 安装prce模块: PCRE(Perl Compatible Regular Expressions)是一个Perl库，包括 perl 兼容的正则表达式库。nginx的http模块使用pcre来解析正则表达式，所以需要在linux上安装pcre库。 地址 : http://www.pcre.org/\n//下载`wget https://ftp.pcre.org/pub/pcre/pcre-8.37.tar.gz //解压 tar -zxvf pcre-8.37.tar.gz //然后,进入包，配置： ./configure //安装 make \u0026\u0026 make install 安装openssl模块,OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。 nginx不仅支持http协议，还支持https（即在ssl协议上传输http），所以需要在linux安装openssl库。地址: http://www.openssl.org/ //下载 wget https://www.openssl.org/source/openssl-1.1.0e.tar.gz // 解压 tar -zxvf openssl-1.1.0e.tar.gz //然后,进入包，配置： ./configure //安装 make \u0026\u0026 make install 安装gzip 模块, zlib库提供了很多种压缩和解压缩的方式，nginx使用zlib对http包的内容进行gzip，所以需要在linux上安装zlib库。 地址 http://www.zlib.net/ //下载 wget http://prdownloads.sourceforge.net/libpng/zlib-1.2.11.tar.gz?download //解压 tar -zxvf zlib-1.2.11.tar.gz?download // 然后,进入包，配置： ./configure //安装 make \u0026\u0026 make install 也可以 yum安装\nyum install -y pcre pcre-devel yum install -y openssl openssl-devel yum install -y zlib zlib-devel 安装Nginx并启动 //创建一个文件夹\ncd /usr/local/ mkdir server cd server/ //下载 : wget http://nginx.org/download/nginx-1.7.8.tar.gz //解压 tar -xvf nginx-1.7.8.tar.gz //创建目录 mkdir nginx //\u003e\u003e安装一个第三方模块,可以打印输出一些东西，一般用于调试nginx的参数时使用(也可以不安装) //\u003e\u003e创建一个模块目录 用于放第三方模块 mkdir nginx-module //\u003e\u003e进入目录: cd nginx-module //\u003e\u003e下载: wget https://github.com/openresty/echo-nginx-module/archive/v0.60.tar.gz //\u003e\u003e解压: tar zxvf v0.60.tar.gz echo-nginx-module-0.60 //进入安装目录 cd nginx-1.7.8 //配置 ./configure --prefix=/usr/local/server/nginx --add-module=/usr/local/server/nginx-module/echo-nginx-module-0.60 --with-debug 源码的安装一般由有这三个步骤：配置(configure)、编译(make)、安装(make install) 一般在编译前加上一句： ./configure --prefix=/xxx/xxx 其中–prefix选项就是配置安装的路径，如果不配置该选项，安装后可执行文件默认放在/usr/local/bin，库文件默认放在/usr/local/lib，配置文件默认放在/usr/local/etc，其它的资源文件放在/usr/local/share，比较分散。 为了便于集中管理某个软件的各种文件，可以配置–prefix，如： ./configure --prefix=/usr/local/server/nginx --with-http_stub_status_module --with-http_ssl_module 可以把所有资源文件放在/usr/local/server/nginx的路径中，就不会分散了。 // 编译安装 make \u0026\u0026 make install //进入启动目录 cd .. cd nginx/sbin/ //启动 ./nginx //这个时候可以访问本机IP了 配置Nginx 打开配置文件 vi /usr/local/nginx/conf/nginx.conf 配置文件\nuser root; worker_processes auto; error_log logs/error.log warn; pid logs/nwarn.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log logs/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; client_max_body_size 20m; client_body_buffer_size 20m; gzip on; #开启gzip压缩功能 gzip_min_length 10k; #设置允许压缩的页面最小字节数; 这里表示如果文件小于10个字节，就不用压缩，因为没有意义，本来就很小. gzip_buffers 4 16k; #设置压缩缓冲区大小，此处设置为4个16K内存作为压缩结果流缓存 gzip_http_version 1.1; #压缩版本 gzip_comp_level 1; #设置压缩比率，最小为1，处理速度快，传输速度慢；9为最大压缩比，处理速度慢，传输速度快; 这里表示压缩级别，可以是0到9中的任一个，级别越高，压缩就越小，节省了带宽资源，但同时也消耗CPU资源，所以一般折中为6 gzip_types text/plain text/css application/javascript text/javascript; #制定压缩的类型,线上配置时尽可能配置多的压缩类型! gzip_vary on; #选择支持vary header；改选项可以让前端的缓存服务器缓存经过gzip压缩的页面; 这个可以不写，表示在传送数据时，给客户端说明我使用了gzip压缩i include /usr/local/server/nginx/conf/conf.d/*.conf; } Nginx 常用命令 nginx -s reload # 重新载入配置文件 nginx -s reopen # 重启 Nginx nginx -s stop # 停止 Nginx nginx -t # 检查配置文件nginx.conf nginx -s quit #优雅停止nginx，有连接时会等连接请求完成再杀死worker进程 nginx -v #查看版本 nginx -c filename #指定配置文件 nginx -h # 查看帮助信息 nginx -s reopen #重新打开日志文件，一般用于切割日志 ","description":"\n","tags":[],"title":"\nlinux 中nginx 的安装","uri":"/posts/post-343/"},{"categories":["java"],"content":"写在前面 需要说明的是，这篇文章的主旨不是要实现一个完美的Excel导入功能，而是希望做到抛砖引玉以及帮助部分同学展开自我思考的思路。\n好了，话不多说，我们直接进入正题。\n背景定义 我们在完成功能前一般需要梳理一下需求，由于本篇文章旨在引导，所以需求一般会比较简单。\n我们定义如下背景：\n某公司由于业务需要，现想要自主研发管理系统，这就需要将公司部分数据从原有系统导出（现有系统已支持），然后导入到新系统中。由于公司体量庞大，业务和数据较多，所以公司领导层希望研发部逐步完成数据转移。研发部的第一个功能就是人员信息数据转移，已知原有人员信息模本中盖内容包括：所在部门，姓名，性别，出生日期，年龄，户籍所在地，居住地，就职时间，婚姻状况，教育程度，联系电话，紧急联系人，紧急联系人电话。\n由于研发部主要都是Java开发人员，所以研发部决定先用java开发一版demo，于是采集了部分样本数据：人员信息\n由于业务庞大，为分工明确，研发部将数据导入分为多个模块（eg: 文件上传，数据转换，数据填充，相关业务初始化，数据入库）。\n分析需求 其他模块暂且不分析，我们简要分析一下上述背景中关于数据转换需求：\nExcel文件上传后，需要读入文件内容，然后逐行转换数据为指定对象。 貌似这个功能很简单，我们就直接开始吧。\n创建Demo Project 我们尽量精简一点，我们使用Eclipse（或者idea）创建一个Maven项目\n初始化好框架代码 读取Excel文件 需要注意的是，我们虽然是要读取文件，所以第一步就是找到文件，所以我们先创建一个FileUtil类\n然后完成第一个方法，读取文件：\npackage cn.com.pfinfo.excel.util; import java.io.File; import java.io.FileNotFoundException; import java.net.URI; import java.net.URISyntaxException; import java.net.URL; /** * 文件操作工具类 * * @author cuitpf * */ public class FileUtil { /** * 根据文件路径找到对应的文件，并返回文件对象。 * * @param fileLocation 文件本地路径 * @return 文件对象 * @throws FileNotFoundException */ public static File getFile(String fileLocation) throws FileNotFoundException { if (fileLocation == null) { throw new RuntimeException(\"文件地址不能为空\"); } ClassLoader cl = FileUtil.class.getClassLoader(); URL url = (cl != null ? cl.getResource(fileLocation) : ClassLoader.getSystemResource(fileLocation)); if (url == null) { throw new FileNotFoundException(\"本地文件不存在\"); } // Load file by URL try { URI uri = new URI(url.toString().replaceAll(\" \", \"%20\")); return new File(uri.getSchemeSpecificPart()); } catch (URISyntaxException ex) { // Fallback for URLs that are not valid URIs (should hardly ever happen). return new File(url.getFile()); } } } 加载工作簿 这一步怎么都绕不过去的就是依赖apatch-poi。这里给出maven配置依赖的方式\n\u003c!-- https://mvnrepository.com/artifact/org.apache.poi/poi --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.poi\u003c/groupId\u003e \u003cartifactId\u003epoi\u003c/artifactId\u003e \u003cversion\u003e${poi.version}\u003c/version\u003e \u003c/dependency\u003e \u003c!-- https://mvnrepository.com/artifact/org.apache.poi/poi-ooxml --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.poi\u003c/groupId\u003e \u003cartifactId\u003epoi-ooxml\u003c/artifactId\u003e \u003cversion\u003e${poi.version}\u003c/version\u003e \u003c/dependency\u003e 其他直接导入jar包的或者其他构建工具的读者请自行添加依赖。\n添加了依赖后，我们就可以开始编码了：\npackage cn.com.pfinfo.excel.util; import static cn.com.pfinfo.excel.config.ConstantConfig.XLS; import static cn.com.pfinfo.excel.config.ConstantConfig.XLSX; import java.io.File; import java.io.FileInputStream; import java.io.FileNotFoundException; import java.io.IOException; import java.net.URI; import java.net.URISyntaxException; import java.net.URL; import org.apache.poi.hssf.usermodel.HSSFWorkbook; import org.apache.poi.ss.usermodel.Workbook; import org.apache.poi.xssf.usermodel.XSSFWorkbook; import cn.com.pfinfo.excel.config.ConstantConfig; import cn.com.pfinfo.excel.exception.ImportExcelBaseException; /** * 文件操作工具类 * * @author cuitpf * */ public class FileUtil { /** * 根据文件路径找到对应的文件，并返回文件对象。 * * @param fileLocation 文件本地路径 * @return 文件对象 * @throws FileNotFoundException */ public static File getFile(String fileLocation) throws FileNotFoundException { if (fileLocation == null) { throw new RuntimeException(\"文件地址不能为空\"); } ClassLoader cl = FileUtil.class.getClassLoader(); URL url = (cl != null ? cl.getResource(fileLocation) : ClassLoader.getSystemResource(fileLocation)); if (url == null) { throw new FileNotFoundException(\"本地文件不存在\"); } // Load file by URL try { URI uri = new URI(url.toString().replaceAll(\" \", \"%20\")); return new File(uri.getSchemeSpecificPart()); } catch (URISyntaxException ex) { // Fallback for URLs that are not valid URIs (should hardly ever happen). return new File(url.getFile()); } } /** * 根据文件路径获取文件中的工作簿，如果文件不是{@link ConstantConfig#XLS}或者{@link ConstantConfig#XLSX}格式的，会返回{@code null}对象 * * @param localFilePath 文件路径 * @return 如果文件格式是excel格式，返回工作簿对象，否则，返回null对象 * @throws ImportExcelBaseException 文件如果受损导致不能打开，将抛出自定义异常。 */ public static Workbook getWorkbook(String localFilePath) throws ImportExcelBaseException { try (FileInputStream fileInputStream = new FileInputStream(getFile(localFilePath))) { if (localFilePath.endsWith(XLS)) { return new HSSFWorkbook(fileInputStream); } else if (localFilePath.endsWith(XLSX)) { return new XSSFWorkbook(fileInputStream); } return null; } catch (IOException e) { throw new ImportExcelBaseException(e); } } } 建立映射关系 excel如何转换为java对象呢？我们需要建立一个映射关系，告诉程序，比如：当你发现姓名这一列的时候，它对应的对象属性为name。\n这样的映射关系我们传统编码中，是这样写的（代码太长，我就用伪代码表示一下了）：\nread line read cell from line get cell.index of line if(index = 1) user.name = cell.value else if (index = 2) user.sex = cell.value ... return user 这种方式当然也能实现功能，但如果某天不需要某个属性了，模版中删除了一列，这里的代码改动可能不会太小。所以上面的代码可能不太优雅，我们需要使用优雅的代码来解决问题。\n由于jdk1.5推出了注解这个概念，所以在那之后多数公司在实现excel导入的时候，都采用注解的方式进行协助。我们这里也采用注解协助开发。\n在此之前我们需要了解几个概念。java是面向对象的编程语言，万物皆对象。所以我们需要先分析编码在我们可能会接触到的对象概念：工作簿，工作表，行，列，单元格。\n每一个Excel文件都可以看作是一个工作簿，当打开一个Excel文件时，就等于打开了一个Excel工作簿 当打开了Excel工作簿后在窗口底部看到的”Sheet“标签表示的是工作表，有几个标签就表示有几个工作表 在每个工作表内，被网格线纵横隔开的就是单元格 工作表内从左到右的方向被称为行 工作表内从上到下的方向被称为列 工作簿并非只单纯的包含工作表，它还可以包含图表和宏表等 我们导入数据的时候，就是把一个个工作表导入成为一个个对应的集合，表中的一行数据对应集合中的一个元素。\n反过来，我们一个元素就是描述的某个工作表的某一行数据，元素的属性就是对应的这一行的一个个单元格的数据，具体对应关系就是元素属性和列的对应关系\n通常，我们会将第一行标记为表头，就像这样：\n所以，属性的数据就是对应的表头所在列的数据。\n最后总结一下：\n对象：描述某个工作表的一行数据 对象的属性： 描述某个工作表的一行数据的某一列。 现在可以创建注解了。\n首先是类注解：\npackage cn.com.pfinfo.excel.anno; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * 工作表注解，用于描述实体Bean对应的工作表 * @author cuitpanfei * */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) public @interface Sheet { String value() defult \"Sheet1\"; } 然后是属性注解：\npackage cn.com.pfinfo.excel.anno; import java.lang.annotation.ElementType; import java.lang.annotation.Retention; import java.lang.annotation.RetentionPolicy; import java.lang.annotation.Target; /** * 工作表注解，用于描述实体Bean对应的工作表 * @author cuitpanfei * */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.FIELD) public @interface Cell { /** 对应的列名称 */ String name() default \"\"; /** 列序号 */ int index(); /** 字段类型对应的格式 */ String format() default \"\"; /** 校验是否可以为空 */ boolean isEmpty() default true; } 读取数据 这一步比较冗长，我们先写一个大致代码框架出来(不必要的代码这里都已经略过了)\npublic \u003cT\u003e List\u003cT\u003e map(String sheetName, Class\u003cT\u003e clazz){ //获取表头映射关系 //检查获取到的映射关系 //加载工作表 //获取工作表 表头 //检查表头和映射关系是否匹配 //根据映射关系和表头的关系加载表数据 //映射数据为泛型数据集合 //返回映射结果 return null; } 最后 大体的脉络我们清楚了，后续主要是填充好就好了。\n（未完待续）\n","description":"\n","tags":["excel","Java"],"title":"\nExcel导入简易版（一）","uri":"/posts/post-4/"},{"categories":["语言"],"content":"前言 Java 语言是当前互联网应用最为广泛的语言，作为一名 Java 程序猿，当业务相对比较稳定之后平常工作除了 coding 之外，大部分时间（70%~80%）是会用来排查突发或者周期性的线上问题。由于业务应用 bug（本身或引入第三方库）、内外部环境、底层硬件问题等原因，Java线上服务出现故障/问题几乎不可避免。例如，常见的现象包括部分请求超时、用户明显感受到系统发生卡顿等等。\n尽管线上问题从系统表象来看非常明显，但排查深究其发生的原因还是比较困难的，因此对开发测试或者是运维的同学产生了许多的困扰。排查定位线上问题是具有一定技巧或者说是经验规律的，排查者如果对业务系统了解得越深入，那么相对来说定位也会容易一些。\n不管怎么说，掌握 Java 服务线上问题排查思路并能够熟练排查问题常用工具/命令/平台是每一个 Java 程序猿进阶必须掌握的实战技能。笔者依据自己的 工作经验总结出一套基本的线上问题排查流程，同学们可以根据自己的实际工作情况进行归纳总结。\nJava 服务常见线上问题 所有 Java 服务的线上问题从系统表象来看归结起来总共有四方面：CPU、内存、磁盘、网络。例如 CPU 使用率峰值突然飚高、内存溢出(泄露)、磁盘满了、网络流量异常、FullGC 等等问题。基于这些现象我们可以将线上问题分成两大类: 系统异常、业务服务异常。\n系统异常 常见的系统异常现象包括: CPU 占用率过高、CPU上下文切换频率次数较高、磁盘满了、磁盘 I/O 过于频繁、网络流量异常（连接数过多）、系统可用内存长期处于较低值（导致 oom killer）等等。这些问题可以通过 top（cpu）、free（内存）、df（磁盘）、dstat（网络流量）、pstack、vmstat、strace（底层系统调用）等工具获取系统异常现象数据。\n此外，如果对系统以及应用进行排查后，均未发现异常现象的根本原因，那么也有可能是因为外部基础设施 IAAS 平台所引发的问题。例如运营商网络或者云服务提供商偶尔可能也会发生一些故障问题，你的引用只有某个区域如广东用户访问系统时发生服务不可用现象，那么极有可能是这些原因导致的。今天，我司部署在阿里云华东地域的业务系统中午时分突然不能为广东地区用户提供正常服务，对系统进行各种排查均为发现任何问题。最后，通过查询阿里云公告得知原因是\"广东地区电信线路访问华东地区互联网资源（包含阿里云华东1地域）出现网络丢包或者延迟增大的异常情况\"。\n业务服务异常 常见的业务服务异常现象包括: PV 量过高、服务调用耗时异常、线程死锁、多线程并发问题、频繁进行 Full GC、异常安全攻击扫描等。\n问题定位 我们一般会采用排除法，从外部排查到内部排查的方式来定位线上服务问题。\n首先我们要排除其他进程（除主进程之外）可能引起的故障问题 其次排除业务应用可能引起的故障问题 最后可以考虑是否为运营商或者云服务提供商所引起的故障\n定位流程 系统异常排查流程 业务应用排查流程 Linux 常用的性能分析工具 Linux 常用的性能分析工具使用包括 : top（cpu）、free（内存）、df（磁盘）、dstat（网络流量）、pstack、vmstat、strace（底层系统调用）等。\nCPU CPU 是系统重要的监控指标，能够分析系统的整体运行状况。监控指标一般包括运行队列、CPU使用率和上下文切换等。\ntop命令是Linux下常用的 CPU 性能分析工具,能够实时显示系统中各个进程的资源占用状况,常用于服务端性能分析。\ntop 命令显示了各个进程 CPU 使用情况，一般 CPU 使用率从高到低排序展示输出。其中 Load Average 显示最近1分钟、5分钟和15分钟的系统平均负载，上图各值为2.46，1.96，1.99。\n我们一般会关注 CPU 使用率最高的进程，正常情况下就是我们的应用主进程。第七行以下：各进程的状态监控。\nPID : 进程id USER : 进程所有者 PR : 进程优先级 NI : nice值。负值表示高优先级，正值表示低优先级 VIRT : 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES RES : 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA SHR : 共享内存大小，单位kb S : 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程 %CPU : 上次更新到现在的CPU时间占用百分比 %MEM : 进程使用的物理内存百分比 TIME+ : 进程使用的CPU时间总计，单位1/100秒 COMMAND : 进程名称 内存 内存是排查线上问题的重要参考依据，内存问题很多时候是引起 CPU 使用率较高的见解因素。\n系统内存：free 是显示的当前内存的使用，-m 的意思是M字节来显示内容。\nfree -m 部分参数说明：\ntotal 内存总数: 3790M\nused 已经使用的内存数: 1880M\nfree 空闲的内存数: 118M\nshared 当前已经废弃不用,总是0\nbuffers Buffer 缓存内存数: 1792M\n磁盘 磁盘满了很多时候会连带引起系统服务不可用等问题\ndf -h du -m /path 网络 dstat 命令可以集成了 vmstat、iostat、netstat 等等工具能完成的任务。\ndstat -c cpu情况 -d 磁盘读写 -n 网络状况 -l 显示系统负载 -m 显示形同内存状况 -p 显示系统进程信息 -r 显示系统IO情况 其它 vmstat：\nvmstat 2 10 -t vmstat 是 Virtual Meomory Statistics（虚拟内存统计）的缩写, 是实时系统监控工具。该命令通过使用 knlist 子程序和 /dev/kmen 伪设备驱动器访问这些数据，输出信息直接打印在屏幕。\n使用 vmstat 2 10 -t命令，查看 io 的情况 （第一个参数是采样的时间间隔数单位是秒，第二个参数是采样的次数）。\nr 表示运行队列(就是说多少个进程真的分配到CPU),b 表示阻塞的进程。 swpd 虚拟内存已使用的大小，如果大于0，表示你的机器物理内存不足了，如果不是程序内存泄露的原因，那么你该升级内存了或者把耗内存的任务迁移到其他机器。 free 空闲的物理内存的大小，我的机器内存总共4G，剩余120M左右。 buff Linux/Unix系统是用来存储，目录里面有什么内容，权限等的缓存，我本机大概占用40多M cache 文件缓存 si列表示由磁盘调入内存，也就是内存进入内存交换区的数量； so列表示由内存调入磁盘，也就是内存交换区进入内存的数量 一般情况下，si、so的值都为0，如果si、so的值长期不为0，则表示系统内存不足，需要考虑是否增加系统内存。 bi 从块设备读入数据的总量（读磁盘）（每秒kb） bo 块设备写入数据的总量（写磁盘）（每秒kb） 随机磁盘读写的时候，这两个值越大((超出1024k)，能看到cpu在IO等待的值也会越大 这里设置的bi+bo参考值为1000，如果超过1000，而且wa值比较大，则表示系统磁盘IO性能瓶颈。 in 每秒CPU的中断次数，包括时间中断 cs(上下文切换Context Switch) strace：strace常用来跟踪进程执行时的系统调用和所接收的信号。\nstrace -cp tid strace -T -p tid -T 显示每一调用所耗的时间. -p pid 跟踪指定的进程pid. -v 输出所有的系统调用.一些调用关于环境变量,状态,输入输出等调用由于使用频繁,默认不输出. -V 输出strace的版本信息. JVM 定位问题工具 在 JDK 安装目录的 bin 目录下默认提供了很多有价值的命令行工具。每个小工具体积基本都比较小，因为这些工具只是 jdk\\lib\\tools.jar 的简单封装。\n其中，定位排查问题时最为常用命令包括：jps（进程）、jmap（内存）、jstack（线程）、jinfo（参数）等。\njps：查询当前机器所有JAVA进程信息\njmap：输出某个 Java 进程内存情况（如产生那些对象及数量等）\njstack：打印某个 Java 线程的线程栈信息\njinfo：用于查看 jvm 的配置参数\njps 命令 jps 用于输出当前用户启动的所有进程 ID，当线上发现故障或者问题时，能够利用 jps 快速定位对应的 Java 进程 ID。\njps -l -m -m -l -l参数用于输出主启动类的完整路径 当然，我们也可以使用 Linux 提供的查询进程状态命令，例如：\nps -ef | grep tomcat 我们也能快速获取 Tomcat 服务的进程 id。\njmap 命令 jmap -heap pid 输出当前进程JVM堆新生代、老年代、持久代等请情况，GC使用的算法等信息 jmap -histo:live {pid} | head -n 10 输出当前进程内存中所有对象包含的大小 jmap -dump:format=b,file=/usr/local/logs/gc/dump.hprof {pid} 以二进制输出档当前内存的堆情况，然后可以导入MAT等工具进行 JMap（Java Memory Map）可以输出所有内存中对象的工具，甚至可以将 VM 中的 heap，以二进制输出成文本。\njmap -heap pid：\njmap -heap pid 输出当前进程JVM堆新生代、老年代、持久代等请情况，GC使用的算法等信息 jmap 可以查看 JVM 进程的内存分配与使用情况，使用 的 GC 算法等信息。\njmap -histo:live {pid} | head -n 10：\njmap -histo:live {pid} | head -n 10 输出当前进程内存中所有对象包含的大小 输出当前进程内存中所有对象实例数（instances）和大小（bytes），如果某个业务对象实例数和大小存在异常情况，可能存在内存泄露或者业务设计方面存在不合理之处。\njmap -dump：\njmap -dump:format=b,file=/usr/local/logs/gc/dump.hprof {pid} -dump:formate=b,file= 以二进制输出当前内存的堆情况至相应的文件，然后可以结合 MAT 等内存分析工具深入分析当前内存情况。\n一般我们要求给 JVM 添加参数 -XX:+Heap Dump On Out Of Memory Error OOM 确保应用发生 OOM 时 JVM 能够保存并 dump 出当前的内存镜像。当然如果你决定手动 dump 内存时，dump 操作占据一定 CPU 时间片、内存资源、磁盘资源等，因此会带来一定的负面影响。\n此外，dump 的文件可能比较大,一般我们可以考虑使用zip命令对文件进行压缩处理，这样在下载文件时能减少带宽的开销。在下载 dump 文件完成之后，由于 dump 文件较大可将 dump 文件备份至制定位置或者直接删除，以释放磁盘在这块的空间占用。\njstack 命令 printf '%x\\n' tid --\u003e 10进制至16进制线程ID(navtive线程) %d 10进制 jstack pid | grep tid -C 30 --color 某 Java 进程 CPU 占用率高，我们想要定位到其中 CPU 占用率最高的线程。\n（1） 利用 top 命令可以查出占 CPU 最高的线程 pid\ntop -Hp {pid} （2） 占用率最高的线程 ID 为 6900，将其转换为16进制形式（因为 java native 线程以16进制形式输出）\nprintf '%x\\n' 6900 （3） 利用 jstack 打印出 Java 线程调用栈信息\njstack 6418 | grep '0x1af4' -A 50 --color jinfo 命令 查看某个JVM参数值 jinfo -flag ReservedCodeCacheSize 28461 jinfo -flag MaxPermSize 28461 jstat 命令 jstat -gc pid jstat -gcutil `pgrep -u admin java` 内存分析工具 MAT 什么是 MAT? MAT（Memory Analyzer Tool），一个基于 Eclipse 的内存分析工具，是一个快速、功能丰富的 JAVA heap 分析工具，它可以帮助我们查找内存泄漏和减少内存消耗。使用内存分析工具从众多的对象中进行分析，快速的计算出在内存中对象的占用大小，看看是谁阻止了垃圾收集器的回收工作，并可以通过报表直观的查看到可能造成这种结果的对象。\n右侧的饼图显示当前快照中最大的对象。单击工具栏上的柱状图，可以查看当前堆的类信息，包括类的对象数量、浅堆（Shallow heap）、深堆（Retained Heap）。\n浅堆表示一个对象结构所占用内存的大小。深堆表示一个对象被回收后，可以真实释放的内存大小。\n支配树（The Dominator Tree）： 列出了堆中最大的对象，第二层级的节点表示当被第一层级的节点所引用到的对象，当第一层级对象被回收时，这些对象也将被回收。这个工具可以帮助我们定位对象间的引用情况，垃圾回收时候的引用依赖关系\nPath to GC Roots 被JVM持有的对象，如当前运行的线程对象，被systemclass loader加载的对象被称为GC Roots， 从一个对象到GC Roots的引用链被称为Path to GC Roots， 通过分析Path to GC Roots可以找出JAVA的内存泄露问题，当程序不在访问该对象时仍存在到该对象的引用路径。\n日志分析 GC 日志分析 GC 日志详细分析 Java 虚拟机 GC 日志是用于定位问题重要的日志信息，频繁的 GC 将导致应用吞吐量下降、响应时间增加，甚至导致服务不可用。\n-XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/usr/local/gc/gc.log -XX:+UseConcMarkSweepGC 我们可以在 Java 应用的启动参数中增加 -XX:+PrintGCDetails 可以输出 GC 的详细日志，例外还可以增加其他的辅助参数，如 -Xloggc 制定 GC 日志文件地址。如果你的应用还没有开启该参数,下次重启时请加入该参数。\n上图为线上某应用在平稳运行状态下的GC日志截图。\n2017-12-29T18:25:22.753+0800: 73143.256: [GC2017-12-29T18:25:22.753+0800: 73143.257: [ParNew: 559782K-\u003e1000K(629120K), 0.0135760 secs] 825452K-\u003e266673K(2027264K), 0.0140300 secs] [Times: user=0.02 sys=0.00, real=0.02 secs] 解析说明:\n[2017-12-29T18:25:22.753+0800: 73143.256] ： 自JVM启动73143.256秒时发生本次GC. [ParNew: 559782K-\u003e1000K(629120K), 0.0135760 secs] : 对新生代进行的GC，使用ParNew收集器，559782K是新生代回收前的大小,1000K是新生代回收后大小,629120K是当前新生代分配的内存总大小, 0.0135760 secs表示本次新生代回收耗时 0.0135760秒 [825452K-\u003e266673K(2027264K), 0.0140300 secs]:825452K是回收堆内存大小,266673K是回收堆之后内存大小，2027264K是当前堆内存总大小,0.0140300 secs表示本次回收共耗时0.0140300秒 [Times: user=0.02 sys=0.00, real=0.02 secs] : 用户态耗时0.02秒,系统态耗时0.00,实际耗时0.02秒 无论是 minor GC 或者是 Full GC，我们主要关注 GC 回收实时耗时， 如 real=0.02secs，即 stop the world 时间，如果该时间过长，则严重影响应用性能。\nCMS GC 日志分析 Concurrent Mark Sweep（CMS）是老年代垃圾收集器，从名字（Mark Sweep）可以看出，CMS 收集器就是“标记-清除”算法实现的，分为六个步骤：\n初始标记（STW initial mark） 并发标记（Concurrent marking） 并发预清理（Concurrent precleaning） 重新标记（STW remark） 并发清理（Concurrent sweeping） 并发重置（Concurrent reset） 其中初始标记（STW initial mark） 和 重新标记（STW remark）需要“Stop the World”。\n初始标记 ：在这个阶段，需要虚拟机停顿正在执行的任务，官方的叫法 STW（Stop The Word）。这个过程从垃圾回收的\"根对象\"开始，只扫描到能够和\"根对象\"直接关联的对象，并作标记。所以这个过程虽然暂停了整个 JVM，但是很快就完成了。\n并发标记 ：这个阶段紧随初始标记阶段，在初始标记的基础上继续向下追溯标记。并发标记阶段，应用程序的线程和并发标记的线程并发执行，所以用户不会感受到停顿。\n并发预清理 ：并发预清理阶段仍然是并发的。在这个阶段，虚拟机查找在执行并发标记阶段新进入老年代的对象（可能会有一些对象从新生代晋升到老年代， 或者有一些对象被分配到老年代）。通过重新扫描，减少下一个阶段\"重新标记\"的工作，因为下一个阶段会 Stop The World。\n重新标记 ：这个阶段会暂停虚拟机，收集器线程扫描在 CMS 堆中剩余的对象。扫描从\"跟对象\"开始向下追溯，并处理对象关联。\n并发清理 ：清理垃圾对象，这个阶段收集器线程和应用程序线程并发执行。\n并发重置 ：这个阶段，重置 CMS 收集器的数据结构，等待下一次垃圾回收。\nCMS 使得在整个收集的过程中只是很短的暂停应用的执行，可通过在 JVM 参数中设置 -XX:UseConcMarkSweepGC 来使用此收集器，不过此收集器仅用于 old 和 Perm（永生）的对象收集。CMS 减少了 stop the world 的次数，不可避免地让整体 GC 的时间拉长了。\nFull GC 的次数说的是 stop the world 的次数，所以一次 CMS 至少会让 Full GC 的次数+2，因为 CMS Initial mark 和 remark 都会 stop the world，记做2次。而 CMS 可能失败再引发一次 Full GC。\n上图为线上某应用在进行 CMS GC 状态下的 GC 日志截图。\n2017-11-02T09:27:03.989+0800: 558115.552: [GC [1 CMS-initial-mark: 1774783K(1926784K)] 1799438K(2068800K), 0.0123430 secs] [Times: user=0.01 sys=0.01, real=0.02 secs] 2017-11-02T09:27:04.001+0800: 558115.565: [CMS-concurrent-mark-start] 2017-11-02T09:27:04.714+0800: 558116.277: [CMS-concurrent-mark: 0.713/0.713 secs] [Times: user=1.02 sys=0.03, real=0.71 secs] 2017-11-02T09:27:04.714+0800: 558116.277: [CMS-concurrent-preclean-start] 2017-11-02T09:27:04.722+0800: 558116.285: [CMS-concurrent-preclean: 0.008/0.008 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 2017-11-02T09:27:04.722+0800: 558116.286: [CMS-concurrent-abortable-preclean-start] 2017-11-02T09:27:04.836+0800: 558116.399: [GC2017-11-02T09:27:04.836+0800: 558116.400: [ParNew: 138301K-\u003e6543K(142016K), 0.0155540 secs] 1913085K-\u003e1781327K(2068800K), 0.0160610 secs] [Times: user=0.03 sys=0.01, real=0.02 secs] 2017-11-02T09:27:05.005+0800: 558116.569: [CMS-concurrent-abortable-preclean: 0.164/0.283 secs] [Times: user=0.46 sys=0.02, real=0.28 secs] 2017-11-02T09:27:05.006+0800: 558116.570: [GC[YG occupancy: 72266 K (142016 K)]2017-11-02T09:27:05.006+0800: 558116.570: [Rescan (parallel) , 0.2523940 secs]2017-11-02T09:27:05.259+0800: 558116.822: [weak refs processing, 0.0011240 secs]2017-11-02T09:27:05.260+0800: 558116.823: [scrub string table, 0.0028570 secs] [1 CMS-remark: 1774783K(1926784K)] 1847049K(2068800K), 0.2566410 secs] [Times: user=0.14 sys=0.00, real=0.26 secs] 2017-11-02T09:27:05.265+0800: 558116.829: [CMS-concurrent-sweep-start] 2017-11-02T09:27:05.422+0800: 558116.986: [GC2017-11-02T09:27:05.423+0800: 558116.986: [ParNew: 120207K-\u003e2740K(142016K), 0.0179330 secs] 1885446K-\u003e1767979K(2068800K), 0.0183340 secs] [Times: user=0.03 sys=0.01, real=0.02 secs] 2017-11-02T09:27:06.240+0800: 558117.804: [GC2017-11-02T09:27:06.240+0800: 558117.804: [ParNew: 116404K-\u003e3657K(142016K), 0.0134680 secs] 1286444K-\u003e1173697K(2068800K), 0.0138460 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 2017-11-02T09:27:06.966+0800: 558118.530: [GC2017-11-02T09:27:06.966+0800: 558118.530: [ParNew: 117321K-\u003e2242K(142016K), 0.0135210 secs] 738838K-\u003e623759K(2068800K), 0.0140130 secs] [Times: user=0.03 sys=0.00, real=0.02 secs] 2017-11-02T09:27:07.144+0800: 558118.708: [CMS-concurrent-sweep: 1.820/1.879 secs] [Times: user=2.88 sys=0.14, real=1.88 secs] 2017-11-02T09:27:07.144+0800: 558118.708: [CMS-concurrent-reset-start] 2017-11-02T09:27:07.149+0800: 558118.713: [CMS-concurrent-reset: 0.005/0.005 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 如果你已掌握 CMS 的垃圾收集过程，那么上面的 GC 日志你应该很容易就能看的懂，这里我就不详细展开解释说明了。\n此外 CMS 进行垃圾回收时也有可能会发生失败的情况。\n异常情况有：\n伴随 prommotion failed，然后 Full GC：\n[prommotion failed：存活区内存不足，对象进入老年代，而此时老年代也仍然没有内存容纳对象，将导致一次Full GC]\n伴随 concurrent mode failed，然后 Full GC：\n[concurrent mode failed：CMS回收速度慢，CMS完成前，老年代已被占满，将导致一次Full GC]\n频繁 CMS GC：\n[内存吃紧，老年代长时间处于较满的状态]\n业务日志 业务日志除了关注系统异常与业务异常之外，还要关注服务执行耗时情况，耗时过长的服务调用如果没有熔断等机制，很容易导致应用性能下降或服务不可用，服务不可用很容易导致雪崩。\n上面是某一接口的调用情况，虽然大部分调用没有发生异常，但是执行耗时相对比较长。\ngrep '[0-9]{3,}ms' *.log 找出调用耗时大于3位数的dao方法，把3改成4就是大于4位数 互联网应用目前几乎采用分布式架构，但不限于服务框架、消息中间件、分布式缓存、分布式存储等等。那么这些应用日志如何聚合起来进行分析呢? 首先，你需要一套分布式链路调用跟踪系统，通过在系统线程上线文间透传 traceId 和 rpcId，将所有日志进行聚合，例如淘宝的鹰眼，spring cloud zipkin等等。\n案列分析 CPU 使用率高问题定位 按照2.1定位流程首先排除了系统层面的问题。\n利用 top -Hp 6814 输出进程 ID 为 6814 的所有线程 CPU 使用率情况，发现某个线程使用率比较高，有些异常。\nprintf '%x\\n' 2304 #输出线程ID的16进制 jstack pid | grep '0x900' -C 30 --color 输出的日志表明该线程一直处于与 mysql I/O 状态：\n\"Thread-6563\" daemon prio=10 tid=0x00007fda419a9000 nid=0x900 runnable [0x00007fda2b2b1000] java.lang.Thread.State: RUNNABLE at java.net.SocketInputStream.socketRead0(Native Method) at java.net.SocketInputStream.read(SocketInputStream.java:152) at java.net.SocketInputStream.read(SocketInputStream.java:122) at com.mysql.jdbc.util.ReadAheadInputStream.fill(ReadAheadInputStream.java:114) at com.mysql.jdbc.util.ReadAheadInputStream.readFromUnderlyingStreamIfNecessary(ReadAheadInputStream.java:161) at com.mysql.jdbc.util.ReadAheadInputStream.read(ReadAheadInputStream.java:189) - locked \u003c0x00000007d03e81d0\u003e (a com.mysql.jdbc.util.ReadAheadInputStream) at com.mysql.jdbc.MysqlIO.readFully(MysqlIO.java:3116) at com.mysql.jdbc.MysqlIO.nextRowFast(MysqlIO.java:2224) at com.mysql.jdbc.MysqlIO.nextRow(MysqlIO.java:1999) at com.mysql.jdbc.MysqlIO.readSingleRowSet(MysqlIO.java:3507) at com.mysql.jdbc.MysqlIO.getResultSet(MysqlIO.java:490) at com.mysql.jdbc.MysqlIO.readResultsForQueryOrUpdate(MysqlIO.java:3198) at com.mysql.jdbc.MysqlIO.readAllResults(MysqlIO.java:2366) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2789) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2818) - locked \u003c0x00000007ddcc84e8\u003e (a com.mysql.jdbc.JDBC4Connection) at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:2157) - locked \u003c0x00000007ddcc84e8\u003e (a com.mysql.jdbc.JDBC4Connection) at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:1379) - locked \u003c0x00000007ddcc84e8\u003e (a com.mysql.jdbc.JDBC4Connection) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:2931) at com.alibaba.druid.filter.FilterEventAdapter.preparedStatement_execute(FilterEventAdapter.java:440) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:2929) at com.alibaba.druid.filter.FilterEventAdapter.preparedStatement_execute(FilterEventAdapter.java:440) at com.alibaba.druid.filter.FilterChainImpl.preparedStatement_execute(FilterChainImpl.java:2929) at com.alibaba.druid.proxy.jdbc.PreparedStatementProxyImpl.execute(PreparedStatementProxyImpl.java:131) at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493) at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:56) at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:70) at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:57) at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:259) at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:132) at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:105) at cn.com.company.xqy.framework.daoframework.interceptor.PanDaoInterceptor.interceptCachePage(PanDaoInterceptor.java:172) at cn.com.company.xqy.framework.daoframework.interceptor.PanDaoInterceptor.intercept(PanDaoInterceptor.java:45) at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:57) at com.sun.proxy.$Proxy121.query(Unknown Source) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:104) at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:98) at cn.com.company.xqy.framework.daoframework.PanSqlSessionTemplate$1.doInSqlSession(PanSqlSessionTemplate.java:111) at cn.com.company.xqy.framework.daoframework.PanSqlSessionTemplate.executeWith(PanSqlSessionTemplate.java:454) at cn.com.company.xqy.framework.daoframework.PanSqlSessionTemplate.selectList(PanSqlSessionTemplate.java:150) at cn.com.company.xqy.framework.daoframework.PanSqlSessionTemplate.selectList(PanSqlSessionTemplate.java:93) at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:114) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:58) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:43) at com.sun.proxy.$Proxy45.select(Unknown Source) at sun.reflect.GeneratedMethodAccessor4958.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:302) at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157) at cn.com.company.xqy.framework.log.interceptor.DalDigestLogInterceptor.invoke(DalDigestLogInterceptor.java:28) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:208) at com.sun.proxy.$Proxy46.select(Unknown Source) at cn.com.company.xqy.finance.service.CustomerAccountTitleService.selectAllEnablesNoCache(CustomerAccountTitleService.java:1124) at cn.com.company.xqy.finance.service.CustomerAccountTitleService$$FastClassBySpringCGLIB$$363dc6fc.invoke(\u003cgenerated\u003e) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:651) at cn.com.company .xqy.finance.service.CustomerAccountTitleService$$EnhancerBySpringCGLIB$$613b9107.selectAllEnablesNoCache(\u003cgenerated\u003e) at cn.com.company.xqy.finance.service.datafix.BalanceFixService.amountStatistics(BalanceFixService.java:1121) at cn.com.company.xqy.finance.service.datafix.BalanceFixService.scan(BalanceFixService.java:346) at cn.com.company.xqy.finance.service.datafix.BalanceFixService.access$100(BalanceFixService.java:38) at cn.com.company.xqy.finance.service.datafix.BalanceFixService$1.run(BalanceFixService.java:107) at java.lang.Thread.run(Thread.java:745) 利用 jmap -dump:format=b,file=/usr/local/logs/gc/dump.hprof {pid} 以二进制输出档当前内存的堆情况，然后可以导入 MAT 等工具进行分析。如下图所示，点击 MAT 的支配树可以发现存在某个超大对象数组，实例对象数目多大30多万个。\n经过分析发现数组中每一个对象都是核心业务对象，我们的业务系统有一个定时任务线程会访问数据库某张业务表中的所有记录，然后加载至内存然后进行处理因此内存吃紧，导致 CPU 突然飙升。发现该问题后，已对该方案进行重新设计。\n","description":"\n","tags":[],"title":"\nJava 服务线上问题排查思路与工具使用","uri":"/posts/post-344/"},{"categories":["默认分类"],"content":"github\n作为程序员，最大的同性交友网站估计是大家的标配了，常常会苦恼于git clone某个项目的时候速度太慢，看着控制台那几K十一二K的速度，吐血！！\n原因很简单：github的CDN被高高的墙屏蔽所致了。 所以解决方案也很简单，就是手动把 cdn 和IP地址绑定一下。\n1、获取github地址 访问 http://github.com.ipaddress.com/ 获取cdn域名以及ip地址\n2、获取 global.ssl.fastly地址 http://github.global.ssl.fastly.net.ipaddress.com/ 获取cdn域名以及ip地址\n3、打开hosts映射 Windows环境 C:\\Windows\\System32\\drivers\\etc\\hosts 最末尾添加两句话保存:\n151.101.185.194 http://github.global.ssl.fastly.net 192.30.253.112 http://github.com 打开CMD刷新一下DNS就好了。\nipconfig /flushdns Linux环境 sudo gedit /etc/hosts 添加\n192.30.253.112 http://github.com 151.101.185.194 http://github.global.ssl.fastly.net 保存,退出,并重启网络\n/etc/init.d/networking restart 速度对比: 配置前\nReceiving objects: 17% (151/883), 348.00 KiB | 18.00 KiB/s 配置后\nReceiving objects: 81% (86141/104384), 81.31Mib | 562.00 KiB/s ","description":"\n","tags":[],"title":"\ngithub下载代码的速度太慢","uri":"/posts/post-347/"},{"categories":["默认分类"],"content":"Web开发\n一、校验数字的表达式 1 数字：^[0-9]*$ 2 n位的数字：^d{n}$ 3 至少n位的数字：^d{n,}$ 4 m-n位的数字：^d{m,n}$ 5 零和非零开头的数字：^(0|[1-9][0-9]*)$ 6 非零开头的最多带两位小数的数字：^([1-9][0-9]*)+(.[0-9]{1,2})?$ 7 带1-2位小数的正数或负数：^(-)?d+(.d{1,2})?$ 8 正数、负数、和小数：^(-|+)?d+(.d+)?$ 9 有两位小数的正实数：^[0-9]+(.[0-9]{2})?$ 10 有1~3位小数的正实数：^[0-9]+(.[0-9]{1,3})?$ 11 非零的正整数：^[1-9]d*$ 或 ^([1-9][0-9]*){1,3}$ 或 ^+?[1-9][0-9]*$ 12 非零的负整数：^-[1-9][]0-9\"*$ 或 ^-[1-9]d*$ 13 非负整数：^d+$ 或 ^[1-9]d*|0$ 14 非正整数：^-[1-9]d*|0$ 或 ^((-d+)|(0+))$ 15 非负浮点数：^d+(.d+)?$ 或 ^[1-9]d*.d*|0.d*[1-9]d*|0?.0+|0$ 16 非正浮点数：^((-d+(.d+)?)|(0+(.0+)?))$ 或 ^(-([1-9]d*.d*|0.d*[1-9]d*))|0?.0+|0$ 17 正浮点数：^[1-9]d*.d*|0.d*[1-9]d*$ 或 ^(([0-9]+.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*.[0-9]+)|([0-9]*[1-9][0-9]*))$ 18 负浮点数：^-([1-9]d*.d*|0.d*[1-9]d*)$ 或 ^(-(([0-9]+.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*.[0-9]+)|([0-9]*[1-9][0-9]*)))$ 19 浮点数：^(-?d+)(.d+)?$ 或 ^-?([1-9]d*.d*|0.d*[1-9]d*|0?.0+|0)$ 二、校验字符的表达式 1 汉字：^[一-龥]{0,}$ ^[\\\\u4e00-\\\\u9fa5]{0,}$ 2 英文和数字：^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]{4,40}$ 3 长度为3-20的所有字符：^.{3,20}$ 4 由26个英文字母组成的字符串：^[A-Za-z]+$ 5 由26个大写英文字母组成的字符串：^[A-Z]+$ 6 由26个小写英文字母组成的字符串：^[a-z]+$ 7 由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$ 8 由数字、26个英文字母或者下划线组成的字符串：^w+$ 或 ^w{3,20}$ 9 中文、英文、数字包括下划线：^[一-龥A-Za-z0-9_]+$ 10 中文、英文、数字但不包括下划线等符号：^[一-龥A-Za-z0-9]+$ 或 ^[一-龥A-Za-z0-9]{2,20}$ 11 可以输入含有^%\u0026',;=?$\"等字符：[^%\u0026',;=?$\"]+ 12 禁止输入含有~的字符：[^~\"]+ 三、特殊需求表达式 1 Email地址：^w+([-+.]w+)*@w+([-.]w+)*.w+([-.]w+)*$ 2 域名：[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(/.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+/.? 3 InternetURL：[a-zA-z]+://[^s]* 或 ^http://([w-]+.)+[w-]+(/[w-./?%\u0026=]*)?$ 4 手机号码：^(13[0-9]|14[5|7]|15[0|1|2|3|5|6|7|8|9]|18[0|1|2|3|5|6|7|8|9])d{8}$ 5 电话号码(\"XXX-XXXXXXX\"、\"XXXX-XXXXXXXX\"、\"XXX-XXXXXXX\"、\"XXX-XXXXXXXX\"、\"XXXXXXX\"和\"XXXXXXXX)：^((d{3,4}-)|d{3.4}-)?d{7,8}$ 6 国内电话号码(0511-4405222、021-87888822)：d{3}-d{8}|d{4}-d{7} 7 身份证号(15位、18位数字)：^d{15}|d{18}$ 8 短身份证号码(数字、字母x结尾)：^([0-9]){7,18}(x|X)?$ 或 ^d{8,18}|[0-9x]{8,18}|[0-9X]{8,18}?$ 15位：^[1-9]\\\\d{7}((0\\\\d)|(1[0-2]))(([0|1|2]\\\\d)|3[0-1])\\\\d{3}$ 18位：^[1-9]\\\\d{5}[1-9]\\\\d{3}((0\\\\d)|(1[0-2]))(([0|1|2]\\\\d)|3[0-1])\\\\d{3}([0-9]|X)$ 9 帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]{4,15}$ 10 密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：^[a-zA-Z]w{5,17}$ 11 强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间)：^(?=.*d)(?=.*[a-z])(?=.*[A-Z]).{8,10}$ 12 日期格式：^d{4}-d{1,2}-d{1,2} “yyyy-mm-dd“ 格式的日期校验，已考虑平闰年。：^(?:(?!0000)[0-9]{4}-(?:(?:0[1-9]|1[0-2])-(?:0[1-9]|1[0-9]|2[0-8])|(?:0[13-9]|1[0-2])-(?:29|30)|(?:0[13578]|1[02])-31)|(?:[0-9]{2}(?:0[48]|[2468][048]|[13579][26])|(?:0[48]|[2468][048]|[13579][26])00)-02-29)$ 13 一年的12个月(01～09和1～12)：^(0?[1-9]|1[0-2])$ 14 一个月的31天(01～09和1～31)：^((0?[1-9])|((1|2)[0-9])|30|31)$ 15 金额校验，精确到2位小数。：^[0-9]+(.[0-9]{2})?$ 16.有四种钱的表示形式我们可以接受:\"10000.00\" 和 \"10,000.00\", 和没有 \"分\" 的 \"10000\" 和 \"10,000\"：^[1-9][0-9]*$ 17.这表示任意一个不以0开头的数字,但是,这也意味着一个字符\"0\"不通过,所以我们采用下面的形式：^(0|[1-9][0-9]*)$ 18.一个0或者一个不以0开头的数字.我们还可以允许开头有一个负号：^(0|-?[1-9][0-9]*)$ 19.这表示一个0或者一个可能为负的开头不为0的数字.让用户以0开头好了.把负号的也去掉,因为钱总不能是负的吧.下面我们要加的是说明可能的小数部分：^[0-9]+(.[0-9]+)?$ 20.必须说明的是,小数点后面至少应该有1位数,所以\"10.\"是不通过的,但是 \"10\" 和 \"10.2\" 是通过的：^[0-9]+(.[0-9]{2})?$ 21.这样我们规定小数点后面必须有两位,如果你认为太苛刻了,可以这样：^[0-9]+(.[0-9]{1,2})?$ 22.这样就允许用户只写一位小数.下面我们该考虑数字中的逗号了,我们可以这样：^[0-9]{1,3}(,[0-9]{3})*(.[0-9]{1,2})?$ 23. 1到3个数字,后面跟着任意个 逗号+3个数字,逗号成为可选,而不是必须：^([0-9]+|[0-9]{1,3}(,[0-9]{3})*)(.[0-9]{1,2})?$ 24 备注：这就是最终结果了,别忘了\"+\"可以用\"*\"替代如果你觉得空字符串也可以接受的话(奇怪,为什么?)最后,别忘了在用函数时去掉去掉那个反斜杠,一般的错误都在这里 25 xml文件：^([a-zA-Z]+-?)+[a-zA-Z0-9]+\\.[x|X][m|M][l|L]$ 26 中文字符的正则表达式：[一-龥] 27 双字节字符：[^-ÿ] (包括汉字在内，可以用来计算字符串的长度(一个双字节字符长度计2，ASCII字符计1)) 28 空白行的正则表达式：s* (可以用来删除空白行) 29 HTML标记的正则表达式：\u003c(S*?)[^\u003e]*\u003e.*?\u003c/\u003e|\u003c.*? /\u003e (网上流传的版本太糟糕，上面这个也仅仅能部分，对于复杂的嵌套标记依旧无能为力) 30 首尾空白字符的正则表达式：^s*|s*$或(^s*)|(s*$) (可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式) 31 腾讯QQ号：[1-9][0-9]{4,} (腾讯QQ号从10000开始) 32 中国邮政编码：[1-9]d{5}(?!d) (中国邮政编码为6位数字) 33 IP地址：d+.d+.d+.d+ (提取IP地址时有用) 34 IP地址：((?:(?:25[0-5]|2[0-4]\\d|[01]?\\d?\\d)\\.){3}(?:25[0-5]|2[0-4]\\d|[01]?\\d?\\d)) 35 匹配HTML标签通过下面的表达式可以匹配出HTML中的标签属性。：\u003c\\\\/?\\\\w+((\\\\s+\\\\w+(\\\\s*=\\\\s*(?:\".*?\"|'.*?'|[\\\\^'\"\u003e\\\\s]+))?)+\\\\s*|\\\\s*)\\\\/?\u003e 36 抽取注释 如果你需要移除HMTL中的注释，可以使用如下的表达式。：\u003c!--(.*?)--\u003e 37 查找CSS属性 通过下面的表达式，可以搜索到相匹配的CSS属性。：^\\\\s*[a-zA-Z\\\\-]+\\\\s*[:]{1}\\\\s[a-zA-Z0-9\\\\s.#]+[;]{1} 38 提取页面超链接 提取html中的超链接： (\u003ca\\\\s*(?!.*\\\\brel=)[^\u003e]*)(href=\"https?:\\\\/\\\\/)((?!(?:(?:www\\\\.)?'.implode('|(?:www\\\\.)?', $follow_list).'))[^\"]+)\"((?!.*\\\\brel=)[^\u003e]*)(?:[^\u003e]*)\u003e 39 提取网页图片假若你想提取网页中所有图片信息，可以利用下面的表达式。：\\\\\u003c *[img][^\\\\\\\\\u003e]*[src] *= *[\"\\\\']{0,1}([^\"\\\\'\\\\ \u003e]*) 40 提取Color Hex Codes有时需要抽取网页中的颜色代码，可以使用下面的表达式。：^#([A-Fa-f0-9]{6}|[A-Fa-f0-9]{3})$ 41 文件路径及扩展名校验 验证windows下文件路径和扩展名（下面的例子中为.txt文件）：^([a-zA-Z]\\\\:|\\\\\\\\)\\\\\\\\([^\\\\\\\\]+\\\\\\\\)*[^\\\\/:*?\"\u003c\u003e|]+\\\\.txt(l)?$ 42 提取URL链接 下面的这个表达式可以筛选出一段文本中的URL。：^(f|ht){1}(tp|tps):\\\\/\\\\/([\\\\w-]+\\\\.)+[\\\\w-]+(\\\\/[\\\\w- ./?%\u0026=]*)? 43 检查URL的前缀 应用开发中很多时候需要区分请求是HTTPS还是HTTP，通过下面的表达式可以取出一个url的前缀然后再逻辑判断。：if (!s.match(/^[a-zA-Z]+:\\\\/\\\\//)){ s = 'http://' + s;} 44 校验IPv6地址 ：(([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])) 45 校验IP-v4地址：\\\\b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\\\b 46 判断IE的版本：^.*MSIE [5-8](?:\\\\.[0-9]+)?(?!.*Trident\\\\/[5-9]\\\\.0).*$ 47 密码的强度必须是包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间。：^(?=.*\\\\d)(?=.*[a-z])(?=.*[A-Z]).{8,10}$ ","description":"\n","tags":[],"title":"\n最全的常用正则表达式大全——包括校验数字、字符、一些特殊的需求等等","uri":"/posts/post-349/"},{"categories":["默认分类"],"content":"人为什么要去旅行？这是我见过的最美的答案\n看到朋友圈的谁谁谁，用两句鸡汤文配上几张美图，再加一个定位，我们默默的评论一句“你又出去玩儿啦，好羡慕”，然后手指继续向下滑动，看着其他人的生活，好像都那么多姿多彩。\n![]]]1](https://img.maruifu.com/images/blog/2019/04/r1kdpb4hs2h2erginc69umnpgm.gif)\n唯独自己，公司–家，两点一线，枯燥乏味，日复一日。\n![]]]](https://img.maruifu.com/images/blog/2019/04/u3caf3bd1ii40r0en6i1j8l86r.gif)\n你羡慕的生活，你羡慕的人，你做不到的事情，有人做到了。你不禁疑问，他们哪里来的那么多的时间和金钱？旅行，又究竟是为了什么？\n![]]]](https://img.maruifu.com/images/blog/2019/04/6po4oo574cjberk7dstauajtgq.gif)\n01\n因为旅行，可以滋养我们在一个已经待腻的城市里，日渐枯萎的心。\n![]]]](https://img.maruifu.com/images/blog/2019/04/0e20kvcp10ip4qtqu9jnkd24pk.jpg)\n我们花那么多钱买机票订酒店，花那么多时间查攻略，不是为了简单的发发朋友圈晒几张世界大同的照片，而是用这些时间和钱让漫漫人生长河，变得有趣。\n![]]]](https://img.maruifu.com/images/blog/2019/04/6pm3m4il88jv0o7kafd1vvhq0d.jpg)\n毕竟这世界上，好看的人很多，有趣的灵魂却很少。\n![]]]](https://img.maruifu.com/images/blog/2019/04/q2rroavqrai8fqrba3km4kp5sg.jpg)\n02\n因为旅行，是看清世界的一个最直接的途径。\n![]]]](https://img.maruifu.com/images/blog/2019/04/v3rse75340gtto6p2d9bk1bfga.jpg)\n电影，告诉我世界有无限可能，旅行，让我可以真切的感受世界。\n![]]]](https://img.maruifu.com/images/blog/2019/04/r9lvcttdqmie7p4qb16i693qfm.jpg)\n不要只把向往的远方放在梦想里，而是放在你的计划里。\n![]]]](https://img.maruifu.com/images/blog/2019/04/4s3if33ti0igpq329hq8tnmckc.jpg)\n03\n因为旅行，是一种热爱，而我们愿为了这份热爱买单。\n![]]]](https://img.maruifu.com/images/blog/2019/04/4nt8l53rloh6ao8s4qm04q1iq7.jpg)\n因为心中有那份狂热，你会想要花时间、花金钱，去为了远方而行动。\n![]]]](https://img.maruifu.com/images/blog/2019/04/027358tp48ifnp1168pvvurrds.jpg)\n远方像是一种执念，更像是一种瘾，你不去，它便呼唤你，召唤你，直到你寻踪而至。\n![]]]](https://img.maruifu.com/images/blog/2019/04/pm91jigh7aiuvo8qe2e3a5oka3.jpg)\n04\n因为有些事，现在不做，一辈子都不会再做了。\n![]]]](https://img.maruifu.com/images/blog/2019/04/ue71j31ppujitr6cvukor969q6.jpg)\n该庆幸的是年岁还轻，时光未老，眼还未浊，腿还能动。有着无限的精力和不竭的动力为想要的旅行奔波。\n![]]]](https://img.maruifu.com/images/blog/2019/04/vqsdhsa69ih5dqjf6900l2l04j.jpg)\n我不畏颠沛流离，只为看你一眼。\n![]]]](https://img.maruifu.com/images/blog/2019/04/3b6vn3d632gbfqlm5qmmiarcru.jpg)\n05\n因为旅行，是一种冲动。\n![]]]](https://img.maruifu.com/images/blog/2019/04/2ajp48ak0mjhornmm111o2805s.jpg)\n你不可能等攒够了钱，再去过想要的生活，那个时候，可能世界都变化了一圈。\n![]]]](https://img.maruifu.com/images/blog/2019/04/1nf9a01vr0h1qq417omt7a2q2j.jpg)\n所以，想去哪，就用自己的方式去看看这个世界，无论是徒步、搭车、穷游，还是自驾，都能够有不一样的惊喜。\n![]]]](https://img.maruifu.com/images/blog/2019/04/opuh3v8shqgquoekvn4j102hi0.jpg)\n06\n因为旅行的脚步，永远是向前的。\n![]]]](https://img.maruifu.com/images/blog/2019/04/6mhcgi76rsin6p8didb9fb1jig.jpg)\n停在原地的理由很多，但我们总要坚定一个出发的理由。\n![]]]](https://img.maruifu.com/images/blog/2019/04/qmqe3rek6cggppav8bfb3qf2i9.jpg)\n07\n因为旅行可以更好的工作和生活。\n![]]]](https://img.maruifu.com/images/blog/2019/04/4j8v2q8ti2hkpo6svhj9e2p0b2.jpg)\n即使知道旅行过后，还是要回到原来的城市，工作、生活，但却有一种期待，为了下一次的远行，更好的生活。\n![]]]](https://img.maruifu.com/images/blog/2019/04/s0vqk6b6e8hdfpb95pouel2qmj.jpg)\n见到了世界的生活方式，才能更加清楚的看到内心想要的生活。\n![]]]](https://img.maruifu.com/images/blog/2019/04/7l11q1gossjopo44o8pegbodfo.jpg)\n08\n因为旅行，是年老时，回忆的资本。\n![]]]](https://img.maruifu.com/images/blog/2019/04/qs6bomo1doi1co4bvkgs0snq20.jpg)\n不想年老之时，回想一生，除了千篇一律的工作和平淡入水的生活，别无他想。\n![]]]](https://img.maruifu.com/images/blog/2019/04/6n4lnktftghaeqig61j3h3p3o7.jpg)\n即使老了，也想要做一个积极乐观的老太太，一个时髦超前的老太太。\n![]]]](https://img.maruifu.com/images/blog/2019/04/2r59j9sgmkg30oigkqt4m887je.jpg)\n我们花那么多时间和金钱去旅行，是为了我们那么平凡，却又可以不凡。\n","description":"\n","tags":[],"title":"\n人为什么要去旅行？这是我见过的最美的答案","uri":"/posts/post-350/"},{"categories":["默认分类"],"content":"linux\n一、分析\n这是不同系统编码格式引起的：在windows系统中编辑的.sh文件可能有不可见字符，所以在Linux系统下执行会报以上异常信息。\n二、解决\n1）在windows下转换： 利用一些编辑器如UltraEdit或EditPlus等工具先将脚本编码转换，再放到Linux中执行。转换方式如下（UltraEdit）：File–\u003eConversions–\u003eDOS-\u003eUNIX即可。\n2）直接在Linux中转换（推荐做法）：\n首先要确保文件有可执行权限\n#sh\u003e chmod a+x filename 1 然后修改文件格式\n#sh\u003e vi filename 1 利用如下命令查看文件格式\n:set ff 或 :set fileformat 1 可以看到如下信息\nfileformat=dos 或 fileformat=unix 利用如下命令修改文件格式\n:set ff=unix 或 :set fileformat=unix :wq (存盘退出) 最后再执行文件\n#sh\u003e./filename ","description":"\n","tags":[],"title":"\nLinux中执行脚本No such file or directory。","uri":"/posts/post-354/"},{"categories":["语言"],"content":"我们经常为用到Integer.valueOf(String str)这个方法,如果字符串格式不对,这个方法会抛出一个系统异常NumberFormatException 这里我们就要分析一下这个方法,其中Byte,Short也是调用了Ingeter中的方法. 在Integer类中的定义如下:\npublic static Integer valueOf(String s) throws NumberFormatException { return new Integer(parseInt(s, 10)); } 这里因为parseInt方法返回的int型的,这里调用了一个构造函数产生了一个新的Integer实例. 这里关心的是parseInt方法,该方法代码如下:\npublic static int parseInt(String s, int radix) throws NumberFormatException { if (s == null) { throw new NumberFormatException(\"null\"); } if (radix \u003c Character.MIN_RADIX) { throw new NumberFormatException(\"radix \" + radix + \" less than Character.MIN_RADIX\"); } if (radix \u003e Character.MAX_RADIX) { throw new NumberFormatException(\"radix \" + radix + \" greater than Character.MAX_RADIX\"); } int result = 0; boolean negative = false; int i = 0, max = s.length(); int limit; int multmin; int digit; if (max \u003e 0) { if (s.charAt(0) == '-') { negative = true; limit = Integer.MIN_VALUE; i++; } else { limit = -Integer.MAX_VALUE; } if (i \u003c max) { digit = Character.digit(s.charAt(i++),radix); if (digit \u003c 0) { throw NumberFormatException.forInputString(s); } else { result = -digit; } } while (i \u003c max) { // Accumulating negatively avoids surprises near MAX_VALUE digit = Character.digit(s.charAt(i++),radix); if (digit \u003c 0) { throw NumberFormatException.forInputString(s); } if (result \u003c multmin) { throw NumberFormatException.forInputString(s); 异常1 } result *= radix; if (result \u003c limit + digit) { throw NumberFormatException.forInputString(s); 异常2 } result -= digit; } } else { throw NumberFormatException.forInputString(s); } if (negative) { if (i \u003e 1) { return result; } else { /* Only got \"-\" */ throw NumberFormatException.forInputString(s); } } else { return -result; } } 很显然,该方法的第二个参数表示是基数(最常用的是十进制,还有十六机制,八进制等等).\n如果字符串是空指针,直接抛出异常.\n如果基础小于2或者大于36的话,抛出异常(这种情况一般不会出现,因为我们用的最多就是十进制的了).\n如果是空字符串,也抛出异常,也就是max=0的情况了.\n我们来关注下面的转换过程:\n这里使用了Character中的静态方法digit,这个方法比较复杂,这里先说明它的功能:对于给定的基数,如果是合法的字符(可以转化为数字),返回该数字值,否则返回-1.比如digit(‘3’,10)返回3,digit(‘a’,10)返回-1.\n这段程序看起来很简单,其实还真不容易看懂,这里先说明几个局部变量的含义吧:\nresult:记录返回值\nnegative:符号标志\ni:字符串位置\ns:字符串长度\nlimit:界限\nmultmin:也是一个界限\ndigit:当前字符表示的数字\n先看第一个字符是否是’-‘号,设定符号标志negative和极限值limit.\n注意到limit一定是一个负值.\n处理最高位,这里result保存的是负值,这样就可以对正负数统一处理.\n关键就是这个while循环了,第一个if不用解释了,肯定是因为非法字符.\n第二个if语句的含义:如果result小于multmin,会产生什么结果呢?\n是不是一定会溢出呢?假设不会溢出,就是说结果必须\u003e=limit.\nresult小于multmin,result至少应该位multmin-1,后面有 result=result*radix=(multmin-1)_radix=multmin_radix-radix\n该值肯定小于limit,其中multmin=limit/radix,注意这里都是负数.\n所以假设不成里,如果result小于multmin的话,后面一定会溢出.\n如果这里没有判断的话,溢出就麻烦了,正数也会变负数了.\n第三个if语句的含义:在这条语句以前肯定没有溢出,但是有可能加上最后一位digit就溢出了,所以这个判断也是必要的.\n后面的就比较好理解了,else是表示空字符串\"\".\n如果是负数的还要看是否长度是1,就只是一个’-‘号的情况.\n如果是正数的话返回相反数就可以了.\n这里有好多地方都有可能抛出异常,只要看明白了程序就知道这个异常是 那条语句抛出的了,这里考虑溢出异常:异常1和异常2.\nIngeter.Max_VALUE=2147483647\n下面的两条语句在不同的地方抛出异常.\nIngeter.valueOf(“2147483648”);这个在异常2抛出的.\nIngeter.valueOf(“21474836471”);这个在异常1抛出的.\n这里简单的分析了String转化为Ingeter的过程,其实整个Ingeter类也就主要是这个方法了,Byte和Short都是调用这个方法的. 看看Byte的代码:\npublic static byte parseByte(String s, int radix) throws NumberFormatException { int i = Integer.parseInt(s, radix); if (i \u003c MIN_VALUE || i \u003e MAX_VALUE) throw new NumberFormatException( \"Value out of range. Value:/\"\" + s + \"/\" Radix:\" + radix); return (byte)i; } 了解这个方法后就再也不会为Integer.valueOf()产生的异常感到意外了,特别是在JSP中,因为参数都是String型的,转换的时候动不动就出现异\n常,你该知道怎么回事了吧.\n","description":"\n","tags":[],"title":"\nString转换成Integer源码分析","uri":"/posts/post-360/"},{"categories":["数据库"],"content":"1、用dba角色的用户登陆，进行解锁，先设置具体时间格式，以便查看具体时间\nSQL\u003e alter session set nls_date_format='yyyy-mm-dd hh24:mi:ss'; Session altered. 2、查看具体的被锁时间\nSQL\u003e select username,lock_date from dba_users where username='TEST'; USERNAME LOCK_DATE TEST 2009-03-10 08:51:03 3、解锁\nSQL\u003e alter user test account unlock; User altered. 4、查看是那个ip造成的test用户被锁\n查看$ORACLE_HOME/network/admin/log/listener.log日志 10-MAR-2009 08:51:03 * (CONNECT_DATA=(SID=lhoms)(SERVER=DEDICATED)(CID=(PROGRAM=oracle)(HOST=omstestdb)(USER=oraoms))) * (ADDRESS=(PROTOCOL=tcp)(HOST=10.69.1.11)(PORT=49434)) * establish * lhoms * 0 10-MAR-2009 08:51:03 * (CONNECT_DATA=(SID=lhoms)(SERVER=DEDICATED)(CID=(PROGRAM=oracle)(HOST=omstestdb)(USER=oraoms))) * (ADDRESS=(PROTOCOL=tcp)(HOST=10.69.1.11)(PORT=49435)) * establish * lhoms * 0 这样可知是上面10.69.1.11的ip尝试多次失败登陆造成的被锁 注： 一般数据库默认是10次尝试失败后锁住用户\n1、查看FAILED_LOGIN_ATTEMPTS的值\nselect * from dba_profiles where RESOURCE_NAME = 'FAILED_LOGIN_ATTEMPTS'; 2、修改为30次\nalter profile default limit FAILED_LOGIN_ATTEMPTS 30; 3、修改为无限次（为安全起见，不建议使用）\nalter profile default limit FAILED_LOGIN_ATTEMPTS unlimited; Oracle数据库操作中，我们有时会用到锁表查询以及解锁和kill进程等操作，那么这些操作是怎么实现的呢？本文我们主要就介绍一下这部分内容。\n(1)锁表查询的代码有以下的形式：\nselect count(*) from v$locked_object; select * from v$locked_object; (2)查看哪个表被锁\nselect b.owner,b.object_name,a.session_id,a.locked_mode from v$locked_object a,dba_objects b where b.object_id = a.object_id; (3)查看是哪个session引起的\nselect b.username,b.sid,b.serial#,logon_time from v$locked_object a,v$session b where a.session_id = b.sid order by b.logon_time; (4)杀掉对应进程\n执行命令：alter system kill session'1025,41'; 其中1025为sid,41为serial#.\n查询那个程序导致的\nSELECT v.program,v.* FROM v$session v where serial# = '9' and sid = 586 ","description":"\n","tags":[],"title":"\nOracle用户和表被锁定解决方法","uri":"/posts/post-366/"},{"categories":["数据库"],"content":"受影响版本：Oracle11g以上版本。\n导致密码消失的原因：Oracle 11g中默认的DEFAULT概要文件中口令有效期PASSWORD_LIFE_TIME默认值为180天。\n当以客户端登陆Oracle提示ORA-28002，则基本可以确定登陆帐号已过有效期，使用具有DBA权限的帐号重置该帐号密码即可。\n解决方法：\n以下步骤以具有DBA权限用户操作\n1.查看口令失效用户的profile文件 SQL\u003eSELECT username,profile FROM dba_users; EM：服务器\u003e用户，查看口令失效的用户对应的概要文件，这里假设为DEFAULT，下同。\n2.查看对应的概要文件的口令有效期设置 SQL\u003eSELECT * FROM dba_profiles WHERE profile='DEFAULT' AND resource_name='PASSWORD_LIFE_TIME'; EM：服务器\u003e概要文件\u003e选择刚刚查到的概要文件DEFAULT\u003e查看，查看口令下面的有效期值。\n3.将口令有效期默认值180天修改成“无限制” SQL\u003eALTER PROFILE DEFAULT LIMIT PASSWORD_LIFE_TIME UNLIMITED; EM：服务器\u003e概要文件\u003e选择刚刚查到的概要文件DEFAULT\u003e编辑\u003e口令，在有效期输入或选择你需要的值，保存。\n该参数修改实时生效。\n出于数据库安全性考虑，不建议将PASSWORD_LIFE_TIME值设置成UNLIMITED，即建议客户能够定期修改数据库用户口令。\n在修改PASSWORD_LIFE_TIME值之前已经失效的用户，还是需要重新修改一次密码才能使用。\nSQL\u003ealter user user_name identified by password; ","description":"\n","tags":[],"title":"\nOracle用户密码过期的处理方法","uri":"/posts/post-367/"},{"categories":["数据结构与算法"],"content":" 数据结构 优点 缺点 数组 插入快,如果知道下标,可以非常快地存取 查找慢,删除慢,大小固定 有序数组 比无序的数组查找快 删除和插入慢,大小固定 栈 提供后进先出的方式存取 存取其他项很慢 队列 提供先进先出方式的存取 存取其他项很慢 链表 插入快,删除快 查找慢 二叉树 查找,插入,删除都快(如果树保持平衡) 删除算法复杂 红-黑 树 查找,插入,删除都很快.树总是平衡的 算法复杂 2-3-4 树 查找,插入,删除都很快.树总是平衡的. 类似树对磁盘存储有用 算法复杂 哈希表 如果关键字已知则存取极快,插入快. 删除慢,如果不知道关键字则存取很慢, 对存储空间使用不充分. 堆 插入,删除快,对最大数据项的存取很快 存取其他数据项慢 图 对现实世界建模 有些算法慢且复杂 ","description":"\n","tags":[],"title":"\n数据结构的特性","uri":"/posts/post-370/"},{"categories":["数据结构与算法"],"content":"数据结构：数据与数据之间的结构关系（数组、队列、树、图等结构）\n算法：解决问题的步骤\n总结：\n1、程序 = 数据结构 + 算法 。数据是程序的中心。数据结构和算法两个概念间的逻辑关系贯穿了整个程序世界，首先二者表现为不可分割的关系。没有数据间的有机关系，程序根本无法设计。\n2、数据结构与算法关系：数据结构是底层，算法高层。数据结构为算法提供服务。算法围绕数据结构操作。\n3、解决问题（算法）需要选择正确的数据结构。例如：算法中经常需要对数据进行增加和删除用链表数据结构效率高，数组数据结构因为增加和删除需要移动数字每个元素所有效率低。\n4、数据结构特点：每种数据结构都具有自己的特点。例如：队列：先进先出。栈：先进后出。等等\n5、算法的特性：算法具有五个基本特征：输入、输出、有穷性、确定性和可行性。\n6、数据结构应用：数据结构往往同高效的检索算法、索引技术、排序算法有关\n7、数据结构（逻辑数据结构）通过计算机语言来实现数据结构（存储数据结构）。例如：树型数据结构：通过计算机语言中的数组（节点）和指针（指向父节点）来实现。\n8、存储结构：逻辑数据结构的实现。存储结构通过计算机语言实现。 例如：堆数据结构，堆是一棵完全二叉树，所以适宜采用顺序存储结构（顺序存储：数组），这样能够充分利用存储空间。\n9、算法目的：算法是为数据结构服务。例如：数据结构通常伴随有查找算法、排序算法等\n10、数据结构的优劣：一种数据结构的优劣是在实现其各种运算的算法中体现的。\n二、数据结构：分为逻辑数据结构和存储数据结构两种 （1）顺序存储方法（顺序存储结构） （2）链接存储方法（链式存储结构） 同一种逻辑结构可采用不同的存储方法（以上两种之一或组合），这主要考虑的是运算方便及算法的时空要求。\n","description":"\n","tags":[],"title":"\n数据结构和算法关系","uri":"/posts/post-371/"},{"categories":["maven"],"content":" \u003cproperties\u003e \u003c!-- 所有工程中,对依赖的根组件(root jar)的版本维护 --\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003c!-- 统一字符集 --\u003e \u003cproject.build.sourceEncoding\u003eUTF-8\u003c/project.build.sourceEncoding\u003e \u003c/properties\u003e \u003cbuild\u003e \u003cfinalName\u003espringBoot\u003c/finalName\u003e \u003cplugins\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-compiler-plugin\u003c/artifactId\u003e \u003cversion\u003e3.3\u003c/version\u003e \u003cconfiguration\u003e \u003csource\u003e${java.version}\u003c/source\u003e \u003ctarget\u003e${java.version}\u003c/target\u003e \u003cencoding\u003e${project.build.sourceEncoding}\u003c/encoding\u003e \u003c/configuration\u003e \u003c/plugins\u003e \u003c/build\u003e ","description":"\n","tags":[],"title":"\nmaven编码","uri":"/posts/post-374/"},{"categories":["默认分类"],"content":"勒布朗（LeBlanc）法则：\n稍后等于永不（Later equals never） Dave Thomas，OTI公司创始人，Eclipse战略教父说过:\n没有测试的代码不干净。不管它有多优雅，不管有多可读、多易理解，微乎测试，其不洁亦可知也。 ","description":"\n","tags":[],"title":"\n一个程序员该记住的话","uri":"/posts/post-375/"},{"categories":["语言"],"content":"大家都知道jdk无法直接通过wget下载。原来需要cookie，如下：\n一、下载\nwget --no-check-certificate --no-cookie --header \"Cookie: oraclelicense=accept-securebackup-cookie;\" http://download.oracle.com/otn/java/jdk/7u80-b15/jdk-7u80-linux-x64.rpm sudo rpm -ivh jdk-7u79-linux-x64.rpm 现在下载的要求又有所变化，用原来的方式已经不行了。是动态的生成一个参数。\n解决办法： 在chrome下，打开开发者工具（本人用的mac版本），点击所需要下载的包，看console-\u003elogs会看到一行字：\nResource interpreted as Document but transferred with MIME type application/x-redhat-package-manager: \"http://download.oracle.com/otn/java/jdk/7u80-b15/jdk-7u80-linux-x64.rpm?AuthParam=1461049990_341c3c217ccd4554c0a065149ff156c8\". ，于是，直接使用这个就好了。\nwget -O jdk-7u80-linux-x64.rpm http://download.oracle.com/otn/java/jdk/7u80-b15/jdk-7u80-linux-x64.rpm?AuthParam=1461049990_341c3c217ccd4554c0a065149ff156c8 64位\nwget --no-cookies --no-check-certificate --header \"Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/8u141-b15/336fa29ff2bb4ef291e347e091f7f4a7/jdk-8u141-linux-x64.tar.gz\" 32位\nwget --no-cookies --no-check-certificate --header \"Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-pub/java/jdk/8u141-b15/336fa29ff2bb4ef291e347e091f7f4a7/jdk-8u141-linux-i586.tar.gz\" tar xzf jdk-8u141-linux-i586.tar.gz 解压\ntar xzf jdk-8u141-linux-x64.tar.gz 配置环境变量\nJAVA_HOME=/usr/local/java/jdk1.8/ JRE_HOME=/usr/local/java/jdk1.8/jre CLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin export JAVA_HOME JRE_HOME CLASS_PATH PATH 为了让环境变量即时生效，输入 source /etc/profile 即可。\n","description":"\n","tags":[],"title":"\nwget下载JDK","uri":"/posts/post-379/"},{"categories":["默认分类"],"content":"下载\nwget http://nginx.org/download/nginx-1.10.3.tar.gz 解压\ntar -zxvf nginx-1.10.3.tar.gz 源码编译准备\n./configure --prefix=/usr/local/src/nginx --conf-path=/usr/local/src/nginx/nginx.conf 安装 环境\nyum -y install pcre-devel yum install -y zlib-devel 编译\nmake 安装\nmake install 添加环境变量 nginx/sbin\n启动\n./nginx -c /usr/local/src/nginx/conf/nginx.conf 通过ps -A命令查看nginx进程状态，确认nginx已启动:\nps -A | grep nginx\n此时，输入服务器域名或公网IP，可以nginx的欢迎页面，表明nginx web服务器已经成功安装\n停止 nginx\nps -ef|grep nginx 从容停止Nginx：\nkill -QUIT 主进程号 例如：kill -QUIT 16391\n快速停止Nginx：\nkill -TERM 主进程号 强制停止Nginx：\nkill -9 主进程号 后面详细介绍一下配置文件\nuser www www; worker_processes 2; #设置值和CPU核心数一致 error_log /usr/local/webserver/nginx/logs/nginx_error.log crit; #日志位置和日志级别 pid /usr/local/webserver/nginx/nginx.pid; #Specifies the value for maximum file descriptors that can be opened by this process. worker_rlimit_nofile 65535; events { use epoll; worker_connections 65535; } http { include mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" $http_x_forwarded_for'; #charset gb2312; server_names_hash_bucket_size 128; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_max_body_size 8m; sendfile on; tcp_nopush on; keepalive_timeout 60; tcp_nodelay on; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 2; gzip_types text/plain application/x-javascript text/css application/xml; gzip_vary on; #limit_zone crawler $binary_remote_addr 10m; #下面是server虚拟主机的配置 server { listen 80;#监听端口 server_name localhost;#域名 index index.html index.htm index.php; root /usr/local/webserver/nginx/html;#站点目录 location ~ .*\\.(php|php5)?$ { #fastcgi_pass unix:/tmp/php-cgi.sock; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; } location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf|ico)$ { expires 30d; # access_log off; } location ~ .*\\.(js|css)?$ { expires 15d; # access_log off; } access_log off; } } ","description":"\n","tags":[],"title":"\n阿里云ECS CentOS7.4 64位系统安装nginx","uri":"/posts/post-380/"}]
